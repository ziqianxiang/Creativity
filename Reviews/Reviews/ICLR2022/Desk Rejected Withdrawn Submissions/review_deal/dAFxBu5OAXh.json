{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes an instance-wise discrimination pretext task using image residuals. The method uses a contrastive loss function. Also, the paper proposes a framework based on residual contrastive loss. This framework can learn transferable representations from only noisy inputs. The presented results on various downstream tasks show that the framework can produce good results.",
            "main_review": "The overall quality of the paper is good and it is fairly easy to follow the main ideas. However, there is not enough intuition provided on why this idea would be good.\nThe paper provides good ablations and experiments on several down-stream tasks.\nThere are only a few other methods that this work is compared against in the experiment part. Aren't there any newer state of the art works that are suitable for comparison?\nGive more details about the used reconstruction metrics in order for the work to be self-contained.\nThe experiments and results from chapter 4.4 seem valuable, but there are hard to follow and should be better explained.",
            "summary_of_the_review": "Overall, to the best of my knowledge the paper introduce a novel idea: using the residuals in a self-supervised scenario. They provide results on several down-stream tasks. Also the paper is fairly well written.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "Primary claim: Residual learning has shown success for low-level vision tasks (and high-level vision tasks) in the context of supervised learning. However it has not shown success for low-level vision tasks in the context of self-supervised learning. We provide the first study of contrastive learning for low-level vision tasks and in doing so bridge this gap.\n\nMotivation: As far as I can tell, the full motivation for self-supervised representation learning for the tasks at hand (denoising / super resolution) is \"In many cases, y is unavailable due to annotation costs, e.g. obtaining ground truth data for low-level vision tasks typically requires complex and often constraining procedures.\"\n\nMethod: A contrastive loss over residuals n(x) = x - f_learned(x), computed from positive/negative image-crop pairs, is defined in terms either Bhattacharyya distance, Earth mover's distance, or maximum mean discrepancy. f_learned is trained by minimizing this contrastive loss alongside a perceptual loss/consistency loss term for regularization.\n\nResults: Quantitative results are provided using MIT Demosaicing, Stanford Taskonomy, PASCAL VOC, in terms of PSNR and SSIM. Residual contrastive learning is shown to be comparable to N2N and N2S. No qualitative results are provided, despite end goals of denoising / super resolution / demosaicing.\n\nClaimed Contributions: 1. First formulation of instance-wise pretext task based on residuals (and adaptation of InfoNCE to do so). 2. Proposal of residual contrastive learning + the first study of CL for low-level vision tasks; 3. Demonstration that RCL can learn robust representations without paired ground truth.",
            "main_review": "The primary strengths are that the paper is written clearly when it comes to details and that the proposed method attains competitive quantitative results (in terms of PSNR and SSIM) for denoising and super resolution.\n\nOne weakness is the lack of motivation: the motivation in the introduction should be much stronger. For example, why should the reader care about 'unsupervised contrastive learning' for the tasks considered in the paper (denoising, demosaicing, super resolution), when obtaining pairs for supervision is often simple (as done in much of the prior cited work)? If this is indeed difficult, then please provide examples.\n\nAnother weakness is that the method is largely a combination of existing ideas. This is not necessary a weakness if combined with very strong empirical results + discussion, but that is not the case here.\n\nAnother weakness is the limited results. There are few quantitative results, little discussion, and no qualitative results at all, which is especially alarming since the tasks in the paper are denoising / super resolution / demosaicing. Example: As a distance measure between probability distributions, the authors consider Bhattacharyya distance, Earth mover's distance, and maximum mean discrepancy, and in Table 1 show that EMD leads to marginally better PSNR and SSIM. The full discussion surrounding this is \"RCL with EMD shows robust performance in comparison to RCL with both BD and MMD and may thus be preferred in practical denoising applications.\" In addition, given the goals, qualitative results in the form of random visualizations (noisy, clean pairs) are a must.\n\nSmall details:\n\nRight after equation 2, please fix \"n ~ P(n)\", or omit it entirely if the only aim is to say that n is a random variable.\n\nAssumption 1: This statement seems obvious (and has already been exploited in many papers). Is it for some reason not obvious, such that highlighting it in such a pronounced way makes sense? There is no \"Assumption 2\" anywhere, correct?",
            "summary_of_the_review": "This paper offers a combination of existing techniques to build residual contrastive learning, which aims to leverage self-supervised learning for low-level vision tasks such as denoising and super resolution. As such, it is purely an empirical paper. Given this, the paper should provide a proper motivation of why this is important along with a strong array of results that suggest that the proposed approach is promising. Instead, the paper does not properly motivate the approach, and with regard to results, provides only a limited set of quantitative results, with no qualitative results at all, and with little discussion/insight. Therefore I can't recommend its acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes to train an encoder-decoder network for low-level vision tasks, e.g., image denoising.  \nThe contribution of the paper is to link image denoising with contrastive learning. The assumption is that the noise distribution between two crops sampled from the same image is on average smaller than those sampled from different images. Based on this assumption, a contrastive learning framework is set up in terms of image residuals (rather than image features).  \nExperiments on synthetic and real noisy data demonstrate the effectiveness of the proposed pretraining scheme.",
            "main_review": "Strength:\n- It is a novel and insightful idea to incorporate image residuals (instead of image features) into the contrastive learning framework. In this sense the connection between image denoising and contrastive learning is established.\n\nWeakness:\n- In Table 1, MoCo v2 performs significantly worse than other methods. The reason, however, is unclear. The setting in Table 1 is a linear evaluation setting, where the pretrained weights are fixed. MoCo v2 is the only method that pretrains the encoder only, and it thus has more randomly initialized parameters to be fine-tuned in the following stage. Is the inferior performance of MoCo v2 due to the pretext task misalignment or that MoCo v2 does not train the decoder? The authors are recommended to add the following experiments to make the conclusion more convincing.\n    - Some existing papers pretrain dense image features using contrastive learning for dense image recognition tasks, such as object detection and semantic segmentation. These methods pretrain both the encoder and decoder, but the pretext task misaligns with low-level vision (as claimed in the submission). Comparing with them might make things clearer. Examples include [a] and [b].\n    - [a] Pedro O. Pinheiro, Amjad Almahairi, Ryan Y. Benmalek, Florian Golemo, Aaron Courville. Unsupervised Learning of Dense Visual Representations. In NeurIPS, 2020.\n    - [b] Zhenda Xie, Yutong Lin, Zheng Zhang, Yue Cao, Stephen Lin, Han Hu. Propagate Yourself: Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning. In CVPR, 2021.\n- The perceptual loss in Eq. (9) relies on a pretrained ResNet-50 on ImageNet using labeled data. This setting makes the proposed approach no longer an `unsupervised` learning approach, in the strict sense. A more serious issue is that when comparing the proposed method to existing self-supervised methods (e.g., in Table 1), it is unclear whether the performance gain comes from the proposed design, or the pretrained weights of ResNet-50. I have the following suggestions to mitigate this issue.\n    - Can $g_e$ in Eq. (9) be removed? I mean, comparing the pixel loss instead of the perceptual loss.\n    - Can $g_e$ be instantiated with the pretrained weights using MoCo v2 on ImageNet?\n- Most of the experiments are conducted on synthetic data, except for the last line of Section 4 that shows quantitatively the effectiveness of the proposed method on real noisy datasets. It would be better to add more results on real noisy data, because the noise distribution of synthetic data follows exactly the assumption in the paper (but it is not always true in the real world). Some suggestions to the authors are listed as follows.\n    - What is the performance of other self-supervised learning methods on the SIDD dataset?\n    - Leaderboard of the SIDD dataset can be found at https://www.eecs.yorku.ca/~kamel/sidd/benchmark.php. The supervised learning result in this paper is far from the state-of-the-art. I am not familiar with this subdivided area. Are there any related methods that need to be mentioned?\n- The paper is not easy to read. Many revisions can be made to make it easier to understand.\n    - After reading the first page, I know that the proposed approach is not a general pretraining method but aims to solve low-level vision problems. It would be nice to clarify it in the title.\n    - Section 3.3, Page 4: \"a normalized first-order tensor\". To be simple, \"a normalized vector\" is recommended.\n    - The LHS of Eq. (5) is $L_{contrast}$, but $L_{contrastive}$ appears in the RHS of Eq. (10).\n    - It would be much better to provide some diagrams or pseudocode of the proposed approach, to make the paper easier to understand.",
            "summary_of_the_review": "This paper proposes a novel idea to introduce contrastive learning (in terms of image residuals) into the pretraining for low-level vision tasks. The technical part is insightful.  \nHowever, the experiments fail to demonstrate the effectiveness of the proposed approach. It is arguable whether the performance improvement should be attributed to the proposed method or other issues (e.g., unfair experimental settings and data).  \nI hence cannot recommend acceptance.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}