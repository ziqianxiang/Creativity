{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "Authors analyze the behavior and goals of MixUp augmentation as a set of auxiliary tasks. Improvements on a recent MixUp technique (AutoMix) are proposed and analyzed, and the technique is extended to contrastive learning. ",
            "main_review": "STRENGTHS:\n\n- Well motivated, changes to MixBlock make sense and extension of AMix to contrastive learning is elegant. \n- Technique is broadly relevant and suitably general. \n- A good set of analyses, experiments and ablations. Results are clear and interesting. \n- Paper is well-organized and clearly presented. \n\nWEAKNESSES:\n\n- Contributions are relatively small over and above AutoMix. Improvements to MixBlock are numerous but incremental, and improvement in supervised settings is small relative to the improvement already gained by AutoMix. The extension of AutoMix to contrastive learning is interesting, but note that MixUp has already been extended to the contrastive setting in cited prior work, so the extension of AutoMix is relatively straightforward (unless the cross-view pipeline is meaningfully different from the i-Mix/un-Mix/etc. pipelines from an implementation standpoint, in which case this concrete difference should be discussed and elaborated upon). \n- Appendix is promised but not provided, including some results referred to in the paper.\n- It is evident that real work has been put into adapting AMix to MoCo.v2, but I worry that this has perhaps overfitted AMix to explicitly contrastive learners, which have been recently outperformed by a whole class of non-contrastive (or at least only implicitly-contrastive) approaches including BYOL, SWAV, and Barlow Twins. Can AMix be ported straightforwardly to these more desirable, non-contrastive but still view-based techniques? If not, then the generality of AMix in the proposed setting is severely limited, and if so, this discussion should be added to the paper. \n- Method is presented in abstract (and to some extent, title) as novel. However AMix is essentially AutoMix+ with an extension to contrastive learning. This relationship should be made more clear. \n- This paper is an extension of a paper that has not yet been published. While not an issue with the paper itself per se, it does put things in a somewhat awkward position and raise the bar somewhat for acceptance in my view. \n\nSMALL COMMENTS/TYPOS/GRAMMAR\n\nIt may be worth making clear in section 2.2 that your notation matches the MoCo notation – otherwise without further explanation, the subscripting and superscripting don’t make much sense. \n\nSome awkward language/formatting sprinkled throughout, such as but not limited to: \n- After eq.1, how similar between -> similarity between\n- Before eq.2, pair of augmented image -> pair of augmented images\n- Before eq.3, formally write as -> formally written as\n- Bottom of page 4: x*_mix not equal to M_c -> x*_mix not element of M_c\n- Page 6 line 4: w,h should be subscripted to the summation (presumably)\n- Page 8 line 1: the rest datasets -> the rest of the datasets\n- Page 9 line 3: transferable ability -> transferability \n- Page 9 line 6: table 6 is mislabeled as a figure",
            "summary_of_the_review": "AMix is a well-motivated and clearly powerful technique, applicable to a range of settings and problems. However, the conceptual novelty, performance gain, and scope relative to AutoMix is limited. As an extension of as yet unpublished work, the contribution is not significant enough in and of itself in my view to accept the paper on its own merits. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a class- and instance-level mixup technique called AMix. The authors analyze the properties of instance-level mixup and propose an improved version of Mix Block of AutoMix to enhance the mixup generation process. The proposed AMix framework outperforms the state-of-the-art mixup techniques on image classification under supervised and self-supervised settings. ",
            "main_review": "**Pros**  \n- The proposed AMix improves the state-of-the-art mixup technique (AutoMix) and this paper provides thorough ablation studies for the proposed techniques. \n- The paper conducts extensive experiments on image classification over various datasets, and the proposed AMix consistently outperforms the existing mixup methods. \n\n**Cons**  \nThe paper lacks details of their method.\n- There is no detailed description for their algorithm, and I cannot figure out how the Mix Block is optimized. Is the Mix Block jointly optimized with the feature extractor? Are the parameters of the feature extractor also updated for mixup generation? \n- The paper proposes the three versions of the method (AMix, AMix-C, AMix-I). In section 3.3, the objectives of AMix-C and AMix-I are provided, but I cannot find the main objective of AMix in the paper. (In the case of supervised learning, does AMix refer to AMix-C?)\n\nThe analysis of instance-level mixup generation is not convincing.\n- There needs more interpretation and explanation for Figure2-(c). In the paragraph \"Properties of mixup generation\" in section 3.1, the authors only state the results from the figure and do not provide any interpretation. What can we learn from the figure and how this can lead to the three properties provided on page 4?\n- I cannot figure out the relation between the analysis in section 3.1 and the proposed method in section 3.2.  \n\n**Additional comments**   \n- In section 3.1- Cross-view training pipeline, why containing parts from the same view of the different images is not good for contrastive learning? Could you provide an intuitive explanation?\n- In section 3.1- Properties of mixup generation, how does the combined (inter and intra) mixup policy work? (e.g., randomly choosing inter- or inter-class samples?)\n- In section 3.2, $\\hat{s_i}$ is defined as $\\frac{u_i}{\\lambda} s_i$, but then $\\sum_i \\hat{s_i} = \\frac{u_i^2}{\\lambda}$. Is this right? \n- In Figure 4, how are the classes of SL defined (compared to Fine-grained SL)? \n\nTypos:\n- Page 3, Equation (1): w_{j=1}^T \n- Equation (2), (4): z_q z_k => z_q^T z_k\n- Section 2.2. Beta(\\alpha, \\alpha) needs punctuation.\n- Section 3.2, matrix multiplication does not make sense (=> element-wise multiplication or others)\n- Section 3.2 page 6, w, => w",
            "summary_of_the_review": "Although the paper conducts extensive experiments, this paper does not provide sufficient description for their method and some experiments. Furthermore, their analysis on instance-level mixup generation is not convincing and requires more interpretation. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, the authors present a new method for discriminative visual representation learning, based on the MixUp approach [Zhang et al., 2017]. Specifically, they decompose the mixup into two sub-tasks (mixup generation and classification) and the proposed mixup training method is termed as AMix. Experimental evaluations in both supervised and self-supervised settings on different datasets show the effectiveness of the proposed AMix method. The main contributions are the proposed improved mixup method and the corresponding extensive experimental evaluations.",
            "main_review": "### Strengths:\n\n\\+ The proposed method is shown to be effective for both supervised evaluation and self-supervised ones.\n\n\\+ The authors did a thorough ablation study to validate the effectiveness of the proposed components/modules.\n\n\\+ The paper is generally well-written.\n\n\n### Weaknesses:\n\n\\- The novelty of this paper is a bit limited. Given that the main technique is based on a prior work AutoMix [Liu et al. 2021], the added modifications are a bit incremental.\n\n\\- The authors introduce an additional learnable parameter \\gamma, motivated by the assumption \"might be ignored or cause trivial solutions during training\" (Sec. 3.2). But there is no evidence to back it up, e.g. why it would be ignored and what trivial solutions could be. Besides, an additional parameter is introduced.\n\n\\- The proposed non-linear content modeling module is well-motivated, but it is unclear why to replace the original cross-attention with a self-attention (Fig. 3).\n\n\\- Page 9, \"Fig. 6\" should be \"Table 6\"?\n\nIt would be better to see how the proposed method performs on segmentation-related tasks like semantic segmentation, in addition to the evaluation on detection.",
            "summary_of_the_review": "Overall, the paper is well-written and contributes a new training solution for learning discriminative visual representations, in both supervised and self-supervised settings. It is also validated through extensive experiments, where the proposed method performs better than the other compared methods. This could be a good contribution to the community. But the technical novelty is a bit limited, considering that it is mainly based on an existing work AutoMix [Liu et al., 2021]. There are also some unclear statements/claims in the proposed modules. As a result, I recommend borderline acceptance at the moment and would possibly change my rating after the rebuttal.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A.",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}