{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper shows that test-time adaptation of BatchNorm layers to Gaussian noise can induce a base classifier for randomized smoothing as good as those trained from scratch with Gaussian noise. Specifically, the method adapts the running statistics in each BN layers (following the test-time adaptation literature) with Gaussian-augmented samples in the training (or validation / test) set to make a classifier perform well under Gaussian noise, and use the adapted classifier for randomized smoothing. Experimental results on CIFAR-10 and ImageNet show that the adapted classifier achieve comparable (or marginally better) certified robustness compared to existing method for training smoothed classifiers. ",
            "main_review": "- The paper is clearly written. I found the idea of applying test-time adaptation to obtain a smoothed classifier is quite novel. I also liked the point that the method can use training samples for adaptation, so that it could keep working on the standard threat model of adversarial defense.\n- Nevertheless, I generally feel that several important claims in the paper are not adequately supported by experiments, and this weakens the empirical significance. For example, the paper claims that the proposed model achieves the state-of-the-art in $\\ell_2$ certification, but there should be more evaluations to support this: in fact, to me it looks more like the model could achieve competitive performance to the baseline randomized smoothing models. In case of ImageNet results in Figure 2, the proposed model is quite worse than the baseline Rand (0.5) model. Even for the CIFAR-10 results, the gain seems quite marginal. Also, it seems that the adapted model also suffers accuracy drop when smoothed, and this makes hard to directly compare the robustness of smoothed classifiers. I would suggest the paper to include more quantitative metric to measure this accuracy-robustness trade-off, e.g., by comparing average certified radius [Zhai et al., 2020; Jeong and Shin, 2020].\n- Also, the paper claims that the method can separately choose appropriate $\\sigma$ per sample: indeed this is a good feature, but I could not find a relative empirical support for this claim as well. If the paper could show that this feature can improve the certified robustness compared to existing smoothed classifiers, that would strengthen the significance of the method.\n- Which split is used for sampling the batch for adaptation in the experiment: i.e., among the train, validation or test splits? In particular, it would be great if the paper could compare the performance for these choices, as this choice of target split can impact the practical significance of the method.\n- Why the paper primarily focuses on adapting adversarially robust network, instead of networks from standard training, or Gaussian-augmented training?\n\n[Zhai et al., 2020] MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius, ICLR 2020.\n\n[Jeong and Shin, 2020] Consistency Regularization for Certified Robustness of Smoothed Classifiers, NeurIPS 2020.\n\nPost-rebuttal update ===========================================================\n\nI have read the authors feedback and the other reviewers' comments. I appreciate the authors' detailed response letter, especially for the additional results on ACRs. As many of my important concerns have addressed, I increased my rating from 5 to 6. \n\n\n",
            "summary_of_the_review": "Overall, I found the paper is clearly written, and explores an interesting direction with a novel method in the context of randomized smoothing. Nevertheless, I feel its empirical significance can be a weakness - some of important claims in the paper are not adequately supported experimentally, and their reported gains looks marginal compared to existing randomized smoothing based models. Also, the paper could have compared with more recent training methods form randomized smoothing to support its claim as the state-of-the-art in $\\ell_2$ certification.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes to use adaptive batch normalization to strengthen the adversarial training's model ability to counter gaussian random noise so that it could be better used in the random smoothing certification. Specifically, it first samples batches of data to achieve the adaptive BN's parameters and then uses random smoothing to achieve the certification. The experiments show it could achieve a better certified radius and better accuracy. ",
            "main_review": "Pros:\n1. The question paper focused on is quite interesting and meaningful. \n\nCons:\n1. The paper is poorly written. First, the organization of the paper is not good enough. There is too much background compared with their analysis and the proposed method, which makes the paper not easy to follow and confusing. Second, written English needs to be polished. Some usage of connection words like \"consequently\" is not appropriate.  Also, there are several typos and grammar errors like \"Consequently, robustness against random Gaussian noises of any classifier,...\". Or like line 6 in the Algorithm 1 where I think it should be R=Certify(g,x_test,\\simga) instead of f.\n2. The novelty of the proposed method is quite limited. It is the simple combination of adaptive BN with random smoothing techniques.\n3. Some of their assumptions are not well-supported by their experiments. In Table 2, without the adaptive BN, the adversarial training model actually performs better than baseline and with random noise augmented trained model, where the paper claims the adversarial training suffers more from the situation when Gaussian noise is added.",
            "summary_of_the_review": "Given the poor written quality and limited novelty, I would like to vote for rejecting the paper.",
            "correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a certification through an adaptation algorithm that transforms adversarially trained models into a randomized smoothing classifier using test-time covariate shift adaptation to provide L2 certification. Random smoothing can certify robustness, but it also decreases accuracy. This paper then updates at test-time to adapt to the additive Gaussian Noise, so that some accuracy is recovered. Experiment shows that the approach is effective. It is effective for CIFAR-10, and is partially effective on ImageNet.",
            "main_review": "Strengths:\n1. The idea is neat and interesting.\n\n2. Results show the method is effective.\n\n3. The method can be combined with many existing variants of random smoothing, which can have a broader impact.\n\nWeakness:\n1. Some related work on test time inference is not cited [1,2].\n\n[1] Tent: Fully Test-time Adaptation by Entropy Minimization. ICLR 2020.\n[2] Adversarial Attacks are Reversible with Natural Supervision. ICCV 2021.",
            "summary_of_the_review": "I recommend accepting this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}