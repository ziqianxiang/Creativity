{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper conducted an empirical study of existing loss weighting based multi-task learning techniques. By comparing them in both CV and NLP multi-task benchmark datasets, the authors also identified a simple random loss weighting method achieving similar performance. This paper provided both empirical and theoretical analysis of why random loss weighting can achieve similar performance efficiently.",
            "main_review": "This paper did a great job conducting empirical comparison of existing loss weighting methods for multi-task learning.\n\nIt is quite surprising to see a random loss weighting baseline achieving reasonably comparable results. But the authors not only provided theoretical analysis as well as studied the effect of RLW with different sampling distributions. \n\nWeaknesses\nOverall I like the work and findings of this paper, but I feel like there are some places that the paper can improve.\n(1) Even though the paper compared 9 state-of-the-art approaches in experiments, the discussion on the results are mostly related to RLW. It would be good to include more discussions on  when and how these existing approaches work the best.\n(2) I think the experimental study can be improved by including the mean and standard-error of multiple runs.\n(3) Usually these MTL methods can be strongly affected by model capacity, even though the authors mentioned DMTL (table 1) is smaller than MTAN (table 4), it is still better to see how model capacity changing in the same model architecture can affect the results of RLW and other methods.\n(4) How is the other HP tuned and selected?\n\nNit: what does DMTL stand for?\n",
            "summary_of_the_review": "This paper conducted empirical analysis on many most recent loss weighting methods for multi-task learning, and found a simple random loss weighting approach that can achieve similar results. Even though this is quite impressive, I would love to see some experimental study with more details on standard-error of different methods, and HP tuning.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "Authors propose a dynamic loss weighting algorithm that chooses random loss weights per step from a chosen distribution in a multitask setting. Model with these dynamic weights is then trained until convergence. Theoretical analysis on convergence is provided and experimental results on NYUv2, PASCAL-Context, and XTREME are given. The method seems to perform relatively on par or a bit worse compared with other SOTA methods but does not require computation of gradients. ",
            "main_review": "On the one hand, I think this kind of experimentation is quite necessary within multitask learning. We are starting to accrue a large number of loss-balancing methods and having an even-playing-field analysis of these methods is useful. The method proposed by the author is tested in various multitask settings and for many architectures and tends to at least come close to SOTA methods in many of these settings.\n\nHowever, I find the author's proposed method rather unconvincing, for the following reasons:\n\n- The theory of convergence is almost unnecessary in my opinion, as the authors are just adding extra zero-centered stochasticity to the training process, so of course things have similar convergence properties as the unmodified vanilla method.\n\n- Authors do not provide sufficient analysis on how to pick the distribution, which of course is a major added hyperparameter. \n\n- Many results seem to somewhat underperform SOTA. While it is interesting that RLW comes close to SOTA numbers in my cases, it is known that for multitask learning models gains from even SOTA methods can be mild depending on context, so it's unclear if the presented results actually imply that RLW is performing well.\n\n- More information needs to be provided in terms of the number of trials run for each experiment and error bars. Otherwise I believe it is not correct to provide 6 different experimental rows corresponding to RLW and then pointing out the rows which happen to perform better. Statistically, the comparison between RLW and the base SOTA methods is then not an apples-to-apples comparison. What makes this more confusing is that different distributions seem to perform better for different results. \n\n- Related to the last remark, how does the performance of RLW compare to performance with the optimal (through grid search) loss weights? Given that the number of tasks within the benchmarks the authors chose tends to be small (~2-4 tasks), while the only large-number-of-task dataset authors explored (CelebA) is notorious for producing rather clustered results, I would think it likely that an optimal static loss weighting might outperform RLW here as well. If so, that makes a careful statistical analysis with error bar calculations even more crucial. ",
            "summary_of_the_review": "I believe that more papers like this would be welcome additions to the multitask learning literature as they give us birds-eye views of the research landscape, but the author's approach leaves me with considerable concerns both in algorithmic design and statistical analysis of the results that need to be addressed before I am convinced this method is working as authors claim. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "Here, the authors present a novel method for multitasking loss weighting called Random Loss Weighting (RLW). The method is straightforward and clearly described; RLW considers the loss weights lambda as random variables. In practice, it works by sampling the loss weights from a distribution (authors evaluated six different distributions) with some normalization and then minimizing the aggregated loss weighted by the normalized random weights. The authors provided an extensive empirical evaluation including eight state-of-the-art loss weighting strategies on six computer vision datasets and the XTREME benchmark (four multilingual problems). RWL results are comparable to previous strategies, but with a lower computational burden. The authors also provided a theoretical analysis on how the extra randomness from the sampling affects the convergence and effectiveness of RLW compared with fixed loss weights optimized via SGD.",
            "main_review": "- Strengths\n  - The paper provides an interesting approach in the multi-task learning field; specifically a loss weighting strategy relying on a random sampling of loss weights. In particular, it shows a comprehensive and extensive evaluation of eight loss weight strategies in orthogonal data sets of computer vision and natural language processing. To the best of my knowledge, this is the most comprehensive evaluation of weight-loss strategies (yet not the first one, perhaps cite https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848395 ?). Additionally, a theoretical analysis of convergence is also provided.\n  - RWL results are comparable with previous weight-loss strategies, but the relative RWL training speed over EW is faster than most methods (based on results for only one dataset - NYUV2).\n- Weaknesses\n  - Major\n    - The paper claims that the RLW strategy is as computationally efficient as EW, but results are only provided to NYUV2 and omitted for PASCAL-Context. Is it possible to extend the “delta t” analysis to other settings such as the XTREME benchmark (5.6) and RLW with different architectures (5.7)? Specifically, DWA and UW seem to be as efficient as the proposed RLW in terms of “delta t” (table 1). In table 4, UW achieved better performances. Thus, efficiency analysis should be provided in the other datasets.\n    - Six different distributions are evaluated for RLW and according to the results, there is no clear winner among these strategies. Could some discussion be added about this? Any MTL application using RLW will need to test the different distributions? Is there any practical advice other than try six additional baselines?\n  - Minor\n    - The paper claims in the abstract that have unified eight representative task balancing methods from the perspective of loss weighting. With this, I was expecting RLW to be a method unifying or being a generalization of all eight baselines, but it's not the case. Unify is related to categorizing these eight baselines into three different groups (learning approach, the solving approach, and the calculating approach). There is also another “unified”, which is related to the comprehensive experimental setup using these eight baselines provided. Perhaps make this \"unify\" term clear to the reader?\n    - Negative transfer is a potential side-effect of multi-task learning and also observed when using different weight-loss strategies such as UW. Could any comment be made about how RLW could alleviate this phenomenon, or if there is any RLW feature/property that could help on this?\n",
            "summary_of_the_review": "Overall,  I like the empirical evaluation of the previous loss weighting strategies using a comprehensive number of datasets in different areas. I think this is valuable and needed given the importance of these strategies in multi-task learning and the lack of evaluation for that. Also, the method proposed is quite simple, yet provides comparable results . Additionally, the paper claims that method is computationally efficient. However, the results for this claim are only partially supported leading to major concerns stated in the Weaknesses section. With this, I vote for rejecting (marginally below the acceptance threshold). Hopefully, the authors can address my concerns in the rebuttal period.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposed a simple yet effective weighting strategy called Random Loss Weighting (RLW), where random weights were sampled from a distribution. The authors analyzed the convergence of RLW and revealed that RLW has a higher probability to escape local minima than existing models with fixed task weights, resulting in a better generalization ability.",
            "main_review": "This paper proposed a simple yet effective weighting strategy with random weights sampled from a distribution. \nThe authors proved the convergence of RLW and revealed that RLW has a higher probability to escape local minima than existing models with fixed task weights, resulting in a better generalization ability. \nThe proposed method looked elegant and novel to me.\n\nMy major concerns are three fold:\n1) The authors didn't conclude / prove which distribution is best for MTL or how to choose the distribution for different datasets.\nThe best distribution was inconsistent across different datasets.\n2) The proposed approach completely neglects the relationship between tasks, and thus it may fails in some cases where some tasks are highly correlated.\n3) The reported results of RLW with different distributions and baselines were comparable (very close). I'm not sure in what extent the results can be affected by the randomness of the loss weights.",
            "summary_of_the_review": "This paper proposed a simple loss weighting approach and provide proofs (I didn't not check the proof in the appendices) for convergence and generalization. The theory part looks interesting. The paper could be improved as mentioned above.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N.A.",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}