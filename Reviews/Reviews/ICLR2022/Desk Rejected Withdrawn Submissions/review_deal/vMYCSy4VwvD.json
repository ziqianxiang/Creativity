{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper targets finding an off-the-shelf solution for the MULTI-DOMAIN ACTIVE LEARNING task. By doing a comparative study on different combinations of MD models and AL strategies, they provide a framework combined by Multinomial Adversarial Networks (MAN) with the best vs second-best (BvSB) uncertainty strategy. The experiments on five textual and visual classification datasets show the proposed framework’s superiority and robustness.\nThe authors first introduced MDL and AL separately and pointed out there are few works utilizing AL on MDL while those existing works are based on the specific models for specific applications and not generalized enough. Therefore, an off-the-shelf MDAL method is desired. The paper’s idea is straightforward and easy to follow. The experiments are conducted with combinations of 5 MD models and 4 AL strategies and are discussed in detail.  \n",
            "main_review": "Strength\n+ A good attempt to combine MDL and AL with a comprehensive survey of existing works\n+ Meaningful insights on the off-the-shelf solution to this problem\n+ Comprehensive experiments\n\nWeakness\n- I have a few concerns about the experiment. First, for Fig 1, the authors mentioned “At the latter stage, these two models perform worse than the other models in the most datasets except on digits dataset.” However, from the figure, the DANN and SDL-joint outperform SDL-separate on Amazon, Office-31 with a large margin, and competitive with others on Inter-Twin Moons. Second, larger visual datasets like Office-Home are recommended.\n- Lack of theoretical justification of why the off-the-shelf solution is a good one\n- As a survey paper, lack of recommendation for future directions and how should this direction move forward\n",
            "summary_of_the_review": "This is a good survey to understand the status quo of MDL and AL and has recommended one off-the-shelf solution for practical use.  But it lacks theoretical justification and also lacks enough insights on the future of the direction.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper provides a somehow more thorough analysis of active learning methods in the presence of domain shift. Authors considered several deep learning domain adaptation strategies and measured their performances once equipped with an AL strategy. ",
            "main_review": "My review will be short.\n\nMy main concern here is, an empirical study should provide pointers as \"what to do\" or \"not to do\". After reading this paper, I still have no clear idea for an MDAL problem, what should be the better strategy to employ. I believe the authors failed to show a consistent message and the work right now shows a few experiments, some of them are not interesting nor challenging (eg., Office, toy data). There are much more challenging DA datasets that might provide a better understanding but my point is not \"why not a bigger dataset\", my point is, I do not know what to do after reading this paper if I have an MDAL problem. Somehow, some of the results suggest random sampling is the method of choice but obviously this cannot be the goal of active learning.\n\nOn a different and minor point, In section 3, \"Sharing model parameters without share representations\", isn't this somehow \"Sharing domain-invariant representations\"? I am not sure what exactly the distinction would be. The authors mentioned \"other works share parameters without explicitly sharing representations\" but once the parameters are shared, the representation would be available (unless there are some privacy concerns). I appreciate if the authors expand this part and provide more details as to what is fundamentally different and why these two families should be separated.\n",
            "summary_of_the_review": "I cannot see a clear message in this work and hence my score, sadly would be negative.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents a comprehensive comparative study of 20 different MDAL algorithms, and makes a benchmark on five datasets, involving textual and visual classification tasks. And the authors find the combination of Multinomial Adversarial Networks (MAN) with the best vs second-best (BvSB) uncertainty strategy shows its superiority in most cases.",
            "main_review": "The contribution of the paper is very clear, this is the first comparative work for the MDAL setting. This paper provides comprehensive experiments, including both qualitative analysis and quantitative results, to show the comprehensiveness of the benchmark.\nBut I think this type of paper is not suitable for ICLR conference, without their method, any technical novelty, empirical novelty and significance. ",
            "summary_of_the_review": "This type of paper is not suitable for ICLR conference, without any technical novelty and significance. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper studies multi-domain active learning (MDAL) problem. It presents a study of different off-the-shelf solutions to MDAL by combining approaches for multi-domain learning and active learning. As multi-domain baselines, authors select three methods (DANN, MDNet and MAN), while for active learning they study three strategies (random, uncertainty, EGL and BADGE). They explore all combinations of the above mentioned domain adaptation and active learning approaches.",
            "main_review": "Strengths:\n- The MDAL problem is very relevant and important, but currently understudied, especially in the deep learning space. \n- The paper provides a comprehensive comparison of the off-the-shelf approaches to this problem.\n- The paper is easy to follow and well structured.\n\nWeaknesses:\n- The paper would be much stronger if authors propose their method to MDAL, or at least some adaptation of the existing approaches. Currently, the paper just evaluates combinations of different methods which all represent ad hoc solutions to the problem. In that regard, contributions of this paper are not significant.\n- The evaluation itself could be stronger as well. For example, currently only three domain adaptation methods are selected (DANN, MDNet and MAN). Why are these methods selected? Comparison to more recent methods would make this paper stronger. \n-  The results are very hard to compare. Each combination of AL and multi-domain adaptation is presented as a one panel and in the current form it is very hard to compare different approaches. Presenting results in the tables would make different approaches much easier to compare. Currently, this is done only for the random strategy in the Appendix.\n- Currently, the paper just reports how well each of the strategies work, but lacks insights about why for example MAN and uncertainty work better than the others. More insights would make the paper stronger.\n",
            "summary_of_the_review": "The paper compares combinations of active learning and multi-domain learning methods as a solution for multi-domain active learning, but all the solutions present ad hoc approaches to the problem. As such, I believe that the contributions of this paper are not significant enough to be published at the ICLR. Even if seen only as the evaluation paper, the evaluation itself could be more comprehensive (for example including more multi-domain learning methods), the paper could provide more insights and the results could be better presented.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}