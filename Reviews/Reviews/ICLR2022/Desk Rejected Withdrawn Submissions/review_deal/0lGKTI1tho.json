{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes POLAR, a reachability analysis framework for neural network-controlled systems. POLAR improves the previous Taylor model overapproximation approach in two aspects: 1) use Bernstein polynomial to overapproximates activation function; 2) use symbolic remainders to mitigate the so-called wrapping effect, that is, instead of computing an overapproximated interval at each step, keep track of linear transformation matrices to delay overapproximation as late as possible. The experimental evaluation compares POLAR with three other recent work and shows that POLAR achieves the best performance on almost all tasks.",
            "main_review": "Strengths: \n- the main idea is clearly explained through several small but illustrative examples;\n- using Bernstein polynomials to overapproximate activation functions is novel;\n- the application of symbolic remainder is effective.\n\n\nWeaknesses:\n- the chosen benchmark only consists of 6 problem instances, and the number of state variables of each problem is fairly small (i.e., 2 to 4);\n- the argument that Taylor approximation requires the approximated function to be differentiable and thus is not applicable to ReLU function is not correct, because ReLU is differentiable almost everywhere (except for at zero);\n- the name of \"symbolic remainders\" is a bit misleading or confusing, since there is really no symbolic value introduced, instead, just accumulates linear transformations to delay overapproximation;\n- an ablation study (e.g., disable Bernstein polynomials or symbolic remainder) would be helpful to better understand the performance improvement.\n\n \n",
            "summary_of_the_review": "This paper makes relatively incremental contributions to the verification of neural network-controlled systems. Introducing Bernstein polynomials and the symbolic remainder seems quite effective on the chosen benchmark. However, I am not quite familiar with the chosen benchmark and find it difficult to assess the significance of experimental evaluation. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposed a method for overapproximating outputs from small neural networks in the context of flowpipe construction of ODE systems controlled by neural networks. ",
            "main_review": "The paper proposed a method for overapproximating outputs from small neural networks in the context of flowpipe construction of ODE systems controlled by neural networks. The work is technically sound, but fairly misleading in the contributions, comparison with existing work, and important baselines are missing.\n\nFirst of all, the context is for rigorously bounding reachable sets of ODE systems, which is an important and hard problem. However, the current work is only dealing with the problem of bounding the output of the control function, which is a simple feedforward neural network. In fact, one needs to read into the technical details to see that this is really what the paper is about, and the flowpipe construction part only serves as a context. This by itself is not a problem, but it does open up a huge range of recent literature on bounding outputs of neural networks in both the ML community and the formal methods community, and none of these have been mentioned. Of course, the authors emphasize that the current overapproximations are in function forms which is the key contribution, but I do not think that is difficult at all given the simplicity of Taylor models. \n\nBerstein polynomials themselves are very well-known as function approximators for global optimization (because the representation itself can be exponentially long). In fact, the ReachNN work https://arxiv.org/pdf/1906.10654.pdf has already used Berstein polynomials for the same problem, and the main improvement in the current work is to use sets of univariate Berstein polynomials for coordinate-wise overapproximations to avoid the exponentially sized representation, but apparently at the cost of overapproximation by simple projections. It is really concerning that the authors highlight the comparison with Verisig in Figure 5, but avoid giving detailed conceptual explanation of the comparison with much more closely related approach of ReachNN and Sherlock. These tools only appear in the experiment section, and it of course does not help when we realize these are by almost the same set of authors (everything is on arxiv). \n\nOverall, apart from the questionable presentation that downplays similarity with the authors' previous work, the value of the paper can not be fairly evaluated before a lot more comparisons with SOTA tools on robustness analysis of neural networks are performed.  ",
            "summary_of_the_review": "Apart from the questionable presentation that downplays similarity with the authors' previous work, the value of the paper can not be fairly evaluated before a lot more comparisons with SOTA tools on robustness analysis of neural networks are performed.  ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "Not checking any box, but the authors do have an obligation to discuss a lot more about the comparison with their very recent previous work using very related approaches, rather quickly brushing them off in the introduction without mentioning the similarity. ",
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The authors attack a significant problem or bounded-time reachability analysis of neural-network controlled systems (NNCSs). The method allows for verification of decision-making procedures applied by trained neural networks to systems with the known continuous model (continuous plants).\n\nThe claimed main novelty of the paper is the application of the basic Taylor Model arithmetic in combination with the univariate Bernstein polynomial interpolation to handle non-differentiable NN activation functions.\n\nThe algorithm is tested in a set of benchmarks introduced in the other related work. \n\nThe main theoretical result states that the TM flow pipes computed using the POLAR approach are state-wise approximations for the reachable sets.\n\n",
            "main_review": "The authors propose a new algorithm improving bounded-time reachability analysis of neural-network controlled systems (POLAR). POLAR is based on the previous works, the method is sound, and improves a set of benchmarks introduced in related work, the reported improvement of POLAR over other related work in Table 1 concerns the runtime & benchmark coverage.\n\nI have significant concerns about the paper and the presented results, I summarize all of my major concerns below.\n\n### 1. The method seems not suitable for deep (reinforcement) learning practice.\n\nI have significant doubts regarding the applicability of the proposed method in deep-learning, reinforcement learning & high dimensional dynamics modeling context. The first sentence of the introduction reads _“Neural networks have been increasingly used as the central decision-makers in a variety of tasks Mnih et al. (2015); Lillicrap et al. (2016); Pan et al. (2018)”_, where authors indicate solving examples of reinforcement learning controllers applied to Atari benchmarks/continuous robotic environments.  This class of problems is characterized by the high dimensionality of the environment model itself (e.g. dim. of rigid body actuator state vectors in robotics / dim of pixel screen in Atari games/complexity of the learned world model). The dimensionality of those problems certainly exceeds greatly the dimensions of the studied benchmarks - the number of state variables varies from two to four, and the number of neurons in each layer is 20. \nI gave some thought if the Taylor model + Bernstein interpolation approach is scalable. Unfortunately, my conclusion is negative. I think such an approach does not scale up. AFAIK Taylor’s model approach requires to recursively compute the polynomial coefficients. The cost of computation depends on the state dimension, the complexity of the plant vector field (M_F), and on top of that, the computation order is quadratic w.r.t. the Taylor polynomial degree. Then the nonlinear activations are Bernstein interpolated, multiplying the overall complexity by a quadratic factor w.r.t. the Bernstein polynomial order times the NN depth. Unless the authors convince me otherwise, this does not seem to scale up for larger (>10) orders of polynomials and states. There are no details given of how one of the crucial parts of the algorithm - the linear-nonlinear part decomposition is being performed. This computation may be of significant complexity. I could not find exact order numbers employed by the authors to see what problems are reachable using the approach at all.\n\n###  2. Concerns regarding the novelty of the approach\n\nI like to contest the claimed novelty of the proposed method claimed in the introduction. The polynomial arithmetic framework does not seem to be novel.  A Taylor model + Bernstein polynomials approach was already introduced in j. Fan et. al. _\"ReachNN*: A tool for reachability analysis of neural-network controlled systems\"_. Even the studied benchmarks are the same as in the related work. The only new element considers neuron-wise Bernstein polynomial interpolation, which seems to be a straightforward modification over the related work algorithm. The symbolic reminders is also not a new idea, as noted, it is adapted from Chen & Sankaranarayanan (2016) (for ODEs), but I believe it circulated in interval analysis literature even earlier (see the next paragraph). Overall, I rather see the algorithm as an improved ReachNN*, rather than a standalone tool, deserving a new acronym (POLAR). \n\n###  3. Related work is not presented, the bibliography is not complete.\n\nThe bibliography can certainly be improved. The related work section misses any discussion and comparison of the other than TM techniques for computation of overestimation of reachable sets of nonlinear dynamical systems; also the provided list of related work does not seem to be complete. The wrapping effect, widely mentioned in interval analysis literature already appeared in original works by R. Moore, dating back to 60's, is here attributed to Jaulin et al. (2001). AFAIK the idea of not computing the term A*I directly but rather keeping separate coordinate system (matrix A) and the intervals (interval vector I) goes back to R. Lohner _“Computation of Guaranteed Enclosures for the Solutions of Ordinary Initial and Boundary Value Problems”_, 1992. Also see the book: U Kulisch, R Lohner, A Facius, _“Perspectives on Enclosure Methods”_, 2001, Springer.\n\n### 4. Not Clear Benchmarks.\n\nThe proposed benchmarks are taken from a related work paper entitled: “ReachNN: Reachability Analysis of Neural-Network Controlled Systems, “ not presented on a machine learning venue. The examples are not even presented in the paper. Only rough information about their dimensionality is given. It is unclear what a single test was about at all. This is a serious flaw, which assumes the knowledge of the previous work and refers to another paper to know what the studied benchmarks are.  It is also clear that the used examples are much smaller than the ones used in deep learning practice. There is no information given how the controllers were trained /synthesized, no information available on how the tool is implemented, does it use any external libraries. If it is possible to provide a NN controller that was obtained using standard e.g. PyTorch machine learning toolkit. \n\n### 5. Choice of the employed benchmark metrics.\n\nTable 1 summarizing the results in the main text provides a single metric used for comparison i.e., the runtime in seconds. As the benchmark problems are not presented at all, it is hard to decide about the significance of the obtained results in comparison to existing tools.  The benchmarks seem to be highly dependent on integration time-horizon, polynomial approximation orders, and time-stepping,  none of which is provided in the paper. Also, a discussion of another comparison metric - tightness of bounds is deferred to the appendix, where just plots allowing for visual comparison are provided. It would make sense to quantify the benchmarks using the final enclosure volume / average enclosure volume.\n\n### Other remarks: \n\n* p.7: What do you mean by decomposing function into the linear and the remaining part in q_i ? I guess there is no unique decomposition q_i(y) = Q_i*y + q_i^R(y).\n* eq. top of p. 6: symbol L_j is not introduced,\n* p.12 end of B.1: what citation ‘[a]’ supposed to mean?\n* p.12/13 B.2 proof: No reference given for the ‘Base Case’ part of the proof, i.e. that TM flow-pipe construction for the ode with control variable is sound. Another gap is an argument that the Bernstein polynomial interpolation layer-by-layer of the NN controller is also sound, this does not look obvious to me.\n",
            "summary_of_the_review": "The studied problem and the algorithm itself are nice. However, I have significant doubts about the algorithm novelty, the reported benchmarks, the practicality of the method, and the presentation and completeness of the paper. All of my concerns are summarized in the five paragraphs above. \n\nConcluding, I think that the paper’s flaws overweight its advantages, and hence, unfortunately, I recommend a rejection of the paper in its present form. \n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}