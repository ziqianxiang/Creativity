{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper tackles the problem of non-rigid shape matching. The framework mostly follows the Diff-FMaps approach originally projecting 3D shapes into low-dimensional non-linear embedding and applying a linear transformation on the embedded space for solving shape matching.  The paper focused on non-linear embedding learning and skipped the inference of linear transformation.\n\nThe major contribution of this paper attempts to add regularization to the feature embedding via considering the symmetry structure. To achieve the goal, they assume a point-to-point symmetry map is provided and propose two objective functions considering symmetry and commutativity used in the functional map framework. The experimental results show that the newly added objective functions improved the Diff-Fmap on several benchmarks.",
            "main_review": "**Strengths**\n\nConsidering symmetry structures of shapes and adding extra regularization for embedding learning to reduce ambiguous matching is intuitive. The authors followed the Diff-Fmaps [1] to infer an optimal transformation $C$ in Eq. 2 given a ground truth pointwise map. The difference here is that the ground truth pointwise map is a self-symmetry map generated from augmenting every shape itself.\n\n**Weakness**\n\nThe novelty is limited and the overall contributions are incremental. \n\n* Compared to the Diff-FMap, the paper considers the symmetry structure of shapes. However, this is achieved by leveraging extra self-symmetry ground truth labels ( it remains unclear to the reviewer whether the generation requires manual annotations though, please clarify). And it is non-trivial to obtain such a label from an arbitrary shape, which prevents it from applying to practical applications at large scalability. \n\n* In addition, the Euclidean Loss is directly borrowed from the Diff-FMap without a modification. The original Diff-Fmap has shown the important idea of doing deep non-linear embedding + linear transformation for shape matching with a two-stage optimization. Under this context, the paper is an incremental work over Diff-Fmap by adding simple regularization, i.e., symmetry & commutativity, which are well-known concepts in functional map frameworks.\n\n* Missing qualitative examples. The authors claimed the self-symmetry structure is beneficial to shape matching. The authors could have provided visual examples to show these cases.\n\n* The authors are suggested to evaluate other popular benchmarks, e.g., datasets presented by CorrNet3D [2] or DPC [3].\n\n[1] Correspondence Learning via Linearly-invariant Embedding, Neurips 2020\n\n[2] CorrNet3D: Unsupervised End-to-end Learning of Dense Correspondence for 3D Point Clouds. CVPR 2021\n\n[3] DPC: Unsupervised Deep Point Correspondence via Cross and Self Construction. 3DV 2021\n",
            "summary_of_the_review": "The reviewer is leaning to reject the paper due to the limited novelty and evaluation. \n\nThe paper adds simple regularization techniques from known concepts of the functional map framework to the Diff-FMap, making it an incremental contribution. Also, it needs extra annotations for building the self-symmetry map, which is non-trivial to obtain from arbitrary shapes.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a non-rigid shape matching method based on deep-learning-based embedding. The paper follows a recent approach that the shapes can be represented in another embedding space where the source and target are linearly related. Knowing the ground truth correspondence map between the (training) shapes, a deep network can be trained to learn the embedding as well as the functional map between the shapes. The contribution of the paper from recent related work is that a self-symmetry-based loss is added for adding structural information, and the loss for comparing the shapes is simplified so that no functional map is needed. Experiments show that the proposed method achieves similar or better performance to the recent state-of-the-art.",
            "main_review": "The proposed method provides better performance than the baseline (Marin et al. (2020)) and achieves similar or better performance to others that require additional information (mesh structure) or efforts (handcrafted features/computation). That being said, the proposed method also requires additional self-symmetry information beforehand, so it may be only natural that it has better performance than the baseline, like other methods with additional information. In terms of novelty, it largely follows the baseline (which is somewhat incremental) but proposing self-symmetry as a regularizer is somewhat new. There is some contribution here, but there are also many concerns about the proposed method.\n\nThe most important concern is about the self-symmetry constraint, which is the main point of the paper. The impact of the self-symmetry as a regularizer is not well addressed in the paper. I have many questions about this choice. How strong is this constraint? It might be helpful for structures with obvious symmetries (like a human body), but does it even make sense for general objects? Moreover, it seems that the proposed method requires ground truth pointwise self-symmetry map. Is this easy to obtain for general point cloud data (as in the problem setting of this paper)? It seems to me that this can be quite costly.\n\nAnother thing I'm confused about is that there is a disparity between losses. For the Euclidean loss, the authors removed the functional map transformation from the one in Marin et al. (2020), of which the modification is claimed to be easier to use. For the self-symmetry loss, however, the functional map still resides. What is the significance of this setting (which is not well explained in the paper)? Is it because the network has to learn the embedding function somehow with the functional map and the authors are leaving this to the self-symmetry constraint? If this is true, then the question leads to the previous point (=how strong the self-symmetry condition is).\n\nThere are also some concerns about experiments: Here, the baseline of Marin et al. (2020) has been re-trained with larger point sets, however, the parameters were set the same as in the original paper. I'm not entirely convinced about this point and there is a good chance that it is more likely the case where the best performing parameters can be different for a different resolution. So it is required to show that this is still the best parameter for the given resolution in the paper. Another confusing point is that Marin et al. (2020) gets worse when the self-symmetry constraint is added. Why is this? Since the proposed method and this method share large similarities except for the simplified Euclidean loss, it seems to me that this doesn't make sense. An in-depth explanation has to be provided about this point because the only difference of this modified baseline from the proposed method is the Euclidean loss (which seems to be too much to be the core reason). Moreover, why didn't the authors test this modified baseline for the partial matching scenarios?\n\nThe followings are questions that can possibly also involve the work of Marin et al. (2020): A pseudo-inverse is involved in the calculation of the functional map, which is subjected to gradient calculation. In my understanding, this is not really \"differentiable\" and there are degenerate (or unstable?) regions. This must be appropriately addressed in the paper. Another thing is that this whole learning basis/embedding approach lacks a deeper discussion about uniqueness and ambiguities. Is there any chance that there can be multiple solutions for this learning scheme where some of them can exhibit unstable behaviors? Of course, this is a bigger question and it is not entirely up to this paper to find the answer. Yet still, providing a discussion can be helpful for readers to grasp the fundamental justification of the approach.",
            "summary_of_the_review": "The proposed method is somewhat incremental, and the main contribution of the method (=introducing self-symmetry constraint) needs more thorough justification.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a novel supervised learning approach to address the well-established problem of non-rigid shape matching. In comparison to existing works, the authors propose to make use of intrinsic self-symmetry properties of training shapes as additional supervision. The method is evaluated on the FAUST and SHREC'16 partiality benchmarks.",
            "main_review": "Technical soundness: There are a few inconsistencies in the proposed method:\n- Eq. (6) seems to be inconsistent in terms of how correspondences are concatenated. The motivation is to enforce that the mappings X->Y->Y_f and X->X_f->Y_f are equivalent. Regardless of what convention is used, the indexes of both terms in Eq. (6) do not match.\n- How is the map T_XXf^gt defined for partial shapes? The way it is used in Eq. (3) is only well defined if every point has a corresponding symmetric point (which is evidently not the case for partial shapes).\n\nPresentation: \n- The quality of the writing is below average.\n- Most related approaches show qualitative figures to illustrate obtained correspondences. This is crucial to put the obtained results into context. I suggest to show texture maps and/or colormaps with at least one example per considered benchmark. \n- It would be particularly interesting to see visualizations of the learned embeddings.\n- No partial shapes are shown in the paper.\n- It is difficult to see details of the shapes (e.g. facial region) in Fig. 1 due to the simplistic style. Even the aspect ratio/scale of the xyz axes seems to be distorted.\n\nRelated work:\n- The related work discussion is appropriate. \n- I suggest to add the following recent method to the discussion. [b] is out of scope since it is very recent (3DV oral), but still relevant for the proposed approach:\n\n[a] Eisenberger, Marvin, et al. \"NeuroMorph: Unsupervised Shape Interpolation and Correspondence in One Go.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n\n[b] Attaiki, Souhaib, Gautam Pai, and Maks Ovsjanikov. \"DPFM: Deep Partial Functional Maps.\" arXiv preprint arXiv:2110.09994 (2021).\n\nResults:\n- Several crucial baseline comparisons are missing: (Litany et al., 2017a; Groueix et al., 2018; Halimi et al., 2019; Roufosse et al., 2019; Donati et al., 2020; Eisenberger et al., 2020; Sharma & Ovsjanikov, 2020). Specifically (Halimi et al., 2019) shows results on partial shape matching. All of these methods have publicly available code.\n- Results on FAUST are comparable to the unsupervised method (Sharma & Ovsjanikov, 2020) (it only uses rotational alignments as \"weak supervision\"), even though the proposed approach is fully supervised and requires additional self-symmetry maps. Also, virtually all methods listed in the previous bullet point report and error of 1.7-2.5, much lower than 5.\n- Results are reported on the FAUST benchmark which is considered to be solved in the shape community. Most methods since DeepFM (Litany et al., 2017a) consider the more challenging FAUST remeshed benchmark. This should be straightforward, since the PointNet backbone is stable to surface resampling.\n- The standard benchmarks SCAPE remeshed, as well as generalization results \"S+F\" and \"F+S\" are missing, see e.g. (Donati et al., 2020).\n\nCertain (minor) claims in the paper are incorrect:\n- Sec. 1, 2nd paragraph: The authors state that (...) do not consider partial shape matching, even though two of the listed references (Halimi et al., 2019; Sharma & Ovsjanikov, 2020) show results on such benchmarks.\n- Sec. 4, 2nd paragraph: The authors state that an advantage of the proposed methods is that baseline methods require mesh data as inputs whereas theirs operators on point clouds. I believe that (Sharma & Ovsjanikov, 2020) also only works on point clouds, since it is based on PointNet++.\n\nMinor:\n- Notation of Phi_X is inconsistent: In Sec. 3, it depicts features per basis function, whereas in Sec. 4 it is features per point.\n- The methods section would benefit from an overview/architecture figure.\n- Add captions to all figures in Sec. 5.\n- Add cumulative curves for other baseline methods to the Figure on pg. 7.\n- Do not use * for multiplication in Eq. (7). \n- Ideally, add more than 3 settings each to Fig. 2 & 3, to get a more dense plot.\n- Certain points, like the training set, from \"implementation details\" should be mentioned in Sec. 5 instead.\n- Another relevant ablation study would be to show the effect of the number of subsampled points. \n- How does resolving intrinsic symmetries help to address partial shape matching, when parts of both symmetric components are missing (e.g. the whole upper body)? ",
            "summary_of_the_review": "I do not believe that the paper in its current form is ready for publication at ICLR. As detailed above, I have a number of doubts regarding the technical soundness of the paper, missing baselines and experimental settings and the general quality of the presentation.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work tackles end-to-end embedding learning for shape correspondence. Building on (Marin, 2020) the authors introduce self-symmetry maps to regularize the embeddings, and as a linearly invariant middle-space allowing canonical end-to-end embeddings better than previously seen. The work introduces several novel ideas and has extensive empirical comparisons in its favor. The communication of the ideas is ok but not great, and leave many questions. Furthermore, I believe the work can be improved by presenting the ideas more graphically and intuitively.\n",
            "main_review": "In the Introduction and Related Work sections the authors introduce the literature and core ideas of their paper. The main aspects of the literature that this work touches on are functional maps, a shape matching technique leveraging the LBO basis (usually) to correspond functions instead of points which induces a point correspondence. Functional maps have turned out to be critical as functions on manifolds are generally more compatible than extrinsic representations or their statistics, and the optimization methods used are robust. However, there has been limited (Litany et al, 2017; Marin et al, 2020) success using deep learning methods to enhance these approaches, either through embedding learning or by predicting useful functions for shape characterization (other than the top eigenfunctions). Thus, the authors have proposed introducing reflective self-symmetry as an additional regularizer. Symmetries in shapes are known to produce issues for shape matching (A Condition Number for Non-Rigid Shape Matching, Ovsjanikov et al, 2012), so the introduction of symmetry maps does have some solid grounding. A loss is introduced to correspond learned embeddings under the given self-symmetry maps. As in this work, the learned embeddings are a function of extrinsic coordinates (unlike many previous works) the self-symmetry maps are just given by a reflection.  As the ultimate shape embedding is desired to be canonical the correspondence loss of (Marin, 2020) is applied to the functional alignment of these self-symmetric shapes. This results in a correspondence which is used to form the losses for the point matching task. To align 2 given input shapes, the soft correspondence matching is used to align the source and its symmetric counterpart, the source and target, and in a commutativity loss. Thus, ultimately the matching happens through these soft correspondence matrices, primarily via the euclidean loss. \n\nWhen it comes to the method and the formulation I find there are a several points that are unclear. To start, I think that there is some awkwardness with section 4, in that you have extensive explanation of the symmetry in 4 but then have subsection 4.1 to explain the Loss functions and implementation. It seems like using more subsections to better organize your contributions would clarify the high level ideas and read better. In terms of the methods, several things are left unclear. Eqn. 2 --- does this need to be recomputed at each iteration, or is this computed 1 time at the beginning of training? You say \"Given a self symmetry ground truth pointwise map TXXf\"... but this is computed automatically, right? You mention a \"siamese architecture based on PointNet\" ... but this is not elaborated on past this point. Doesn't this make the embeddings in (2) different than (3) or (4)... Shouldn't the embeddings technically be multi-variate embeddings, e.g. \\Phi_{XY}, if the representations are based on a siamese architecture? Also, doesn't PointNet have a linear transform meant to align shapes in a semi-canonical way at the beginning of it and wouldn't that cause the self-symmetry information to disappear? Can you explain in a little more detail why (4) does not enforce point-to-point matching? It seems that (Marin, 2020) did that?\n\nThe main issues that I have with the experimental section are that some of the claims are not obvious. For example, why does this work perform better on the holes/cuts experiments? Could some ablation or further theoretical analysis clarify that? You claim that the introduction of the self-symmetry map and regularization can help with issues arising in shape matching due to symmetry, but you don't do any specific analysis on this (for example, use the paper (Ovsjanikov et al, 2012) mentioned above to show your matching handles ill-conditioned matching better, or show that you can handle matching shapes with more symmetry. As you operate on point-clouds, your work should be more robust to noise in the vertex location, did you test this or is it considered out-of-scope? \n\nMy last point of critique is that this work lacks the signature \"visual flair\" of this research area. A single visualization of a reflection map of a point cloud leaves the reader underwhelmed. Typically, visualization via a colormap applied to corresponding functions in the embedding basis can be used to show computed correspondences. I don't think you can do the exact same thing with your representation, but I do think you need to show better visualizations. There are many possible routes to do so and it is considered a useful tool for understanding in this literature. Both point-to-point matches by pushing a function from one shape domain to another, and error functions, are often visualized.",
            "summary_of_the_review": "While this work is somewhat complicated, it is significantly novel in the introduction of matching symmetry maps up a linear transform. The experimental comparisons are extensive and favor the work in question. However, due to some unclear exposition, I do not think this work is currently acceptable in ICLR. If the authors can address some of my questions and concerns, I am willing to carefully consider their points.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}