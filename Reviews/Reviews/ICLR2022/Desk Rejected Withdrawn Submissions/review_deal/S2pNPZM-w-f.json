{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This work studies the problem of applying GNN for model-based control and it is relevant to the conference. The paper proposes the input convex graph neural networks (ICGNN) whose inputs and outputs are related via convex functions thus the decision-making problem becomes a convex optimization problem, this is to avoid the existing issue that non-convexity of GNN models often hinders solving model-based control problems. Experimental validation is provided to show the effectiveness of the proposed methods on  benchmark graph problems and physical heat diffusion problems. \n\n",
            "main_review": "The main contribution of this paper is to offer input convex graph neural networks (ICGNN) to model the decision-making problem as a convex optimization problem. This result is from a recent line of research on inductive biases for solvability. For example, many existing works impose convexity to the ML models so that entire decision-making can be done by solving convex optimization problems. The input convex neural network (ICNN) (Amos et al., 2017) is a general method for reformulating NN models as they become convex functions w.r.t the inputs. The convexity of ICNN helps to solve optimal control problems by employing recurrent extensions of ICNN (Chen et al., 2018b; 2020; Yang & Bequette, 2021). This work is an extension from the above works and balances the representability (generalizability) of GNN models and solvability of ICNNs in ML pipe-lined decision-making problems. The numerical experiment is light but the provided simulation on the control area seems useful and beneficial to the area. \n\n\n\t",
            "summary_of_the_review": "In short, the paper is technically sound and the developments are clear. The derived model and analysis under convex functions seems to be a useful contribution to the literature, showing a modest improvement over the state of the art. ​However, the paper is still not novel enough based on several existing works and could be strengthened by demonstrating more significant results instead of incremental, such as novel models or weaker conditions. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper studies the training and application of graph neural networks that are convex in their inputs. The authors present the network architecture and a few variants, along with computational results comparing them against \"vanilla\" graph neural networks.",
            "main_review": "The work is a natural combination of \"input convex\" and \"graph\" neural networks. The discussion of the novel methodology in this work is short (~1 page), and is surprisingly terse and informal given the space devoted to describing the existing work it builds upon. It appears that there is some care has gone into the computations, but the authors do not spend much time motivating the applications, describing any existing solution methods, or on explaining why graph neural networks are the right tools for the job (as opposed to vanilla feedforward NNs, or something else entirely). Without a firmer baseline, it is difficult to evaluate the merit or improvement offered by the new methods.\n\nOther comments:\n* p2: \"Furthremore\"\n* In Sections 3 and 4, the extensions from IC to PIC and ICR is a bit lengthy and fairly straightforward. Consider moving to an appendix.\n* Proposition 4: What, formally, is ICGNN? You state it is convex: what are the inputs and outputs? In Proposition 1 we had restrictions on the parameters--how should we understand Prop 4 as a restiction on the network parameters (or not)?\n* p4: What does \"convex path\" and \"non-convex path\" mean?\n* p5: You don't really describe how to train ICGNN; instead, you discuss training in the convex of a ICNN (e.g. in terms of W and sigma). How does this map to ICGNN? Where do the weights W appear? Etc. \n* p6: \"thier\" and \"hyperparmeters\"\n* Is there relevant prior art to motivate the applications, or compare your solution methods against? If so, cite it.\n* p12: Broken reference",
            "summary_of_the_review": "The paper is a novel combination of two proven types of neural networks, but the motivation for why this combination is an interesting one is a bit lacking, and the discussion of the novel methodology is very terse.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper adapts the input convex neural network (ICNN) framework to handle GNNs.",
            "main_review": "This paper adapts the input convex neural network (ICNN) framework to handle GNNs.\n\nThe paper is fairly well written, and the applications are interesting.\n\nI have a few comments only, mostly requesting clarifications:\n\nHow does the non-convexity of GNN hinder solving model-based control problems? Why not just apply SGD and solving, like any other ML problem?\n\nThere is a broad literature using GNNs in the realm of control that I believe is relevant for the problem at hand (especially given the emphasis of using ICGNN on control problems):\n\nJ. Paulos, S. W. Chen, D. Shishika, and V. Kumar, \"Decentralization of multiagent policies by learning what to communicate\" 2019 IEEE Int. Conf. Robot. Automat. Montreal, QC: IEEE, 20-24 May 2019, pp. 7990-7996.\n\nF. Gama, E. Tolstaya, and A. Ribeiro, \"Graph neural networks for decentralized controllers,\" in 46th IEEE Int. Conf. Acoust., Speech and Signal Process. Toronto, ON: IEEE, 6-11 June 2021, pp. 5260–5264.\n\nF. Gama and S. Sojoudi, \"Graph neural networks for distributed linear-quadratic control,\" in 3rd Annu. Conf. Learning Dynamics Control, vol. 144. Zürich, Switzerland: Proc. Mach. Learning Res., 7-8 June 2021, pp. 111–124.\n\nIn proposition 1 and 2, does the fact that the matrix is \"non-negative\" implies that it is elementwise non-negative? Or that it is positive semi-definite?\n\nPropositions 1 and 2: Please clarify convex with respect to what. Convex with respect to z_k? With respect to theta? With respect to x?\n\nMinor comments:\n\nSection 2.3 \"gradient\" is misspelled as \"graident\".",
            "summary_of_the_review": "The paper is fairly well written, and the applications are interesting.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}