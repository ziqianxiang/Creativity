{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper raises a novel question of how to discover meaningful representations from an untrimmed human kinematic video in a self-supervised manner. The proposed method ‘Temporal Alignment Network’ leveraged contrastive learning to learn the frame-wise and temporal aligned features. Additionally, the proposed methods achieved good results.",
            "main_review": "Strength\n\n(1)\tThe idea of considering the unsupervised action detection as the acton discovery is interesting.\n\n(2)\tThe lexicon building step is interesting and novel.\n\n(3)\tThe experimental results on the AIST++ dataset outperform the self-supervised sequence representation learning methods.\n\nWeakness\n\n(1)\tFrom the reviewer’s view, this proposed ‘acton discovery’ task is very similar to skeleton action detection. The authors are suggested to explain the differences between these two tasks, except for unsupervised.\n\n(2)\tThis paper is more related to self-supervised skeleton action recognition instead of self-supervised video action recognition. The authors are suggested to add the self-supervised skeleton action recognition in the related works. Additionally, TCN and TCC, which are used to compare on the AIST++ dataset, are designed for self-supervised video action recognition. Comparison with self-supervised skeleton action recognition methods is needed.\n\n(3)\tNormally, the ‘temporal alignment’ means doing the sequence matching and finding similar actions that happened on different time periods of two skeleton sequences. The reviewer is a little confused why using contrastive learning and only pulling two augmented sequence data’s same-frame features can perform the ‘temporal alignment’.\n\n(4)\tAs mentioned at the start of Section 3, there are five properties in representation learning. The reviewer wants to ask where is the ‘Intra-compactness and Inter-separability’ shown in this paper?\n\n(5)\tLeveraging the contrastive learning in video action recognition and skeleton action recognition is not a new idea, the reviewer does not think this part is novel enough.\n\n(6)\tThere are some better results on the PKU-MMD dataset and shown in [1], the authors are encouraged to compare with them.\n\n[1] Spatio-Temporal Attention-Based LSTM Networks for 3D Action Recognition and Detection. TIP 2018\n",
            "summary_of_the_review": "As mentioned in the ‘weakness’ part, the main contributions of this paper are (1) a new task and (2) the ‘temporal alignment network’ module. For the new task, I think it is similar to skeleton action detection. I am confused about the meaning of ‘temporal alignment’, and the contrastive learning used in this module is not novel enough, in my opinion. So I tend to give the ‘marginally below the acceptance threshold’ now.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a self-supervised representation learning method for primitive human action discovery (termed \"actons\").  The investigation is focused on 3D skeleton sequences of human actions.  The method consists of two disjoint steps: (i) frame-level representation learning using a transformer architecture (termed the \"Temporal Alignment Network\" and (ii) acton discovery by way of K-means clustering over all the encoded frames.  The method is evaluated on two datasets, AIST++ (dance focused) and PKU-MMD (51 varied actions).  The method is compared to several recent representation learning baselines and a moderate improvement on the chosen metrics over the (adapted) baselines is demonstrated.",
            "main_review": "Positives:\n\n+ paper is well written and easy to follow\n+ necessary ablations are presented that exercise the various dimensions of the proposed method\n\nNegatives:\n\n- novelty of method is limited\n- evaluation is limited\n- missing related work\n\nThe novelty of the method appears weak.  It combines the SimCLR self-supervised learning framework with K-means for prototype discovery on 3D skeleton sequence data.  How does the overall framework differ from [Nyugen et al. 2020]?  The current paper appears to follow the same framework.  Is the only key distinction the application domain?  Please clarify.\n\nOn the empirical side, how suitable is Kendall's tau to videos with repetitions?  Please discuss.  Overall, while the evaluation is promising, it is limited to two datasets.  Evaluation on additional datasets would strengthen the contribution, e.g., [a, b]. \n\n[a]  Kinetics-Skeleton (https://github.com/open-mmlab/mmskeleton/blob/master/doc/SKELETON_DATA.md)\n\n[b] Jun Liu, Amir Shahroudy, Mauricio Perez, Gang Wang, Ling-Yu Duan, and Alex C. Kot, NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding, TPAMI, 2020.\n\nGiven the paper's main claim is unsupervised learning action discovery, to contextualize the contribution a better coverage of the literature on the topic is suggested, see:\n\nAJ Piergiovanni Anelia Angelova Michael Ryoo Irfan Essa, Unsupervised Action Segmentation for Instructional Videos, Learning from Unlabeled Videos (LUV) Workshop, CVPR (2021) (and citations on unsupervised and weak-supervised methods within)\n\nalso consider related work on representation learning via alignment, e.g.,\n\nChien-Yi Chang, De-An Huang, Yanan Sui, Li Fei-Fei, Juan Carlos Niebles, D3TW: Discriminative Differentiable Dynamic Time Warping for Weakly Supervised Action Alignment and Segmentation, CVPR, 2019\n\nKaidi Cao, Jingwei Ji, Zhangjie Cao, Chien-Yi Chang, Juan Carlos Niebles, Few-Shot Video Classification via Temporal Alignment, CVPR, 2020.\n\nIsma Hadji, Konstantinos G. Derpanis, Allan D. Jepson, Representation Learning via Global Temporal Alignment and Cycle-Consistency, CVPR, 2021.\n\nalso related work on representation learning specific to skeletons is not adequately covered, e.g.,\n\nLilang Lin, Sijie Song,Wenhan Yang, and Jiaying Liu., MS2L: Multi-Task Self-Supervised Learning for Skeleton Based Action Recognition, MM, 2020.\n\n\n\n\n\n\n ",
            "summary_of_the_review": "Overall, I have concerns with the novelty of the method and the evaluation.  The method is a straightforward application of well known methods.  Please clarify the relationship between the current work and [Nyugen et al. 2020].  Is the main distinction the application domain?  With the limited novelty on the technical side, a larger burden is placed on the empirical side.  Here, the method is limited to two datasets, additional datasets would strengthen the paper's claims.  Finally, a better coverage of related work is needed (e.g., representation learning in the context of skeletons).",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This is an interesting paper that aims to action recognition/understanding from joint skeletons. However, it does this using longer-term sequences. To achieve this, it uses self-supervision in the training process through temporal alignment and then the clustering and mutual information and language entropy understanding of the clusters.",
            "main_review": "Positives\n\nThe performance seems to greatly improve over previous works on the published datasets.\nThe introduction of a temporal alignment phase, this self-supervised phase (standard contrastive learning via augmentations in rotation, translation and speed), is then clustered to perform the recognition of the dance genres.\n\nNegatives\n\nBehind the novel application/domain, the augmentation and clustering are pretty standard.\nThe comparison with the other approaches is primarily constructed baselines for this paper, not other works",
            "summary_of_the_review": "While the work is interesting and produces better results than the other presented methods, there is little novelty in the actual method as its \"just\" SIMCLR augmentation based self-supervised work",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}