{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents KGRefiner, which is a method that adds auxillary nodes in the original KG to improve the performance of existing KG embedding methods. The authors have shown that the KG embedding methods (TransE, TransH, TransD, RotatE) consistently improve performance if applied on the new KG enhanced by using KGRefiner. This phenomenon is very interesting, and it is good to know that we do not need to add too many edges to achieve the result. Time cost is also evaluated, which is good.",
            "main_review": "Strengths: see \"summary of the paper\" for the main strengths and contributions of the paper. It is interesting to see that such a simple method can result in consistent performance gain.\nWeakness: I think the contribution of the paper is a little in doubt, as there lack sufficient and fair comparison with the existing methods:\n1. The method improves accuracy by incorporating ontology-view KG with instance-view KG, which is very similar with JOIE [1]. I think JOIE did a better job in terms of presenting the problem and evaluation and the authors could take a look and see if it inspires you. The thing is that we can usually experience performance gain after integrating new data (ontology-view KG), right? So it is only fair if we also compare with TransE (or other KG embedding methods) on all KG (i.e., ontology+instance KG), right? I feel that these baselines are missing.\n2. The authors mention some other baselines like SACN and mentioned that SACN cannot generalize to other datasets. However, I do not see comparison with SACN even in FB15K237, which the authors say that SACN can be applied to. It will be better if there is a comparison or some discussions about why we do not consider SACN as a baseline.\n3. The authors report the time for deep models but not the accuracy. What is the accuracy for ConvE & ConvKB? Does the KGRefiner improve their performance for these deep models? I understand that the authors wish to propose a quick method, but the motivation of KGRefiner seems to be applicable on deep models, and it will be a little werid if KGRefiner cannot improve the performance of deep models, right? Also, it is a little difficult to understand why we need to decrease the training time from 40s or 279s to 5s, because 279s is acceptable for most people, right? I think it may be fairer if we draw a time-accuracy curve, and it will be great if RotateE+KGRefiner can outperform a simple ConvE or ConvKB with a small number of parameters and need around 5s to run.\n\n[1] Hao, J., Chen, M., Yu, W., Sun, Y., & Wang, W. (2019). Universal representation learning of knowledge bases by jointly embedding instances and ontological concepts. Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 1709–1719. https://doi.org/10.1145/3292500.3330838",
            "summary_of_the_review": "Strengths: important topic, interesting findings, intuitive and easy to implement methods.\nWeakness: lack of sufficient and fair evaluation, need better justification for motivation. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes KGRefiner, a method for augmenting knowledge graphs in order to improve the performance of translation-based knowledge graph completion methods. KGRefiner applies to knowledge graphs where entities have (potentially hierarchical) attributes, and the method uses these attributes as additional nodes in the knowledge graph. The attribute nodes are connected to the entities they are related to in order to augment the knowledge graph structure and provide entity type information that can aid in knowledge graph completion. KGRefiner is applied to commonly-used subsets of the Freebase and WordNet knowledge graphs, and is shown to improve the performance of a range of different translation-based knowledge graph completion methods.",
            "main_review": "The paper proposes a simple and intuitive method for augmenting knowledge graph structure in order to improve knowledge graph completion. The description of the method is clear, and experiments show the benefit of the KGRefiner approach across multiple datasets and translation-based knowledge graph completion methods.\n\nThe primary limitations of the work are limited technical novelty and lack of thorough experimental evaluation, particular a comparison that includes other knowledge graph completion methods. KGRefiner is proposed as a method of improving translation-based models, with the justification that these methods are faster than others. However, the proposed knowledge graph augmentation may also benefit other knowledge graph completion methods (perhaps even more than translation-based methods), and a performance comparison to these methods would demonstrate whether there is a tradeoff between the performance afforded by KGRefiner and the computational cost of training across methods. It is also unclear exactly how KGRefiner differs from other methods of using attributes to augment a knowledge graph with additional nodes/edges, such as the approach applied to FB15k-237 by Shang et al. (2019). The authors claim that the approach by Shang et al. is limited to FB15k-237, is too computationally costly, and is uninterpretable, but a direct comparison of the performance and computational cost of translation-based methods applied to this alternative attribute-based augmentation would help validate these claims. Finally, the justification for KGRefiner includes a description of how the approach might align entity representations according to entity type in the knowledge graph embedding space (Figure 1 in the paper). However, this is not followed up in the analysis - does this alignment actually occur? Investigating this through further analysis may help explain the observed performance improvements, especially if the goal is to present KGRefiner as a more interpretable alternative to existing knowledge graph augmentation approaches.",
            "summary_of_the_review": "While the proposed method is simple and the limited experimental results show that it improves performance, additional empirical evaluation and analysis is necessary to strengthen the work.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes to refine KG for better link prediction. In specific, the authors use two types of refinement methods: adding type information and remove noise. To achieve this, they refined FB15k237 and WN18RR manually and using pre-defined rules. Based on the two refined datasets, experimental results show improvements.\n",
            "main_review": "Weaknesses:\n1. The presentation needs polishment. For example, Fig.1 is rather vague. what do you mean \"two entities use the same relation\"? In the introduction, \"The (Moon et al., 2017)\" format is incorrect.\n\n2. Some claims are not accurate and backgrounds investigation is not sufficient. For example, \"previous link prediction methods did not notice that Paris is a city and France is a country.\". Actually, many KGE methods introduce type information, such as [1,2].\n\n3. Experiments are not convincing. The following important baselines are missing, and some variants of translational models should be considered, such as adding isA triples directly into the training set.\n\n[1] R. Xie, Z. Liu, and M. Sun, “Representation learning of knowledge graphs with hierarchical types,” in IJCAI, 2016, pp. 2965–2971.\n[2] Z. Zhang, F. Zhuang, M. Qu, F. Lin, and Q. He, “Knowledge graph embedding with hierarchical relation structure,” in EMNLP, 2018, pp. 3198–3207.",
            "summary_of_the_review": "See weaknesses.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed to enhance the translational distance models in knowledge graph embedding with adding new nodes and relations to graphs. The news nodes and relations come from the hierarchical information of entities. The experimental results show that the proposed refinement method can improve the results of baselines.",
            "main_review": "Strengths:\n1. The proposed method can be used as an additional preprocessing step for a lot of KGE methods, which improves its applicability;\n2. The results show that the proposed method can improve the performance of baselines on FB15k-237 and WN18.\n\nWeaknesses:\n1. The proposed method is based on the analysis on the two specific datasets, FB15k-237 and WN18. It is unclear if this method can be applied in other KGs.\n2. How do the authors get the hierarchical information of relations? Is this hierarchy also available for other KGs?\n3. Based on the proposed model in Eq. 4 and 5, it seems that the proposed new relation RelatedTo and new entity Country are unnecessary, as the model is actually learning to make France and Iran close to each other. Moreover, in Section 4.1, if the authors force $France+HasAttribute \\approx capital$ and $Paris + RelatedTo \\approx capital$ and these two equations should also hold for other (capital, country) pair, this again means that the model actually learns to make all capitals close to each other and all countries close to each other. If this is the case, then why not directly make the entities belonging to the same category close to each other? Why introducing new relations and entities?\n4. According to the experimental results, the proposed method does not performs well on FB15k-237 dataset.\n5. The language and figures in this paper need to be improved.\n",
            "summary_of_the_review": "In summary, the proposed method in this paper is too specific for the given datasets, and the method also has severe technic issues. The experimental results do not show that it can consistently improve the baselines. Moreover, the language and figures need to be improved. Overall, this paper is clearly below the standard of ICLR, and I vote for reject.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes to use the hierarchy of relationships and entities to refine knowledge graphs to improve link prediction.",
            "main_review": "Strengths:\n1. The idea of adding additional nodes in knowledge graph based on hierarchy structure for improving link prediction is interesting. \n2. It significantly improve the results of TransH on FB15K237 and TransH, TransD over WN18RR.\n\nWeakness:\n1. Section 4 about knowledge refinement using hierarchical relations is not clearly written. The author mentioned one example relationship \"entity→physical entity→object→location →region→area→center→seat→capital→national capital\". Where does this relationship come from? Is it manually extracted by authors? Or they can be obtained from external source? The authors also mention that they choose the last 3 levels and conduct filtering by 100 repetitions. However, there are no hyper-parameter analysis on how the number of levels or number of repetitions would affect the results.\n2. Experiment results are not promising. For link prediction on KG, MRR is usually the most important metric that people focus on. Base on this metric, the KGRefiner only improves the results of TransH and TransD, which are two underperforming methods compared to TranE and RotatE. Moreover, there exists other KG completion methods QuatE [1], which shows much better performance and still very efficient. \n3. Lacks of comparison with attribute based knowledge graph completion methods such as [2], since the added nodes can also be treated as attributes. \n \n[1] Zhang S, Tay Y, Yao L, et al. Quaternion knowledge graph embeddings[J]. arXiv preprint arXiv:1904.10281, 2019.\n[2] Lin Y, Liu Z, Sun M. Knowledge representation learning with entities, attributes and relations[J]. ethnicity, 2016, 1: 41.52.\n\n",
            "summary_of_the_review": "In summary, the idea of knowledge graph refinement using hierarchy structure of relations and entities is interesting but the performance is not promising, and the paper needs major revision about method introduction, related work discussion and baseline comparison.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}