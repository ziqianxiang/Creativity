{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper on hand, proposes a new approach for multiple instance learning, leveraging ideas from active learning. In this way, a small subset of instances is sampled for further annotations. Backed up by related work (from MIL and AL) the approach is deduced and evaluated for simple, but well-known benchmarks, demonstrating that over time better results can be obtained.",
            "main_review": "The paper on hand combines ideas from multiple instance learning and active learning and demonstrates that this combination could be beneficial in practice. On the positive side, the approach is backed up by proven theory and the experimental results demonstrate the claimed benefits. In addition, a thorough discussion on related work from both domains is given. On the negative side, however, the paper is lacking a clear structure and a clear summary and conclusion. To this end, many important details are just given in the appendix, which many readers would not read.  Moreover, the experimental setup is not fully clear.\n\nFurther Comments:\n\n(1) The beginning of the introduction needs to be restructured such that terms that are discussed are introduced before. It does not make any sense arguing about the properties of a bag if this is introduced later on? On the other hand, the reader would be familiar with the main concepts of MIL and thus such basic definitions could be left out?\n\n(2) Using a theorem without a proof does not make any sense. In particular, it is unclear why Eq.(4) is highlighted in this way?\n\n(3) There are many abbreviations used might would need to be introduced at some points, such as \"DRBL\" or \"P-F samling\".\n\n(4) Referring to (2) and (3), having an appendix covering the most relevant aspects of the paper does not make any sense? In particular, it the appendix would not be covered in a camera-ready paper. Overall, it might be better to resubmit the paper to journal presenting all necessary information on a decent detail level?\n\n(5) The x-axes in the figures would be easier to read if the numbers are rotated.\n\n(6) In general, a more thorough comparison to related approaches would be of interest.\n\n(7) The meaning of Fig.5 is not fully clear.\n\n(8) The mathematical writing must be seriously checked.\n\n(8) The bibliography needs to be seriously checked for consistency and correctness!",
            "summary_of_the_review": "The overall idea of the paper is interesting and also the first sketch of experimental results shows that the approach would be meaningful. However, the paper is suffering from clarity and clear structure. Thus, either the key aspects have to be described more concisely or the paper should be extended to a journal version covering all aspects. Thus, the main idea is clearly appreciated, however, in its current form, the paper is not ready for publication.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes an active deep multiple instance learning (ADMIL) model that samples a small subset of informative instances for annotation, includeing a variance regularized MIL loss and a P-F sampling function to effectively explore most challenging bags.",
            "main_review": "1. Many opinions in the article are only statements and lack the support of actual experimental data. For example: \n(1) Why this method can it robust to outliers and multimodal scenarios?  Then for these outliers and multimodal scenarios, what is the difference between the score distribution of the previous method and the distribution of this method?\n(2) In 3.3 P-F ACTIVE SAMPLING, What is the approximate ratio of these three bags? What are the detailed experimental differences between the previous method and this method in the three types of bags?\n\n2. The setting of this article lacks practicality. In the era of big data, the cost of fine-grained annotation is getting lower and lower, and a large number of large data sets with many categories and fine annotations have appeared, such as COCO and Kinetics 700. The setting of active learning on Pascal VOC can refer to [1].\n\n3.The related content of Figure 1 is confusing, and the content needs to be reorganized. Figures 1 and 6 are examples, and the situation of a lot of data needs to be analyzed.\n\n[1]Yuan, Tianning, et al. \"Multiple instance active learning for object detection.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\n",
            "summary_of_the_review": "Overall, I think the paper lacks deep analysis to explain the effectness.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper tries to improve instance-level prediction in multi-instance learning. Specifically, this paper proposes an active deep multi-instance learning model. A variance regularized loss function is designed to effectively accommodate the highly imbalanced instance distribution. It optimizes a distributionally robust bag level likelihood as its convex surrogate. Based on that, a novel P-F sampling function is developed that combines a probability vector and predicted instance scores, obtained by optimizing the robust bag likelihood. Experiments conducted over multiple real-world datasets clearly demonstrate the state-of-the-art instance-level prediction achieved by the proposed ADMIL model.",
            "main_review": "Strengths:\n+ The overall idea is neat, simple and effective.\n+ Experiments show the effectiveness of the proposed method in instance-level multi-instance learning.\n+ DRBL loss is elegant and theoretical analysis is convincing.\n\nMy main concerns are on the writing quality:\n+ This paper is not very easy for me to follow. I suggest the authors improve the paper in a future version.\n+ The motivation is not very clear for me. Why do you use the variance term in the loss function? It is very important to be explained clearly.\n\nOverall, the idea in this paper is interesting but I think it needs to be polished to tell the story to the readers.",
            "summary_of_the_review": "I think the idea in this paper is neat, simple and effective. My main concern is on the writing quality. Thus I think this paper is marginally above the acceptance threshold.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethics concerns",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper introduces an active learning model to learn to annotate instances in a bag. The bags are annotated with the Multiple Instance Learning (MIL) formalism. The authors proposed the distributionally robust bag level likelihood (DRBL)-based MIL loss. They also proposed the P-F active sampling which is used to select the instances to annotate. The proposed approach is evaluated on 20NewGroup, Cifar10, Cifar100, and Pascal VOC. ",
            "main_review": "**Strengths**\n\n- I like the idea of learning the instances to annotate. This number can change for each bag so easy bags have few annotated instances whereas difficult bags have more annotated instances.\n- The authors derived a new loss function: the DRBL-based MIL loss. They also give some theoretical guarantees about this loss function. \n- The authors introduced a new sampling function to select the instances to annotate\n- The authors analyzed the hyper-parameters lambda and beta. \n\n**Weaknesses**\n\n- I am not sure why it is important to have a convex loss function. The author should motivate the importance of this design. The objective function optimized in the experimental section does not seem convex due to the neural network architecture. \n- The authors should clarify the connection with (Duchi & Namkoong, 2019). It is important to explain the novelty w.r.t. this paper.\n- Overall, I think the experimental session should be improved because it is not very convincing.  \nActive learning is a topic that exists for a long time, and a lot of works have been published. I think it is important to compare the proposed approach with some recent active learning algorithms. \n- The proposed approach annotates some instances. I think it can be a good idea to report the results of some state-of-the-art MIL models. It will give a lower bound and can help to understand the potential impact of the proposed approach.\n- There is no comparison with already published results so it is quite challenging to understand the potential strengths of the proposed approach. \n- I think the writing in the paper can be improved. For example, the authors should clarify that the goal is to do instance classification which is quite different from MIL that does bag classification. It is a bit confusing to have a model named ADMIL but it is not evaluated for bag classification which is a standard MIL task. However, I agree that if you have a good instance classification model you can do bag classification. Some notations can be improved. For example with the current notations, the loss in equation 5 takes a positive bag as input but the positive bag does not appear on the right side which makes that equation hard to understand. \n- I wonder what is the scalability of this approach. The model is evaluated only on small datasets. I wonder how it scales to larger datasets like ImageNet, or when the bags are large.\n- I think it can be interesting to analyze the diversity of the selected instances. The authors mentioned that diversity is important but there is no empirical result to confirm it. \n- I think it can be good to show the variance in figure 3. It is likely that the random sampling has a non-zero variance. \n- The proposed approach seems to be quite sensible to the hyper-parameters lambda and beta\n",
            "summary_of_the_review": "Overall, I think the proposed idea in this paper looks interesting but it lacks some information to understand its potential impact. In particular, there is no comparison with some state-of-the-art active learning algorithms.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}