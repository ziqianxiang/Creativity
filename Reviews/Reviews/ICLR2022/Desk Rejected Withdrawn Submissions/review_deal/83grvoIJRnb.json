{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposed an end-to-end one-stage scene graph generation framework based on heavy usage of transformers (cross attentions). The proposed method first utilizes a CNN backbone with self-attention to extract a relation-specific feature map. Then, a DETR-like entity detector detects object candidates from the feature map. Subsequently is a compositional triplet constructor that utilizes compositional triplet query representation, which differs from previous holistic triplet queries, and uses an encoder-decoder manner to generate triplets predictions. The final component is a scene graph assembling module that assembles scene graphs from the generated triplet predictions using correspondence matching.",
            "main_review": "Strength:\n- This paper achieves SOTA results with solid quantitative comparisons in the scene graph detection task. Being a one-stage method, It reaches comparable performance with two-stage methods.\n- Attention maps well demonstrate the interpretability of the proposed method.\n- The effectiveness of component modules is empirically and quantitatively well studied in the ablation section.\n\nWeaknesses:\n- The method section (section 4) is not well written with several not-well-stated approaches, confusing grammar mistakes, ambiguous notations, and non-corresponding figures and texts. Some additional declarations or illustrative figures and refinement of the writing are needed.\n  - In section 4.2.2, the structure of the dynamic triplet query generation is not trivially understandable. In Fig.1, the input of DQG is \"initial triplets query\", and the output is \"dynamic triplets query\". But in Sec.4.2.2., there is no clue that suggests what $Q_{tri}$  means and what $\\tilde{Q}_{tri}$ means (the readers can only guess that $Q_{tri}$​ is probably the \"initial\"). Some declarations or illustrative figures might help. \n  - In section 4.2.3 -> predicate Sub-decoder, what does the \"supervision\" in \" ... of its associated boxes as **supervision**\" mean? Are there additional pre-training steps here to learn $\\tilde{Q}_{tp}$? What exactly does \"To learn the representation of predicate query $\\tilde{Q}_{tp}$​\" means? \n  - In section 4.2.3 -> Entity Sub-Decoders, a grammar mistake possibly exists in the line \"cross attention **between** the entity queries of ... **between** the entity representation ...\". By \"between ... between ...\", I suggest the authors mean \"between ... and ...\". In other words, the second \"between\" in this sentence might be a typo for \"and\".\n  - In section 4.2.3 -> Query Refinement, it is unclear that when does \"query refinement\" happens and how does it affect the framework, in both the paragraph and Fig.2(a).  $Q^{l+1}_{tp,ts,to}$ only occurred once in the figure, and there seems to be no subsequent modules that use $Q^{l+1}_{tp,ts,to}$ as input. Do the authors mean iterative updating these varaibles?\n  - The notation in Fig.2(a) is confusing. I am guessing that the output of the \"compositional triplet decoder\" is \"$\\{P_p, B_s,P_s,B_o,P_o,B_p\\}$​\", but in Fig.2(a) it appears to be \"$Q^{l+1}_{ts,tp,to}$​\".\n  - $\\mathcal{F}$​  only appears in Fig.2(a) throughout the whole paper. I am guessing it should be $\\mathcal{H}$, from Section 4.2.3 -> Query Refinement.\n- Inference time is unclear. What is the unit of \"time\" in Table 1? What is the inference time of previous one-stage methods and two-stage methods? There should be more solid comparisons among the inference time of the proposed method, previous one-stage approaches, and previous two-stage approaches since \"efficiency\" is one of the biggest sell-point.\n- Missing ablations.\n  - In the proposed method, the authors use a DETR-like detector to detect entity candidates, and stated: \"any alternative one-stage detector can be used here\". There should be ablation studies with alternative one-stage detectors that empirically clarify whether the performance boost is due to the proposed novel contributions or due to the use of a DETR-like detector.\n  - The ablation studies show the quantitative effects of the component models. Additional visualizations of ablation studies would be nice. For example, a visualization of the attention maps comparison of \"dynamic triplet query generation\" against \"holistic triplet queries\" will better demonstrate the effectiveness of using the proposed dynamic triplet queries, like Fig.3.\n - The proposed method uses the Transformer-based component, which has been proven as a powerful part. Therefore, there needs a baseline that only uses the transformer or just ablates the transformer part to verify the effectiveness of other proposed components. \n",
            "summary_of_the_review": "The performance of the proposed method is superior. However, there are two main problems. Firstly, the methodology part is not clearly stated, which makes it hard to understand the details of the proposed method. Secondly, the ablation study needs more items to show the effectiveness of the proposed method. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors propose a new one-stage method for Scene Graph Generation (SGG) by using DETR. The method develop a decoding-and-assembling paradigm and a set of dynamic triplets queries rather than the prevalent triplet queries. Experiments show improved accuracy and inference time compared to the state of the art.",
            "main_review": "** Strength **\n1. The method use a set of dynamic triplets queries rather than the fixed triplet queries. This design sounds interesting.\n\n2. The authors reproduce many methods for HOI on SGG dataset. I think this work is well engineered.\n\n3. The body part of this paper is well-written.\n\n** Weakness **\n1. The graph assembling design may cause misleading on performance:\n\nThe post-processing assembling in many previous works [1,2,3] adopt the minimum matching cost between detected objects and interaction predictions, rather than top-k. All of them tend to avoid too much predicates in one pair by using this optimal matching.\n\nGenerally, the performance of SGG with multiple predicates in one triplet are much better than that with single predicate in one triplet. [6]\n\nThe graph assembling in this paper allocates $K$ subjects and objects to each predicate. Then, the authors take $K \\cdot N_r$ triplets for evaluation. So it actually breaks the rule that limits the number of predicates in one pair to a low level. The multiple predicates definitely lead to higher performance than any other method.\n\nIn a nutshell, it is necessary to use the optimal matching in assembling like HOTR [2] for comparison with these methods. At least this will prove the gain of performance is from the new matching cost, instead of the top-k trick.\n\n\n\n2. The authors do not discuss how their work outperform other methods in detail. Why is the performance quite higher on mR but lower on R relative to other model such as BGNN [5]? Some other detailed analysis should also be done. For instance, visualization, analysis on visual relationship detection quality, etc.\n\n\n3. More ablation studies should be done. The authors show the enough complicated triplet matching cost in the supplementary, especially the modified GIOU cost and predicate cost. So why devise such a complicated cost? The matching cost selected in the previous transformer-based works are relatively simple [2,3]. How performance varies if the matching cost is changed into the plain format? Some ablation studies should be considered.\n\n\n4. The lack of comparison. A lot of baselines are only compared on X101-F but not on R101 backbone in Tab. 1. Some classic and powerful methods such as Motifs [6] and VCTree [7] are not contained in Tab. 1.\n\n\n5. Some reference links are not properly displayed in the supplementary. Many citations in the supplementary are in form of question mark in this PDF.\n\n\n6. Some description are not easy to understand. In the supplementary, the meaning of this sentence is not clear: \"To circumvent this, we relax the matching threshold to prevent the NMS mechanism from learning.\" Does it mean using the post-assembling to replace NMS?\n\n\n\n\n[1] Liao, Yue, et al. \"PPDM: Parallel Point Detection and Matching for Real-time Human-Object Interaction Detection\". CVPR 2020.\n\n[2] Kim, Bumsoo, et al. \"HOTR: End-to-End Human-Object Interaction Detection with Transformer\". CVPR 2021.\n\n[3] Chen, Mingfei, et al. \"Reformulating HOI Detection as Adaptive Set Prediction\". CVPR 2021.\n\n[4] Tang, Kaihua, et al. Unbiased Scene Graph Generation From Biased Training. CVPR 2020.\n\n[5] Li, Rongjie, et al. \"Bipartite Graph Network with Adaptive Message Passing for Unbiased Scene Graph Generation\". CVPR 2021.\n\n[6] Rowan Zellers, et al. \"Neural motifs: Scene graph parsing with global context\". CVPR 2018.\n\n[7] Tang, Kaihua, et al. \"Learning to Compose Dynamic Tree Structures for Visual Contexts\". CVPR 2019.",
            "summary_of_the_review": "See above.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "In this paper, a one-stage framework of scene graph generation is proposed. The method is based on DETR’s philosophy, viewing scene graph generation as a direct set prediction. With the compositional triplet queries and several decoders, the model can output the triplets directly. The authors evaluated the model on VG and OpenImages V6 and their SGTR demonstrates good performance.\t",
            "main_review": "Strengths\n\na. With the query-based detection system, the complexity of relationship inference the is reduced. Without considering of the proposed Scene Graph Assembling, the complexity is reduced from O(n^2) to O(n). \n\nb. The subject/object queries do not directly work on the feature map, but the predictions of the entity detection. This could provide more accurate location/category information.\n\nc. The paper is well-structured \n\n\n\nWeaknesses\n\na. It is not clear if the triplet encoder has the same structure as DETR’s encoder (in the paper the authors say: Using a similar structure...). The author define A(x,y,z)=FFN(MHA(q,k,v)). Does it mean that the residual connection is removed? If there is the residual connection, please reformulate it. If the triplet encoder is the same as DETR’s encoder (only different weights), it looks a bit redundant. \n\nb. The authors use subject/object/predicate queries rather than holistic triadic queries. However, these queries cannot be understood in relation to each other due to permutation invariant. The authors’ original design intention was: for example the first subject, object, predicate query interact with entity and encoder features to get the first triplet. But in fact, when the first subject query interact with entity features, the model doesn’t know which object/predicate query is connected with the first subject query. Although the information between the S/O/P queries is exchanged in Query Refinement, The impact of this design flaw is still difficult to eliminate. This is also evidenced in Figure 3 in the paper: The attention of the predicate does not overlap with the subject/object (man walking on street but the building gets attention/ person sitting on sidewalk but tree gets attention).\n\nc. In the ablation study (Table 3), without Graph Assembling the performance drops to R50=7.3. It demonstrate that E/D/P (main contributions) do not work well. I think this is caused by the cause listed above in Weakness (b). I cannot understand why the model with Graph Assembling performs R50=23.3. This module is not involved in training, only samples some entity predictions?\n\nd. The widely-used R50/R100 should also be compared in Table 1. It is necessary to discuss why SGTR has a very high mR50=17.6 (GPS-Net 7.4) while R50=23.3 (GPS-Net 28.9) is lower than other baselines.\n\ne. Please indicate which GPU is used to measure the inference speed. Are all the models tested on the same GPU?\n\n\nFurther comments\n\nI found some typos (not all), please correct it:\na. In Fig 1 SGC or SGA? DQG or DQG?\nb. Fdet or Fdec in Eq.1\nc. In the abstract: “...queries significantly improving...”\nd. In the introduction: “...scene graph generation (SGG) lying in...”\ne. In the introduction: “...develop a assembling scheme...”\nf. In 4.2.2 “such an holistic triplet”\ng. In 4.2.3 “...sub-decoder can be summaried”\nh. In 4.2.3 “between the entity queries of...between the entity representation”\n",
            "summary_of_the_review": "While well written in general, this paper suffers some main technical flaw, see weakness (b) above. I think this is a potential work towards one stage scene graph generation, when the flaw is addressed appropriately. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "none",
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes to generate image scene graphs by learning compositional queries with Transformers. The proposed scene graph generation method is motivated by DETR object detection framework. In essence, it produces a set of visual relations predictions utilizing detected object semantics. Finally, to mitigate the problem of redundant prediction of the same object in the set of visual relations, a scene graph assembling module generates one graphs from the set of triplets. The proposed method achieves good performance on class-balanced metrics (mean Recall)on Visual Genome. It's performance is also reasonable for non-class balanced metrics like Recall. ",
            "main_review": "The most important component in the framework is the scene graph assembly mechanism which is evident from their ablation experiments, without this assembling mechanism the SGG performances are significantly worse.  This essentially means that the subject/object predictions in the set of triplet predicted triplets are to be blamed for. This module involves top-k index selection procedure. I am not sure if this module is completely differentiable, if not it breaks the initial claim of this method being fully trainable. Since the Triplet Constructor uses the entity semantics as input, I am not fully convinced that it's a one-stage design. \nThey report reasonably good inference time. \nI appreciate the authors mentioned about a similar line of work in HOI. In particular I'd like to see how does an approach similar to HOTR performs for SGG. Conceptually, HOTR is simple to understand. \n\nIt appears that the manuscript has been written in a haste. There are plenty of grammatical errors that hinder the flow of the paper. A few examples are as following:\n“the main challenge of scene graph generation (SGG) lying in” =>  “... lies in ”\n“A assembling scheme” => “an assembling scheme”\n“This module enables our method produce scene graphs with proper graph node-edge consistency rather than heuristic post-processing” => “... to produce ...” ?\nFig 1: The caption reads QDG, it should be DQG. the caption also reads SGC. Shouldn’t it be SGA?  \n“We denote the The refinement process can be formulated as: “ … clearly a hindrance to the reading of the paper\n“We takes the entity prediction .. “ =? \"we take ..\"\nF-top is the top-K index selection operation for the scene graph assembling module. How can this be end-to-end trainable ?\n“Our method strong relie .. “ \n\n\n",
            "summary_of_the_review": "I am not entirely convinced about the method being a single-stage one. Object detection entity features are used for the triplet constructor block. Thus they aren't two parallel or independent paths. The method is inspired by transformer based object detection, specifically visual relations set prediction. Overall, this paper has merits, technical novelties but it appears to be way more complicated than it is necessary. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}