{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes an alternative approach to training deep latent generative models, named Auxiliary Supervised Learning (ASL). The authors make use of the obvious fact that if the latent representations are given (via some pre-trained encoder) then learning the generative model becomes a much easier task; $\\max \\log p(x_n,z_n) \\ \\text{for }n = 1 \\cdots N$. In other words, the unsupervised learning problem which involves a difficult integral is transformed into a supervised learning problem. To train the distribution $p(z)$, the authors propose to use a flow. With regards to how to obtain the encoder to generate the latent representations $z$, the authors discuss various approaches including a new approach which is obtained by optimizing a (novel to the best of my knowledge) bound on $I(x,z)$. The authors then perform some experiments on toy-datasets as well as FashinMNIST and CIFAR-10 in order to demonstrate that the new model is able to generate samples with reasonable quality.     \t",
            "main_review": "**General Comment**\t\n\nWhile I beleive researching new methods to train deep latent generative models to be very important and of interest to the ICLR community, I am not sure the current draft meets the bar of an ICLR submission. What I see the major problems with this paper are the following:\n\n- It seems to me that this paper reverses the problem of representation learning via deep generative models. Many of the common use cases of deep generative models are in fact *not*  generation, but focused on the representation learning aspect (e.g. the literature on disengagement. topic modelling, clustering, scene understating, ….). And one of the main reasons we train generative models is with the hope that the posterior of the learned model represents meaningful features about the data and has a good notion of uncertainty. The current paper is trying to solve the inverse problem which is: if we already have good features, can we train a good generative model. I am not necessarily saying this problem does not make sense, however, it should be mentioned that this drops many of the use cases for why people use models such as VAEs. In fact, the part I enjoyed most about the paper was Section 3.2 which discusses a new approach to learn representations via MI maximization. I am not very familiar with the MI estimation. Assuming that the proposed model in Section 3.2 is novel, I would rewrite the paper around Eq.3, but that requires another revision. \n- Even solely focusing on generation, I don’t see this approach competing with other generative models such as GANs or flows, given the likelihood is still defined at a pixel-level. The only VAE based approaches that are able to compete in terms of generation are hierarchical VAEs such as NVAE which has many layers of latent representations and I do not see an easy way of extending the proposed approach to hierarchical generative models. \n- With regards to novelty, I find this paper more of a *framing* of existing objectives rather than a new model. For example, the log-likelihood $\\mathbb{E}_{q(z|x)}[\\log p(x|z)]$ in VAE can also be interpreted as a supervised task where $z$ is generated from the encoder. In other words, how much ASL is different from a VAE that is trained by first training the encoder fully and then the decoder? I understand the prior on $u$ here is a flow but this prior has also been used in VAEs as well [1].\n- In my opinion, the experiments do not show enough evidence that there is much gain. There is no quantitative comparison in terms of generation. It is hard to tell for me from Fig 6, if the 2-stage VAE is any worse than ASL. And the baselines here are mostly very simple.\n\n**Clarity**\n\nThe paper is very well-written. Good job!\n\n**Questions**\n\n- Could the authors expand on the choice of $u \\sim f(x,\\epsilon)$? Why not simply use a re-parameterized Gaussian? How much would this matter? Sorry if I missed this in the paper. \n- Is there a particular reason for why the notation was changed from $z$ to $u$ for the latent representations? \n\n\n**References**\n\n[1] Bauer, Matthias, and Andriy Mnih. \"Resampled priors for variational autoencoders.\" The 22nd International Conference on Artificial Intelligence and Statistics. PMLR, 2019.\n",
            "summary_of_the_review": "See **General Comment**",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "\nThis paper takes on the problem of training deep generative models, building on the probabilistic framework of variational autoencoders (VAEs, Kingma & Welling '14). That is, given a large high-dimensional dataset of feature vectors x and a desired latent variable model with low-dimensional encoding variable u, the problem is to produce an \"encoder\" and \"decoder\", which allow generating samples or reconstructions and (potentially) computing likelihoods for given features.\n\nClassically, the VAE trains the encoder and decoder simultaneously to maximize a lower bound on the log-likelihood of the data under a latent variable model that assumes Gaussian noise. The claim in this paper seems to be that even though the VAE allows very flexible mean functions in the generative model via neural nets, the Gaussian noise assumption may be too limiting.\n\nTo overcome the weaknesses of VAEs, the paper suggests a two-stage process called Auxiliary Supervised Learning (ASL) to fit a deep generative model.\n\nStep 1: Train an \"encoder\" and a \"decoder\", using any desired objective, such as:\n\n- maximize ELBO (like a classic VAE)\n- maximize a new unbiased bound on Mutual Information (MI, see Sec. 3.2)\n\nStage 2: Freeze the pretrained encoder from step 1 -- which defines p(u|x) -- and then use samples from this encoder to produce refined models for p(u) and p(x|u) the decoder. In stage 2, the two models can be updated separately in parallel, because given an encoder, each update is decoupled from the other.\n\nThe models for p(u) and p(x|u) in this second stage are flexible:\n- Marginal density estimation for p(u) can be done via a normalizing flow or other sample-then-transform explicit likelihood model\n- Conditional density estimation for p(x|u) -- called \"supervised learning\" in the paper -- could also use a flexible model, but for experiments it seems the probabilistic model chosen is like a classic VAE decoder with mean determined by a neural network and Gaussian noise.\n\nExperiments examine the visual quality of generative samples and reconstructions, compared to classic VAEs and to normalizing flows.",
            "main_review": "# Strengths\n\n+ The new bound on mutual information (MI) that can be used to train probabilistic encoders and decoders is potentially interesting and broadly useful\n+ Toy dataset experiments are nice for building some intuition\n\n\n# Weaknesses\n\n- W0: Clarification / ablation studies needed to understand the value of stage 2\n- W1: Conceptual justification of why the second stage procedure is valuable is missing\n- W2: Need to cite related work on improving VAE optimization of encoder/decoder\n\n## W0: Clarifications and ablations needed to understand the value of stage 2\n\nStage 1 (VAE or MI) produces an encoder and a decoder, as well as an initial marginal p(u).\nStage 2 (ASL) produces a latent variable marginal p(u) and a refined decoder p(x|u).\n\nI think readers would benefit from knowing which products from each stage are used in each experimental result. For example, to make a \"reconstruction\" (as in Fig 5), I think you need the new decoder but not the marginal p(u).... is that right? Because you are given the image x, and you just sample from the encoder and then from the decoder.\n\nI suggest in each figure/caption, you point out exactly how the result benefits from the ASL procedure (does it use the new p(u)? does it use the new p(x|u)?)\n\nI also suggest you consider making side-by-side plots that show various \"ablations\", such as:\n\n- Showing a result from using the MI objective in stage 1, without ASL stage 2\n- Keeping the marginal from stage 1 fixed, and showing a result with stage 1 and stage 2 decoders\n- Compute the training-set ELBO using the encoder from stage 1, and the decoders from stage 1 (classic VAE) and from stage 2 (your VAE+ASL). This will suggest if stage 1 optimization is delivering the best possible solution (I hypothesize it is not, see W1 and W2 below).\n\nWithout these clarifications, it is difficult to understand why some results look better than others.\nI particularly wonder if the MI objective alone might somehow produce good results without the need for further ASL refinement.\n\n\n\n## W1: Conceptual justification for the second stage is inadequate : Is the improvement from Representation, Objective, or Algorithm?\n\nWhy should we expect that given a fixed encoder (which essentially freezes the joint distribution p(x,u) you are trying to model), that the second stage refinement of the decoder p(x|u) should produce a better model than the original decoder training process?\n\nFrom what I can tell, the decoder used here is still using Gaussian noise and the same architecture as in stage 1. Thus, the representations used here are the same as in stage 1, and if the new decoder is \"better\" after stage 2, shouldn't the decoder produced by stage two also be considered better under the original objective used to pretrain in stage 1?\n\nMy hypothesis is that, if you use a classic VAE in stage 1 and then refine as proposed in this paper in stage 2, that the improvements seen in the experiments are really just due to the fact that the stage 1 optimization is notoriously bad at producing high-quality decoder/encoders (see W2 below for literature). Thus, if you had a better algorithm for stage 1 (or simply just ran stage 1 longer to get better convergence), I suspect you'd get similar gains to your ASL-VAE.\n\nIn the rebuttal, I hope the authors can clarify: Is the improvement from a new representation/model? Or do you agree with my understanding that we're really just overcoming an algorithmic deficiency from stage 1 (the stage 1 objective is good, but the algorithm cannot find great solutions)?\n\n\n## W2: Missing connections to previous literature on improving VAE encoder/decoder optimization\n\nThere is substantial literature that suggests that the usual simultaneous gradient-based training of both the encoder and decoder in VAEs has problems due to the two models falling out of \"sync\" (the encoder is not a good approximation of the posterior implied by the decoder, or vice versa). As a remedy, the literature suggests that interleaving different updates or subtly adjusting the objective during training can somewhat fix the poor performance of the resulting encoder/decoder.\n\nFor example, see the studies\n\n- Lagging Inference Networks and Posterior Collapse in Variational Autoencoders (He et al. ICLR 2019)\nhttps://arxiv.org/pdf/1901.05534.pdf\n\n- Semi-Amortized Variational Autoencoders (Kim et al. ICML 2018)\nhttps://arxiv.org/pdf/1802.02550.pdf\n\n- Cyclical Annealing Schedule: A Simple Approach to Mitigating KL Vanishing (Fu et al. NAACL 2019)\nhttps://arxiv.org/abs/1903.10145\n\nLike the present work, these works alternatively freeze one part (encoder or decoder) and update the other, or otherwise interleave standard joint gradient updates with other updates. Substantial gains in VAE solution quality result, because the optimization algorithm is better at finding solutions (using the original standard VAE objective).\n\nI'd like the authors to comment on how they see their proposed method (which freezes the encoder and only refines the decoder) as compared to these ideas (which perform more extensive algorithmic adjustments).\n\n",
            "summary_of_the_review": "Overall I think the paper has some interesting insights (especially the new lower bound on the Mutual Information, which could be a contribution on its own if properly elaborated). However, I don't think the paper adequately explains the value of the \"stage two\" ASL procedure (the refinement of p(u) and p(x|u) given a fixed encoder). I have concerns about both the conceptual justification and the experimental justification of stage two, and I think there are missing connections to the growing literature on improving optimization of VAEs that would be essential before a version should be accepted.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a new way to train deep generative models by framing the learning problem as a supervised learning algorithm.\n\nSince p(x,u) = p(u|x)p(x), they first pretrain an encoder p(u|x), then draw a dataset (u,x) with x ~ p(x) and u ~ p(u|x), then learn an unconditional model p(u) and a regression model p(x|u).\n\n",
            "main_review": "Overall, I like the idea proposed in this paper. However my review changed significantly (from an accept to a reject) once I have seen the experimental section, which I don't find enough. This is the main weakness in the paper, and I provide the reasons later in this review.\n\nFirst, some comments. I think introduction should cite diffusion probabilistic generative models and autoregressive models, which are the other main family of deep generative models (first paragraph in the introduction).\n\nI find section 2.2 incorrect. I don't agree with the fact that in a supervised learning algorithm  we assume that p(y|x) is concentrated around its mean value, and that the standard deviation is unwanted. This has to do, with the fact, that usual training criteria such as L_2 norm assumes p(y|x) is Gaussian, and optimal Bayes decision theory tell us that we should predict the mean (when we use an L2 loss function in our Bayes rule) in order to minimize the error probability. But in my opinion this is not something inherited form the supervised learning algorithm but from the decision we want to make with our trained model. Actually, one is free to learn the conditional variance from p(y|x,sigma) as practitioners do, for example, with Gaussian processes. So in general I think that the paper claim:  \"Therefore, the ASL framework is meaningful when the conditional distribution px|u(x|u) has a small uncertainty.\", should be justified in another way. Actually I dont understand what the authors want to tell us here. I recommend clarifying this point.\n\nAnother thing I think the authors should somehow motivate/clarify is related to section 3.1. The authors claim (based on a reference) that a VAE with latent_space > observed_space  can optimally reconstruct X. However, earlier in the manuscript they motivate the need of observed_space >> latent_space so that the density estimation of p(u) is easier. So I dont really see the point of section 3.1 Perhaps the authors should use a VAE with latent_space <<< observed_space and use a normalizing flow to enhance the representation power of q(z|u) in order to obtain a more optimal VAE for their comparison\n\nI think there is an error in figure 5. Isnt the figure of the middle the figure MI-ASL rather than VAE-ASL? I find the figures from the middle sharper.\n\nI think the experiments are not enough. I think that to provide more light into the framework some likelihood values should be provided on a test set, and compare with other deep generative models where likelihoods can be estimated such as: VAE ,normalizing flows or autoregressive models.  And also perhaps adding one or two more datasets such as CIFAR10. Also I think it will be meaningful to compare the likelihoods assigned to out of distribution samples with other models so that we can also see how this new deep generative framework do on this task.\n\nNote that I dont really expect the framework to be better just to be accepted for this conference. I like the idea so I am just asking to see at which point is this new deep generative framework in comparison to others. I think this is an important point to set the base for future research on this family of generative models. Hence I cannot recommend accepting the paper in its current form. If all my concerns are addressed I'd change my score to an accept. Unfortunately, I think there is no time enough to complete all the things I'd expect to see. \n\n\n",
            "summary_of_the_review": "\n- Some small issues to correct \n- Experimental evaluation is clearly missing important points to provide light into the proposed approach.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper introduces a method for training deep generative models with a latent variable structure by individually training the components (encoder, decoder and prior). The authors frame this as first training an encoder to generate latent samples and then treating training the decoder as a “supervised” learning problem. The authors then introduce a mutual information-based training objective for training the encoder. The authors show reconstructions and samples on Fashion-MNIST and CelebA as well as a few synthetic datasets to support their claims.",
            "main_review": "As I mentioned in my summary, it seems to me that, in the VAE-ASL case, this approach simply boils down to training a VAE, then holding the encoder fixed and continuing to train the decoder. Possibly also training a more expressive density for the prior p(z). I honestly don’t find the motivation for this approach convincing. The motivation as described in section 2 comes down to the assertion that supervised learning is inherently easier than unsupervised learning, which is a very broad and not necessarily true claim. The authors don’t really make any theoretical claims about why, all else being equal, this 2-stage process would produce better results. They do state that their approach is meaningful if p(x|u) has small uncertainty, but I don’t see how this changes from standard VAE training. My intuition is that this approach would likely produce worse results, and I’m not sure that the experiments disprove this.\n\nThe authors give another motivation in section 4, which is that in typical VAEs the prior and conditional distributions [p(z), p(x|z), q(z|x)] are all assumed to be Gaussian, which can be overly restrictive. Many prior works (which the authors cite) do not make this assumption and allow for training VAEs with more expressive distributions. The authors simply state “they still suffer from the limitations of VAE” without further explanation. They also do not compare against any of these methods in their experiments, so it’s hard to determine if any shown advantages of their model would hold up if the VAEs compared against used more expressive priors/posteriors.\n\nFor the MI based method, it seems to me that if the encoder is structured in the same way as the typical VAE, that is $U \\sim \\sigma_{\\phi}(x) \\cdot \\epsilon + \\mu_{\\phi}$, then bound in theorem 1 is exactly equivalent to the reconstruction loss of a standard VAE with Gaussian likelihoods: $E_{q(z)}[p(x |z]$. It does seem that the encoder structure could potentially be different here, though it’s implied that the experiments use the standard structure. The regularizer used for U does appear to be meaningfully different, but there is no discussion of why this particular regularizer was chosen. I would like to see this regularization approach compared and contrasted with the the standard VAE’s KL(q(z|x)||p(z)) loss and perhaps discussion if there are differences in the encoders being used. If there is a strong theoretical and empirical argument for this these changes to DGM training I would recommend restructuring the paper to focus on that.\n\nAs mentioned above my main issue with the experiments it that this approach is only compared against a standard VAE and not against any more modern improvements to that model. For the synthetic experiments only a 2D latent space is used and the network architectures used are unclear, as is the architecture used for p(u). Based on my experience I would say that existing VAE methods could easily fit those datasets as well as the ASL approach if tuned to the same extent.\n\nThe qualitative results look reasonable, on-par with what I would expect from a recent VAE approach, but there is no quantitative comparison on image data. This work would benefit from reporting held out likelihoods or something like FID scores. \n",
            "summary_of_the_review": "Overall, I’m unfortunately very skeptical of the claimed benefits of the proposed approach. I feel that this paper needs significantly stronger motivation and greatly expanded experiments with stronger, more contemporary baselines.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}