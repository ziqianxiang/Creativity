{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a method to disentangle factors of variation:\n- predicted\n- known nuisance factors\n- unknown nuisance factors\nThe predicted factors are trained with supervised classifier, while the known nuisance factors are trained in a weakly supervised manner: only the number of perturbed factors are given as a supervisory signal.\nThe main contribution is the a training technique of the known nuisance factors. The input image pairs are encoded, the resulting latent vectors are partitioned, then they are randomly swapped, finally decoded back into the image domain. During the swapping the swap detector decides which features to swap based on KL divergence or Jensen-Shannon divergence of the feature representations.\n",
            "main_review": "\nGood:\n\nThe task is interesting and important, the explanations are intuitive, the method is simple and easy to implement.\n\nThe method was tested on may datasets and compared to many prior works quantitatively.\n\nThe experiments how that the proposed loss terms help the performance, the method works as expected, and the proposed implementation tricks (e.g. warmup) improve performance as well (Fig 4. 5.).\n\nBad:\n\nThe impact is limited, the method is a combination of ideas from prior work. No fundamentally novel task, new theory/understanding or surprising new experimental results were presented.\n\nThe writing could be clearer and better organised:\n- \"except the top k highest D_m value elements.\" an explicit formula would be nice to add.\n- L_VAE is not defined explicitly, which would be important for a no-expert reader\n- The loss L is defined in two places (equation 6 and 10). The RHS of 6 is the subset of the RHS of 10, so it is not too ambiguous, but still this should be fixed.\n-\" L_{Z_p} = D(...)\" this term could be defined earlier than equation 10, i.e. right after equation 8. This way 1) the reader does not have to go back to the section where D(...) is defined and 2) At that section the reader will have a good idea what D(...) will be used for later.\n- It would be better to denote explicitly which loss function depends on which parameters, e.g. 'L_VAE(enc, dec) = ...', where one can denote the networks instead of their parameters for easier understanding\n\nSome relevant early works are not cited\n- Reed etal.: Deep visual analogy-making, NeuRIPS 2015\nIt is a supervised method with feature swapping.\n- Mathieu etal.: Disentangling factors of variation in deep representation using adversarial training. NeuRIPS 2016\nIt does disentangling with feature swapping with GAN in a weakly unsupervised way.\n- Hu etal.: Disentangling Factors of Variation by Mixing Them CVPR 2018\nIt is an unsupervised disentanglement method with GAN that is using a feature swapping very similar to the proposed one, except they use a classifier instead of swap detector.\n",
            "summary_of_the_review": "There is not one big reason why I recommend rejection, but the weaknesses add up, which is not compensated by a high enough impact.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a new model for representation learning composed of two parts: a predictive representation and a disentangled representation. The predictive representation contains information for the prediction task. The disentangled representation disentangle all nuisance factors of variation. The model learns the predictive representation using a contrastive loss (similar to supervised contrastive approaches [8]) and a weakly-supervised disentanglement approach (as have been proposed by Locatello et al. [7]). The weakly-disentanglement approach is extended by a swapping mechanism, in which representations of paired observations are swapped if they are similar to each other (measured by the KL). The final objective combines a VAE-objective ($L_{VAE}$) with a supervised cross-entropy loss ($L_{CE}$), a weakly-supervised KL regularization for disentanglement ($L_{disentangle}$), a supervised contrastive loss ($L_{Sup}$) and a class-similarity loss ($L_{Z_p}$). The authors showed that their supervised method improved classification and disentanglement performance compared to unsupervised/weakly-supervised methods. They further conducted ablation studies to understand what parts of loss influence the performance the most.\n",
            "main_review": "*Strengths*\n* Topic: Learning disentangled and invariant representations remain an ongoing challenge, and the authors address an interesting problem: How to separate predictive class information from class-invariant representation.\n* The authors present experiments with four datasets and a broad range of model comparisons to evaluate disentanglement and predictive performance.\n\n*Weaknesses (this summarizes the overall weaknesses, please see comments below for details)*\n\n* Clarity:\n    * The terms independence, invariance, disentanglement, alignment have been used (sometimes interchangeably) without really defining / describing them. For this paper this needs to be defined and discussed.\n    * The related work reads more like a background section. It would be clearer if you can compare against past work. How are you different, how are you similar?\n* Motivation and significance:\n    * The model builds on three existing approaches that should be correctly acknowledged: 1) The weakly-supervised disentanglement by Locatello et al. [8] is enhanced by the detecting & swapping approach. It is not clear how much the detecting & swapping approach advances the disentanglement performance. 2) A supervised contrastive approach similar to [7] and 3) using an average over class-specific representations [1, 8]. I think an extension by combining these approaches is totally okay w.r.t. novelty, if you can show that this combination enhances overall performance. However, the authors should clarify which model their model is based on, e.g., by comparing their model to the existing approaches in the related work and mentioning it in the main methodology section.\n    * The overall picture is missing (and it also reflects in the evaluation): Why is it essential to separate class from content (I assumed this is the goal; however, the paper is not clear on this)? Which applications would benefit from it this?\n    * It is unclear whether the goal is to separate/disentangle predictive and nuisance representation: The predictive representation is averaged for having a common class-specific representation, but does that mean that the nuisance representation is independent of it?\n* Empirical evaluation: \n    * The empirical evaluation does not necessarily show the advantages of training both disentanglement and predictive part. Can you think about applications where it is important to have this separation (e.g., fairness, robustness)?\n    * The training uses common disentanglement datasets, which are good for evaluating disentanglement performance. However, they are synthetic, and it is not necessarily granted that the performance will generalize for real-world datasets. Can you show that this method can generalize to real-world datasets, e.g., CIFAR-10/100, ImageNet, CelebA, etc.?\n    * The comparison with existing disentanglement is not fair as all comparisons are unsupervised or weakly-supervised, whereas the proposed model is supervised.\n    * It is not clear how well the predictive part $z_{p}$ is disentangled from the nuisance part $z_{n}$. Can you quantify this? As this is the overall goal, however, not shown in the evaluation, this decreases the impact of this paper.\n\n*Detailed comments*\n\n* Concerning this work, can you explain what disentangled and invariant representations are? As there are different definitions or notions of both terms, it would be good to clarify that. What is the difference between these two?\n* [Sec. 1, 1st paragraph] \"Typically, a DNN learns to encode representations which contain all factors [...]. Disentangled representation learning and invariant representation learning are often used to address these challenges.\" Can you add the references to these works you are referring to? Further, this statement is not quite correct. Disentangled representation also learns to encode all factors of variations. However, disentanglement refers to the factors of variation being disentangled in the representation space.\n* [Sec. 1, 2nd paragraph] \"invariant representation learning [...] in which they split representation $z$ into two parts [...]\": Some references are missing here [1, 2, 3, 4]\n* [Sec. 1, 4th paragraph] \"[...] supervised disentangled representation methods cannot handle unknown nuisance factors [...]\": Can you back this claim or add references to past work?\n* [Figure 1]: I don't quite understand this Figure. What does the image on the left and the colors represent? Can you explain all subplots a), b), and c)?\n* [Sec. 2, Related work] The related work reads more like a background section. It would be clearer and more helpful to the user to know how your work is related/similar (similar tasks, similar approach/methodology) to these past works and how they are different (what are you contributing)?\n* [Sec. 2, 1st paragraph] typos / errors: \"evidence lower bound of likelihood [...]\" -> \"evidence lower bound of the log-likelihood [...]\", \"between distribution $q_{\\phi}(z|x)$\" -> \"between approximate distribution $q_{\\phi}(z|x)$\", \"the negative of ELBO\" -> \"the negative ELBO\"\n* [Sec. 3.1] What are \"known\" and \"unknown\" latent factors? In what way are they \"known\"?\n* [Sec. 3.1] What exactly do you mean under weakly supervised disentangled representation learning? What are the assumptions made here?\n* [Figure 2] The Figure says \"Concat\"; however, Section 3.2 describes a \"Detect and Swap\" approach. What is being done here?\n* [Sec. 3.2, Detecting and Swapping the distinct latent factors] \"we can directly measure the mutual information between the corresponding the dimensions [...] by measuring [...] either KL divergence or Jenson-Shannon divergence\": This is not correct. The mutual information is calculated by using the KL divergence between the product of the variables and the joint of the variables. The way the authors present it's just the KL divergence between two Gaussian latent variables, not the mutual information.\n* [Sec. 3] latent variable corresponding to the unknown nuisance factors $z_{nu}$: This has been introduced in Section 3.1. However, it has not been used any further. What is the purpose of introducing it?\n* [Sec. 3.2, Disentangled representation loss function]: What is $L_{VAE}$? Is this the ELBO?\n* [Sec. 3.3, 1st paragraph] \"After we obtain the disentangled representation $z_{nk}$, the predictive factors $z_p$ may still be entangled with $z_{nu}$\": Why can't $z_p$ be entangled with $z_{nk}$?\n* [Sec. 3.3, Making $z_p$ independent of $z_n$] \"we generate new latent representation $\\bar{z}_p$\": From which input is $\\bar{z}_p$ \"generated\"? Do you mean \"calculated\"?\n* Table 1: What is used for classification, only $z_p$? Are the models fair comparisons as some of them are unsupervised?\n* Can you quantify how well the representations are disentangled from each other, e.g., using mutual information?\n* Can you describe the training procedure? E.g., dataset split, optimization, evaluation settings.\n\n*References*\n\n[1] Hosoya, H., 2018. Group-based learning of disentangled representations with generalizability for novel contents. arXiv preprint arXiv:1809.02383.\n\n[2] Bouchacourt, D., Tomioka, R. and Nowozin, S., 2018, April. Multi-level variational autoencoder: Learning disentangled representations from grouped observations. In Thirty-Second AAAI Conference on Artificial Intelligence.\n\n[3] Creager, E., Madras, D., Jacobsen, J.H., Weis, M., Swersky, K., Pitassi, T. and Zemel, R., 2019, May. Flexibly fair representation learning by disentanglement. In International conference on machine learning (pp. 1436-1445). PMLR.\n\n[4] Klys, J., Snell, J. and Zemel, R., 2018. Learning latent subspaces in variational autoencoders. arXiv preprint arXiv:1812.06190.\n\n[5] Khemakhem, I., Kingma, D., Monti, R. and Hyvarinen, A., 2020, June. Variational autoencoders and nonlinear ica: A unifying framework. In International Conference on Artificial Intelligence and Statistics (pp. 2207-2217). PMLR.\n\n[6] Mitrovic, J., McWilliams, B., Walker, J., Buesing, L. and Blundell, C., 2020. Representation learning via invariant causal mechanisms. arXiv preprint arXiv:2010.07922.\n\n[7] Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., Maschinot, A., Liu, C. and Krishnan, D., 2020. Supervised contrastive learning. arXiv preprint arXiv:2004.11362.\n\n[8] Locatello, F., Poole, B., Rätsch, G., Schölkopf, B., Bachem, O. and Tschannen, M., 2020, November. Weakly-supervised disentanglement without compromises. In International Conference on Machine Learning (pp. 6348-6359). PMLR.",
            "summary_of_the_review": "I don't think the paper in its form is ready for acceptance. Therefore I am recommending a rejection. The motivation for class-content disentanglement is not clear and the method feels like combining several methods without reasoning about why it is advantageous to combine them. The evaluation does not support claims (mutual independence of known nuisance factors, robustness, invariance) very well and lack in details. \n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper presents a disentanglement learning method based on feature swap, which is further combined with a contrastive loss to better extract class-relevant factors.",
            "main_review": "- Though combining disentanglement learning based on feature swap with contrastive learning is quite interesting, I think the empirical validation is weak and limited for acceptance. \n- The “encoding-swap-decoding” approaches (Jha, 2018; Feng, 2018; Hu, 2018; Szabó, 2018; Lezama, 2019; Park, 2020; Chen, 2020) have been widely used in the field of disentanglement learning, but the proposed method was not compared with these approaches. In particular, the baselines in Table 3 only include VAEs that use a training loss for disentanglement (e.g., feature independence loss, group information), but I think the feature swap methods are more powerful than such loss-based methods because explicit design constraints are incorporated into the learning process. I would suggest the authors to describe the key differences with existing feature swap methods and add some experimental comparisons with them.\n- Though the ablation studies in Tables 4 and 5 are interesting, the effectiveness of each term in the final loss Eq (10) was not shown. (i) What happens if L_disentangle or L_Zp is removed from Eq (10)? (ii) Could the authors repeat the experiments in Table 5 on the disentanglement datasets (3dShapes, MPI3D) and report the results? It would be helpful to understand the effectiveness of L_contrastive in terms of disentanglement. (iii) how did the authors set the loss weighting values in Eq (10) (i.e., alpha, beta, gamma)?\n- Instead of the simple MNIST variants, it would be better to include additional results on more complex data (e.g., faces images) to show the applicability of the proposed method.\n- It would be better to add the t-SNE visualization of baseline methods and compare it with Figure 5 in Appendix to visually show the strength of the proposed method.\n- I was not able to find implementation details (e.g., architecture details, hyperparameters, the number of models for computing the average scores in Tables) required for reproducibility.\n- Typos in the last sentence of page 8: As shown “in Table 3”, our approach surpass”es” both unsupervised and weakly-supervised method”s” “in terms of” almost all metrics.\n\n(Jha, 2018) Disentangling Factors of Variation with Cycle-Consistent Variational Auto-Encoders, ECCV’18 \\\\\n(Feng, 2018) Dual Swap Disentangling, NeurIPS’18 \\\\\n(Hu, 2018) Disentangling Factors of Variation by Mixing Them, CVPR’18 \\\\\n(Szabó, 2018) Challenges in Disentangling Independent Factors of Variation, ICLRW’18 \\\\\n(Lezama, 2019) Overcoming the Disentanglement vs Reconstruction Trade-Off via Jacobian Supervision, ICLR’19 \\\\\n(Park, 2020) Swapping Autoencoder for Deep Image Manipulation, NeurIPS’20 \\\\\n(Chen, 2020) A Cyclically-Trained Adversarial Network for Invariant Representation Learning, CVPRW’20 \\\\\n",
            "summary_of_the_review": "I think the main idea is quite good, but the empirical results are weak and not impressive. I thus find it difficult to argue for acceptance of the work.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes to accomplish both disentangled and invariant representations simultaneously. The main framework used in this work is VAE. The authors hope to divide the latent state into 3 parts: a predictive factor $z_p$, a known nuisance factor $z_{nk}$, and an unknown nuisance factor $z_{nu}$. This work assumes each latent dimension corresponds to a latent factor. Two supervisions are know: 1. the supervised label for the predictive factor $z_p$. 2. a pair of samples with known number ($k$) of different generative factors. For the nuisance factors, the proposed method detect and swap the distinct latent factors to identify $z_{nk}$. For learning the predictive factors, besides the supervised cross-entropy loss, this paper further introduces a supervised contrastive loss to strengthen the learning of predictive factors. The work is validated on 4 datasets, and multiple disentanglement metrics and the supervised accuracies.\n\nThe major contributions as claimed in the paper:\n1. They extend and combine both disentangled (nuisance factors) and invariant representation (predictive factors) learning.\n2. They use reconstruction and swapping to split the latent state to 3 parts.\n3. Their experimental results outperform the compared methods. ",
            "main_review": "Pros:\n1. This work gives a good background on the invariant and disentangled representation learning. The illustrative example is also clear. \n2. The overall idea including the warmup schemes is novel. It is interesting to use reconstruction for disentanglement, and contrastive learning for invariance in this problem setting. \n3. The experiments include the comparisons on accuracies and disentanglement metrics. Some key ablation studies are also performed, which helps understand the importance of different modules.\n\nCons:\n1. My major concern the problem setup. My feeling is that this is more like a makeup problem. You actually know the underlying latent factors a priori. Then you manipulate the factors to generate synthetic datasets under your problem formulation, and presume you don't know some latent factors. All four datasets are this type of scenarios. I'm ok if you use one or two as the illustrative toy example. But too many of them would make me doubt your method's generality. I understand beta-VAE, beta-TCVAE and so on all used the synthetic datasets in the past, but given that now so many papers have studies them, we are now more interested in less synthetic scenarios [1, 2].\n2. Though you claim the knowledge of the number of changed factors, k, is weak supervision, I don't think this is that weak. First, you assume each dimension corresponds to a latent factor. This is rather ideal. In most cases, it is almost impossible for you to capture a whole factor with only 1 dimension in the latent space. Second, I don't think knowing the number of changed factors is that easy. Intuitively, if you want to know the number of changed factors, you probably need to identify which ones have changed first. But identifying the changed ones is not that easy. Of course, if you can show some real-world applications in the experiments, I probably would take the assumption. But given the actual datasets are all synthetic examples, the claims are less convincing.\n3. Though the synthetic datasets have discrete number of independent factors, where each class has discrete categories, it is typically not true in the real-world cases. Also, the factors could be entangled (e.g. snow typically relates to a bare tree rather than a green tree).\n4. In your problem formulation, you have the full supervision of the prediction classes, and the number of changed variables. I wonder given such rich supervision, whether you can show some downstream generation results to demonstrate the learnt factors are semantically meaningful.\n5. Could you further clarify which factors are predictive factors, which are nuisances factors? It seems that given a total number of factors, you can easily inter-change them?\n6. I don't think Locatello et al. (2019) requires that you have to use supervision. It mentions that inductive bias is necessary. The inductive bias could be supervision, data structure itself, or even model architecture.\n7. In section 4.1, you mentioned that Eq. 10 does not directly guarantee good performance. But Eq. 10 is really what your whole section 3 is about. Why don't you describe the final method that indeed \"works\"?\n8. $A(i)$ from Eq. 9 is not defined.\n\n[1] Bai, J., Wang, W. and Gomes, C.. Contrastively Disentangled Sequential Variational Autoencoder. NeurIPS 2021.\n\n[2] Han, J., Min, M.R., Han, L., Li, L.E. and Zhang, X.. Disentangled Recurrent Wasserstein Autoencoder. ICLR 2021.",
            "summary_of_the_review": "Overall, I don't feel the problem setup is very natural and practical. Though the method fits the problem design, it might not generalize well to real-world scenarios. Some assumptions made in this paper are also too ideal. Given that in this problem, the supervision is quite rich, I think the authors can perform more downstream tasks like generation tasks. Some claims are also not very consistent throughout the paper. I think the paper needs improvements. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}