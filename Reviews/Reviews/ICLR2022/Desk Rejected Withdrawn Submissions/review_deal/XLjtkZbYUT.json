{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper presents a disentangled learning model for causal effect estimation named MimCE, which is based on an existing mutual information minimization technique (CLUB; ICML-20). Existing works on learning disentangled latent variables cannot ensure independence between instrumental factors, confounding factors, and risk factors. This paper tries to address this challenge by minimizing the mutual information between the three latent variables learned. Empirical experiments are done with IHDP and synthetic datasets and treatment effect estimation, as well as the identification of the disentangled factors, are evaluated.",
            "main_review": "Overall, the idea of minimizing mutual information between the disentangled factors to enforce the independence between them is a natural and reasonable approach to take. This paper implements the idea using the cutting-edge technique, CLUB, which makes it empirically a strong model and outperforms a number of SOTA disentangled representation learning models.\n\nHowever, my concerns are mainly:\n\n(1) The rigor in presenting the theoretical results, especially when mentioning work by others, needs significant improvement. It seems to me that Theorem 1 and 2 are Theorems 3.1 and 3.2 of the CLUB paper. The way the authors present them in the paper is extremely misleading. If the authors insist on introducing them for the paper to be self-contained, at least an explicit citation would be required in the form like \"Theorem 1. [Theorem 3.1, (Cheng et al., 2020)]\". \n\n(2) Similarly, Theorem 4 has in fact been established by Zhang et. al. in the TEDVAE paper.\n\n(3) The presentation needs to be significantly improved. Some notations/concepts are not clearly explained. For example, what is the imbalance prediction task in Section 3.2? What is the function $h^{t_i}$ and $\\pi$ in Section 3.2.1? Does IPM mean integral probability metric? Some of other errors:\n - Page 4: is often harm to --> is often harmful to;\n - Page 4: may due to --> may be;\n - Page 4: is lack of --> lacks of; ...\n - Page 4: $\\mathbf{x}\\subseteq\\mathbb{R}^d$ --> $\\mathbf{x}\\in\\mathbb{R}^d$.\n\n(4) Another question is that in Table 1, the authors use * to indicate t-test against DR-CFR, why not comparing against DeR-CFR or TEDVAE? They seem to outperform DR-CFR.",
            "summary_of_the_review": "The model presented in this paper is an reasonable approach. Empirical evaluation show improvement against a number of SOTA baselines. However, the presentation of this paper needs quite some rework before it can be accepted.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper addresses the problem of learning disentangled representations of the underlying factors of observational data for the downstream task of causal inference. It provides an intuitive solution to the problem by attempting to minimize the mutual information between the learned representations. The CLUB method is employed for estimating the mutual information terms. The extensive experiments demonstrate that the proposed method achieves state-of-the-art.\n",
            "main_review": "The paper is well-written and easy to read. It proposes an intuitive yet interesting idea to solve the task at hand. The paper also provides an extensive set of experiments that supports the claims. \n- There are, however, parts of the paper that are not explained well enough. For example, it is unclear how Equation (18) ensures getting non-zero disentangled factors. This is very important since if it doesn’t work as advertised, the representation learned for \\Upsilon might be degenerate.\n- In table 2, provide standard deviations so that statistical significance tests are meaningful. From what I’ve seen in the literature, the standard deviation for IHDP is often too high to be able to get a statistical difference between methods’ performances.\n- In Section 4.3 (Figure 2 and Tables 2 and 3), the results of DeR-CFR and TEDVAE are missing. I’m curious to see how they compare to DR-CFR and the proposed method.\n- Section 4.4 requires elaborating what is being tested and lacks proper discussion. Perhaps the authors could move the proofs for Theorems 3 and 4 to the Appendix in order to make space.\n\nMinor comments:\n- Consider bringing Figure 5c inside the main text as it explains the underlying factors in a graphical model.\n- Page 1, paragraph 2, line 1: typo (Trail → Trial).\n- Footnote 1: aka means “also known as”, so the word “called” is not needed and should be removed.\n- A few grammatical mistakes throughout the paper.\n",
            "summary_of_the_review": "As mentioned in the main review, there are parts of the paper that require more elaboration. I am willing to increase my score if those concerns are addressed.\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The authors present a disentangled representation learning method for treatment effect estimation. Their central thesis is that current methods cannot decompose well, covariates into disjoints factors. Enter MimCE which obtains independent disentangled factors for ITEs.",
            "main_review": "# Introduction\n\n- Sentence construction: \"importance across in many domains\" -> \"importance across many domains\" (you have lots of English errors across the paper, I suggest you get it proof-read before resubmitting for ICLR camera or another conference).\n- Do we take it to mean that $t$ is short for treatment? If so, spell it out.\n-  What is the meaning of your conditional $p(t\\mid \\mathbf{x}) \\neq p(\\neg t\\mid \\mathbf{x})$? When would that statement ever be true, lest in the binary case where you have 50% chance of either? What are you trying to say?\n- \"For example, rich customers are more willing to watch the ads and buy the expensive goods relative to the poor ones\" - what? How on earth do you know this?\n- \"Even though we already have all the confounders in our variable\" what does this mean? We have all the confounders in our variables? Since when?\n- What is BNN, what is CFR? What do they stand for, why are they relevant to me as a reader? I shouldn't have to go to the original source. You should spell out the abbreviation the first time you use it. Same with CEVAE, GANITE...\n- \"Obviously, disentangled representation learning methods can achieve explicitly identification of the latent factors.\" why is this obvious?\n- Use \\citet when you are referring to works in first-person; do not use \\cite for everything, it is not grammatically or formally correct.\n- This was a very difficult section to read. It needs major reformatting to even make sense.\n\n# Related works\n\n- You are repeating a lot of what you said in the introduction. I suggest that you either combine both sections or move your related work discussion from section 1 to this section.\n- As before; you've provided us with an army of acronyms and we have no hope of figuring out what they stand for unless you tell us. We cannot be expected to go to the source to find out. E.g. what are the abbreviated terms in D$^2$VD?\n\n# Methodology\n\n- \"observed factual outcome\" - what is that? Do you mean the true outcome?\n- $\\mathcal{T}$ is your intervention domain, not potential interventions; they are not potential because they are possible and they live in a specific region noted by $\\mathcal{T}$.\n- $do(t)$ does not refer to the removal of incoming edges, it means an intervention on the SCM, which can be associated with a causal graph in which the incoming edges on the intervention variable are removed. $do(t)$ is the operator from Pearl's do-calculus. I recommend the exact definition on page 203 of (Pearl, 2009), definition 7.1.1. for a more in-depth treatment.\n- You'll need to give us a lot more information on why you need definitions 1-3 to be satisfied for your method. Just stating that they should be is hardly helpful.\n- I am truly confused by your diagram in figure 1. For example, what is IPM?\n- Why is the loss-function linear in the terms? Is that a requirement?\n- You are using $\\omega_i$ for something but I have no idea what, it is not used anywhere before equation (3) from what I can tell. \n- I am going to take a stab at guess that IPM == \"integral probability metric\" - I am guessing this because you never tell me and you use it twice before _not_ defining it.\n- I am seriously confused: it looks like Cheng et al. (2020) introduced CLUB but now you're saying you introduce CLUB and what is more you prove it and theorem 2. Why are you proving someone else's theorem? Is theorem 1 or 2 or both yours or just 2?\n- It is quite an editorial leap to define something you talked about on page one, six pages later ($\\mathcal{G}$ and $p(\\cdot)$) - I suggest you move these definitions out of theorem 4 and to the introduction.\n- Do you mean to say, instead of \"Hence, it is significant to estimate ITE only \" to say \"Hence, it is _sufficient_ to estimate ITE only\"\n\n# Experiments\n\n- I find it very difficult to scrutinise this section since the exegesis of the methodology is so convoluted and difficult to understand. The results look impressive and good but they may well be down to parameter initialisations. Because the methods are so poorly explained, it is difficult to say at this point if they bear out what they purport to show.",
            "summary_of_the_review": "The authors very poorly introduce a new disentangled representation learning method for ITE. It may be SoTA it may not. The exposition, construction and editorial choices made in the paper, make it very difficult to understand and follow.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents a disentanglement framework for causal effect estimation with observational data. The treatment variable and the outcome variable usually have a set of confounders ($ \\Delta $), instrumental variables ($\\Gamma$) and adjustment variables ($\\Upsilon$) which need to be identified so that causal effects can be estimated by adjusting for them. This paper proposes to tackle this problem by having an encoder which projects the observed context variables into a latent space which are then reprojected using three different decoders corresponding to confounders, instrumental variables and adjustment variables. These latent factors are then disentangled by using a Mutual Information (MI) based loss function (called MIM). The approximation to MI is based on the CLUB algorithm (Cheng et al. 2020) which requires access to conditional densities. Since this conditional density is not available for the latent variables, a variational framework is proposed to estimate it. Experiments are performed on IHDP and synthetic datasets to show the efficacy of the proposed method.\n",
            "main_review": "Treatment effect estimation from observational data is an important problem especially given that confounder variables are not known. The approach taken by this paper based on representation learning and mutual information minimisation between the latent variables is an interesting one and potentially could be promising. \n\nThe proposed approach builds on the framework of  DR-CFR (Hassanpour & Greiner, 2020) and DeR-CFR (Wu et al., 2020). The main difference of the proposed approach as against these two approaches is how the latent variables corresponding to the three factors $ \\{ \\Gamma, \\Upsilon, \\Delta\\} $ are disentangled. The approach uses an estimate of the mutual information between these latent factors in order to achieve it. To estimate the mutual information between latent variables corresponding to different factors, a recently proposed CLUB algorithm (Cheng et al. 2020) and its variational variant is used. \nIn this sense, the proposed technicalities are themselves not novel. However, the overall method might still be relevant and interesting to the problem of treatment effect estimation. In addition, the proposed algorithm is relatively simple although it contains many terms in its loss functions and their corresponding hyperparameters. \n\nI would like to mention here that disentanglement in an encoder-decoder framework has been an active line of research on its own (Bengio et al 2013, Locatello et al 2019, Higgins et al 2017), independently of the problem of treatment effect estimation. It would be apt for this work to discuss this aspect briefly in the motivation and how the present paper differs from the disentanglement sought here. In addition, the proposed approach is concerned with getting a marginal distribution over each of the latent factors mutually independent of each other. In this regard, it's probably a good idea to contrast with the approach of FactorVAE (Kim and Mnih, 2018), which has a similar setup. In this context, it would be interesting to know if the regulariser sought in FactorVAE could be preferable in this setup over mutual information minimisation, which needs additional variational inference formulation.\n\nThe clarity and exposition of the paper can be improved. For example, what does \"Base\" correspond to in Figure 4? Which $\\mathbf{W}$ is being referred to after Eq. 17? And is it averaged row-wise to obtain $\\tilde{\\mathbf{W}}$? And what is the motivation behind averaging neural network weights? Also the baselines for ablation study needs to be explained a bit better. Does \"w/o ED\" mean that MIM is performed directly on the features $X$?  Does \"w/o ED+MIM\" mean that treatment effect estimation is directly performed with the features $X$? \n\nThe main concern I have is that it's not clear how much the disentanglement (and the MIM procedure) is actually making a difference in treatment effect estimation. I believe this is mainly stemming from the way disentanglement is evaluated. According to theorem 3 of the paper, if the MIM loss goes to 0, then each of the latent factors are mutually independent of each other and hence disentangled. Given this definition, I would like to clarify what is the motivation in proposing a metric to quantify disentanglement based on Weight Matrix Orthogonality (WMO) of encoder decoder weights? Is it not sufficient to see if the latent factors are independent (by doing some sort of independence tests on held out data, or even more simply $\\ell_{\\text{CLUB}}$ on held out data)? I fail to understand how using encoder and decoder layer weights is a good metric for disentanglement, given that there would be many non-linearities in these layers. If WMO is the desired metric, then directly optimising it should be sufficient and it's unclear why it needs to be augmented with MIM. When disentanglement is measured with WMO, the authors always augment their approach with WMO to show superior disentanglement, however, the results are not reported for treatment effect estimation when MIM is augmented with WMO. Does better disentanglement in terms of that metric translate to treatment effect estimation? So as it stands currently, the proposed approach (MIM) gives good counterfactual estimates, however it's not clear how much disentanglement it obtains. On the other hand, MIM + WMO gives better WMO loss (even better than just directly optimising for it) however it's not clear how well an augmented version performs in terms of counterfactual estimation. \n\nThe evaluation seems to be only on IHDP and synthetic datasets with binary treatment and outcomes. Is it the case that the proposed approach is limited to binary treatment and outcomes? If not, the discussion for the case of continuous treatments needs to be included and evaluated on. If binary treatments are the only focus, then the paper would benefit from a more thorough evaluation, for example with Jobs and Twins dataset as done in (Liuyi et al, 2018).\n\nReferences:\n\n1. Locatello, Francesco, et al. \"Challenging common assumptions in the unsupervised learning of disentangled representations.\" ICML, 2019.\n2. Kim, Hyunjik, and Andriy Mnih. \"Disentangling by factorising.\" ICML, 2018.\n3. Higgins et al betavae: Learning basic visual concepts with a constrained variational framework. ICLR, 2017.\n4. Bengio, Yoshua, Aaron Courville, and Pascal Vincent. \"Representation learning: A review and new perspectives.\" PAMI, 2013.\n5. Yao, Liuyi, et al. \"Representation learning for treatment effect estimation from observational data.\" NeurIPS, 2018.\n\n\n",
            "summary_of_the_review": "Despite the importance of the problem, I feel that this paper needs a revision with regards to clarity, exposition and related work. In addition, the way disentanglement is being evaluated is still vague (using the products of averaged neural network weights). Hence, it does not shed a light on how much disentanglement is actually achieved, and how it influences treatment effect estimation (which is the main contribution of the paper). I would be willing to raise my score if my concerns (see last 3 paragraphs above) are sufficiently addressed.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}