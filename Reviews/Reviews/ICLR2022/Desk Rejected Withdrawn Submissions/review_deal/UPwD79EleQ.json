{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper tackles test time data augmentation for improving the predictions of trained models. The authors propose a modification of the recently introduced method by Kim et al. (2020) that consists of a loss prediction module to select the best transformations before inference. Instead of applying a single transformation, the authors propose to iteratively augment every image until the identity transformation is selected or the maximum number of iterations is reached. Further, the paper proposes to compute the final prediction via the entropy weighting method, instead of averaging over a number of transformations.",
            "main_review": "I see as main strength of the paper that the proposed idea is both reasonable and simple. However, my overall impression of the paper is that it does not make a sufficiently strong submission for ICLR. My main concerns are about the clarity of the presentation and the originality and significance of the proposal.\n\nRegarding clarity, the paper is hard to read and navigate. The introduction does not provide a clear motivation for the proposed methods and the section finished leaving the reader (me, at least) without a clear idea of what the proposal will be, beyond mentioning some key terms such as \"cyclic\" and \"entropy\" whose specific meaning in the proposal will only be explained later. The methods section (3) is also rather confusing in that it is not clear which parts are a recap of previous work (for example the paper by Kim et al., 2020), and which parts correspond to original contributions of this paper. The clarity of the experiments section (4) could also be explained, in my opinion, by presenting in a more structured way the experimental setup. I had to re-read several times some sections and match back and forth with the information on the figures and tables and captions to understand the methods. Beyond these most important aspects, the paper also contains multiple typos and grammatical issues that hinder the readability. I list some of these below.\n\nIn terms of originality and significance, I believe the paper provides limited contribution. The proposed method is a modification of that by Kim et al. (2020). An incremental contribution can be relevant and significant for the community if the results clearly improved the previous method. In this case, however, the cyclic augmentations and the entropy weight method for the predictions only marginally, in the best case, improve over the baseline, at higher computational cost.\n\n### Typos and errors\n\nSome potential typos, typesetting, or grammatical errors I have identified are the following:\n\n* Page 2: with each augmentation is regarded as -> where each augmentation is regarded as OR with each augmentation regarded as\n* Page 2: On contrary to -> Contrary to\n* Page 2: As we follow the instance-level TTA is the effective level of -> ?\n* Page 2: there are more potential rooms for -> there is more potential room for (for example)\n* Page 3: In field of active learning -> In the field of active learning\n* Page 3: a loss value can used -> a loss value can be used\n* Page 3: how much uncertain the data is -> how uncertain the data is\n* Page 4: Ultimately, the loss... -> Finally, the loss...\n* Page 4: the least loss value -> the smallest loss value\n* Page 6: according the top -> according to the top\n* Page 6: Ideally to say -> Ideally (?)\n* Page 6: for assuming that -> assuming that\n* Page 6: On contrary -> On the contrary",
            "summary_of_the_review": "The contribution is incremental with respect to recently published work, while the results are only marginally better in the best case. Furthermore, the clarity of the paper should be improved, in my opinion, to make a strong submission for ICLR.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety"
            ],
            "details_of_ethics_concerns": "Some figures contain photos of faces.",
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper further investigates a Test-Time-Augmentation (TTA) policy to apply multiple transformations in a consecutive manner, using the cyclic loss prediction module. The proposed method is quite intuitive, and the experiments on clean and corrupted ImageNet are presented. ",
            "main_review": "#### Strengths\nThe proposed method is fairly straightforward and intuitive. Finding the consecutive multiple transformation in test-time is well suited to the cyclic loss prediction module. \n\n----\n#### Weaknesses\n* In Table 1, I failed to see the performance improvement over previous approaches in case of AugMix augmentation. This suggests that the cyclic TTA doesn’t improve the performance or robustness in most practical scenarios (i.e. having strong augmentations in training). \n* It would be very interesting to see the results of comparison between the proposed cyclic TTA and baselines in case of using much stronger target networks than ResNet-50. When we’re using EfficientNet-B0, Swin-Transformer, or many other strong architectures, the performance improvement may be more invisible.\n* I failed to understand the meaning of relative computing cost in Table 1. It seems that the cyclic of cost 1 is as fast as the center crop, which is not possible, because the cyclic procedure requires multiple evaluations on the loss predictor. Could you elaborate how to determine the relative cost? \n* I also failed to see the benefit of EWM, which is one of the components in the proposed approach. In terms of Top-1 accuracy and mCE in Table 1, with or without EWM performs very similarly. \n",
            "summary_of_the_review": "Unfortunately, the empirical evidence of the proposed cyclic TTA is not strong enough. Unless my major concerns are not addressed in the rebuttal, I'll stick to borderline reject.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes a way to find the flexible data augmentation during test-time in a computationally effective way. Specifically, they propose cyclic-TTA, which iterates the selection of data-augmentation until policy thinks we should not add DA any more (or reach out the maximum iteration), in conjunction with an entropy weighted mechanism. They empirically validate its performance on ImageNet-C dataset compared with several baselines. ",
            "main_review": "**Strengths**\n\n1. The tackled problem is important and interesting. \n\n2. The cyclic loss prediction module is technically sound to consider flexible data augmentation. Its extension to multiple transformations is reasonable. \n\n\n**Weaknesses**\n1. This paper (especially abstract and section 1) is very hard to follow especially for those who are not familiar with the work of Kim. From the introduction, neither the proposed method nor why the proposed method should work is clear. There is no description about experimental setup, and how it is significant in section 1.\n\n2. Empirical evaluation is only conducted in ImageNet-C and performance improvement over prior methods is incremental. Given there is no theoretical foundation, the empirical results should be significantly strengthen. \n\n3. Connection between Cyclic TTA and EWM is not clear. At the first glance, the reader might think that these are two distinct proposals and should not be discussed at the same time. It is better to discuss why EWM can improve performance especially when using Cyclic TTA. \n",
            "summary_of_the_review": "Overall, I found the technical proposal (especially cyclic loss prediction) is very interesting and its extension to multiple transformations is reasonable. However, given there is no theoretical foundation, significant effort on the empirical evaluation is required to meet the level of conference. Writing should be significantly improved as well. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a test-time augmentation algorithm, which builds off of previous work in test-time augmentations and proposes a new method (EWM) to perform augmentations at test time to aggregate predictions. The paper tests their algorithm on the standard Imagenetand Imagenet-c benchmarks.",
            "main_review": "Positives:\n- The paper is straightforward and well motivated. \n- The paper's second proposal of EWM is a very interesting idea, although builds off of [1] slightly (which is not cited)\n\nNegatives:\n- \"Although training the loss predictor with a separate validation set seems to\nbe more suitable, for the loss values by the target network prediction from training data would not\nperfectly simulate the actual test condition, regardless, it has been reported that they do not make\nmuch difference in performance\" I appreciate the papers honesty, but I would prefer to see this in practice. I think it would be better if the authors were to run quick results on the validation set to confirm that this is really the case, otherwise it makes it quite difficult to evaluate the empirical results despite what the other papers have found. \n- The paper uses seemingly weak baselines. Some baselines that could be useful include some of the ones mentioned in the related works section or ones that employ better test-time training algorithms such as [1] with or without the cyclic loss.\n- I would also like to see experiments on other datasets / data splits, since the paper only shows experiments in one setting. It would be preferred if its non-classification since such algorithms already perform well on typical image classification test sets. Since overall the results are a bit unconvincing to me, since the \n- The paper misses some key citations for papers that also do test time adaptation (but not test-time augmentations although the fields share similarity in motivation) [1-3]\n- Table 1 is misleading as in the \"Average\" column, for augmix, 10 crops outperforms the cyclic part of the paper. \n- 10 random crops appears to be very competitive with the paper despite its simplicity, and the paper is not able to outperform it by a small margin. Is it possible to get the variance over multiple seeds to ensure that the performance improvement is indeed valid. \n- The \"cost\" for EWM is not discussed, since its likely that it incurs a greater cost than something simpler such as average 10 crop.\n- (lesser in value) it would also be interesting to see if its possible to combine [1] and the cyclic portion of the proposed algorithm\n\n\n[1] https://arxiv.org/abs/2006.10726\n\n[2] https://arxiv.org/abs/2009.10623\n\n[3] https://arxiv.org/abs/1909.13231",
            "summary_of_the_review": "I quite like the EWM and the cyclic methods proposed, but I am somewhat unconvinced of the empirical evaluations. See the main review. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}