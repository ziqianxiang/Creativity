{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This manuscript proposes an algorithm that uses Shapley's value for model/feature selection at the training stage.\n\nIt then demonstrates its technique in two environments, click-through rate (CTR) and asset pricing.\n\nThe paper does not sufficiently clearly explain, in my view, how it differs from earlier uses of Shapley's value for model/feature selection (e.g. Lipovetsky & Conklin, 2001; Sundararajan & Najmi, 2020). ",
            "main_review": "**Strengths**\n\nFeature/model selection is an important problem; the techniques presented here perform well on the chosen datasets against the chosen comparators.\n\n**Weaknesses**\n\n1. _exposition_: \n    1. the manuscript burns space discussing 'data-centric methods'.  In my view, this is a distraction that adds nothing to the main arguments, while cutting down on the space available to properly substantiate those arguments.  I recommend cutting this material and bolstering the main arguments.\n    1. there are minor typos and grammatical errors at a few places.  In most cases, the authors' intent is intelligible, but it would be nice to clear them up.\n    1. \\citep{} should be used in many of the cases that \\cite{} or \\citet{} is currently used\n    1. no footnotes in abstracts, by historical convention\n    1. I'd re-draft the abstract to make it a bit clearer: this will be people's first point of contact with the paper\n    1. the figures are too small to read\n    1. what's the difference between Ghorbani & Zou's 2019 application of Shapley to \"each data sample\" and \"local Shapley values\" (in the sense of Lundberg & Lee)?\n    1. I missed how the \"toy\" MovieLens analysis in \\S 4.6 differed from the MovieLens analysis performed earlier in the manuscript.  Thus, I'd recommend clarifying that paragraph.\n    1. re: the asset pricing example, I don't know that I'd say it's \"_exactly_ a regression task\"; in addition to \"well-designed\" factors, well-learned factors can also be important; I would say that Sharpe's CAPM model is a significant contribution to modern asset pricing theory, not \"the birth of asset pricing theory\" (Modigliani and Miller were already at work in the modern era; do you want to exclude e.g. Graham & Dodd from asset pricing?).  I'd cut \"for many decades\": for as long as there have been assets and markets, people have been trying to price them.\n\n1. further _developing main arguments_:\n    1. justification of Algorithm 1.  Yes, of course, we _can_ do this: why should we?  What properties does the algorithm have?  Is it 'greedy' in its addition of features?  If so, can anything be said about what sorts of datasets this is problematic for?\n    1. relationship to existing uses of Shapley's value for model/feature selection (q.v. Lipovetsky & Conklin, 2001; Sundararajan & Najmi, 2020)?\n    1. relationship to Agarwal et al.'s _neural additive models_ (q.v. https://arxiv.org/abs/2004.13912), which also seeks to maintain both accuracy and interpretability.  Would it be an appropriate benchmark for comparison?\n    1. relationship to dropout: Shapley drops out features; the dropout parameter (p.6, CTR data) drops out hidden nodes.\n    1. is there any advantage in using interaction indices/measures of joint feature importance, given the paper's interest in assessing feature interactions?\n    1. the CTR 70:20:10 training:validation:test split seems unusual to me.  To what extent do the results depend on this?\n    1. I'd like to see runtimes/compute costs in Tables 2 and 3.  I'd also like to see the models learned by the various asset pricing approaches: as the FFM5 has few features, I would expect that we should be able to gain intuitions from this exercise \n\n(Properly addressing these issues seems more fundamental to me than, say, improving the existing algorithm's approximation techniques.)",
            "summary_of_the_review": "The paper presents an approach for addressing model/feature selection in a performant and interpretable way - which is clearly an important goal.\n\nAt present, though, it presents very little theoretical defense of its approach (including by comparison to the existing literature), relying instead on a couple of examples.\n\nBy cutting extraneous material (e.g. all the 'data-centric' material), the main arguments can be buttressed to better convince the reader of the approach's validity.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, the authors proposed to find useful feature interactions based on feature Shapley value method. The authors utilized the MC-based approach for fast computation of Shapley values. Experiments are carried out on two real-world problems (CTR prediction and price estimation) with comparison to several baselines.",
            "main_review": "Strength\n1. The authors study an interesting and important problem for automatic feature interaction discovery.\n2. The authors carried out a through experiment on two tasks with comparison to several state-of-art DNN-based approaches.\n\nWeakness\n1. Some description of the paper is not very clear. First, which level are the feature interactions defined? It is on field level or feature level. In algorithm 1, the author mentioned feature set and number of features in Table 1. However, based on the results in Section 4.6, seems the interaction is on the field level instead. In would be good for a clarification. Second, it is not very clear how the NN (Shapley) model works. Is it cross + embedding?\n2. One main motivation to automatically detect interaction is for efficient inference. The authors should include comparison on (1) the inference time for each of the model and the number of parameters (2) the training time for each model (pure training for baselines and interaction detection + training for a fair comparison for the proposed method).\n3. Besides the automatic feature interaction selection methods, the authors should compare to work on explicit feature interaction section method like “Feature Interaction Interpretability: A Case for Explaining Ad-Recommendation Systems via Neural Interaction Detection” or the GDBT_LR schema for feature interaction discovery in “Practical lessons from predicting clicks on ads at facebook”.\n4. The experiment on the asset pricing is not very illustrative. It is obvious that adding interaction to a linear model would improve the prediction performance. It would be much useful to compare to other methods to find interactions.\n5. The proposed method seem a direct application of Shapley value method for CTR model. The proposed MC computation is not innovative and the description of the early step part is not very clear.\n",
            "summary_of_the_review": "The proposed method is a direct application of an existing technical. Also there are a few issues in the writing and the experiments in the paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents an algorithm to estimate feature shapley value with reasonable computational cost. Capturing important feature interaction becomes practical.\nThis allows a model to include only important feature interactions and simple model with important feature interaction can performance well\nExperiment result shows the benefit of this approach",
            "main_review": "Strengths:\n  1. Clearly presents the importances of feature interactions. It does the heavy lifting to calculate the feature interaction value, filter out unimportant feature interactions, and only include the important interactions in the model. \nInstead, most of the current approach is to use general model techniques to utilize feature interactions, which is computational intensive, requires large memory, and huge search space.\n  2. The optimization of the shapely calculation seems reasonable\n\nWeekness:\n  1. The experiment dataset may not be big enough to show long term gain\n  2. What is the accuracy gap between calculating Shapley value using its definition versus using this algorithm?\n  3. It is not unique to use shapley for feature selection. This is another paper talking about using shapley value for feature selection. http://www.cs.columbia.edu/~scohen/ijcai05features.pdf\n  4. It is not clear how often to calculate the shapley value and therefore update the features to the model input. And how to decide that update frequency? Any trade-off?",
            "summary_of_the_review": "The main contribution of this paper is not a framework, but an algorithm.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper proposes an interesting approach for improving predictions by focusing on learning interactions over improving a particular algorithm. The paper proposes \"Feature Shapley\", an approach for explicitly learning important feature interactions using Shapley values.",
            "main_review": "Strong points:\n- The focus on capturing the correct feature interactions to use is interesting -- many approaches consider feature selection by considering individual features (and not interactions)\n- The paper is well-motivated: often, too much attention in prediction problems is paid to incrementally improving an algorithm when a greater focus on the mean model could result in larger improvements\n- The comparisons of the proposed approach to other methods are thorough (though only on the original datasets; characterizing these as \"experiments\" is misleading)\n\nMajor concerns:\n- My main concern about the paper is the lack of experimentation and reproducibility.\n    - Experimentation: a deeper analysis of the proposed method is necessary. Consider generating data under a wide variety of scenarios (with a large and small (or zero) number of interactions, with complex or simple mean models, binary and continuous outcomes, etc.) to fully explore the properties of the method.\n    - The example in Section 4.6 is not clearly explained, and the figure is unclear.\n    - The experiments and data analyses need to be clearly explained so that they can be reproduced. Code should be made available.\n- The proposed approach, while well-motivated and interesting, does not appear novel. Shapley values have been used many times for feature importance, and the literature is full of examples where attention is paid to modeling the correct interactions between features. A clearer motivation for the proposal, and where it sits in the literature, would be good (including less focus on the approach as \"novel\").  It is possible that Equation (2) is the novel approach, and this could be highlighted (rather than equation 1) and explained.\n- The exposition could be improved in many places: for example, what is the interpretation of using the learned features (end of Section 2)? if the goal is beyond prediction, how do we account for the fact that we've used the data twice (once for learning the interactions, and a second time for estimation)?; sections 4.1 and 4.2 could be combined and streamlined; the order of sections 5.2 and 5.1 could be switched and streamlined.\n- Why did you focus on linear models? It seems that other methods could provide an even larger performance boost (and you mention this in the conclusion); these methods should be simple to implement and shouldn't add much to computation time (since the bulk of computation time likely comes from estimating the Shapley values)\n\nMinor comments:\n- the GitHub link in footnote 2 is incorrect, it should be https://github.com/WeiyuCheng/AFN-AAAI-20\n- there are typos throughout\n- Figure 2 could be better explained, particularly panel (c)",
            "summary_of_the_review": "I vote for rejecting the paper. The exposition of the paper needs to be improved (including less emphasis on the method as \"novel\"), and the experiments need to test the method in a wider array of settings.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}