{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The authors propose solving linear Fredholm integral equation of the second kind \nby projecting onto a polynomial basis and optimizing the weights using a stochastic optimization\nmethod (Adam). The method is illustrated on four 1-d integral equations.",
            "main_review": "As far as I can tell, this paper just uses a Nystrom method with a polynomial basis ansatz and solves\nthe resulting linear system using Adam. The connection to neural networks is pretty far-fetched. ",
            "summary_of_the_review": "There just isn't anything going on here.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper proposes a learning approach for numerically solving linear Fredholm integral equations of the second kind. The learning approach is essentially a regression problem using a number of fixed basis functions. Experiments show the proposed approach has small approximation error on a few problem instances.",
            "main_review": "My concern mainly lies in three folds.\n1. The novelty and significance of the proposed approach are not clear. It seems to me the proposed approach is just using a few fixed basis functions to fit a target function. This is just a simple fitting task and the approach does not seem to be novel. \n2. The performance of the proposed approach is not compared with any baseline approaches, it is hard to tell whether the proposed approach has a superior performance over existing approaches. \n3. I am not sure if the problem instances in the experiment section are representative or not in the field, there is no discussion why choosing these problems.\n\n",
            "summary_of_the_review": "In summary, the novelty seems to be limited and comparison with existing approaches is not sufficient. Thus, I vote for rejection.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper used a gradient based method for solving a linear integral equation and interpreted it as a one-layer neural network. The method is then used for solving 4 linear integral equations. ",
            "main_review": "The paper is neither novel nor significant. In fact, there is no proper neural networks used in the study and the author essentially only used gradient decent method and interpret it as a one layer neural network. All the problems are actually solved by the collocation method using the gradient descent optimizer and calling such a method NN-collocation is in my opinion not appropriate. \n\nGiven the linearity of the problem, I suspect other methods (e.g., LU decomposition) will easily outperform the gradient descent method for all the very simple linear problem the author addressed in the paper. ",
            "summary_of_the_review": "In summary, the paper is far below the standard of ICLR and I recommend a strong rejection. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The authors propose a numerical method to solve Fredholm integral equations of the second kind using neural networks. To improve the quality of solutions, the authors utilize the pre-defined polynomials and learn neural networks to predict coefficients of solutions.",
            "main_review": "Strengths\n* Neural networks for amortization have been studied in the literature and papers claim that approximating and predicting the solutions of iterative methods directly by NNs allow efficient algorithms. To this extent, solving integral equations by NNs is an interesting topic.\n\t\nWeaknesses\n* I have no doubt that this paper is not fully baked yet. This manuscript has no comparison with baseline algorithms and no sufficient related work. Also, the main benefits of the proposed method are not presented. ",
            "summary_of_the_review": "Although solving integral equations by NNs could be an interesting application,  this manuscript is not ready to be published nor reviewed. Overall, more significant contributions are needed before submission. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper combines the spectral collocation method and neural networks to solve linear Fredholm integral equations of the second kind. The approach is simple and only requires a neural network with a single nonlinear layer. The authors write the solution of the Fredholm equation as a linear combination of polynomials so that the coefficients in this combination are a subset of the weights in the NN. The mean square error is the loss function. The authors apply their technique to four examples that are second kind Fredholm equations with separable and smooth kernels. They demonstrate that it works on these four examples.",
            "main_review": "Spectral collocation methods go back to at least Clenshaw in the 1950s. They have been used on linear Fredholm integral equations (FIEs) for over 70 years. In my opinion, using NNs on the four examples in the paper is not sufficient for a research-level publication. Those examples are too trivial. The use of low-rank techniques is how an expert might solve the presented FIEs.  A non-expert would use dense linear algebra. \n\nI will go through each example in turn: \n\nExample 1: Since exp(x+y) = exp(x)*exp(y), the FIE can be discretized as (I + 2*v*D_w*v^T)*u = v, where v is a vector obtained by evaluating exp(x) on the Gauss quadrature grid, I is the identity matrix, and u is the solution vector. The entries of u are approximate values of the solution on the Gauss quadrature grid. The matrix D_w is a diagonal matrix with diagonal entries of the Gauss quadrature weights. Moreover, the linear system (I + 2*v*D_w*v^T)*u = v can be solved super fast using the Woodbury formula in O(n) operations, where n is the size of the quadrature rule.  If you form the degree n-1 polynomial interpolant that goes through the vector u, then the polynomial interpolant will converge to the true solution exponentially fast in n.   It's extremely difficult to beat this optimal complexity and super-fast approach to solving example 1. The authors will need to add a comparison. \n\nExample 2:  Since exp(2*x-5/2) is independent of y, this example is even easier than Example 1. Similar techniques apply as Example 1. \n\nExample 3: This is the most involved example in the paper.  On [0,1]x[0,1] the function x*(exp(x*y)-1) can be represented by a low rank sum of the form sum_{j=1}^r g_j(x) h_j(y) for some r that depends on one’s accuracy goal. Therefore, the FIE can be discretized as (I + rank-r)*u = b, where b is the function exp(x)-x evaluated on the grid, which can be solved super fast using the Woodbury formula. \n\nExample 4: Since the kernel is x*y, this example is essentially the same as Example 1. \n\nTherefore, the paper applies NNs to extremely easy problems: second kind Fredholm equations with separable and smooth kernels.  For this to be a research-level publication, the authors will need to apply their ideas to more challenging problems and show that they are competitive with other state-of-the-art approaches. ",
            "summary_of_the_review": "Unfortunately, I cannot recommend acceptance of this manuscript. I find the use of neural networks on linear FIEs unmotivated. I hope that the authors can rethink their approach here and come back with a significantly better manuscript that is competitive with state-of-the-art approaches. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}