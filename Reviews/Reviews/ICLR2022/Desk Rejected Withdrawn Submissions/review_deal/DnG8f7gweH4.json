{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposed a method, PCEA, that makes self-supervised methods benefit from info-erasing data augmentations, which are shown to hurt the performance in previous works. The authors also propose a SimReg loss to prevent multiple child views from collapsing into one single representation.\n\nWhen combined with existing self-supervised learning methods MoCo v2 and SimSiam, the proposed method outperforms other info-erasing augmentations. When combined with MoCo v2, it outperforms other self-supervised methods.",
            "main_review": "## Strength\n- substantial performance improvement compared to other info-erasing augmentations (Tab1)\n- competitive performance on various self-supervised benchmarks when combined with MoCo-v2\n\n## Weakness\n- Since the augmentation pipeline contains many extra steps, the review thinks one important piece of ablation is missing: the same augmentation pipeline **without** erasing. The performance improvement might come from the piecing and chipping or from the multiple child-views, not necessarily from the info-erasing augmentation.\n- Is the proposed method compatible with other info-erasing augmentations? For example, those listed in Sec 2.3.\n- Is the proposed method compatible with clustering-based self-supervised methods such as SwAV?\n- The design motivation of each step in the augmentation pipeline is not well discussed.\n- what are the similarity scores of child views trained with and without SimReg loss?\n",
            "summary_of_the_review": "As listed in the weakness part, the reviewer has the concern of whether the performance improvement is actually coming from the info-erasing augmentation or from the proposed augmentation pipeline. Also, it's unclear whether the proposed pipeline is compatible with other info-erasing augmentation or other self-supervised methods. Nevertheless, the proposed method still achieves competitive performance. The reviewer may consider adjusting the score if the listed concerns are properly addressed.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This work proposed a new image augmentation approach for generating \"views\" in self-supervised learning. The new image augmentation approach consists of several steps (1) standard augmentation (2) random erasing (3) piecing four augmented images into a large patch (4) chipping the large patch into four smaller patches. Experiments shows this approach is better than other information-erasing augmentation methods.",
            "main_review": "This work asked a simple question and provided a clear answer. The simple question is \"can we use information-erasing augmentation methods in self-supervised learning\"? The clear answer is \"yes\". There are sufficient experiment results showing the benefit of \"Piecing and Chipping\" compared to other augmentation strategies.\n\nThere are no wrong questions, but is the answer good enough for ICLR? So far I am not convinced. What makes PCEA stand out as an augmentation approach for self-supervised leaning? There is little effort spent on understanding beyond empirical experiments. Would visualize the embeddings learned on the augmented images help?",
            "summary_of_the_review": "What makes PCEA stand out as an augmentation approach for self-supervised leaning? There is little effort spent on understanding beyond empirical experiments.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper describes a data augmentation procedure for creating artificial views for contrastive learning. Specifically, the idea is named 'Piecing and Chipping' where a set of standard augmented views of an anchor image is pieced together and then chipped away via random four-way splits. The pieces are then used as new augmentations for contrastive learning. Experiments on imagenet100 and imagenet-1K linear evaluation show promise. Experiments are also provided on transfer learning tasks demonstrating promising performances.",
            "main_review": "Strengths:\n1. The paper is easy to follow (apart from a few minor typos and grammatical errors) and the presented idea is quite simple.\n2. Experiments demonstrate promise on imagenet-100 and 1K.\n\nWeakness:\n1. I think the main weakness of this method is perhaps that it is not clear what the proposed augmentation is helping with? Of course, it leads to some improved results, but from a technical perspective, the idea looks quite similar to standard random crops, and the recently proposed multicrops (in SWaV Caron et al., NeurIPS 2020), where some smaller crops are made to have embeddings similar to a global crop. Thus, while the proposed idea is quite creative, its scientific merit needs more insights, especially with regard to ideas already out there. \n\n2. The experiments show some improvements on some baselines, however I would think the state of the art on imagenet-1K and such are quite higher than the methods reported as baselines. For example, SWaV is already at about 75+ and Dino Caron et al.) is even higher (although the paper seems to report weaker numbers for some reason). Thus, the paper should provide results against these comparisons to see if the proposed augmentations show anything better over these methods.\n",
            "summary_of_the_review": "The paper lacks any solid insights behind how the presented method is better than prior approaches and how it leads to better results. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None I can see. ",
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This work proposes a data augmentation method, namely PCEA. The augmentation process is built based on the intuition that spawning child-views should be different but similar to the parent-view. This work also presents the SimReg loss to regularize the utilization of the child-views.\n\n",
            "main_review": "1) the proposed method significantly improves the accuracy of linear classification on ImageNet-100. However, the improvement on MsCOCO is marginal. It seems that the proposed method has limited generalizability.\n\n2) The data augmentation pipeline is reasonable, but the motivations of the method are unclear. For instance, in step 2, I wonder why the authors propose to piece four different child-views? In step 3, how to locate the candidate region and why?\n\n3) There are too many hyper-parameters in the PCEA method. In Section 5, a few ones are determined by grid search. But searching all of them is prohibitively expensive. So, how to make sure that the PCEA method work in real-world scenarios?\n\n4) I am confused about the Similarity Regularization loss. What do q_1 and q_2 mean in Equation 1? More importantly, what is the training objective in the experiments?\n",
            "summary_of_the_review": "The proposed data augmentation method seems to be effective on large-scale datasets such as ImageNet and MsCOCO. However, the whole pipeline includes numerous hyper-parameters chosen by gride search, which makes the reproducibility and application to other cases challenging. In addition, the effectiveness of the proposed SimRegloss is not clearly demonstrated.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}