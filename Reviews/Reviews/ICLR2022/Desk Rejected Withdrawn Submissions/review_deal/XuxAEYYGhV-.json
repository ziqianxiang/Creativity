{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This work proposes a data augmentation approach based on interpolating generative models with the aim of improving the generalization of neural networks on out-of-distribution samples. The authors considered the domain generalization setting and used multiple generative adversarial networks (GANs) trained on the source domains to generate out-of-distribution examples. The authors claimed that training one GAN per domain might be susceptible to mode collapse and to mitigate this potential issue, they propose to first train a GAN on one of the source domains and then fine-tune the generator (without updating the parameters of the discriminator) on each of the remaining domains. Finally, the model considered for generating (potentially) out-of-distribution data is the result of a convex combination of the parameters of each domain-specific generator. The proposed approach was evaluated on multi-class classification tasks on three computer vision datasets following a leave-one-domain-out protocol. The introduced augmentation scheme was used along with different training strategies, including ERM. Overall, it was shown that increasing the number of augmented examples was helpful for improving a model’s performance on unseen domains. Moreover, the proposed scheme to train GANs on the source domains was evaluated by computing the FID of generated samples. ",
            "main_review": "This work proposes a data augmentation approach based on interpolating the generators of  GANs trained/fine-tuned on source domains. Samples from such generative models are claimed to be “out-of-distribution” with respect to the training distributions and are considered at training time as a way to increase the diversity of the training data in such a way that potential spurious correlations between features and labels are no longer observed in the dataset. Given that previous work on domain generalization has empirically shown that data augmentation is critical for improving neural networks' ability to generalize out-of-distribution, I believe this paper tackles a relevant problem. Moreover, the idea of using a mixture of conditional GANs to allow a controlled generation of examples seems interesting. However, this submission lacks support for many of its claims, as well as a deeper investigation of why/if the proposed approach works. My main concern is the fact that there is no clear evidence to support the claims the proposed augmentations are helping because they are generating out-of-distribution data. In the following, I provide a detailed description of my concerns along with suggestions to address them.\n\n- I have major concerns regarding how sound and well-supported are the main contributions of this work as per the authors summary at the end of the introduction:\n\n  - “We take a step towards understanding OoD generalization from a data augmentation perspective”. Besides the empirical evaluation showing that increasing the number of samples from the GAN is helpful, there is no further evidence to support this claim. Notice, also, that this experiment only shows that increasing the training data with augmented examples is helpful, however, it is not clear how diverse these examples are. Therefore, it is unclear to me whether this improvement is observed mostly due to having more training examples available.\n  - “Our experimental results show that our proposed framework can explicitly generate diversified OoD samples”. From the presented experiments it is not clear to me if the generated examples can be indeed considered as out-of-distribution. It is necessary to include in the manuscript either theoretical results or experiments to assess this hypothesis. A suggestion to do so is to consider a model-dependent notion of divergence between distributions. For that, it is necessary to train a model to distinguish real and generated examples by performing binary classification. This should be done for each domain in training data so that the classification performance can be a proxy for the H-divergence between each domain and a distribution of augmented examples. Notice that the same hypothesis class as considered for the final evaluation should be considered for this experiment so that it is possible to get a clear idea of how “out-of-distribution” the generated samples for the particular considered class (i.e. the class represented by ResNet-18 models).\n\n- The paper lacks clarity in several sentences which makes it difficult to properly understand some points that seem crucial for the narrative developed in the manuscript. For example:\n  - At the beginning of Section 2.1, the authors mentioned: “In OoD scenarios, we are interested in augmenting the training data with similar but different additional virtual examples”. What exactly are “similar but different” examples? Does this correspond to data that was augmented in such a way that spurious correlations are broken? Please clarify this. \n  - In Section 2.1 (page 3), the authors mentioned that “The well-trained GANs are able to synthesize photo-realistic images”. Could the authors please clarify what they mean by well-trained GANs?\n  - Algorithm 1: The algorithm depicted by Algorithm 1 seems to not be correct. As far as I understood, there should be a loop between lines 2 and 3 a loop with index j indicating that the generator with parameters \\theta_i is fine-tuned on all the remaining domains prior to the training of the classifier. Moreover, as far as I understood, the weights of the convex combination in line 4 are hyperparameters and, therefore, they should be included as a requirement along with the other hyperparameters. Finally, in line 9 it is stated that the training of the classifier is performed until convergence. What was the adopted convergence criterion adopted throughout all the experiments? From Section 3.1, it seems to me that rather than evaluating a convergence criterion, training was performed during a pre-defined number of epochs. Please clarify this in order to ensure reproducibility.\n  - In Section 3.2 (page 6), the authors mentioned “we evaluate and analyze the results of our method on four datasets: Full Colored MNIST, Fashion MNIST, PACS, which represent different aspects of distribution shifts.” What exactly are these different aspects of distribution shifts and why do the authors believe the proposed augmentation approach would be suitable for mitigating the effects of these specific types of distribution shifts?\n  - The authors mentioned in Section 3.2 that they compared their approach with advanced OoD algorithms. Could the authors clarify what aspects make these particular algorithms advanced?\n\n\n- I also have concerns regarding the experimental design and some of the conclusions drawn from the experiments:\n  - In Table 3, the authors compared the ERM+the proposed approach with several domain generalization methods. However, as previous work showed (Gulrajani and Lopez-Paz, 2020) data augmentation is crucial for domain generalization under these experimental circumstances. Given that, it is not possible to judge the merit of these results without mentioning the augmentation protocol employed when training each one of the considered baselines. Moreover, in case no augmentation was included in the training of the baselines, I don’t think this comparison is fair since the aspect being assessed by the experiments would be the effect of augmenting the data, rather than how to augment the data. I think a better way to assess the effect of the proposed augmentation is to compare it with other strategies such as RandAugment, or only simple augmentations such as rotation and horizontal flip. Also, the number of augmented examples for each approach should also be included in the comparison, otherwise, it is not possible to conclude if the improvement stems from an increase in the number of training examples or from the augmentation strategy. \n  - When analyzing the results presented in Table 1, the authors mentioned on page 7 that increasing the number of augmented examples consistently improves the performance of all the considered methods. However, this is not verified in the results since for ERM, there is a decay in performance when the number of augmented examples increases from 20k to 25k (the average accuracy goes from 73.50 to 64.26). Please remove such claims from the text.\n\n\n- Minor concerns:\n  - Section 2.2 (page 5): There is no Table 3.2 or Table 3.4 in the manuscript. \n  - Equation 2 is too close to the text in the bottom paragraph to a point where they are overlapping.\n  - Typos (did not affect my score):\n     - Page 4: inspires by the priors literature -> inspired by the prior literature\n     - Page 6: epoch -> epochs\n     - Page 7: facility -> facilitates",
            "summary_of_the_review": "Given that previous work on domain generalization has empirically shown that data augmentation is critical for improving neural networks' ability to generalize out-of-distribution, I believe this paper tackles a relevant problem. Moreover, the idea of using a mixture of conditional GANs to allow a controlled generation of examples seems interesting. However, this submission lacks support for many of its claims, as well as a deeper investigation of why/if the proposed approach works. My main concern is the fact that there is no clear evidence to support the claims the proposed augmentations are helping because they are generating out-of-distribution data. I also raised important concerns regarding the experimental setup and inconsistent conclusions drawn from the results. Moreover, the paper lacks clarity in various aspects and misses important references to closely related work. All in all, I think this work considers a promising research direction but due to the concerns I raised, it is not ready to be considered for publication yet.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This work considered using generative models, in particular StyleGAN2, to increase the diversity of the training data for better OOD performance. The core idea is to learn multiple conditional generative models in a so-called pre-training and fine-tuning manner. Specifically, 1) the training data was assumed to have multiple (N) source domains (such as styles and colors). 2) StyleGAN2 was first trained on one source domain and then was fine-tuned on each of the other domains, to get the resulting N StyleGAN2 models. 3) An interpolation of model parameters from the above N StyleGAN models and the style-mixing between two batches were performed for better generation diversity. Experiments on Full Colored MNIST, Colored Fashion MNIST and PACS datasets were conducted to show the effectiveness of the proposed method. \n",
            "main_review": "Strengths:\n\n(1) The idea of interpolating model parameters from multiple GANs for more diverse data generation is new and interesting.\n\n(2) Experiments on the considered datasets show the proposed data augmentation can benefit the OOD classification.\n\n\nWeaknesses:\n\n(1) The presentation needs a significant improvement. \n\nFirst, there exist many typos and grammatical errors in the paper. For example, “inspires by the priors literature...” (Section 2.2), “This facility the GANs training on...” (Section 2.2), and “...are successfully being changes...” (Section 2.3), “...compare FID results of the visual quality...” (Section 2.3). \n\nSecond, many descriptions of the method are vague, imprecise or unclear. For example, is the proposed method called “interpolated GAN”? I couldn’t find a definition of this term that has been used later in the main text. How does the proposed method select the source domain for training (while others for fine-tuning)? Randomly chosen? Also, how are the prior methods (ERM, IRM, Mixup and REx) combined with the proposed method? It is unclear to me. \n\nFinally, in experiments, what does “Real Data” mean? It is not crystal clear to me even after reading the main text. I suggest the authors make the captions of Table 1 and 2 more self-contained with detailed explanations of “Real Data” and “Syn. XXX”. In Table 6, what do the reported numbers mean? No metric mentioned in this table. Also, the discussions in Section 2.3 seem to be a summary of experimental results. Why not move them to the experiment section?\n\n(2) The proposed method requires that the domain information (such as styles and colors) has to be known. That is, in order to train and fine-tune generative models in different source domains, we have to know the corresponding domain labels to split the training data into multiple domains. First, this domain information is expensive to obtain in practice, making the proposed method of less practical importance. Second, using extra supervision for data augmentation may lead to an unfair comparison with baselines that do not need this supervision. \n\n(3) Experiments were performed on toy datasets. Only simple datasets, including Full Colored MNIST, Colored Fashion MNIST and PACS, are considered during evaluation, which makes the results less convincing if the method can be applied to the real cases. Perhaps one reason is because for more complex datasets, such as ImageNet-C, the domain information is difficult to obtain. This also implies that the proposed method lacks practical significance. \n\n(4) In Table 2, we can see an increasing OOD acc comes with a decreasing IID acc. This trade-off is what we want to avoid in practice. How do the authors justify this observation?\n\n(5) In Table 1, for ERM, its OOD accs are not monotonically increasing. Because “Syn 20K” has a higher OOD acc (73.50) than “Syn 25K” (64.26). \n",
            "summary_of_the_review": "Overall, I feel the weaknesses of the paper are significant, regarding the presentations, the practical significance of the method, and the experimental evaluations. Thus, I recommend rejection.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "The authors have well addressed the ethics concerns that the proposed method may have raised.",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors studied the OOD generalization in classifiers for GANs with data augmentation. Instead of training GANs directly on multiple source domains, the authors proposed to pre-train on one domain and then fine-tune on other source domains.  Linear interpolation and style-mixing are applied to boost the performance of OOD generalization. Extensive simulation is performed to validate the efficiency of the algorithm for OOD generalization.",
            "main_review": "Strengths:\nExtensive simulations are implemented to compare with state-of-the-art approaches.\n\n\nWeaknesses:\n. It is claimed that the generated OOD samples cover larger diversity ranges. If the generated OOD samples all belong to the same classes as those in the training set, how to quantify such diversity?\n\n. The experiments show that with more synthesized data the OOD generalization improves. Then the question is what if we use only synthesized data for training classifiers? What's the performance? Is there any tradeoff between using real data and synthesized data?\n\n. The authors emphasized the superior performance of the proposed algorithm. However, with more synthetic data the training time would be significantly increased. It's better to add discussion on both the advantage and limitations of the proposed algorithm for a fair comparison with benchmarks.\n\n. In Algorithm 1 line 3: how to pick \\theta_i to update \\theta_j?  To achieve a better performance, do you have to carefully pick a network for fine-tuning?\n\n. How to set the interpolation coefficients (Equ. 1) in your experiments? How do these parameters affect the performance of OOD generalization? \n\n. In Table 1, what's the difference between in distribution check mark and cross mark? What's the OOD data here? Are the results averaged over different OOD datasets or for some particular OOD dataset?\n\n. Results on colored fashion MNIST: the described numbers are incorrect. They are from Table 1, not Table 2.\n\n",
            "summary_of_the_review": "Extensive simulations are performed to study the performance of the proposed algorithm. However, some key parts are not well explained/studied (eg, diversity of OOD samples, tradeoff between real samples and synthetic data, and how to pick a network for fine-tuning).",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper aims to improve the OOD generalization of classifiers, whereby given K source domain training data the aim is to generalize to a target domain. To do this, the paper proposes to generate samples from GANs and then use these as additional training data, with the hope that they can increase the generalisability of the model to the target domain. Directly generating samples from the GAN trained over source data might not be helpful as the GAN samples can contain the spurious correlations present in the training data which will not be useful over the target domain. The paper instead proposes to use Interpolated GAN, whereby a GAN is trained over each of the k source domains(using a shared discriminator), and then the parameters of the k generators are linearly interpolated to produce an Interpolated GAN. The paper claims that samples generated from this Interpolated GAN are realistic and can be used to increase the diversity of the training data which in turn helps the model to generalize to the target domain. They verify their claims with experiments over Colored MNIST, Colored Fashion MNIST and PACS dataset.",
            "main_review": "Strength -   \n1) The idea is well motivated in the paper and is easy to follow.\n2) The empirical results do show the benefit of the proposed approach.\n3) Different ablations are performed to verify the effectiveness of different components such as the size of the generated dataset.\n\nWeakness - \n1) The tasks considered for OOD generalization are pretty weak. The proposed interpolated GAN method approach will not work when there is for instance only a single source domain. Recent works([1]) have often referred to OOD generalization as the task of improving robustness across corrupted target domains such as CIFAR10-C or ImageNet-C. Can the authors explain how their approach can be used for such OOD generalization tasks and also present some results?\n2) For datasets such as Coloured MNIST and Coloured Fashion MNIST, the aim is to make to model be texture invariant. For this instead of using generated samples, the model could also have trained on style-transfer augmented samples as done in [2] which would the model look at the shape. Can the authors compare against such a baseline?\n3) The authors mention that they compare their method against advanced augmentation methods, but only use Mixup as the augmentation. It seems that using several other advanced augmentations such as Manifold Mixup, CutMix, RandAugment might itself suffice to increase the generalization of the network. Can the authors compare against these augmentations?",
            "summary_of_the_review": "The tasks considered in the paper and the baselines used are not really good enough to fully understand the benefit of the proposed approach.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}