{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper empirically studies the role of depth in fully-connected networks for learning certain types of target models, given either by a single \"k-local\" label, i.e. the sign of some interaction between k variables, or \"k-global\" labels, which pool such local interactions over different shifts. The authors then provide various experiments on trained networks as well as NTK kernels, suggesting that depth may help with local models, but may hurt with global models for finite-width networks, and comment on the limitations of NTK. Finally, the authors provide some motivation from statistical physics for studying such local/global models, and discuss some explanations for the observed phenomena in terms of chaotic signal propagation.",
            "main_review": "The finding regarding the role of depth for learning local vs global interaction models is interesting, and may motivate further theoretical studies for why this is the case. However, the significance of using deep fully-connected networks for such problems is unclear, and both the experiments and the discussions could be more thorough:\n\n* the choice of network widths and depths is unclearly justified, particularly in figures 1/2. Could you compare models with the same number of total parameters instead? or the same widths at every layer? In figures 1/2/4, why do you only consider depths 1 and 7? Overall, I believe the experiments could be more comprehensive in covering a wider range of models.\n\n* \"we stop the training if E_train = 0\" seems a bit strange as a model selection criterion, and could favor models that do well at that specific point: why not pick the best possible model throughout training (and even beyond the zero training error point)?\n\n* It is expected that the NTK would work poorly on such problems in high dimension with low-dimensional structure. Why does it seem to work better for global models? Also, different depths seem to lead to different behaviors in some cases, could this be due to the lack of bias term, which makes it hard to approximate even/odd functions? (see [here](https://arxiv.org/abs/2007.01580) or [here](https://arxiv.org/abs/2009.14397))\n\n* There are some inconsistencies in the plots, e.g., some plots have error bars, but most do not.\n\n* While the discussion on signal propagation is interesting, it would be useful to have further discussion, and alternative hypotheses of why depth (and maybe hierarchy?) may help local models more than global ones.\n",
            "summary_of_the_review": "Interesting observations, but experiments and discussion do not seem extensive enough for publishing such an empirical paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors aim to study the advantages and disadvantages of depth in neural networks by experimentally observing their generalization error for two classification task, a \"local\" task and a \"global\" task. They observe that for the local task, deep fully-connected networks outperform shallow networks, but for the global task the reverse is true. They also look at the effects of depth and learning rate, and include the NTK limit in their experiments. They motivate their tasks by analogy to statistical physics.",
            "main_review": "The paper is clearly written over all and the experimental results are interesting (novel to me). However, I have some concerns about the presentation and the experimental protocol.\n\nWhat the authors call $k$-local label is just a sparse parity of the (signs of) the inputs; or equivalently a monomial threshold. The $k$-global label is a polynomial threshold function. The authors do not include any discussion of the ML literature on learning sparse parities/monomials/polynomials. These are very simple functions and I would have liked for the results presented here to be contextualized to a much greater extent.\n\nI am most concerned about the fact that in their experimental protocol, they stop the training when the training error $\\mathcal{E}_\\text{train}$ is 0. It is well-known that when training a deep neural network with SGD, the test performance often continues to improve long after training error has reached 0 (a.k.a. interpolation). It is unclear whether the authors' results would be valid if they continued to train the deep networks, and this leads me to doubt the relevance of their results, unless they restrict their claims to be about what happens early in training or until interpolation. In general I'm worried about how well the results here hold up to changes in the experimental protocol. The authors themselves show that the results vary considerably depending on various hyperparameters such as learning weight and width.\n\nThe authors propose a potential explanation for their experimental results in terms of \"chaotic signal propagation\". The explanation isn't very well fleshed out. I didn't understand, for example, why they focus on $L^1$ distance as opposed to another metric. Beyond this explanation, I would have liked to see more conceptual exploration of the empirical results. For example, since the data are drawn from a normal distribution, is the global function able to be learned by only looking at a small fraction of the labels? How does the 1-hidden layer network represent the local and global functions? etc.\n\nThe authors make some fairly strong claims about the importance of their findings; e.g. \"Our main result thus implies that shallower networks are more suitable for machine learning of thermodynamic systems,\" and with my misgivings above it is doubtful to me that these claims are justified.",
            "summary_of_the_review": "This paper presents some interesting experiments involving the dependence of performance on depth in a few toy tasks. I am recommending rejection because the experimental protocol does not seem sufficient to justify the strong conceptual claims made by the authors, and because they do not discuss any related work about problems like the specific toy problems they consider.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents an empirical analysis on the role of depth in the inductive bias of fully connected neural networks. Specifically, the authors propose to study the performance of shallow and deep neural networks (and their respective infinite-width NTKs) on two synthetic non-linear datasets: One with local features, and another one with global features. Surprisingly, deep neural networks have a better performance on the local dataset, while they suffer on the global one, where the wide networks shine. The authors argue that the NTK regime is not able to capture this type of inductive bias.",
            "main_review": "## Strengths\n1. **Problem is relevant**: Studying the role of depth is an important research question, which as far as I know has not been fully answered in previous studies. In particular, the investigation proposed in this paper regarding the interplay of depth with data structure seems to be novel and timely.\n2. **Non-uniform superiority of deep neural networks**: The results showing that shallow neural networks can generalize better than deep models to datasets with global features is very surprising.\n3. **Dynamics of active regime**: I find especially compelling the result presented in Fig. 4 showing how learning rate governs the transition from a lazy to an active regime, and how this drives the performance of a deep network on the local and global feature datasets. Fig. 3 is also quite insightful.\n\n## Weaknesses\n1. **Dataset structure is too specific**: In my opinion, the design of the $k$-local and $k$-global labels is too narrow, and this makes the results presented in this paper too specific. This has considerably affected my final negative score. In this sense, I would be open to increase my score if the authors could show that their findings can generalize beyond their narrow setup. That is, considering the empirical nature of this work I would expect the authors explore their hypothesis on more general forms of local and global features. One possible way to this would be to work on some teacher-student model like the one proposed by Favero et al. 2021, which defines a space of random functions defined by global and local features and allows to control their smoothness. Alternatively, one could also replace the constraints in (1) and (2) by random functions of these indices (e.g., parameterized by a random neural network).\n   - Alessandro Favero, Francesco Cagnetta, Matthieu Wyart. \"Locality defeats the curse of dimensionality in convolutional teacher-student scenarios\". arXiv 2021\n2. **Results for NTK on MSE**: I do not see the reason why the authors decided to use MSE instead of cross-entropy loss to train the NTKs. The `neural_tangents` library allows to train infinitely wide networks on any loss, so there is no reason for the authors to prefer the closed-form MSE solution to the cross-entropy trained NTK one.\n\n## Other comments\n1. **Missing citation**: Although from a completely different point of view, Nguyen et al. 2021 also studied the role of depth on neural networks used in practice and should be cited.\n   - Thao Nguyen, Maithra Raghu, Simon Kornblith. \"Do Wide and Deep Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth\". ICLR 2021\n2. **Physics dataset is still synthetic**: Although I understand why the authors have tried to argue in favor of the relevance of their synthetic problem by motivating it through its connection to statistical physics, in practice, their physics task is also synthetic. Overall, I am of the opinion that this section is irrelevant to the current message of the manuscript, and does only take away space for a more in-depth analysis of the described phenomena.\n3. **Role of depth is not investigated in Fig. 4**: Fig. 4a does only present the results for a shallow neural network. Since the main topic of this work is to study the role of depth, I would encourage the authors to also provide the analogous figure for deeper NTK models.\n\n",
            "summary_of_the_review": "Overall, I think the problem studied in this work is timely and of interest to the community. In particular, I appreciate the fact that the presented empirical findings are somehow close to theoretically tractable setups, which might help in the development of new mathematical theories to understand deep learning. However, this being said, I also think that the current experimental setup is rather limited, and might not transfer to more general scenarios. In this sense, as long as the authors do not provide results on more diverse tasks, and provide a deeper analysis, I would vote for rejection.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "(1) The authors propose a new synthetic dataset generated by Gaussian input data with local labeling function and global labeling function, where the intuition comes from thermodynamic systems in physics. (2) The authors run some experiments using shallow and deeper neural networks and conclude that the shallow networks work better with global labeling function while deep networks work better with local labeling function. (3) The authors use chaotic signal propagation to roughly explain the observations described in the second point mentioned above. ",
            "main_review": "Strengths:\n1. Novelty: Although in deep learning and computer vision field, it is well-known that deep model is sensitive to the local pattern (e.g. Generative Adversarial Network or adversarial attacks in deep learning model) and shallow model is related to global features (style transfer), the authors propose and study the relationship between model depth and locality of relevant features. \nFigure 3 is the most interesting result in this paper from my perspective. For the global labeling function, when we increase the depth of models, the test error increases, while the test error decreases for the local labeling function case. This phenomenon is against common sense that a deeper model will have a smaller generalization risk. It somehow answers the question in the title that a deeper model may have worse performance. \n\nWeakness:\n1. Contribution: The paper’s contribution is limited. As I mentioned above, although the authors propose a good question, they do not study it thoroughly. (1) The paper only contains observations and high-level rough explanations by using chaotic signal propagation. The paper misses detailed and formalized analysis. The paper only contains observations. (2) For Section 4 (chaotic signal propagation), the explanation is not novel as well,  which browser from “Exponential expressivity in deep neural networks through transient chaos”. \n\n2. Limitation: The paper only considers a synthetic dataset related to thermodynamic systems in physics. (1) I cannot find the generalizability of these labeling functions (especially for equation 2). The claim may be limited to this specific setting. (2) On the other hand, the paper does not run experiments on the real-world dataset. I wonder whether Figure 3 is true for the real dataset. If not, then the observations of this paper have limited value.\n\n3. Experiments: The experiment part is not thorough. (1) The paper only considers 1 layer and 7 layer neural networks. The paper should try more cases e.g. 2, 3, and 30 layers. (2) The parameter numbers for each experiment are not consistent. For example, in Figure 3d, the parameter numbers of shallow networks are much larger than the deep networks, so it is hard to support the claim that the shallow model is better for global labeling cases. \n\nMinor Questions:\n1. The paper does not consider regularization and double decent curves. In my opinion, the phenomenon in Figure 3 may be related to regularization. If there is an explicit regularization term, the story may be different. The experiments for regularization should be on paper from my perspective. \n2. Section 3.1 is unremarkable. The authors may move it to the appendix or prune it. Also, there is no amazing claim or conclusion for the NTK part. \n",
            "summary_of_the_review": "Although the paper is novel as I mentioned in the strengths, there is some critical weakness including marginal contribution and severely limitation. Thus, my rating is reject. I may change my rating based on rebuttal and other reviews’ comments. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}