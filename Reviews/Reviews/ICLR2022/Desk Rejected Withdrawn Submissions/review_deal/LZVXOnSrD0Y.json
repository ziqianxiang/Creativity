{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Reject",
        "comment": "The paper introduces a method to approximate a Pareto front for multi-objective TSP. The proposed method first converts the MOTSP into a set of constrained single-objective optimization problems with different preference-based constraints. Then it builds a modified TSP-Net with preference augmentation to solve all the constrained problems. The method is empirically compared with multi-objective genetic algorithms and a DRL-based approach, showing to be competitive in the approximation of the Pareto front.\n\nAfter reading the authors' feedback and discussing their concerns, the reviewers reached a consensus and they think that the paper is still not ready for publication. The authors need to improve their experimental evaluation in order to make it more robust and fair."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The authors have presented a Pareto frontier approximation network (PA-Net) for multi-objective travelling salesman problem. The authors showcased that the PA-Net was able to generate good quality Pareto fronts with fast inference times as opposed to other learning methods such as\nThe authors leveraged the generalization by using deep neural networks to solve the large values of number of preference vectors that are computationally hard and showcased that the formulation can find concave Pareto frontier too.\n\n\nContributions:\n\n\na. Computation time in training the models and generalizing for other instances\n\n\nb. The proposed approximation methodology performs well in hyper volume and on the computation time.\n",
            "main_review": "\nStrengths:\n1. The authors have provided a good background on the problem with adequate review of literature.\n2. Motivation to determining the Pareto optimal solution as a constrained programming for the MOTSP is well written and provides good readability.\n3. The authors had explained the experimental design clearly in Section 4 and well-written. \n4. The authors have also presented the convergence of the proposed method to Concave Pareto Front.\n\nNeed some minor improvements\n1. Need supportive evidence for making a strong statements such as \"These classical methods to solve MOTSP are typically handcrafted and don’t generalize well for different problem instances.\" (Section 1 Page 1). \n2. Rationale of leveraging Monte-carlo sampling to calculate HV needs to be explored in detail.\n3. Although the proposed methodology yields better results under the Hyper volume and computation time, the authors are obliged to provide the rationing of the performance against DRL-MOA, NSGA-II and MOEA/D. \n4. The authors had taken good care in explaining and conducting the experiments in detail but the performance analysis of the different algorithms provided were inadequate. \n5. The authors had the scope to explain why the classical algorithms are not well performing in larger instances and deep learning based models performing well in those scenarios but missed to detailed out in the discussion section.\n\nTypo:\nAppendix section - First paragraph as a typo. Please correct it.",
            "summary_of_the_review": "At the outset, this article seems to be a decent contribution to the literature on Multi-objective optimization problem in general, showing little improvement over the state-of-the-art. The paper is structured well and provided adequate/necessary references. The experimental results showcased the dominance performance of the proposed PA-Net over some of the evolutionary and a deep learning method in the literature. However, there are additional clarity needed to reinforce its acceptance to ICLR 2021. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper introduces a method to approximate a Pareto front for multi-objective TSP from neural combinatorial optimization using deep reinforcement learning.\nThe PA-Net method uses a constrained optimization problem formalization with a preference vector to control the solution generation.\nAn experimental evaluation is performed and PA-Net is compared to multi-objective genetic algorithms and one DRL-based method from the literature. PA-Net performs competitive and approximates the Pareto front well.",
            "main_review": "The extension of neural combinatorial optimization towards multi-objective problems is timely and a relevant topic to bring the subfield forward.\nHowever, the contribution of this paper towards the field seems to be small, being mostly the different formulation of the problem as a constrained optimization problem, while being otherwise based on the methodology from the literature.\n\nAt the same time, the focus is only on the TSP problem, which is one of the favorite problems in this subfield, but not very strongly constrained and not expressive enough by itself. The paper would benefit a lot from also considering other problems.\n\nRegarding the experiments, I would be interested in a more precise evaluation of the effect of the preference vector. How specifically can individual points on the Pareto front be identified and selected without enumerating over many solutions?\nIt also looks like that PA-Net does not find as extreme solutions as DRL-MOA (Figure 2). Could the authors comment on that?\nWhy did you not consider an exact solver, e.g. with a linearized objective, as an additional baseline?",
            "summary_of_the_review": "The paper makes a contribution to multi-objective TSP solving with DRL.\nThe contribution itself is interesting, but in combination with the experimental evaluation too limited to be properly judged at this point.\nIn my opinion, the paper is not yet ready to be published and should be extended in its applications and evaluation.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This work proposes a Pareto frontier approximation network (PA-Net) to learn the Pareto frontier for multi-objective traveling salesman problem (MOTSP). The proposed method first converts the MOTSP into a set of constrained single-objective optimization problems with different preference-based constraints. Then it builds a modified TSP-Net with preference augmentation to solve all the constrained problems. For a new MOTSP instance, the trained network can generate different approximate Pareto solutions by adjusting the preference. The experimental results show that the proposed PA-Net method has a good performance on MOTSP instances with different numbers of cities and objectives.  ",
            "main_review": "**Strengths:**\n\n+ The studied problem, MOTSP, is important and could be useful for many real-world applications. The learning-based approach for multi-objective combinatorial optimization is a timely research topic and could be interesting to many researchers in the community. \n\n+ The proposed method can generate different approximate Pareto solutions with a single model. It also has a good overall performance and training times on different MOTSP instances, but also with many concerns.\n\n**Weakness:**\n\n*Method:*\n\n**1. Problem Formulation:** \n\nA key step in the proposed method is to convert the multi-objective optimization problem into different constrained single-objective optimization problems. However, many conversion methods have already been proposed [1-3] which can tackle the non-convex Pareto frontier. None of them are discussed in this work. Is the proposed problem formulation new or adopted from other works? \n\nWhat are its advantages (and disadvantages) over other methods? \n\nWhat is J(\\pi_k) in (7)?\n\n**2. Finding the Whole Pareto Front:**\n\nTheorem 1 is a crucial motivation of this work to find the whole Pareto front. However, the theoretical property of Theorem 1 is relatively weak. It can only guarantee that the optimal solution of the constrained single-objective problem can dominate other solutions that satisfy the same constraint. Therefore, the obtained solution is not guaranteed to be Pareto optimal (can be dominated by other feasible solutions out of the constrained set). In addition, even assuming all the single-objective problems can be successfully optimized, there is also no guarantee that all Pareto solutions can be found by the proposed method. \n\nIt is also confusing why the obtained solutions can exactly lie on the unit vector in Figure 1. In my understanding, the proposed method can find a solution that satisfies the preference-based constraint while minimizing the L2 norm of all objectives. Since the problem has an inequality constraint, the obtained solution should be close to the unit preference vector but not guaranteed to be exactly on the unit vector.\n\n**3. The Model Structure:**\n\nTo incorporate the preference into the TSP-Net model, the proposed method simply adds the preference embedding to each node (city) embedding. According to the ablation study in Appendix, the preference embedding network can be a simple single-layer FC. The rest model is the standard TSP-Net where the whole transformer-based encoder can be totally replaced by a single 1-D convolution layer. Why can this simple structure work so well for MOTSP? Will it significantly hurt the model performance of each individual preference compared to a single objective model?\n\nMore concerns on the results are listed below in the experiment part.\n\n**4. Other Problems and Related Work:**\n\nOne important advantage of the learning-based method is its flexibility to solve different problems [4]. Although this work focuses on MOTSP, I believe it could have a larger impact by showing its ability to solve other problems. \n\nMany works on deep multi-task learning and multi-objective RL have been cited and discussed multiple times in the related work section, while they are not the most related work to this paper. I think it is better to shorten this part into a single paragraph, and leave more space to discuss the related work on learning-based solvers (e.g., [4]) and other approaches for MOTSP. \n\n*Experiments:*\n\n**5. Competitive Baselines:**\n\nAccording to the experimental results, the learning-based solvers are much better than the heuristic-based solvers. However, for the single objective TSP, the SOTA heuristic-solver (e.g., Concorde) usually has the best performance. Since the obtained Pareto front is not highly non-convex (as in Figure 2), the results for linear scalarization + Concorde should be included for a better comparison.\n\n**6. Unfair Comparison:**\n\nThe comparison to other learning-based solvers is questionable. First of all, one contribution of DRL-MOA is the transfer learning based training method. The required training epoch (and time) is far less than those reported in this paper. Hence the results reported in Table 1 are misleading. It seems that all the PA-Nets are trained on the 120-city instances for 2,3 and 5 objective MOTSP. However, the original DRL-MOA is only trained on the 40-city MOTSP. As reported in this work, \"The trained model of bi-objective TSP for DRL-MOA (Li et al.,2020) is used.\", will it lead to unfair comparison?\n\nThe TSP-Net is more powerful than the Ptr-Net used in DRL-MOA, so it is expected that it can have better performance. However, it only moderately outperforms DRL-MOA on the 2 and 5 objective problems, and has worse performance on the 3-obj problems. A more reasonable baseline is to use the TSP-Net in DRL-MOA to check whether the preference-based model could lead to worse performance.\n\nTo calculate the hypervolume, this work reports the results with {100,500,500} preferences for the 2, 3, and 5 objective MOTSP instances, while it only reports the results of {100, 91, 40} networks for DRL-MOA. Although it is understandable that one advantage of PA-Net is to generate a dense approximation, the results of {91, 40} preferences should also be reported for a clear comparison. Since PA-Net (with 500 preferences) are already outperformed by DRL-MOA (with only 91 models) for the 3-objective MOTSP, will it be significantly outperformed by DRL-MOA with the same number of solutions?\n\n**7. Missing Experiment Settings:**\n \nHow many training samples and epochs are used to train the PA-Net and DRL-MOA? How many test instances are used to measure the performance for different methods? If there is only one instance for each kind of problem, the results are not convincing. What is the run time (inference) for each method to solve the MOTSP instance with different numbers of objectives and cities?\n\nThe details for Hypervolume calculation (e.g., the reference points for different instances) are missing.\n\n**8. Surprising Results on the Ablation Studies:**\n\nIt is quite surprising that the transformer-based encoder is not needed for the TSP-Net, and only a simple one-layer FC is needed for preference embedding. With this setting, the whole PA-Net should have a much smaller scale. What are the total numbers of parameters for these ablation settings (1, 2, and 3)? With the 1-D Conv encoder, the ablation 3 model should be even smaller than the Prt-Net. Why it still needs ~12 hrs to train the model? Why can this model still outperform the Ptr-Net model on the 2-objective MOTSP?\n\n**Reference:**\n\n[1] Das, Indraneel, and John E. Dennis. \"Normal-boundary intersection: A new method for generating the Pareto surface in nonlinear multicriteria optimization problems.\" SIAM journal on optimization 8, no. 3: 631-657, 1998.\n\n[2] Mavrotas, George. Effective implementation of the ε-constraint method in multi-objective mathematical programming problems. Applied mathematics and computation 213, no. 2: 455-465, 2009.\n\n[3] Miettinen, Kaisa. Nonlinear multiobjective optimization. Vol. 12. Springer Science & Business Media, 2012.\n\n[4] Kool, Wouter, Herke van Hoof, and Max Welling. Attention, Learn to Solve Routing Problems!. ICLR 2019.",
            "summary_of_the_review": "This work aims to build an efficient learning-based model to approximate the Pareto frontier for MOTSP. The MOTSP is an important problem, and the learning-based multi-objective optimization solver could be interesting to many researchers in the community. However, I have many major concerns on both the proposed method (e.g., problem formulation, theoretical analysis, model structure) and experimental results (competitive baselines, unfair comparison, surprising results), and cannot give acceptance to the current manuscript.  \n\n+++ post rebuttal +++\n\nThank you for your several rounds of detailed responses and the improved manuscript. However, since my major concerns still remain, I keep my initial score.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "\nThis paper studied an NN-based method to approximate the Pareto front (PF) for multi-objective optimization (MOO) problems. As a practical example of the MOO problem, the authors focused on the MO traveling salesman problem (MOTSP) and developed a new approximation method.\n\nA critical problem discussed in the paper is how to efficiently and effectively approximate the PF. In contrast to an existing work (Li et al. 2020) that separately training networks for different preferences, meaning that the training process is time-consuming, the proposed approach using PA-Net uses a single network (i.e., an augmented version of the TSP-Net).\n\nThe targeting MOO problem is converted to constrained optimization problems (key: divide problems using constraints and preference vectors). The Lagrangians of constraints are used to train a policy in an actor-critic manner using solutions and preference vectors.\n\nFrom the experimental results, the advantage of the proposed PA-Net is shown in terms of (1) training time, (2) HV, and (3) computational time (i.e., inference time). Some graphical illustrations are helpful to compare the PFs estimated by different methods. Roughly speaking, the performance of the PA-Net outperformed existing methods.",
            "main_review": "# Pros and Cons\n\n## Pros\n\n- The targeting problem (MOO and the approximation of the PF) is of importance when discussing optimization problems in the real world.\n- The proposed formulation (e.g., the surrogate optimization problems (up to $K$), training by the actor-critic approach) enables the user to estimate the Pareto front efficiently.\n- The estimation performance outperforms the existing methods.\n\n## Cons\n\n- Evaluation problem class is limited (MOTSP with possibly artificial objective functions).\n    - I guess that other general methods (NSGA, MOEA/D) are developed as a general solver, but PA-Net based on the TSP-Net is a specialized approximator for the MOTSP.\n- Some notations or explanations are missing or confusing to follow the detail of the paper.\n\n# Comments\n\nTo clearly understand the paper and clarify its score, I would like to clarify the following point.\n\n(I) Is the proposed approach (surrogate opt. as in Eq.(6)-(7)) general or problem-specific? As far as I read, this PA-Net consists of two ideas; (1) conversion to the set of surrogated CO problems for each preference vector and (2) a generalization of the TSP-Net for efficient learning. As far as I understand, we can solve other MO problems using the proposed approach with appropriate solvers.\n\nThis point is important to clarify because other counterparts (i.e., NSGA, MOEA/D) seem to be general approaches, but the PA-Net is based on the TSP-Net. That is, it is a problem-specific approach for the MOTSP. In that sense, the performance of the PA-Net is possible to expect (e.g., Concorde is much faster than a general solver like Gurobi).\n\n(II) The following points should be clarified to increase the readability of the paper.\n\n\n(II-1): It is better to define the problem of 'approximating the Pareto fronts' in the paper.\n\nAs stated, a Pareto front is a set of points (in Sec.2.1; A set of all such points form a Pareto frontier). So, we have many Pareto fronts (i.e., many sets of solutions), but we should select a better one in terms of something (e.g., HV). So, a mathematical definition of this problem could clarify the purpose of the paper.\n\n(II-2): How to set the hyperparameter $K$?\n\n(II-3): Eq(16): the suffix $i$ of $f_i$ is confusing due to the sigma on $i$ at the second term.\n\n(II-4): Table3: Why HVs of NSGA-II and MOEA/D only for 3-obj are much fewer than others for 200-City?\n\nFor example, in 5-obj, it was roughly 70% of the PA-5, but 3-obj showed apparent different behaviors of others only for 200-city. What happened?\n\n(II-5): I cannot follow the problem details of the dimension (size). What do 120x4 and 120x6 mean? in Experiments (above Table 1, below Eq.(16))\n\n(II-6): Notation $\\\\{100, 91\\text{ and }, 40\\\\}$ is hard to interpret (above Table 1, below Eq.(16)).\n\n(II-7): No definition of $\\nabla_{\\phi} D_\\mathit{CR}(\\phi)$ used in the critic update.\n\n(II-8): The definition of $S_k$ and $A_k$ should be updated (modified) because $A_k = \\\\{\\pi_k\\in A_k \\mid \\dots\\\\}$ seems to be a circular definition (i.e. when defining $A_k$, $A_k$ is used to write $\\pi_k$). The definition of $S_k$ has the same problem.\n\n(II-9): Minor bug fix or confusing parts for me:\n\n- Eq.(12) $L(\\pi,\\vec{w}_k)$ -> $L_k(\\pi,\\vec{w}_k)$ or not? ($L$ without the suffix $k$ is not defined?)\n- Eq.(13) phi -> $\\phi$\n",
            "summary_of_the_review": "This paper developed a new approximation method of the Pareto fronts on the MOTSP problem by combining two ideas: (1) existing TSP-Net and (2) surrogated optimization problem for each preference vector. According to the explanations and experimental results, the proposed method seems to work efficiently and effectively for the MOTSP problem.\n\nSince only a problem class of MOTSP with possibly artificial objective functions (e.g., {2,3,5}-MOTSP) is discussed and evaluated, the effectiveness of the proposed method is limited (at least, no evidence for more general MOO problem classes). However, the proposed approach is interesting and solid. I guess that the audience of ICLR'22 is interested in both the problem itself and the proposed method.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}