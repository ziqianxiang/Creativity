{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposed a value refinement network (VRN) architecture to solve navigation tasks. The method locally modifies an initial plan computed base on simple state space abstraction. The VRN is essentially a value function of the full state of a domain. The empirical study shows that the method is able to 1) match the performance of computationally more costly planning in the original state space; 2) maintain high performance in a dynamically changing environment, without resorting to replanning.",
            "main_review": "Strengths:\n1.\tthe method is well motivated and relevant work and methods are discussed and compared. \n2.\tComprehensive empirical studies are provided to verify the hypotheses and goals the proposed framework aims to achieve\nWeakness  :\n1.\tthe method seems to be restricted to navigation tasks, where the state space can be factorized into states that corresponds to global plan and states that is more related to local plans. \n2.\tThe method seems have to assume the state information is fully observable, which may not be true for real world navigation tasks, where sensor input is noisy and state information is partially observable.\n3.\tMost studies in this work are empirical, it might be better if some theoretical analysis, such as sample complexity, asymptotic performance can be provided\n\nOther comments:\nIn equation (1), the term $m\\sim M$ already subsumes $s_{0,m}\\sim S_0$, hence the subscript of expectation should be made more concise.\nFor the VRN architecture, how many input channels is considered? Is it a fixed number for all the experiments, or it is something task dependent? \nIn section 5.2 it is assumed that a function that transforms the abstract sub-goal z_g in to a low-level continuous target vector is available. How realistic is such an assumption? For navigation tasks, maybe it is yes, but how generalizable is to other tasks?\n",
            "summary_of_the_review": "In all, this paper did a nice and careful empirical study of their proposed method for navigation tasks and is able to demonstrate that it can achieves similar performance as applying planning methods in the original state space and performs well in dynamic environment without replanning. My main concerns is that the scope of the paper is a little narrow and its generalizability maybe confined to the area of path planning and autonomous driving in robotics. I would like to see more broader applications of the proposed method by provide another use case of the proposed method. Also, this paper could be strengthened if any theoretical guarantee can be provided. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I don't have any ethics concerns of this paper.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a method for accelerating Q-learning by conditioning the learned Q-function on state values for a manually-defined abstraction of the current MDP. In particular, it considers MDPs that combine a 2D grid-based navigation task with some more-complicated \"local\" dynamics, such as gridworld navigation combined with constraints regarding agent orientation. In such domains, the \"abstraction\" is defined to be the underlying grid-based navigation task, without the complicating local dynamics. The Value Refinement Network (VRN) is essentially a variant of double-DQN+HER that conditions on the value function for this abstract task. In a given state, it first solves a corresponding abstract task using exact value iteration on a (manually defined?) abstract dynamics model, then conditions the learned Q-function on a local \"crop\" of values around the current (non-abstract) state. Experiments show that this approach learns faster than baselines like standard DQN.",
            "main_review": "Main strengths:\n\n- The high-level motivation in the introduction is strong: planning on precise dynamics models can be costly, and so coarse-grained planning combined with local re-planning is a great idea. Conceptually, the idea of local, ML-based value refinement is not new (e.g. see [Learning Heuristic Functions from Relaxed Plans](https://www.aaai.org/Papers/ICAPS/2006/ICAPS06-017.pdf), which uses a learned model to refine value estimates from a dynamics relaxation), but is still powerful.\n- The algorithm is straightforward, and the appendix is quite thorough in explaining details of the evaluation environments, hyperparameters, and so on. I was a little confused by some of the baselines, but I feel like I could reproduce the main method based on the details given in the paper.\n\nMain weaknesses:\n\n- The most significant weakness (and the reason for my low score) is that it's not clear what problem the proposed method is solving. The introduction has some interesting motivation about online refinement of a precomputed, approximate value function, and talks a bit about how value iteration can be computationally expensive when applied to complex environments. However, the rest of the paper focuses on 2D grid-based navigation tasks, which are computationally trivial at the kinds of scales being considered. If computational efficiency is going ot be the motivation for VRN, then claims that existing methods are too inefficient must be experimentally or theoretically substantiated.\n- Although the introduction talks about the computational cost of planning, the experimental evaluation does not consider this at all. Indeed, the experimental evaluation does not include state-of-the-art planning baselines (e.g. by using weighted A\\* for deterministic environments and LRTDP for stochastic environments, ideally both guided by a heuristic). This makes it hard to substantiate claims about the absolute computational advantages of VRN. It would be ideal to have plots that show how policy quality improves as a function of the number of node expansions for each planning algorithm, or as a function of wall time (with algorithms executed on comparable hardware). This would make it possible to exactly quantify the computational advantages of VRN.\n- VRN is described in such a way that it sounds like it is limited to 2D grids. e.g. Figure 2 talks about extracting a 2D crop from a grid in order to create a value prior, which obviously only works on grids. I think the conceptual insight in this paper is actually broader: it would be easy to extend the notion of spatial locality to deal with arbitrary MDP structures, such as by using the dynamics and cost function of the environment abstraction to define which states are \"near\" to each other. In my opinion, the paper would be stronger if it presented its core ideas in a more domain-agnostic way, and also had experiments in environments other than 2D grids.\n\nMinor issues and comments:\n\n- \"Exemplary\" should be changed to \"example\" throughout the paper. \"Exemplary\" is a synonym for \"outstanding\", \"remarkable\", etc.\n- Algorithm 1 is long and has only single-letter variable names. It may be more useful to the reader if Algorithm 1 were factored into functions and modified to use descriptive variable names, even if that would mean moving part of it to the appendix. Most of the algorithm is the same as DQN+HER, so it may be easiest to put the novel parts of the algorithm in the main body of the paper and then leave the standard DQN subroutines (e.g. collecting $\\epsilon$-greedy rollouts) for the appendix. The comments do make things better, though.\n- Algorithm 1: the use of $A \\gets B$ notation to denote adding to a set is also confusing; usually this denotes assignment. It also seems like $D_d$, $D_r$ and $D_{\\mathcal I}$ are ssigned to but not used anywhere.\n- Figures 3 and 5: the text in these figures is too small to read without PDF magnification. Please increase the size of the axis labels etc.\n- Figure 3: why do the VI 2D/3D baselines require training? I thought VI was being applied to a predefined model, in which case there should not be any learning going on (after VI converges).",
            "summary_of_the_review": "I think the abstract motivation for this paper is strong, but it does not connect well with the actual algorithm and evaluation tasks: they seem too trivial to exhibit the high planning costs talked about in the introduction. Moreover, the algorithm is currently described as being limited to 2D grid-based navigation tasks (or slight extensions of such environments), which are a very simple class of planning problems for which strong baselines already exist. As a result, I am not convinced of the technical significance of this work. I think that rewriting the motivation to connect better with the actual properties of the proposed algorithm would significantly strengthen the paper. That said, there may be some technical depth that I am overlooking here—please correct me if my summary above is missing important aspects of this approach.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a hierarchical approach to value estimation in RL, where an initial estimation is perform on state abstractions which are further refined to the especfic task at hand. The usecase described in the paper is in generalization across tasks sampled from some distribution of MDPs.\nThe experiments focused specifically on 2D grid-world style of navigation.\n\n",
            "main_review": "The paper presents an interesting approach to estimating value functions through state abstraction to improve generalization. The authors show that learning an initial value function in a small simplified abstract state space provides a good starting point for finding good estimates of task specific value functions.\n\nStregths:\n- I like the idea of using abstract states to provide a good initialization for the value function estimation in the origin state space.\n\n- The results on the given experiments support some of the ideas presented in the paper.\n\n\nWeakness: \n- The paper and all experiments focus only on environments where there is a simple intuitive interpretation of an abstract state; larger grids, ignoring orientation are a simplification of the original state space. I would have liked to see a general approach on identifyin these abstract states, and some experiment on a non grid-like domain. At present, the scope of the paper seems too narrow.\n\n- Related work: given that this work sits somewhere between RL and planning, I am surpised that there is not much of a discussion on hierarchical planning, specially since the experiments are mainly focused on path finding, for example HPA* (https://webdocs.cs.ualberta.ca/~mmueller/ps/hpastar.pdf ).\n\n- Hidden cost: I don't expect this to be significant, but a comment about the extra cost incurred by the value estimation in the abstract space would be helpful. If this cost was significant, then the evaluation with other methods based on training iterations that don't require this pre-computation would not be fair.\n\n- An issue I have with the current state of the paper is that all tests are very similar in nature, so it makes it difficult to get a sense of how practical this approach is in general. For example, one question that comes to mind is that in all experiments the dimensions abstracted away are agent-centric (they describe some attribute of the agent, not the environment itself). So the 2D abstract representation maintains a lot of the information of the environment anyway.\nWhat if instead of a 2D environment, we were looking at a 3D world with (x,y,z) coordinates. What should be the two coordinates to use? Should we keep them all and make the abstract states 3D?\nThe reader would probably have a hard time using this technique in a problem that differs slightly from the type of problems presented here, I think providing some guidelines on how these abstractions should be created be really beneficial.\n\n- ",
            "summary_of_the_review": "Interesting idea, but the scope seems too narrow and it makes it hard to evaluate how useful this technique would be in general.\nI think it requires some further work on formalizing the formulation and techniques beyond simple 2D navigation tasks.\nI like the direction this is going, I would encourage the authors to further develop this idea.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper presents an algorithm that performs approximate hierarchical planning. The idea is to first plan in the higher level of state abstraction, obtain the value function, and use that value function as an input to the value function for more concrete level planning. For instance, the paper uses the navigation problem with 3 degrees of freedom (x,y, orientation) as an example. It first creates a state abstraction by ignoring the orientation, and given the value function for this abstract problem, it uses it to find the value function for the full problem with 3 DoF. The empirical results are shown in several navigation tasks, one of which involves a non-holonomic robot. ",
            "main_review": "Strengths:\n- The high-level idea of the paper, which is to use the solution for the easier abstract problem and then using that to warm-start the original problem is interesting and promising direction.\n\nWeaknesses:\n- The biggest weakness was the experiment. More concretely, the method that author proposes is a planning algorithm, and there are many existing 2D navigation planning algorithms, such as A*, D*, and RRT that are known to work well. However, the paper only compares with learning-based methods, making it difficult to truly assess its practicality.\n- The second weakness is its limitation to 2D navigation problems. I cannot find the result to be convincing if the method can only solve 2D navigation problems. 2D navigation problem has been already studied extensively in the field of robotics, and the field has already moved onto planning in higher DoF. I think the high-level idea in this paper is a good one, and it is generally applicable. I would advice the authors to look for harder and practical applications.\n- This is a minor point compared to the two points above, but I do not understand why your method is able to perform “local replanning”. It seems that your method simply takes in the value function for the abstract-level, and is not doing anything specific to local replanning.\n\n",
            "summary_of_the_review": "With the current submission I recommend reject.  Although the paper shows good intuition, its applicability is limited, and its value is difficult to assess due to lack of comparison to well-established baselines. I, however, urge authors to find more difficult and practical application for their intuition, because I think it is a very general idea and has a lot of potential to be impactful.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}