{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper considers the problem of estimating (semantic) correspondences between two images. Similar to previous work, the proposed approach computes 4D correlation volumes between the images by dense feature matching. Contrary to most previous work, which applies convolutions on the 4D volumes to filter out wrong matches, the proposed approach applies a transformer to be able to model global interactions between matches. The proposed approach combines FastFormer with rotary positional embeddings to filter outliers in the correlation volumes, followed by estimating a dense flow field based on the resulting matches. Experimental results on three datasets show better or similar results compared to the baselines. The paper further provides a detailed ablation study on its two main design choices (transformer type and type of positional encoding).",
            "main_review": "On the positive side, the paper is well-written in general and I found it easy to follow the description of the method. The proposed approach is technically sound and the idea of using a transformer to process the 4D correlation volumes is intuitive and meaningful. The proposed approach is evaluated on three standard datasets and improves upon the current state-of-the-art on the most challenging one while performing roughly on par on the other two datasets.\n\nMy first main point of criticism is that I feel that the paper overstates its contributions. The paper states that it proposes \"the Visual TransforMatcher, a novel image matching pipeline built on transformers for global-aware correlation map refinement and dynamic attentive weights\". Yet, it is not fully clear to me what the novelty of this approach is: \n* On a technical level, the two main components seem to be the FastFormer and the rotary positional embedding, which seem to be taken directly from the literature. The paper claims to \"extend rotary positional embedding used in language sequences to model the 4D match-wise positional embedding,\" but I can't seem to find any details on how the used embedding differs from the one proposed by Su et al.\n* On a conceptual level, [Sarlin et al., SuperGlue: Learning Feature Matching with Graph Neural Networks, CVPR 2020] already applied a transformer-like attention mechanism for self-attention (correlating features within an image) and cross-attention (correlating features found in different images) for feature matching. While Sarlin et al. operate on a discrete set of matches, [Sun et al., LoFTR: Detector-Free Local Feature Matching with Transformers, CVPR 2021] apply transformers on the full 4D correlation volume in order to generate dense matches between images while modelling global relations. Similar to the proposed approach, Sun et al. use a transformer (Linear Transformer) with a computational complexity linear in the input sequence. While both papers are applied to non-semantic matches, they seem very similar in their underlying ideas to the proposed method. In particular, the existence of Sun et al. seems to contradict the claim that the paper is \"the first to directly process such a high-dimensional (4D) input using a self-attention mechanism within feasible computational constraints\".\n\nMy second main point of criticism is the clarity of the experimental evaluation:\n* In Table 1, there are multiple entries marked with either a  $\\dagger$ or a *. Yet, the meaning of both symbols is not explained. Looking at the text, I would assume that the  $\\dagger$ corresponds to using data augmentation, but I am not sure. Without the information, it is very hard to understand the results shown in the table, especially since TransforMatcher typically is (slightly) worse than the state-of-the-art while TransforMatcher$\\dagger$ performs better. Further, it is also unclear to me how the methods are grouped in the table.\n* Regarding the results in Tab. 1, the paper states that the proposed method \"exhibits state-of-the-art performance when transferred to the Spair-71k dataset, while being comparable on the PF-PASCAL and PF-WILLOW datasets\". On the Spair-71k dataset, the proposed method is 2.7 (0.1 F) respectively 0.4 (0.1 T) points better than the second-best performing method. On the PF-Pascal dataset, the proposed method is 2.8 (0.05) respectively 0.2 (0.1) points worse than the best performing method while being 2.1 (0.05) respectively 3.9 (0.1) points worse on PF-Willow. If the performance difference on PF-Pascal and PF-Willow counts as \"being comparable\", wouldn't it be more correct to also state that the proposed approach performs comparable on Spair-71k?\n* The paper states that \"The results in Table 2 show that the trend of results using the small subset of SPair-71k is similarly consistent when using the large subset of SPair-71k.\" It is unclear to me what \"trend\" refers to in this context. Previously, the paper discussed the relation between the proposed method and previous work, so naturally trend would refer to this relation. Yet, Tab. 2 does not show the results of any of the baselines. This is rather confusing.\n* The paper states that \"The results in Table 2 show that using rotary positional embedding results in significant gains over absolute positional embedding.\" Yet, rotary embedding without data augmentation does not perform significantly better than absolute embedding with data augmentation. \n* Given that the paper claims to \"develop a light-weight architecture\", I feel that experiments measuring run-time efficiency are missing.\n\nThe following minor comments did not affect my recommendation:\n* The paper states that \"An emerging trend is to exploit high-dimensional convolution on the correlation map, enforcing semi-local constraints on the correlation tensor to refine matches (Rocco et al., 2018; Lee et al., 2021a;b). However, these work commonly consume a high computational cost with a large number of parameters in the kernels\". Yet, there is work such as [Rocco et al., Efficient ´\nneighbourhood consensus networks via submanifold sparse convolutions, ECCV 2020], [Li et al., Dual-resolution correspondence networks, NeurIPS 2020], and [Zhou et al., Patch2Pix: Epipolar-Guided Pixel-Level Correspondences, CVPR 2021] that is designed to handle the memory bottleneck.\n* A reference for the Adam optimizer is missing.\n* Many of the references do not include the venues where the papers were published.",
            "summary_of_the_review": "My main criticism is that the main claims of the paper need to be better supported, especially given prior work on using transformers and attention for processing matches. Without clarifications, the technical contribution of the proposed approach and the significance of the paper are unclear. In its current form, I thus do not think that the paper can be accepted.\n\nHowever, most of the weaknesses listed above seem inherently addressable and I am willing to raise my recommendation if a rebuttal can clarify the two main problems identified above.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethics concerns.",
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes a semantic correspondence matching algorithm based on the Transformer architecture. The method utilizes recent advances in the Transformer architecture (FastFormer) and also the positional embedding associated to it (Rotary embeddings). The transformer is applied directly on the correlation volume, which the paper proposes to use a multi-channel one, where each channel is associated with different layers of the backbone. The method is shown to outperform the state of the art on SPair-71k and slightly worse on PF-PASCAL and PF-WILLOW.",
            "main_review": "## Paper strength\n\n### The paper delivers state of the art on SPair-71k\n\nThe method outperforms existing methods and achieves the state of the art in SPair-71k. The authors also promise to release the code to reproduce the results.\n\n## Paper weaknesses\n\n\n### Overclaimed contribution\n\nThe claim on 4D input and self-attention is questionable. Superglue [c] also creates a graph composed of self and cross image matches, which is then processed using a Graph Neural Network with self-attention mechanisms. CAT also applies self-attention, albeit differently---it is the reviewer's humble opinion that while the processing is different and therefore not direct, it is unclear whether this distinction warrants a claim.\n\n### Weak novelty\n\nThe novelty also seems weak. In terms of the architecture, the main change from existing works seems to be that a multi-channel correlation volume is constructed via comparing features at different layers, which is then fed into a FastFormer. It is possible that the reviewer may be missing something here, but there does not seem to be a secret ingredient to this “match-to-match” attention strategy.\n\n### Missing ablation study\n\nNo ablation study on the multi-channel correlation volume strategy, which seems to be the main novelty. Other choices of using Rotary positional embedding and FastFormer are adapting existing components. The ablation study indeed shows that these are important and valid design choices, but they are engineering solutions of improved components applied to the semantic correspondence problem, and hence not very novel. The multi-channel correlation volume strategy, however, does seem novel, but is not ablated to be know whether this new component makes a difference.\n\n### Missing related works\n\nThe choice of local features and matching citations in the introduction is somewhat questionable. The paper does not cite the best-performing ones [a,b,c, d], nor the ones that started it all [e,f,g].\n\n- [a] Tyszkiewicz et al., \"DISK: Learning local features with policy gradient\", NeurIPS 2020\n- [b] Mishchuk et al., \"Working Hard to Know Your Neighbor’s Margins: Local Descriptor Learning Loss\", NeurIPS 2017\n- [c] Sarlin et al., \"Superglue: Learning Feature Matching with Graph Neural Networks\", CVPR 2020\n- [d] Jin et al., \"Image Matching across Wide Baselines: from Paper to Practice\", IJCV 2021\n- [e] Yi et al., \"LIFT: Learned Invariant Feature Transform\", ECCV 2016\n- [f] Yi et al., \"Learning to find good correspondences\", CVPR 2018\n- [g] Choy et al., NeurIPS 2016 (in comparisons)\n\nRelated works section should also at the very least mention existing work on correspondences and attention mechanisms, such as [c] and [h]\n\n- [h] Jiang et al., \"COTR: Correspondence Transformer for Matching Across Images\", ICCV 2021\n\n### Presentation quality \n\nThe paper poses itself as a correspondence matcher but is in fact dealing with the semantic correspondence problem. This should be made much more clear, in order to not confuse the readers.\n\nThe abstract and the introduction do not read well, because \"match-to-match attention\" is used as a novel term without the high-level idea behind it. As of now, the reader simply has to believe in the author's claims that it provides more robust. \"semi-local constraints\" is also a term that is not explained in the introduction, which again makes the paper hard to follow. The root of this problem lies in the fact that the term \"match\" is not well defined in this context. Are they sparse correspondence matches? are they putative match regions? are they local patches that are to be matched across images? In light of the later Section 4.2, it seems to mean that the transformer is applied to the cost volume directly, which is not very novel. This is hence quite misleading.\n\nThe introduction MUST deal with recent work on correspondences with transformers. For example, the distinction with CAT [Cho et al., 2021] is a must. In addition, the paper also should discuss how it differs from COTR [h], which is not on image correspondences. COTR is not a method designed for semantic correspondences, but there is nothing preventing the method from being applied to it.\n\nFigures 1 and 2 are very far away from where they are referenced. \n\n###  Table 2\n\nWhy are results in Table 2 differing from Table 1? The results claim SPair-71K but seem like they are for PF-PASCAL? Was there a typo?\n\n## Questions for the rebuttal\n\nI would like to hear back from the authors regarding the following items:\n- Ablation study on the multi-channel\n- Distinction from existing applications of Transformers on cost volumes other than architectural changes with justifications on why it makes sense that these justifications are necessary\n- Rebuttal on the weak novelty\n- How presentation could be improved\n- Any other misunderstandings\n",
            "summary_of_the_review": "While the paper delivers SOTA performance, the novelty of the paper is weak. The idea of processing cost volumes for better correspondences has been extensively explored, including one that uses a transformer architecture. The proposed method utilizes more modern components than existing methods, which shows improvements on one dataset. The presentation of the paper also fails to convince readers into understanding the insight behind why it's useful other than pure empirical results. Moreover, the discussion on match-to-match attention is confusing and misleading, and the paper is not properly positioned within the existing literature.\n\nI want to add that I really appreciate the authors' work. I would be very happy to be corrected by the authors about any misunderstanding that I may have had in my review. \n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes an end-to-end semantic match network with visual transformers for global context learning to improve the match efficacy.",
            "main_review": "Strengths: \n1. Good motivation. Compared with CNNs, visual transformers have been proved to have stronger ability of global context embedding, which is very important to feature match especially under large viewpoint and appearance changes. \n2. This paper is well organized and very easy to read. \n\nWeakness:\n1. Novelty. With the success of visual transformers in a wide range of visual applications, e.g, classification and semantic segmentation, some works have introduced visual transformers into the task of dense match, e.g., LoFTR: Detector-Free Local Feature Matching with Transformers. CVPR 2021. The author should also discuss the difference with this work. \nBesides, as one of major novelties of this paper, the proposed match-to-match attention is more like a cross attention defined on different channels instead of the whole tensor. From my point of view, it’s not novel enough to get this paper accepted.\n\n2. Results. The author conducts experiments on 3 datasets including SPair-71k, PF-PASCAL, and PF-WINDOW, but only achieves better performance on 0.1 (F) SPairs-71k. The effectiveness of the proposed method is not well proved.\nAlso, I’m very curious about the memory cost of this work. It seems like the channel-wise cross attention will increase the memory dramatically.",
            "summary_of_the_review": "Based on the strengths and weakness, I vote weak reject for this paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes an image matching algorithm based on transformer network. It introduces match-to-match attention which captures global match-wise interactions in the 4D space of correlation maps. Efficient transformer structure is employed for feasible computational cost and rotary positional embedding is employed for improved matching performance.",
            "main_review": "Strengths(+):\n1. Using high dimensional (4D) correlation map in a transformer network for image matching is interesting and the achieved result on standard benchmarks of semantic matching (SPair-71k) is promising.\n2. The paper is clearly written and easy to follow. The difference between this work and the closest related work [Cho et al., 2021] is well summarized.\n\nWeaknesses(-):\n1. The main concern of this paper is its technical novelty. As the paper summarized, the contribution on feasible computational cost is Fastformers (Wu et al., 2021), which is existing work, another contribution on rotary positional embedding (Su et al., 2021) is also existing work. So it seems that the paper just combines some existing techniques in a transformer framework to solve the high dimensional image matching problem, the corresponding ablation study cannot prove the strength and novelty of the proposed method.\n2. Some key experiments may missing, i.e. the real speed and memory cost of the proposed method, since a lot of image matching applications may have constraints on memory and computational resources.\n3. The experimental results on database of PF-PASCAL and PF-WILLOW still have some significant gap (-0.2%~-4.5%) with state-of-the art algorithms",
            "summary_of_the_review": "Due to the limited technical novelty, my overall rating would be rejection",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}