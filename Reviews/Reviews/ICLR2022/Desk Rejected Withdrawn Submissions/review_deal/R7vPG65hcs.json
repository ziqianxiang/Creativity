{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper studies an interesting topic: efficient inference on embedded devices. The major contribution of this paper can be summarized as below:\n\n(1)  A single-shot based channel pruning method for efficient inference\n\n(2) An efficient reconfigurable DL accelerating system  that supports FPGA and edge GPU deployment\n\n(3) Empirical advantages in compression and speedup",
            "main_review": "Strength:\n\n(1) The paper is well-motivated. Efficient inference on embedded or edge devices is of significant potential applications.\n\n(2) Development and deployment of efficient inference algorithm on FPGA with acceleration\n\nSuggestions:\n\n(1) Energy measurement\n\nOne advantage of edge device-based DL inference is the energy savings. The benchmark of energy consumption becomes more important when we discuss DL systems for satellite. Is this possible to provide energy measurement so that we could compare the proposed method with baselines on FPGA devices?\n\n(2) Deployment on Embedded GPU devices\n\nMost of the GPU based experiment is conducted on NVIDIA RTX 3080. Is it possible to provide empirical analysis on embedded devices such as NVIDIA TX2?  Is the proposed method robust to different GPU/ FPGA devices?\n\n(3) Effect of quantization\n\nHow does the quantization approach affect the proposed method. Does the proposed method robust in different quantization levels?\n",
            "summary_of_the_review": "This paper studies an interesting topic and proposes a new method with efficiency improvements. It would benefit both DL and IoT/Architecture community if we demonstrate more practical deployment in situations such as satellite environments. However, more experiments may be needed for the improvement. I am open to discussion on the new experimental results.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors present a single-shot pruning method for compressing trained networks into smaller, FPGA-ready hardware. They also present a method for improving the precision when the network's prediction is deemed \"ambiguous\". They evaluate their approach on a remote sensing task.",
            "main_review": "# Strength:\n- the concept of compressing network for embarked spatial applications is exciting and important\n\n- the experimental results are encouraging\n\n# Weakness:\n- this paper lacks rigor. Most technical terms (e.g., \"probably approximately wrong\") are not defined and misused. Hypotheses are never stated and appear in the middle of \"proofs\" (e.g., bottom of p5). Explanations are very hard to follow, and the results are somewhat dubious.\n\n- In Lemma 1, the work of Corbiere et al. 2019 is misrepresented and misunderstood. Corbiere et al. propose to learn the True Class Probability (TCP) and certainly do not state that if an (uncalibrated) network predicts a max probability of 0.5, then the results are \"probably approximately correct\" (a term which is never defined here beyond a 30-year-old reference). In fact, this is the opposite of what the paper claim: the max class probability should not be used to qualify a model but instead the TCP should be used instead, which the authors here do not do. Even if the authors had learned to predict TCP, theorem 2.1 of Corbiere et al. does not state the claimed results for a TCP between 1/K and 1/2, and the authors here claim that a probability under 0.5 indicates a \"probably approximately wrong\" prediction (?).\nFinally, the terms \"probably approximately correct\"/ \"wrong\" are not defined and used without any rigor. The \"proof\" in the appendix combines mathematical words without rigor and does not constitute proof since terms are not well-defined and are used rather loosely.\n\n- Fig5 seems dubious to me, it seems unlikely that the accuracy of the baseline would drop sharply to almost zero (worse than random??) after a 20% reduction in parameters. The fact that the y axis conveniently starts at 10% and not 0%  hides the behavior on the high sparsity regime.\n\n- The use of a knowledge graph to reduce ambiguity is very hard to follow. What are the attributes in question? How is the graph used exactly? How was this graph obtained? What is the difference between the filter's and the kernel's parameters? Why is L never introduced? Why is the effect of this step not evaluated in an ablation? And if it actually helps, why not use it in all cases even non-ambiguous ones?\n\n-  The authors frame their contribution as something general but only test their method on a single dataset\n\n- Finally, the English level of the authors is rather low. There are mistakes / clumsy formulation in almost every sentence. While this is generally ok, here it is combined with an apparent lack of rigor and makes the paper very hard to read. Furthermore, many mistakes would have been caught with a free online grammar checker.\n\n# Suggestions:\n\nThe compression/performance reported is encouraging. The authors should focus on this nice contribution and submit their work in a more specialized venue.",
            "summary_of_the_review": "This paper is not ready for publication. The statement and proofs lack the rigour necessary to express mathematical ideas. The experiments are lacking, and ideas are hard to follow.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "Motivated by DL model inference on FPGAs onboard satellites, this paper proposes 1.) a method for performing \"adaptive inference\" based on class probability prediction and a given knowledge graph and 2.) a single-shot based channel pruning method to reduce the model size.\n\nThe high-level idea of the ambiguity algorithm is to reweight the predictions made by a classifier for a given sample based on \"attributes\" identified in the sample by a separate object detection model. This reweighting is driven by a knowledge graph -- a bipartite graph of attributes and classes where edge weights are measures of affinity between attributes and classes. This reweighting is only done for samples where the model is uncertain, i.e when the largest predicted probability is less than some threshold value.\n\nThe single-shot channel pruning method iteratively removes channels based on a summed version of the weight criterion from the SNIP method.",
            "main_review": "The paper proposes two interesting directions that are well motivated in the geospatial ML space, however, these methods would likely be best described in two separate papers as they are not immediately connected. For example, the ambiguity algorithm requires running an object detection model and exists to improve the performance of a classification model. Is this model also to be run on FPGAs onboard a satellite? It is not clear why both this and the pruning algorithm exist in the same paper. Also, it is not clear why a single-shot channel pruning method is appropriate for compressing a model to be run onboard a satellite. *Any* compression method could be used to produce a more effeciently run model, the method need not be single-shot.\n\nAs is, this paper has a few large problems  \n- Results\n  - The paper reports results on the UC Merced land use satellite imagery dataset with a baseline accuracy of 80% using a ResNet101 (and a best accuracy of 83.81 after pruning with the SNIP-sum method). However, this dataset is widely considered \"solved\", with almost any deep learning approach achieving >97% accuracy -- see [1] for an approach from 2015 that fine-tunes GoogleNet to get >97% and see [2] for simple training setup that achieves >99% with a ResNet50.\n  - Similarly, on CIFAR-10, a semi-recent approach [3] prunes 62% of the channels in a VGG-16 and achieves 93.18%. Based on Fig 7. from the Supplemental work, this appears to outperform all tested methods.\n  - The paper does not mention a multi-attribute classifier used to apply the proposed amiguity adaptive inference model at all. An object detection model is needed to run the proposed algorithm, so should be at least described in the experiments section.\n- Lemma 1 needs to be extensively clarified. As is, it states that if a model predicts a class with >= 0.5 probability then the classification is \"probably approximately correct\" and if the model predicts all classes with a probability <= 0.5, then the \"estimation result can be probably approximately wrong\". This is not a Lemma that can be proven or disproven as it will depend heavily on the model, dataset, definition of \"approximately\", etc.\n\nThe authors should consider: splitting this work up into two parts, checking the UC Merced training/evalution setup for bugs, performing an expanded literature review on relevant compression methods for comparison, and checking/clarifying the details of all proposed methods.\n\n[1] Castelluccio, Marco, Giovanni Poggi, Carlo Sansone, and Luisa Verdoliva. \"Land use classification in remote sensing images by convolutional neural networks.\" arXiv preprint arXiv:1508.00092 (2015).\n\n[2] Neumann, Maxim, Andre Susano Pinto, Xiaohua Zhai, and Neil Houlsby. \"In-domain representation learning for remote sensing.\" arXiv preprint arXiv:1911.06721 (2019).\n\n[3] Zhao, Chenglong, Bingbing Ni, Jian Zhang, Qiwei Zhao, Wenjun Zhang, and Qi Tian. \"Variational convolutional neural network pruning.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2780-2789. 2019.",
            "summary_of_the_review": "This paper should be rejected, it has large flaws in its experiments/results. ",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}