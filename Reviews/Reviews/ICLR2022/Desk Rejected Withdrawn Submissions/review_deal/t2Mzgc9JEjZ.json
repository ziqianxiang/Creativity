{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "Although I have no knowledge about certified patch robustness, I tried my best to understand the article. The paper improves the certified patch robustness by involving vision transformers and further boosts the inference speed by dropping masked tokens (corresponding to masked patches) and using striped ablations.",
            "main_review": "**Pros**:\n\nIt is interesting that the vision-transformer based certified patch defenses have much better performances than the conventional CNN based. \n\nThe modification of the dropping  masked tokens and involving striped ablations significantly boost the inference speed.\n\n\n\n**Cons**:\n\n1. Although it is an interesting attempt to combine vision-transformer. The paper is still not profound enough in my perspective. I suggest the author go in-depth analysis with the insight of why vision-transformer have much better performances than CNN, and then give some unique designs.\n2. The acceleration did not give new insights, it looks more like engineering improvements. I do not deny that acceleration is an important and useful contribution. However, I pay more attention to some new understanding in the research field.",
            "summary_of_the_review": "I lean to weakly reject the paper due to the above cons.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper performs certified patch defenses by using ViT to replace the ResNet. It proposes two tricks to accrete the inference speed, one is removing the masked token from the input of ViT and another is using strided ablations.",
            "main_review": "Highlights:\n1. The authors demonstrate that ViT performs much better than ResNet on this certified patch defenses task.\n2. Then they reduce the computation cost through some tricks to speed up the inference.\n \nDrawbacks:\n1. It seems that the authors think that the standard model is not robust. This may be true on the CNN model, but some recent studies [1, 2] have shown that vision transformer has stronger robustness than CNN. The author should report how robust the standard ViT is. It is disappointing not to find such experimental results in the paper. If the standard ViT has very strong robustness, then the effect of using the smooth model will be greatly reduced. This is a major flaw in the paper.\n2. The author still uses the smoothed method previously proposed to do CERTIFIED PATCH ROBUSTNESS. They simply use ViT to replace the CNN model and perform some regular experiments. Contribution is insufficient.\n3. The author should explain their motivation for using ViT more clearly. Simply using ViT to replace CNN model does not seem to make sense. The authors claim adversarial patches may fool the model. But the situation of adversarial patches that can fool ViT needs more exploration and the author did not give any evidence and related references. If ViT can be naturally robust to adversarial patches, why do we need certified patch defenses? Now that how adversarial patches can interfere with ViT is not clear, how can we judge the effect of smoothed ViT?\n\n[1] Naseer, Muzammal, et al. \"Intriguing Properties of Vision Transformers.\" arXiv preprint arXiv:2105.10497 (2021).\n\n[2] Bhojanapalli, Srinadh, et al. \"Understanding robustness of transformers for image classification.\" arXiv preprint arXiv:2103.14586 (2021).",
            "summary_of_the_review": "The effectiveness of the proposed smooth ViT compared to the standard ViT is not explained clearly.  In the technical part, the proposed method simply uses ViT to replace CNN as the backbone, and other technical details are similar to the previous method (derandomized smoothing). So I think the contribution and innovation of this work are limited.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper addresses the problem of certified patch robustness. Specifically, instead of using CNNs as the backbone, the ViT model is used, which is shown to be more robust to certified patch defense. To remove the computational redundancy, the image patch tokens without overlapping with the unmasked part of the original images are dropped. Experiments are carefully designed and comparisons are shown with previous methods as well as the CNN models with a similar amount of parameters. Promising results on both certified and standard accuracy are shown on ImageNet and CIFAR10 datasets. ",
            "main_review": "Strengths:\n+ The writing of the paper is clear and easy to follow. \n+ The experimental analysis is clear and well-motivated and comparison with previous methods are fairly compared. Also, the strided ablation and block smoothing are also carefully studied, though the strided ablation does not appear to be effective.\n+ The method introduced in this paper is simple and effective.\n\nWeaknesses:\n- Though good improvements are achieved by the introduced method, the novelty appeared to be a bit limited, as simpy adopting the ViT and dropping the masked regions only appear to be two implementation modifications.\n- Experimental results are only shown on two datasets, ImageNet and CIFAR10. It will be more promising if results on more datasets can be shown. ",
            "summary_of_the_review": "Overall, the paper introduced a simple method to effectively improve the certified patch robustness using ViT and dropping redundant visual tokens. Though effective, the novelty of the proposed method is somewhat limited.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper introduces the vision transformers to the derandomized smoothing defense. Compared with the convolution-based backbone, the vision transformer shows clear improvement in terms of certiﬁed accuracy and inference speed.",
            "main_review": "Strength:\n+ The motivation and principles of the paper are clear and make sense.\n+ The paper is overall well-written.\n+ Extensive experiments demonstrate the superiority of the vision transformer backbone over the convolution-based backbone in derandomized smoothing defense.\n\nWeakness:\n- The paper is only an application of existing technology and empirical analysis. The technical contribution is somewhat limited.\n- Vision transformers (ViT) typically use more sophisticated training techniques than ResNet. So the comparison is not that fair. It would be nice to pre-train the backbone under the same training settings to demonstrate the effectiveness.",
            "summary_of_the_review": "The paper provides an empirical analysis of the vision transformer backbone for derandomized smoothing defense. Although the novelty is somewhat limited, the rich experiments could be beneficial to the community.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}