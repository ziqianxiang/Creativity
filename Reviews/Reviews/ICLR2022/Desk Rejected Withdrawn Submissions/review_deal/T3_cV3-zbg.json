{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper considers dynamic regret or tracking regret as the measure to design adaptive online learning algorithms. The authors try to incorporate optimism into the regret analysis and algorithm such that the overall results would be more adaptive to the environments.\n",
            "main_review": "The paper considers dynamic regret or tracking regret as the measure to design adaptive online learning algorithms. The authors try to incorporate optimism into the regret analysis and algorithm such that the overall results would be more adaptive to the environments.\n\nThe paper did a good job in comparing with Ader (Zhang et al., 2018), but failed to have a fair comparison and discussion with the newest paper on dynamic regret (Zhao et al., 2020), I can find a very brief mention in Remark 6 only.\n\nTo the best of my knowledge, Zhao et al. (2020) studied the dynamic regret of smooth functions and developed an algorithm to be adaptive to gradient variation $V_T = \\sum_{t=1}^T \\sup_{x \\in \\mathcal{X}} \\Vert \\nabla f_t(x) - \\nabla f_{t-1}(x)\\Vert_2^2$. To achieve so, that paper also uses the optimistic online methods to inject optimism in both mirror descent and normalized exponentiated subgradient.  In my feeling, the gradient variation bound is harder to obtain than the general optimism bound, as the gradient variation bound is required to be problem-dependent such that some negative terms are always required, so the analysis and algorithm are typically more involved. This also makes sense even in the vanilla regret measure.\n\nNow that the paper Zhao et al. (2020) has achieved the gradient variation bound, it is believed not hard to obtain the optimism one. For example, after a high-level checking of their paper, I guess one can simply replace Equation (13) of their paper by $m_{t,i} = \\langle M_t, x_{t,i}\\rangle$ to achieve an $O(\\sqrt{M_T(1+P_T)})$. \n\nThe authors should have a good comparison on the novelty in results and techniques compared with Zhao et al. (2020). Please correct me if I misunderstood any part of the paper.\n\n\nRef: Dynamic Regret of Convex and Smooth Functions. 2020. https://arxiv.org/abs/2007.03479\n",
            "summary_of_the_review": "see above",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper studies dynamic regret (competing against the best sequence of comparators rather than best fixed comparator) for online convex optimization (convex feasible set and convex loss functions). Existing algorithms obtain regret bounds in terms of the path length (cumulative norm of the increments) of the comparator sequence for all comparator sequences simultaneously (that is, adaptively). These algorithms work by running a meta-algorithm (Exponential Weights) over existing dynamic regret algorithms (Optimistic Mirror Descent). The present paper uses more refined---but already existing---regret bounds for Optimistic Exponential Weights to obtain dynamic regret bounds that depend adaptively not only on the path length but also a new object that includes the accuracy of the “predictions” used in Optimistic Exponential Weights. An implication of this result is demonstrated for Lipschitz continuous losses to obtain variance regret bounds.",
            "main_review": "## Action Items for Authors\n\nBased on the points I raise below, I think it would be beneficial for the authors to expand on the following summary questions.\n1. What are the concrete benefits of adapting to $M_T$ over other existing quantities? In particular, under what (non-tautological) assumptions about the “predictions” used for the optimistic algorithms might $M_T$ provide tighter guarantees than existing bounds (depending on, e.g., $V_T$)? \n2. What is the specific novelty of Theorems 1 and 2 over existing work, and what benefits does this novelty provide (either for results in this paper or for enabling future results)?\n\n\n## Major comments\n\n### Interpretation of $M_T$. \nThis is the main limitation of the paper in its present form. As far as I can tell, the entire novelty over existing results is the simultaneous dependence on $S_T$ and $L_T$, which allow for *arbitrary* “predictions” of the (sub)gradients of the losses. When the usual choice of predictions is used, which is the t-1 instance of the (sub)gradients, the results reduce to known dependencies on the existing definition of $S_T$ in the literature and the standard quantity $V_T$. I hope the authors can shed some light on alternative choices of predictions that can lead to interesting new guarantees.\n\n### Theorem 1\nUpon inspection of the proofs, the only novelty over Theorem 1 from Zhao et al. (2020) is that the third term of Eqn (4) corresponds to arbitrary “predictions” rather than the t-1 subgradient. Indeed, the proof of the latter result includes both the third and fourth terms, although they do not appear exactly in the theorem statement after a Lipschitz bound is applied (leading to the $V_T$ term, which comes from a crude bound that ignores the gradients are specifically $x^*_t$). This cancellation is actually just deferred to midway through Section 5 of the present paper, which could have been avoided by just citing Theorem 1 of Zhao et al. in the first place (the subtraction term is already discarded for the analysis of Section 4). In short, simply stopping the proof of Zhao et al. early recovers this bound almost exactly, yet they are only mentioned in the appendix as “inspiration”, and the final result of Zhao et al. (modulo arbitrary gradient “predictions”) is what is used for downstream results anyways. I think the differences should be both highlighted and explained in the main body, and unless there is further novelty beyond what I have listed, the result should not be considered a “new” theorem.\n\n### Theorem 2\nThis result is novel compared with the existing literature, which as far as I am aware either a) does not have the final subtraction term (ie, these are standard optimistic FTRL and optimistic OMD bounds) or b) has the subtraction term but only applies to predictions equal to the previous loss (eg, Theorem 19 of Syrgkanis et al.). There are no new techniques used to obtain this result, just some clever adding and subtracting and then standard use of Fenchel-Young and strong convexity, but the total freedom of the user to choose $\\hat \\ell_t$ should be emphasized much more strongly, and will hopefully allow future work to exploit this new perspective. The subtraction term holding for any predictions was in fact so unintuitive that I spent non-trivial time attempting to find a counterexample before believing the result was actually true. \n\nUnfortunately, the present work does not take advantage of the subtraction term in Theorem 2, and consequently should cite existing work for its application (for example, without the subtraction term, Theorem 2 is directly implied by Theorem 7.28 of Orabona 2019). Remark 3 also highlights the KL term as seemingly novel, yet this is a standard object to appear in FTRL bounds for (Optimistic) Hedge. Consequently, it is unclear that the novel aspects are useful to the community, and this requires further explanation (with a new result that actually uses Theorem 2 rather than the existing Theorem 7.28).\n\n### Section 4\nThere is a missing Theorem 2.5, which almost all of Section 4 is devoted to proving but is never stated, and should be called Theorem 3. The current “Theorem 3” can be stated as a Corollary to this new Theorem 3 (the exact naming convention of Theorem vs Lemma vs Corollary is not the point of this comment). The techniques used throughout Section 4 are all standard meta-learning (incorrectly attributed to Zhang et al. (2018), these techniques have been standard since at least the MetaGrad algorithm by van Erven and Koulen (2016)). It is unclear why these details were spelled out and then glossed over for the big-O proof in A.3, it would be good to see all of them detailed (in the appendix) for clarity.\n\n### Section 5\nOnce again, the main result of the section (at the bottom of page 8) is not in a theorem environment, and thus it is not clear what is new, what is exposition, and what is a necessary aspect of the proof. The novelty of Corollary 1 over Zhao et al. (2020) is that the “predicted” losses must be Lipschitz continuous rather than the losses themselves, yet the bound depends explicitly on how close these predictions are to the losses, so it is unclear that this is any meaningful improvement since surely they will do quite poorly if the real losses are not Lipschitz continuous but the predictions are (for fixed L). The choice of prior depending on constants related to the Riemann function seems highly unnecessary; these constants should have negligible difference with choosing a uniform prior and the results are stated in big-O anyways.\n\n### Proof environments\nMany of the results are difficult to follow on first read because the paper is organized like a textbook chapter, walking the reader through steps one-by-one until finally reaching a result. \nNormally a formatting choice would not constitute a major comment, but this makes up a significant portion of the main body and makes the arguments much more opaque. The authors should format the work in the more standard style of having clear theorem statements for their novel results and then clearly self-contained proof environments for each result. \n\n\n\n\n## Typos and wording, other minor comments\n\n1. The definition of regret is imprecise, since it is redundant in Eqn (1) to describe $x_t$ as “generated” by $\\mathcal{A}$. Further, it is crucial to note that the regret bounds throughout the paper hold regardless of which algorithm actually generated the $x_t$’s that informed how $\\psi_t$ was chosen by the adversary. That is, if I played algorithm A and an adversary generated a sequence of losses according to that, and then I asked to bound the regret of algorithm B using the regret bounds of this paper on the losses that reacted to algorithm A, the regret bounds would still hold. This is only true because we are in the full-information setting, and is a crucial fact for such meta-learning over different realizations of the algorithm to work.\n2. $\\hat x^*_t$, $\\hat \\ell_t$, $z_t$, etc are all unquantified in the theorem statements. In general, the statements hold for any such sequences (this is part of the novelty, allowing for any predictions), but it would be good to make this explicit.\n3. Referring to the algorithm as (Optimistic) Mirror Descent, while standard in some literature, is rather misleading since Mirror Descent often refers to a much more general algorithm with arbitrary regularizers. The name (Optimistic) (Sub)Gradient Descent would be more appropriate.\n4. It is worth mentioning that NES has a plethora of different names (Hedge, Exponential Weights, etc) and that the role of $\\ell_t$ being a subgradient is irrelevant to the algorithm (and is only applicable because the loss is convex).\n5. The choice of notation $S_T$ is probably suboptimal, since this already has a name in the literature which corresponds to specifically the case where $\\hat x^*_t  = x^*_{t-1}$. A new symbol that highlights the new generality would be preferable. It is also not clear why this is scaled by the bound on the predicted gradients, which leads to a weird asymmetry in dependence on the bounding constants in the regret bounds.\n",
            "summary_of_the_review": "The technical results have novel aspects and are potentially interesting in their own right. I have also checked the proofs thoroughly and found no issues. However, the new adaptive quantities are not sufficiently motivated, the novelty of Theorem 1 is overstated, and two of the novel aspects highlighted in Theorems 1 and 2 are discarded when these results are used later in the paper (and thus the utility of the novel aspects is unclear). The paper also suffers significantly from a lack of clear distinctions between prior work and novel work, compounded by poor formatting/exposition of proofs. Due to these limitations, I do not think the paper will be useful to the community in its present form, and I believe the necessary changes---namely, additional results that use the novel aspects of Theorems 1 and 2 and take advantage of the utility the benefits of $M_T$ over $V_T$---are too extensive to be done in the review period.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studied the problem of online convex optimization in dynamic environments, and proposed to improve previous dynamic regret bounds. To this end, the authors proposed to modify the existing algorithm called Ader by replacing its meta-algorithm and expert-algorithm with their optimistic variants. Different from the $O(\\sqrt{(P_T+1)T})$ dynamic regret bound of Ader, this paper established a dynamic regret bound of $O(\\sqrt{(P_T+1)M_T})$. However, $M_T$ is a variable that depends on the proposed algorithm, and its advantage is actually not clear.",
            "main_review": "The problem studied in this paper is interesting, and it is reasonable to improve the existing algorithm called Ader by replacing its meta-algorithm and expert-algorithm with their optimistic variants. However, there are some concerns, as follows.\n\nFirst, the idea of improving Ader by replacing its meta-algorithm and expert-algorithm with their optimistic variants has already been utilized by Zhao et al. (2020). But, the authors did not introduce and discuss the algorithms proposed in Zhao et al. (2020). Moreover, the analysis technique of this paper is very similar to that used by Zhao et al. (2020).\n\nSecond, the advantage of the $O(\\sqrt{(P_T+1)M_T})$ dynamic regret bound in this paper is actually not clear. Different from this paper, Zhao et al. (2020) have established a dynamic regret bound of $O(\\sqrt{(P_T+1)(P_T+1+\\min(V_T,C_T))})$ when the losses are smooth, where $C_T=\\sum_{t=1}^T\\varphi_t(z_t)$. If $z_1,\\cdots,z_T$ have a small loss, $C_T$ would be small, and  the $O(\\sqrt{(P_T+1)(P_T+1+\\min(V_T,C_T))})$ regret bound would be clearly better than the $O(\\sqrt{(P_T+1)T})$ regret bound of Ader.\n\nThere are some suggestions. First, the authors should clearly discuss the difference between the algorithm proposed in this paper and that proposed in Zhao et al. (2020). Second, similar to Zhao et al. (2020), the authors should give at least one specific instance of the proposed algorithm such that the $O(\\sqrt{(P_T+1)M_T})$ dynamic regret bound is better than the existing results. Third, it would be better if the authors can provide some experiments to show the advantage of their algorithm.",
            "summary_of_the_review": "The proposed algorithm and the corresponding analysis are similar to Zhao et al. (2020). However, this paper did not clearly show the advantage of their results, compared with existing dynamic regret bounds. Overall, I think this paper should not be accepted.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper studies the online convex optimization problem in the non-stationary environments, where the dynamic regret is taken as the measure. Previous work (Zhang et al.) shows a $O(\\sqrt{T(1+P_T)})$ dynamic regret by using a Hedge algorithm to track multiple OGDs with different step sizes. This work uses the optimistic version of the Hedge algorithm to track multiple optimistic mirror descent algorithm and achieves an $O(\\sqrt{M_T(1+P_T)})$ bound.\n",
            "main_review": "My main concern about the paper is that the proposed method has already appeared in the literature [1,2]. Although the result $O(\\sqrt{M_T(1+P_T)})$ seems not explicitly mentioned by previous works, it could serve as an intermediate result in the previous analysis. \n\nMore specifically, the ONES algorithm has already appeared in [1] (Equation (9)), where the authors use the method to achieve the adaptive dynamic regret bound $\\min\\\\{\\\\sqrt{(1+M_T)P^*_T}, F_T^{1/3}M_T^{1/3}\\\\}$. The regret bound obtained by the paper is almost the same as that in [1], where the only difference is that the previous work considers the worst-case comparator (i.e. comparing with the function minimizer  $z_t^* = \\mathrm{argmin}\\\\ \\varphi_t(z)$). However, the general dynamic regret bound (i.e., comparing with $z_t$) can be immediately obtained by the same argument in [1] and by just replacing the comparator from $z_t^*$ to $z_t$.\n\nReference:\n\n[1] A Simple Online Algorithm for Competing with Dynamic Comparators. Yu-Jie Zhang, Peng Zhao, and Zhi-Hua Zhou. UAI 2020.\n\n[2] Dynamic Regret of Convex and Smooth Functions. Peng Zhao, Yu-Jie Zhang, Lijun Zhang, and Zhi-Hua Zhou. NeurIPS 2020.\n",
            "summary_of_the_review": "In summary, the algorithm proposed by the submission has already appeared in the literature. Although the main theorem has not been explicitly stated by previous work, it can be obtained immediately following the analysis of the previous work. So, I tend to reject the paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The work studies dynamic regret analysis and environmental adaptivity in online convex optimization. The contributions of this work are as follows:\n- A dynamic regret of OMD and a static regret of ONES are proved.\n- The proposed algorithm ONES-OMD achieves a better dynamic regret of $O(\\sqrt{(1+P_T)M_T})$ than Ader since $M_T$ reflects the adaptivity.\n- The proposed adaptive trick results in the same regret bound without knowing $M_T$ in advance.\n- A variant of ONES-OMD with a subgradient variation type regret is proposed.",
            "main_review": "Strengths\n- Theorem 1: Dynamic regret of OMD\n- Theorem 2: Static regret of ONES\n- Comparing to the $O(\\sqrt{(1+P_T)T})$ bound of Ader, ONES-OMD achieves a better bound of $O(\\sqrt{(1+P_T)M_T})$.\n- Adaptive trick enables the bound without knowing $M_T$ in advance.\n- Corresponding results of subgradient variation type.\n\nWeaknesses\n- Justifying $M_T$.\n- No guarantees on the accuracy of $\\widehat{x_t^*}(j)$ and $\\widehat{\\ell_t}$.\n\nThe main contributions of this work are Theorem 1 and Theorem 2. They provide the crucial components for the enhanced algorithms. The analyses of the theorems are rigorous. The work also shows how to leverage existing results (Lemma 1 and Lemma 2) to analyze new problems.\n\nThe technical contribution is the rearrangements in (13). It connects distinct measurements in OMD and ONES via the single notion $M_T$. This allows the analysis of the proposed ONES-OMD. As $M_T$ is a key notion, insufficient justification of $M_T$ becomes a major concern which will be discussed later. The adaptive trick and subgradient variation type result could be viewed as standard extensions of ONES-OMD.\n\nSince $M_T$ is the key factor affecting the main result and various characteristic terms ($P_T$, $V_T$, and $F_T$) are proposed in the line of adaptivity study, the reviewer believes the authors should justify the choice of $M_T$ and compare it with other characteristic terms. As shown in (14), the accuracies of $\\widehat{x_t^*}(j)$ and $\\widehat{\\ell_t}$ determine the value of $M_T$, hence they are crucial to the main result. Therefore, it would be more convincing to provide literature on accurate estimators for $\\widehat{x_t^*}(j)$ and $\\widehat{\\ell_t}$ than merely assuming the accuracies.\n\nGiven the pros and cons, the reviewer considers this work marginally below the acceptance threshold.",
            "summary_of_the_review": "The work proves regret bounds for OMD and ONES. Replacing MD and NES in Ader by OMD and ONES respectively forms the proposed algorithm ONES-OMD. ONES-OMD achieves an $O(\\sqrt{(1+P_T)M_T})$ regret, reflecting its adaptivity by the environmental property $M_T$. The work lacks justification for the choice of the crucial term $M_T$. There are no guarantees on the key estimations $\\widehat{x_t^*}(j)$ and $\\widehat{\\ell_t}$ as well.\n\nThus, the reviewer considers this work marginally below the acceptance threshold.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}