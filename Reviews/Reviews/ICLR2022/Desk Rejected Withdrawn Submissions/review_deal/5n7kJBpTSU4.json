{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposes a unifying paradigm for interpetting different efficient transformer architectures as that of computation under a bounded amount of memory. The paper illustrates by characterizing attention in such a way, new variants of attention may be proposed, and show that such new variants of attention enable improved performance across a variety of benchmarks.",
            "main_review": "I am not very well read in this area, and give the paper a weak accept as I found the paper quite interesting to read and well-written (but am unsure of the novelty and technical soundness of empirical evaluation due to lack of technical knowledge in this area). \n\nStrengths:\n\nThe paper proposes an interesting interpretation of existing approaches towards efficient transformers. The paper proposes a new approach towards attention in transformer inspired by the use of bounded memory through a contextual queries to a fixed set of memory slots.\n\nThe approach appears to perform well, and outperforms compared baselines across several tasks using reported numbers from different papers\n\nThe decoding speed of the approach appears to be faster than other approaches expect for one which requires additional finetuning from a transformer architecture\n\nThe approach is simple and easily to implement across different transformer architectures\n\n",
            "summary_of_the_review": "I found the paper to be an interesting read with solid results across several different domains.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The work Attention with Bounded-memory Control (ABC) generalizes the attention mechanism as an outer product with memory-control vectors, which serve as basis. In the common case, this basis is the identity matrix. However, in the more general case, this could be considered a rectangular matrix, projecting the key and values to a low dimensional space $n$, with $n<<N$. This has the potential to reduce the space and runtime complexity needed to compute the attention computation. This view allows the authors to show how previous performance improvements to attention, such as Linformers, clustering, sliding windows, etc. are  all described under the ABC framework. In particular, the authors show how Linformers can be applied to the autoregressive case, not considered previously. Then, a new alternative is suggested to learn the vector basis using an MLP, such that the base depends on each input element $x$. Last, the derived ABC with MLP, and other instances of the ABC are compared in machine translation, language modeling, and masked language modeling (through fine-tuning), and runtime and space performance.",
            "main_review": "The ABC framework seems is a novel and an interesting unifying perspective to the long line of work of efficient transformers. The work is clear and well described. The authors took a good amount of time to relate their framework to previous work. The experimental section covers usual type of experiments and datasets. The main idea on this paper would be of value to this community.\n\nStrengths:\n* The framework is simple and connections to other models are considered\n* Explanation on how the Linformer can be used in a causal setting\n* Proposal of ABC-MLP as a learned low dimensional basis with comparable results to full transformer.\n\nWeaknesses:\n* The work focuses too much on how to explain other transformer modifications, and misses to explain what would be a good property for the control basis. \n* The reported improvements in runtime and space are not impressive: up to ½ space, and up to 50% speed up comparing to the transformer baseline. \n* The work utilizes the work of Baevski and Auli as a baseline. However, these number are worse than other papers. For example, the original paper from Vaswani et al. obtained 28.4 BLEU score on WMT14 EN-DE, higher than the 27.3 reported here. A better reporting of numbers in the experiments would be appreciated.\n* The cost of considering and multiplying a basis set is not null and should be analyzed in the complexity of the method. It would be interesting to see how much is gained despite the improvement from $O(N^2)$ to $O(nN)$.\n* Lack of std dev/error measurements on the experiments. Some values in the results are too similar among methods. It hard to evaluate the conclusions there.\n\nMinor:\n- The meaning of the word “memory” is overloaded in the text. Please, consider the terms used for the attention mechanism, the actual memory in the hardware, etc. with distinct terms.\n",
            "summary_of_the_review": "I based my score on the value of the presented work, which would be of interest to this community. However, the ABC-MLP version seems an incremental improvement. Also, there are no insights on what could benefit a model based on ABC. I will be eager to reconsider my score if my points above and following question are addressed. \n\nQuestions to authors:\n* Would you mind discussing what properties for the $phi_i$ vectors are desirable to obtain similar performance as the full model with identity $phi_i=e_i$?\n* Can you elaborate on low runtime improvement in the masked LM case (Roberta vs ABC-MLP)?\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "In this paper, the authors introduce attention with bounded-memory control, a unified framework to subsume many recently proposed efficient Transformers including informer, sliding window attention and clustering-based attention. Given this abstraction, it is possible to implement causal attention in the Linformer.\nFurthermore, they propose $ABC_{MLP}$ which has a learned contextualized memory control. Experimental results on different tasks show that their proposed model outperforms existing works.",
            "main_review": "Strengths:\n\n1. It is insightful to abstract existing works.\n2. They extend the Linformer by introducing causal attention.\n3. Extensive experiments show the effectiveness of $ABC_{MLP}$.\n\nWeaknesses:\n1. They do not report the speed and memory of the causal attention models (Table3), it is meaningful to discuss the efficiency of these causal attetnions.\n2. From Table 4, it seems that the proposed model loses some speed and memory for higher accuracy. I am not sure which model is better since Linformer is easy to implement. Therefore, it is necessary to also compare the efficiency of causal attention.",
            "summary_of_the_review": "I think the ABC abstraction is reasonable and helpful to people. However, lack of memory and speed comparison for causal attention makes this work less significant. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper subsumes multiple approaches to efficient transformer attention computations under a single framework: attention-bounded memory control. Specifically, they show that speed-ups from Linformers, clustering based attention, and sliding window attention can be refactored as left-multiplying keys and values by a control matrix $\\Phi$. This applies to both standard and causal transformers.\n\nWhat is the benefit of this framework? It shows that any transformer speed up that can be expressed in this framework admits a causal version. Notably, this allows the authors to derive a causal version of the Linformer. It also provides a new tool for reasoning about attention speed-ups: what $\\Phi$ can provide optimal speed-up with minimal performance loss?\n\nThe authors also present a learned, context-dependent projection of the key and value matrices, which they call $ABC_{MLP}$.",
            "main_review": "*Pros*\n+ It’s helpful to see attention speed-ups contrasted against one another under ABC. I personally would use this as a reference when deciding what approaches to implement and how.\n\n+ The ABC framework allows researchers to quickly derive a causal variant for low-dimensional key and value projections.\n\n+ The ABC framework allows researchers to reason about attention speed ups in terms of these projection matrices.\n\n*Cons*\n- The authors don’t show that the causal Linformer they propose has a significant speed-up empirically (e.g., the last two columns of Table 4 but for a causal task).\n\n- The novelty of the causal form of ABC. Imo, the derivation is very similar to the prefix-sum computations used in the causal variant of Choromanski et. al. (2020).\n\n- The results of ABC_{MLP} aren’t competitive in their results. E.g., in Table 4, $ABC_{NLP}$ achieves <= 1 point jump over Linformer on all tasks with less speed-up.\n\n*Questions*\nWhat is the speed-up performance of Linformer in causal settings?\nWhat is the space and time complexity of the causal variant of ABC in the general case?\n\n*Feedback*\nFor completeness, the authors could strengthen their paper by also showing the runtime complexity in the causal case.\nTo strengthen the paper, the authors could either improve $ABC_{MLP}$ or argue further for the benefits and novelty of ABC (probably with more causal Linformer results).",
            "summary_of_the_review": "I vote to reject this submission. The advertised benefit of ABC (specifically, immediately deriving a causal variant of an ABC-compatible approach) is not substantiated empirically. Results for and novelty of $ABC_{MLP}$ are not strong enough on their own for acceptance.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}