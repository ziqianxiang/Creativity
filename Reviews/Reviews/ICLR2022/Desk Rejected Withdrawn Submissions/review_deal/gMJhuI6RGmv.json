{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposed the first data-driven method for extracting topological face/cycle from 2D CAD line drawings (2D wireframe). The core idea is to cast it as a sequence generation problem, and use Transformer model with pointer-net to predict one or more loops of co-edges on the same face. Based on the identified topology faces, the authors further demonstrate a constrained optimization method for reconstructing the corresponding 3D wireframe. Experiments are carried out on a subset of ABC dataset containing mechanical parts, and comparison are mainly against several variants of its own. The proposed method obtains high recall and maintains a fast runtime.",
            "main_review": "Overall, I think the idea to formulate the topological face identification as a sequence generation problem is interesting, even though the problem itself is just one step in the 3D CAD reconstruction process. The network structure is not new, and I can see that the author draw inspiration from PolyGen's network design. But formulating the right representation for this task to fit in the network still makes a valid contribution. \n\n\n\nStrengths:\n\n- The problem setting is valid, even though it's only one step in the full 3D CAD reconstruction pipeline. It would be better if the paper directly targets at reconstructing 3D CAD model from 2D wireframe, but solely focusing on face identification is also fine. As the first attempt to tackle the problem in a data-driven fashion, the proposed method is technically sound and shows promising results.\n- Desipte some typos, the paper is well written and easy to understand. Illustration figures are well made to help understanding the revelant concept, e.g. Fig.2 and Fig.3.\n\nWeaknesses & questions:\n\n- The main drawback of this paper is the lack of comparison to previous methods. Clearly it's not a new problem, and there are traditional methods, e.g. those heuristic search algorithms that the authors mentioned in the introduction section. It's really discouraging to see that there are no comparison to those prior methods.  Even some simple baselines can help to better understand the quantitative results obtained by the proposed method. This paper would be much more convincing if the authors can address this issue, or give a valid reason for not comparing prior methods.\n\n- The literature is not fully surveyed and many recent related papers are missing. Recently, especially this year, people started to apply deep learning techniques to CAD related problem. There are many published papers that should be cited:  \n  - Encode/represent CAD models:\n    - UV-Net: Learning from Boundary Representations, CVPR 2021.\n    - BRepNet: A Topological Message Passing System for Solid Models, CVPR 2021.  \n  - Generate/reconstruct CAD models:\n    - Fusion 360 gallery: a dataset and environment for programmatic CAD construction from human design sequences, SIGGRAPH 2021.\n    - DeepCAD: A Deep Generative Network for Computer-Aided Design Models, ICCV 2021.\n    - Engineering sketch generation for computer-aided design, CVPR 2021.\n    - SketchGen: Generating Constrained CAD Sketches, NeurIPS 2021.\n\n  I do believe some techniques in the above papers to represent parametric CAD models are also useful here, since the data domain is more or less the same. In particular, I suggest the authors to take a look on UV-Net, BRepNet and DeepCAD.\n\n- Ambiguous cases are not addressed. There are ambiguities in some cases, e.g. Figure 1(b). The paper wrote that previous topological algorithm cannot handle this automatically, so I was expecting the proposed method to produce multiple correct interpretations in this case. However, no results are shown regarding this. I do think it is possible, since the proposed model is auto-regressive and techniques like beam-search can be applied. \n- It would be better to include some analysis on how the performance changes as the CAD model becomes more complex (i.e. increasing number of faces or co-edges)? I was curious to what extent the proposed method can work. It's OK to put it in the supplementary.\n- I also have some questions about the compared variants. For the 'seq2seq', how are edges embeded? If it's still to uniformly sample edge points, then how is that different from representation of co-edges?\n- Why is the prediction accuracy not reported in Table 1? It seems weird to have it in Table 2 but not in Table 1.\n",
            "summary_of_the_review": "In general, I think the paper is currently on the borderline. It targets at an interesting problem, and proposes the first data-driven approach to solve it. The method is technically sound and integrates domain knowledge into the network. However, the evaluation is not well carried out. Particularly, it does not compare to any prior methods or baselines, which makes the results less convincing.\n\nI am willing to improve my score if the authors can address the evaluation issue and include all the missing references listed above.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This work proposed a data-driven approach for face identification from the 2D line drawing of manifold objects. The core idea is to use a seq2seq model to perform face loop generation by predicting one co-edge at each timestamp. Compared with prior works which use tedious searching over all possible face loops and manually-defined heuristics, this work is the first data-driven method that shows advantages in inference speed. In addition, the face identification results could be further used for downstream tasks like 3D model reconstruction, which outperforms AtlasNet based on the assumption that the 2D line drawing inputs are available.",
            "main_review": "The idea of using seq2seq model for face loop generation is novel. The most interesting part is that the face type prediction tokens are used for both face type identification and end of sequence indicator. However, one of my major concerns is the model performance when there are occlusions between lines and vertices in the given 2D wireframe. For example, in the last row of Figure 4, seems like it is relatively hard to generate reasonable face identification if lines are overlapped with each other. Also, how to do position encoding for these occluded lines in the transformer encoder is also not clear to me. I think more discussion and implementation details should be placed about this situation.\n\nThe second weakness of this work is the experiment baselines. All of the compared baseline methods are model variants of the proposed method and no prior works are included. I’m wondering how do other neural architectures for set prediction would perform in this task. For example, we can regard all the edges as points and use PointNet to directly output edge-level prediction in one step. I believe this would be an important experiment to highlight the advantage of the seq2seq model in this task.\n\nI’m quite impressed by the 3D reconstruction results in Figure 5 and I do agree focusing on edge-level embedding is better than taking 2D line drawing images as inputs which have very sparse features. I think an interesting future direction would be to leverage the 3D reconstruction result to refine the face predictions. For example in the second-row fifth-column of Figure 5, seems like the face prediction regards the cylinder as a rectangle plane, which could be fixed in a different view based on the 3D information.",
            "summary_of_the_review": "Overall, I think the paper is well written and interesting to read. The 3D reconstruction results show good potential for future applications. However, I think more discussion on the effect of overlap edges would be useful. And more experiment baselines of prior works could give us a better understanding of the advantage of using seq2seq model for this problem.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents a new method for face identification and 3D reconstruction from 2D wireframes. The main method consists of two components: The first is a data-driven face identification approach, where a transformer pointer network predicts co-edge loops that form faces. The second is a vertex depth estimation approach that depends on co-planar and parallelism constraints. The proposed method is evaluated on 2D wireframes synthesized from CAD models. The first part is shown to outperform several baselines and ablated versions quantitatively, while the second part is qualitatively compared with the existing 3D reconstruction approach.",
            "main_review": "Strengths:\n\n- The problem setting is both novel and interesting. While the problem of 3D CAD model reconstruction from 2D wireframes is widely useful and practical, I have not come across previous literature that uses a learning-based approach to address it.\n- The paper is clearly written and easy to follow. I find the problem introduction and formulation particularly helpful to readers who may not be familiar with the CAD data modality. Despite the arrangement of sections being a bit unconventional where the method is split into two parts each with its own experimental results, I do not find it difficult to read and understand.\n- The first part of the method (data-driven face identification) is novel and makes a lot of sense to me.\n\nWeaknesses:\n\n- The experimental results seem a bit lacking. The face identification method is evaluated quantitatively, but no existing method (e.g. non data-driven) has been compared. The 3D reconstruction method is only evaluated qualitatively, where commonly used metrics exist, such as IOU or EMD.\n- Some settings can benefit from more explanations: The split of dataset results in a very small and uneven validation and test set, with two seemingly ad-hoc threshold values. What are the motivations behind these settings?\n- The constraint-based depth estimation method seems a bit preliminary, where perfectly positioned x and y coordinates are required. In practice, the 2D wireframe can often come from sketch drawings or parsed photos. It would be great to have further discussions on how robust the current approach is.",
            "summary_of_the_review": "Despite the weaknesses mainly regarding more comprehensive experiments, I still find the current result convincing that the proposed method works reasonably well. I find the strengths of novelty and interestingness over-shine the weaknesses. Therefore, I'd recommend accepting this paper.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a data-driven approach for face identification from a 2D wireframe. A variant of the Transformer model is trained from a large dataset of 3D objects and their 2D projections to predict the sequence of edges that forms faces in a natural order. The approach is evaluated on face identification and 3D reconstruction tasks, and shows improved performance over baselines.",
            "main_review": "Strengths\n- The first work to use data-driven methods for face identification by casting it as a sequence generation problem\n- Analyzes the benefit of design choices such as using co-edges, face-wise parallel prediction, and shows robustness to viewpoint type\n- Demonstrates the applicability of the method for the downstream task of 3D reconstruction\n\nWeaknesses\n- The paper claims that the main benefits of using a data-driven approach are (1) ability to handle ambiguous cases and (2) improved runtime over heuristic search. However, the experiments did not include comparisons to classical methods. Without such a comparison it is hard to evaluate the tradeoff in performance/runtime between the two approaches.\n- The method currently relies on a post-processing stage to discard predictions that are invalid or duplicated, but this does not seem sufficient. Because faces can contain nested edge loops, the model can technically predict multiple faces (sets of edge loops) that partially overlap. There is currently no mechanism to handle cases where an edge loop belongs to more than one face prediction. An example is if I have three disjoint edge loops A, B, and C, and the model predicts A+B as one face and B+C as another face. This could be the reason why the “seq2seq + co-edge + parallel” method has slightly lower precision than the “seq2seq + co-edge” baseline in Table 1.\n- Are the Table 2 results showing zero-shot transfer from a model trained with only orthographic projections? Or did you re-train the model for each type of viewpoint? If separate models are trained, I wonder how well a single model can generalize to different viewpoints.\n- Why are the “prediction accuracy” and “face classification rate” metrics reported only in Table 2 but not in Table 1?\n- Figure 4 is hard to understand. First off, black is used for both (1) the input line drawing and (2) to denote wrong face types. It is also unclear why there are different numbers of predictions for each examples. There should be N predictions, where N is the number of co-edges in the input wireframe. Also, it would be helpful to visualize the ground truth faces corresponding to each prediction (determined by the first co-edge that a particular prediction starts at). Also, in the last example, the first prediction and the fourth prediction both seem to highlight the same left edge of the object. I’m guessing they actually highlight different edges but appear the same due to the viewpoint projection, but this way of visualizing the errors is unhelpful.\n- More analysis on how the performance of your model is affected by the number of co-edges / faces in the object could be useful.\n\nMinor comments\n- Abstract: “edges loops...” -> “edge loops”\n- Section 3: “is not vertex” -> “is not a vertex”\n- Section 3: “an important type of topological entities” -> “entity”\n- Section 3: Briefly define B-rep (boundary representation)\n- Section 3: It would be helpful to more precisely define what a vertex and an edge is for a 2D wireframe and provide the dimensionality of the inputs. For instance, an edge representing a line segment can be defined with two 2D points at its endpoints. How about a curved edge? How is a curved edge represented?\n- Section 4.3.1: Missing units for camera distance (meters?)\n- Section 5.3: “a popular deep learning methods” -> “a popular deep learning method”\n- Figure 5: Could you also render a 3D mesh of your predictions, since you have faces and depth?\n",
            "summary_of_the_review": "In summary, I believe applying data-driven methods to face identification appears novel, and the paper shares some design choices that are important for getting such a framework to work.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper addresses the problem in computer-aided design (CAD) of identifying faces from converting 2D line drawings and also reconstruct 3D objects.\nThe problem is cast as a sequence generation problem where an arbitrary edge is selected as starting one, then a variant of the Transformer model is used to predict the edges associated with the same view in a natural order. In this way, searching the space of all possible edges loops is avoided, and challenging cases such as curved surfaces and nested edge loops, can be addressed.\n",
            "main_review": "The main contributions of this work are: \n- A data-driven approach is proposed to identifying closed facet from a 2D line drawing.\n- A simple method is given to reconstruct a 3D model from a single 2D line drawing using the face identification results. The method is supposed to work under some assumptions.\n\nOverall the paper is well written and it is also easy to read and understand. However, there are several weak aspects in the paper:\n- the novelty of the paper is mostly in the application, while the network architecture is a known one. The problem is that the proposed application is not sufficiently well evaluated\n- as a paper contribution authors claimed that advantages and disadvantages of the proposed method over existing geometry and topology-based methods are investigated. Actually there is not much analysis in that respect in the results\n- results for face prediction are reported on just one dataset. In addition, it is not clear how many different CAD models are in the dataset and how many have been included in the training and test\n- there is no comparison with other solutions in the literature for the same task. Without such comparison it is difficult to evaluate the actual effectiveness of the proposed approach\n- results for 3D reconstruction of planar objects are only qualitative. I think authors could have reported quantitative measures by evaluating the displacement between reconstructed 3D models and ground truth-ones\n- comparison with AtlasNet is Figure 5 seems not completely fair since that network is not specialized with the assumptions made by the proposed solution\n\nMinor comments:\n- I suggest changing the term \"face identification\". When used as keywords is results in a lot of confusion with the totally different context of recognizing the human face. \n",
            "summary_of_the_review": "Based on the above comments, I think the contribution of this work is weak:\n- from a theoretical point of view, the methods and techniques used in the paper are well known \n- from an experimental point of view, results are not convincing because they are performed on limited data, and do not address comparison with state-of-the-art solutions. In addition, some of the experiments are also provided in a qualitative way, while a quantitative proof would have been possible and useful. \n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}