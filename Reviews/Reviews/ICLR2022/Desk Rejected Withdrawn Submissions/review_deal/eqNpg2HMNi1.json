{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proposed a machine learning-based system, in specific, a VAE, to learn and generate hyper-parameters of a few physical systems. The authors leveraged Monte Carlo Dropout to make the learned model uncertainty-aware and enabled a diversity results of generated *configurations* of the physical systems. Then, this paper demonstrates an empirical result of the learned model on open-sourced systems.",
            "main_review": "Overall, the paper is highly motivated. The wording is clear, and the majority of the substance is easy to comprehend. My main concern, however, lies in the innovative aspect. \nI must admit that I am not a physical systems specialist. However, the papers' basic premise appears to me to be a straightforward application of the MCMC generation process, whereas most of the assumptions are unclear (e.g., the physical system assumptions corresponding to the process and the corresponding generalizability discussion).\n\n\nQuestions:\n* What is the choice of the network of \\mu, \\phi and \\theta ? \n* Could you please add an ablation study of the necessity of introducing kinetic energy term p.\n* Is there any guideline that how to choose the annealing rate \\lambda, and what setting are you used in your experimental settings?\n* What is the choice of hyper-parameters of Monte Carlo Dropout (such as retaining rate p, model precision \\tau, length scale l)?\n",
            "summary_of_the_review": "I am inclined to give the article a negative result, but if the author can address my concerns above during the rebuttal process, I will consider raising my score",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The paper proposes Hamiltonain Monte Carlo with a novel temperature scaling in the latent space of a VAE for design optimization. Authors also employ Monte Carlo dropout to make the design uncertainty-aware. ",
            "main_review": "Strengths:\n\n(1) Hamiltonian Monte Carlo on the latent space of a VAE is used for design optimization.\n(2) Uncertainty is taken care of by using Monte Carlo dropout in decoder and a specification network.\n(2) Results are reported on three design problems: propeller design, air vehicle design, and race vehicle design. \n\nWeaknesses:\n(1) One of the main weaknesses of the paper is not benchmarking the proposed method against a baseline (existing or proposed). \n(2) The paper should include relevant existing works in discussion. For example, the deep surrogate work presented in Pestourie, et al., npj Computational Materials volume 6, Article number: 164 (2020) should be cited and discussed.",
            "summary_of_the_review": "While the optimization on latent space of a VAE for design optimization of physical systems is interesting, authors do not show comparison of the proposed method against existing baselines. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper considers an important problem of automatic design of physical models via VAE with an additional Specification Network at the latent space of VAE. HMC scheme is proposed to explore the configure space based on the potential and kinetic energy. to reduce the validation time, which, in general, required slow physical model simulations, this work utilizes the variance prediction methods based on \"Monte Carlo dropout\". the partial annealing scheme requires $n$ different annealing temperatures, which should be specified. ",
            "main_review": "Dear Authors, please find below my detailed comments.\n\n1. please add references for the statement: \"the design process lacks a complete formal characterization and relies on human intuition and domain expertise\". In many domains/scenarios, the design process is based on well defined theories and automated. \n\n2. please elaborate on the meaning of \"the design manifold\". which manifold definition do you use? is it \"a manifold is a topological space that locally resembles Euclidean space near each point\"? Else? If you do not use a mathematically-defined manifold, I recommend to change the title, as currently it is just confusing. Loosely-using and/or abusing common terms lead to misunderstanding and confusions. Also, \"manifold learning\" has a particular meaning in machine learning.\n\n3. What does it mean \"valid design configurations but do not address the design objectives\"?\n\n4. \"The exemplar designs are likely to be far from optimal design objectives\". Why? \n\n5. Where do you get the exemplar designs from? \n\n6.  Figure 2: What does it mean \"The specification network predicts the design objectives from the latent space\"? Are not \"the design objectives\" given, as shown at Figure 1? \n\n7. could you please explain the following? \"Figure2 ..and their evaluation on physics models.\" but before you said it is slow to evaluate designs on physical models. \n\n8. RE the loss: please explain why \"MSE on the reconstruction of x\" and \"MSE on the specification s\" are equally important?  \n\n9. RE the loss: where is \"model uncertainty-aware\" reflected by the loss?\n\n10. why pi(z) is define? Normal Gaussian? Fixed?\n\n11. \"This enables exploration of the Pareto frontier..\" how? is it trivial to see from you objective? \n\n12. Figure 1 shows 11 design objectives, which require to specify 11 $\\lambda_i$ in the acceptance probability , $a(z'\\mid)$. The loss $L_{\\lambda}(\\theta, \\phi, \\mu)$ adds an other parameter, $\\lambda$, (Lagrange multiplier). Please explain how do you specify these 12 parameters. \n\n13. Does your method for specifying the parameters scale to the cases of a larger number of design objectives than 11? Please explain how to specify parameters $\\lambda_i$ and $\\lambda$ for 1000 design objectives. If that is impossible, please explain \"the upper bound\" of the feasibility of your method.\n\n14. Figure 2: $\\mu$ is used for the mean of Encoder and for the parameters of \"Specification Network\", $S_{\\mu}$.\n\n15. How is M in K(p) calculated? \n\n16: Figure 3: what are the design objectives,  \"design manifold\", and the other components shown at Figure 2 in this example? Please elaborate how this figure/experiment is related to design of physical model. Is it \"Illustration of DeLPhy\" or of Variance prediction by \"Monte Carlo dropout (Gal & Ghahramani, 2016)\"? \n\n17: Section 4. \"EXPERIMENTS\". All these experiments show only the proposed method. There is no baseline and/or existing SOTA for \ncomparison despite the prior works mentioned in Section 5. The experiment looks ok. but I can not see whether there is progress with regard to the existing methods. this comparison should include a) training time (when possible), b) number of parameters (when possible), c) error bars. \n\n18: Please specify how to chose $\\lambda_i$ and $\\lambda$ in Algorithm 1 for an arbitrary design problem. \n\n19: \"We augment our system to include a vector p\". Why do you need that? What problem is it supposed to solve? Please provide ablation study with/without this augmentation for the physical design problems. \n\nBest Regards,\nReviewer\n ",
            "summary_of_the_review": "The problem of physical model design is very important. Consequently, I provided a detailed review with my suggestion for the improvements. But I am not sure the current status of the work is satisfactory to be published at ICLR. Below is the summery of my considerations for my score. \n\nThere is no comparison to the existing methods for the solution of this problem, which makes impossible to evaluate the novelty and the contribution. \n\n$n$ different temperatures should be specified, which is not clear how to do. and it might be challenging with a larger number of objectives. \n\nThe terms \"manifold\", \"manifold learning\", and \"of manifold..\" have particular meanings. Their use in this paper might lead to confusion and/or abuse of notations. My expectation from the title \"... OVER LEARNED MANIFOLDS\" was to see connections to the known and existing terms. \n\nThere are a number of decisions which are not explained (see please Main Review).\n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper a method called DeLPhy to can generate diverse designs that are optimised for multiple objectives.\nDeLPhy consists a VAE with a mixture of Gaussians prior to learn a latent space of designs.\nFor that latent space, surrogate models that learn to predict design objectives are learnt.\nFor the VAE itself, the decoder contains a dropout layer so that MC dropout is applied to get an uncertainty of a decoded code,\nwhich can be used to rule out implausible designs.\nAnnealed HMC is then be used to sample latent codes by considering both the VAE and the surrogate models.\nResults shows that DeLPhy can indeed produced diverse designs that optimised for multiple objectives.",
            "main_review": "Strengths\n- The paper is well-written and easy to follow.\n- Different components of DeLPhy (VAE, surrogate models, MC dropout, annealed HMC) are well motivated\n- Fig 5(b) is very intriguing - I'm very happy to see MC dropout gives uncertainty estimates that align with the OpenProp simulator.\n- The results on three design tasks (propeller, SAE race vehicle, air vehicle) supports the design and the claim of the model can produce diverse designs optimised for multiple objectives and the uncertainty estimate is useful to stop from exploring infeasible space.\n\nWeaknesses\n- Although the method is supposed to work for multiple objectives, the three tasks all focus only on two objectives. Do we have evidence that the method can work for more than two objectives?\n- The discussion of the proposed method is not as clear as the rest of the paper. I can see the idea of using VAE (or deep generative models) in general is not new; the idea of using surrogate models for costly objectives is not new. I supposed the use of MC dropout (or uncertainty quantification in general) in such tasks is novel and so is the proposed annealed HMC.\n  - Suppose my assessment is true, I can see from the experiments that the usefulness of MC dropout is supported, but how does the annealed HMC? How does it compare to vanilla HMC in the tasks?",
            "summary_of_the_review": "I believe the paper proposes an interesting method for computational design and each of the components make sense.\nI'm concerned about the novelty on a few of the points and the necessity of some components, as mentioned in the end of the Weaknesses section.\nTherefore I don't suggest accept the paper.\nHowever, I'm happy to raise my score if the author can address my concerns.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}