{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper focuses on the task of predicting the fitness of mutated sequences from a given protein family. It proposes to do so by combining a pre-trained autoregressive transformer model (Progen) together with an (optional) unsupervised fine tuning on a relevant MSA for the protein family of interest and a supervised fine tuning on available fitness labels (eg., from a deep mutational scan experiment). The main contributions of the work are about the best way to perform the supervised fine tuning and demonstrating its benefits in different experimental settings.",
            "main_review": "**Strengths**\n1. The 4 DMS used in experiments provide a good coverage of the different scenarios of interest in this type of work (low/high homology, low/high epistasis)\n2. The suggested supervised fine tuning approach is simple to implement\n\n**Weaknesses**\n1. The methodological contributions of this work are limited to formulating the fine tuning as a Bradley–Terry model\n2. The baselines used in experiments have major shortcomings. The work builds primarily on two prior papers focusing on protein fitness prediction:\na. Hsu et al. (discussed in section 2.3) from which the best performing methods are not included in section 5 (eg., augmented Potts, augmented VAE)\nb. Meier et al. (discussed in section 2.4) from which the best performing approach is not included either (ie., MLM pre-training with unsupervised spiked fine tuning on MSA). Instead authors replace this unsupervised fine tuning with a supervised fine tuning on labels (not included in Meier et al) which effectively “throws away that linear head”. Reasons discussed in section 5 for not using the unsupervised fine tuning from Meier et al (“additional training on the pretraining data is needed during evolutionary finetuning to prevent overfitting”) do not seem very compelling\n3. Related to that last point, the text is sometimes misleading. For instance in section 2.4., a reader who is not familiar with Meier et al would likely gather from this paragraph that the supervised fine tuning is done in Meier et al. I would suggest to re-write this subsection to clear that out. Similarly, the sentence “Similar approaches also exist for protein fitness prediction, but throw away information [...] but this information is discarded when the LM is reinitialized with a regression head” (in introduction) or “the traditional approach of discarding a pretrained LM’s linear head” (in conclusion) are also misleading since the current best performing fitness predictors do not actually do that.\n4. Across all experiments, there is an important risk of data leakage that is not discussed, does not seem accounted for and may bias the conclusions: mutations occurring at the same positions should not appear in both training and test sets (otherwise performance may be inflated / model may overfit)\n\n**Clarifications**\n1. Could you please explain how you selected the value for the hyperparameters (eg alpha)? Is it done on a separate validation set? Appendix A2 is not very clear about this.\n2. Did you try the unsupervised fine tuning on low depth MSAs (GFP, GB1)? Sometimes fine tuning on a very limited set of homologous sequences makes a big difference. \n\n**Minor points**\n1. Section 5: would keep the baselines consistent across experiments (same exact methods, same colors, same ordering, etc.)\n2. Typos:\n- Section 1: will be increasingly important for protein fitness prediction (typo)\n- Section 1: Ideally, a LM (not ‘an LN’)\n- Section 1: Last sentence of section 1 is missing one word to be syntactically correct\n- Section 2: last sentence of 2.1 needs to be re-written (current writing does not communicate well your idea)\n- Section 4: Towards bottom of p5 “using the number sequences” (missing “of”)\n\n------------------------------------------------------------------------------\n\n**Final thoughts post rebuttal**\nThank you to the authors for their overall response during rebuttal. Hope the additional thoughts and guidance provided in response will be helpful feedback. Since most points and clarifying questions in my original review were not addressed, my overall assessment remains unchanged.\n",
            "summary_of_the_review": "A simple approach to perform supervised fine tuning that seems to be delivering good results in experiments covering distinct scenarios (low/high homology, low/high epistasis). However, the methodological contributions of this work are relatively limited, several claims are misleading and there are critical issues with the experimental design (missing key baselines, data leakage risk in evaluation).",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The paper tackles the problem of protein function prediction in a few shot setting and proposes a new objective for fine-tuning a pre-trained language model over proteins on the protein function prediction task.\n\nSpecifically, the paper proposes modeling the probability that one sequence has higher fitness than another as a function of the pretrained model's estimated likelihoods for the two sequences; the fine-tuning objective is to maximize the modeled likelihood on ordered pairs of sequences from the labeled training set.\n\nThe approach is compared to alternative pretrained language model-based approaches on tasks with varying complexity. Finally, the approach is compared to results from a previous benchmark paper on two tasks. Overall, the proposed approach improves over the selected baselines.",
            "main_review": "Pros:\n* Protein fitness prediction from few labeled examples is very relevant for sequence design. In particular, building models on labeled sequences with single mutations from the wild-type sequence in order to predict fitness for sequences with multiple mutations is an important problem in the early rounds of biological sequence design.\n* Given the recent results demonstrating promising zero-shot fitness prediction performance with pretrained BERT models, the idea of reusing (rather than replacing) the language modeling head during fine-tuning is timely and interesting. Finally, the proposed fine-tuning objective is sensible and the resulting models are shown to outperform standard fine-tuning approaches (error bars are missing though).\n\nCons:\n* In Figures 2-5, the lack of a one-hot linear baseline makes it hard to understand how challenging the tasks are at each training set size (e.g. the one-hot linear model performed well with 240+ training sequences in the cited Hsu et al. paper).\n* While improving the generic test-set spearman correlation metric is important, it's unclear whether the improvement is on sequences close to the wild-type sequences or on sequences further way. Since one would prefer improvement further away, I think the paper would benefit from a stratified analysis on the best models.\n* Out-of-scope for the rebuttal:\n  * It's not entirely clear to me how the best results in the paper compare to alternative approaches, such as Biswas et al. (or Hsu et al), which also combine evolutionary and fitness label data, or even with the methods used for design (e.g. the linear model on mutation masks) in Bryant et al. in the AAV case.\n  * The paper primarily focuses on one task of biological interest - generalization from single mutations to multiple mutations. The paper would be strengthened if the improvement was also present when more mutations are available at training time and the evaluation is performed on even further mutations.\n\nQuestions:\n* In Figure 3, what's the difference between ProGen + gf-tuning and LM + gf-tuning?\n* In Table 1, is the Ridge model built on a flattened one-hot encoding of the amino-acid sequence?\n\nOther comments:\n* The paper talks about throwing away \"the linear head\". Since the linear head used during pre-training (the (masked) language modeling head) is often replaced by another linear head (the regression head), I found the title confusing. This is a subjective comment though.",
            "summary_of_the_review": "The paper proposes an alternative fine-tuning objective and demonstrates improved performance with respect to alternative fine-tuning approaches. I think that with the addition of the simple baseline and analysis, it can be valuable to the community.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "The authors describe a method for reusing probabilities captured in the linear head of a pre-trained language model for supervised fine-tuning on small labeled datasets. The authors evaluate their method when used to fine-tune protein language models for predicting protein fitness labels, and show that it outperforms existing methods in various settings.",
            "main_review": "- (+) The paper is well written and I enjoyed reading it.\n- (+) Experiments are solid.\n- (-) The proposed method is closely related to existing methods for contrastive fine-tuning, which are not discussed. The methodological contribution seems minor.\n- (-) The claim that the model reuses information from the linear head is not sufficiently supported by experiments.\n",
            "summary_of_the_review": "# Major comments\n1) The proposed loss function (section 3) is closely related to existing pairwise ranking- or contrastive loss functions (https://proceedings.neurips.cc/paper/2009/file/2f55707d4193dc27118a0f19a1985716-Paper.pdf,  https://arxiv.org/abs/2107.02968). Fine-tuning pre-trained language models by using a contrastive loss instead of regression loss is also not new (https://openreview.net/pdf?id=cu7IUiOhujH). Please summarize existing work, describe differences, and rephrase your contributions.\n\n2) Throughout the paper, you attribute the better performance of gf-tuning due to 'not throwing away the linear head'. However, it seems more likely to me that the performance difference is due to using a ranking loss instead of a regression loss for fine-tuning. To understand this, compare to a model whose linear head is reinitialized randomly after pre-training (and evo-tuning), and fine-tuned using the same ranking loss (section \n\n3) Please also compare to a non-linear augmented density model trained with a) MSE loss and b) ranking loss. For example by training a LightGBMRregressor(https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html) and LightGBMRanker(https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRanker.html) on one-hots augmented with p(x) from the language model. This will help to understand if the performance gap between the augmented density model and gf-tuning is either due to learning non-linear actions or the different loss function.\n\n4) Please also report the NDCG score, which is more suited than the Spearman R for assessing the ranking quality of the top variants. Also report the AUC for datasets with a bimodal label distribution.\n\n\n# Minor comments\n5) Can you add error bars to all line plots and report if performance differences are significant? E.g. by randomly splitting datasets multiple times.\n\n6) Section 2: Please generalize your description to binary fitness labels (e.g. protein is active or not).\n\n7) Section 2, 'typically evaluated using Spearman': Other ranking metrics such as NDCG or ROC-AUC are frequently used for assessing ranking. Please rephrase the sentence.\n\n8) Section 2.2: Please also cite existing papers on learning the pooling operator in addition to max and min-pooling.\n\n9) Section 4, 'High vs. Log Homology': Please clarify if 'unsupervised' means unsupervised pre-training or unsupervised fine-tuning on the target domain.\n\n10) Please report the number of parameters of models used in the experiments.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "The authors propose fine-tuning a generative model that learns on protein sequence, and repurposing it (i.e. finetuning it) for predicting protein fitness from a small subset of examples. They start with ProGen, an autoregressive language model trained to predict the subsequent residues from earlier residues (and a set of conditioning tags). The model is fine-tuned on a smaller set of evolutionarily related sequences, and then trained to predict relative fitness ranks, using a small training set for few-shot learning.",
            "main_review": "### Good selection of benchmark models and datasets\nThe authors start with two different models---ProGen and ESM---which are trained to construct internal representations of natural protein sequences in an unsupervised way. The authors also finetune on four different datasets to evaluate fitness predictions. They also compare to other baselines such as Levenshtein distance and BLOSUM62, where available.\n\n### Writing needs to be clearer, specifically in the flow of how things are presented\nThe flow of the paper was oftentimes not very clear. More descriptive headings (e.g. \"Dataset description\" or \"Model finetuning procedure\") would have been more appropriate. Including topic sentences and transition sentences for each paragraph/section would have also helped the ease of reading.\n\n### What is the \"linear head\" that shouldn't be thrown away?\nIt was not clear that section 2 describes benchmarks, and section 3 describes the main contribution of \"gf-tuning\". Given that the title of the paper is \"Don't throw away that linear head\", I had believed that the core contribution was to train a linear head on top of the model embeddings or probabilities (i.e. like in section 2.2-2.4). Instead, the core contribution seems to be to predict the relative order of fitness values using what is effectively the relative probability of seeing the sequence from the underlying language model. There doesn't seem to be a linear head anywhere in this formulation.\n\n### The sole metric being targeted is Spearman correlation of fitness\nAlthough it is important to know whether mutation A endows better or worse fitness than mutation B, it is also important to know by how much. Fitness, in addition to being ordered, exists on an absolute scale. That is, knowing a particular value for fitness is very helpful (e.g. there is often a direct mapping of fitness value to things like enzyme efficacy, receptor response, organism survival rate, etc.).\n\nFurthermore, the loss function in section 3 is designed specifically to optimize for this Spearman correlation metric. If the absolute value of fitness were important to us in any way, then the resulting model wouldn't be very appropriate.\n\n### Seems highly similar to previous works\nThis work seems extremely similar to many previous works. In particular, the core contribution seems to be finetuning a pretrained protein language model to predict fitness. This is already done by several other papers. For example, UniRep (Alley, et. al. 2019) proposed \"evo-tuning\" their autoregressive model to predict fitness values of a GFP protein. The only novel contribution seems to be the formulation of the loss function that is optimized for rank comparison. Beyond that, there doesn't seem to be any major contribution.",
            "summary_of_the_review": "The problem being tackled is a good one, but this problem (and the proposed method of finetuning an unsupervised generative model) has been addressed by previous works multiple times. The core contribution here seems to only be a very specific loss function (i.e. based on ranks) that may do slightly better than previous attempts at optimizing a very specific metric (i.e. Spearman correlation). I am generally very appreciative of non-novel works because they verify or reproduce pre-existing claims, but a paper such as this one may not be very appropriate for a venue like this. Additionally, there are some issues with clarity of writing that make it difficult to support its publication.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}