{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper conduct a practical study on 500 different network architectures sampled from AnyNet search space on 8 different datasets to study the correlation of the model performance across different datasets. A new metric of architecture and performance relationship is introduced. This work empirically found that not all classification tasks are highly correlated, some of them are even have negative error correlation. And also found some observation such as network depth and width.",
            "main_review": "This paper is a kind of technical report. The set up is straightforward and easy to follow and the conclusion is valid for deep learning beginners. However, the conclusion is relatively trivial. There is no novel insight come out of this work.",
            "summary_of_the_review": "Lack of novelty. Lean to reject",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper argues that how well an *architecture instance* performs on ImageNet is not necessarily indicative of how well that architecture instance will perform when trained from scratch on another dataset. This is different from other works which study how well a *trained model transfers*. Further, the number of classes in the dataset is identified as a strong factor in the \"transferability\" of architecture instances, and the width and depth of the architecture instance itself.",
            "main_review": "1. While the main conclusion, that ImageNet is not a good proxy for selecting instances of an architecture to then train from scratch on other datasets, is not too surprising, it is well demonstrated and important.\n2. The role that class number plays in this kind of transferability is new to me and interesting.\n3. The importance of width and depth are good to be confirmed, but not all too surprising given the only two other varied parameters are groups and bottleneck ratio.\n4. It almost feels like the datasets with lowest correlation are all ones with lower intrinsic resolution (<=150px), and those with similar resolution to ImageNet do have reasonable correlation. Concrete is an outlier because it looks trivial and any model performs well. It could be worth checking what happens to a couple of the well correlated datasets, when they are first down-scaled to ~128px. Does the correlation deteriorate a lot, or stay about the same? If the former, it would identify a second dataset-property.",
            "summary_of_the_review": "My review is relatively short because I have previously reviewed this paper in depth. The experiments are still the same and valid, but the story was completely rewritten and is much better now.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper studies the generalizability of CNN architectures. Samples are drawn from a design space of neural networks, such that correlations between performance on datasets can be calculated. Results show that architecture choices based on datasets with more classes might generalise better to other domains. ",
            "main_review": "Strengths\n  * Novel view to study dataset generalization by training CNNs from a design space of architectures.\n  * First paper to investigate the effect of the number of classes on the generalizability of architecture design. \n\nWeaknesses\n  * This paper presents empirical findings for randomly sampled CNN architectures. However, the implications for future research are not clear. What insights could we derive from the presented results? Moreover, I miss the novelty. Concluding that ‘architectures that work well for ImageNet do not work well for other datasets’ feels obvious in some sense. For example, consider the results that transfer learning has lower scores for less relevant datasets [1], or the results that models don’t generalize between dissimilar datasets [2].\n\n* The main results state that selection on a problem with more classes improves generalizability of the chosen model. However, this effect is only shown on one dataset, and one architecture. The results would be strengthened by testing the hypothesis on at least more than one dataset or architecture. In other words, results are limited in scope. When concluding that ‘analysing across datasets with more classes would aid architecture design’, could this be shown for other architectures but CNNs?\n\n* How do models chosen by datasets with many classes differ from models chosen by datasets with few classes? Could the results be confounded by the former simply being bigger models (that subsequently require more generalisation)? Such an effect has been explained by the double-descent phenomenon [3]. \n\n* The paper misses connections to other works about the usefulness of the ImageNet dataset for architecture design. Section 5 states that “ImageNet not only is an imperfect proxy but a very bad one”. What would be an example of such a scenario where this mistake is made? I am not aware of other research that makes this mistake. Moreover, recent works generalise neural network architectures even further and conclude that the dataset and data augmentation diversity are critical factors for high performance[4][5]. How would those conclusions compare with this work?\n\nMinor comments:\n  * Table 2: It seems these training schedules of 10-30 epochs are rather short. Most state-of-the-art results train more than 50 epochs. How does this short training influence results?  [6]\n\n\n\n[1] Zhai, et al. \"The visual task adaptation benchmark.\" 2019.\n\n[2] Torralba and Efros. \"Unbiased look at dataset bias.\" CVPR 2011.\n\n[3] Belkin et al. \"Reconciling modern machine-learning practice and the classical bias–variance trade-off.\" PNAS 2019.\n\n[4] Dosovitskiy, et al. \"An image is worth 16x16 words: Transformers for image recognition at scale.\" arXiv 2020.\n\n[5] Tolstikhin et al. \"Mlp-mixer: An all-mlp architecture for vision.\" arXiv 2021.\n\n[6] Kolesnikov et al. \"Big transfer (bit): General visual representation learning.\" ECCV 2020\n",
            "summary_of_the_review": "The method to analyse architecture generalisability is novel, but the results are limited to only one particular architecture (residual CNN) and only one particular dataset (ImageNet). Results would be strengthened by testing the hypothesis on multiple architectures and more than one dataset. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper studies how well network architectures that work well on the ImageNet dataset perform on other datasets. It trains 500 neural network samples from a neural network architecture search space on different datasets , and shows that the performances of the architectures are highly dataset dependent. For some datasets, the error correlation with ImageNet is negative. The authors also show that ImageNet subsets could have stronger correlation, and also identify two design parameters: the cumulative width and the total depth of the networks.",
            "main_review": "1. The paper is nicely organized and well written.\n\n2. The 500 sampled network architectures have some limitations. The AnyNetX architecture space is not very diverse, allowing only limited changes to the architecture configuration. Moreover, the sampled networks are all within a limited complexity range. As a result, it’s possible that conclusions drawn from this setup will not apply to other settings.\n\n3. The numbers of training epochs are less than the commonly used settings for some datasets. This might make the results and the conclusions less convincing as they might be comparing models that have not converged yet.\n\n4. This paper identifies the cumulative width across layers as well as the total depth of the network as the most sensitive design parameter with respect to changing datasets. The conclusion is made partially because the architecture search space focuses on these two design parameters. If other factors were considered in the search space, they might also affect the results a lot.\n",
            "summary_of_the_review": "In summary, I (as well as many others I guess) agree that we don’t expect architectures that work well on ImageNet also work well on other datasets. This harms the novelty/importance of this work. I also find the experimental setup not very convincing.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}