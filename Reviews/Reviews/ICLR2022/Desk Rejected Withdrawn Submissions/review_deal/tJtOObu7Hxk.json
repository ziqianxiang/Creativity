{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "I believe the paper tackles an interesting problem that has gained some attention recently. Spurious features are becoming more recognised as a reason for the lack of robustness in neural networks. This paper provides an approach for tackling this problem using a novel form of augmentation utilizing the information about the objects. This leads to more than 1 percent improvement in the balanced AP for the model.\n",
            "main_review": "One of the issues with the paper is that it claims to be a mitigation approach to remove \"spurious features\" however the actual method removes at best \"spurious regions\". It is significant, I believe, because with the rocket example even if the person as a spurious region (or object) is removed, there might be spurious features in the handle or the background that determines the object class. \n\nThere is not much rigour in justifying or clearly explaining the solution. Rather than anything else, the method provides a series of heuristics to mitigate the biases in object detection (there are few experiments in other applications but that may not be enough).\n\nIn terms of novelty, similar approaches have already been considered to mitigate spurious correlations. In particular, [2] proposed similarly to mask objects in the context of visual question answering.\n\nThere are no comparisons with similar algorithms. In particular, [1] provides a solution using a generative network that seems to me as a more reasonable general-purpose algorithm for tackling this problem.\n\nIf the method is truly tackling spurious features it might need to include some out-of-distribution set to determine how it performs compared to the baseline. That seems to me a major drawback in the experiments section.\n\nP(Main) is not very well defined. Is that the distribution of the main object in all images? or the marginal \n\nIn section 5.1 why the range of p is set to 0.025 and 0.975. How was this range set?\n\n1 - A. Sauer and A. Geiger, Counterfactual Generative Networks, ICLR 2021.\n2 - Chen et al. Counterfactual Samples Synthesizing for Robust Visual Question Answering, CVPR 2020.",
            "summary_of_the_review": "This paper tackles a very interesting and important problem. However, as mentioned above, some comparison and discussion on the relation with other papers are needed. In addition, I would have liked to see the formalisation of the approach in the sense that how the confounders that contribute to the correlations could be mitigated using the proposed approach. The would certainly help with both justification and clarity of the paper.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "No ethics concerns",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper considers addressing the spurious patterns in the image classification problem. They proposed the Spurious Pattern Identification and REpair (SPIRE) method that detects and fixes the spurious component in the prediction models. Their method is shown empirically promising and valid. My main concerns lie in their method, novelty compared with existing literature, and comparison studies.",
            "main_review": "**Strengths**\n\n1. This paper addressed an interesting and important question in Machine Learning, i.e., how to address the spurious patterns to improve the model prediction. \n\n2. Their proposed SPIRE method was shown to be valid and promising empirically.\n\n**Weaknesses**\n\n1. Since the authors address the spurious patterns as defined in a counterfactual sense, I was expecting that the authors could use a more rigorous framework under causal inference to detect the 'true' spurious effects. Please find the definitions and framework in [1] and [2], related works in [3] and [4], as well as a very recent overview (though is for NLP) in [5] that summarized all the current methods on handling the spurious effect as follows.\n\n[1] Simon, Herbert A. \"Spurious correlation: A causal interpretation.\" Journal of the American Statistical Association 49.267 (1954): 467-479.\n\n[2] Bareinboim, Elias, and Judea Pearl. \"Causal inference and the data-fusion problem.\" Proceedings of the National Academy of Sciences 113.27 (2016): 7345-7352.\n\n[3] Zhang, Junzhe, and Elias Bareinboim. \"Fairness in decision-making—the causal explanation formula.\" Thirty-Second AAAI Conference on Artificial Intelligence. 2018.\n\n[4] Srivastava, Megha, Tatsunori Hashimoto, and Percy Liang. \"Robustness to spurious correlations via human annotations.\" International Conference on Machine Learning. PMLR, 2020. \n\n[5] Feder, Amir, et al. \"Causal inference in natural language processing: Estimation, prediction, interpretation and beyond.\" arXiv preprint arXiv:2109.00725 (2021).\n\n2. The authors claimed an end-to-end pipeline for identifying and mitigating spurious patterns for image classifiers, while based on my understanding, it requires human knowledge to recognize the possible spurious patterns, such as a person. Can the model also handle other types of images without a person?\n\n3. If I didn't miss anything, none of the baseline methods in the comparison studies handle the spurious effects. For a fair comparison, the authors should show their better performance against the current machine learning method for fixing spurious patterns such as [6] and [7] cited in the current paper.\n\n[6] Vedika Agarwal, Rakshith Shetty, and Mario Fritz. Towards causal vqa: Revealing and reducing spurious correlations by invariant and covariant semantic editing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9690–9698, 2020.\n\n[7] Yining Chen, Colin Wei, Ananya Kumar, and Tengyu Ma. Self-training avoids using spurious features under domain shift. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 21061–21071. Curran Asso- ciates, Inc., 2020b.",
            "summary_of_the_review": "I think this paper addressed an important question with reasonably good performance while lacking necessary elaboration and justification on their novelty and performance. As commented in my 'Main Review', my major concerns to recommend this paper lie in their method, novelty compared with existing literature, and comparison studies.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "In this paper, the authors propose a simple mechanism for identifying spurious patterns in training data, and subsequently propose an augmentation method that suppresses such patters via occlusion. For example, if the prediction accuracy for forks is much better when a knife is in the image as well, than when the fork is by itself, then this can be deemed a spurious correlation and occlusion can be used to alleviate it to some extent. The authors also show how the proposed method can improve certain “gap” or lift metrics on some datasets.",
            "main_review": "Mitigating unintended reliance on spurious correlation is a pertinent problem, that has received ample attention. For example, Geirhos et al. 2018 [1] find that CNNs tend to overuse texture information, and propose mitigation schemes via style-based augmentations. In that respect, the current paper shares similarities to these other works. The observation made is fairly straightforward and seem to work in some cases. However, I had several concerns:\n\n1. Even though the idea is simple, the few places details could have been useful are left to the reader, like the equations embedded in setting 2 on page 5. What’s this \\delta? Where exactly do these equations come from? What assumptions were made? How justified are those assumptions?\n\n2. The central contribution is interesting but quite minor, boiling down to identifying pairs of classes where presence of one boosts the other and then selectively removing them. This amounts to running inference, and checking the different data splits.\n\n3. There is no accounting for cases when the correlation is not spurious, and it makes sense to have them in the data as a closer expectation in naturalistic images. While “forks” and “knives” should be individually identifiable, the correlation makes sense and forcing to remove it might actually hurt the task performance. This is evident in some experiments when the performance suffers with the proposed scheme (e.g. Table 3).\n\n4. The presentation of results as %\\Delta is somewhat misleading. For example, looking at Fig. 3 (Left), the “hallucination gap” is 0.5% in absolute terms (100-99.5) which amounts to about 300 images (0.5% of 60,000) labeled as tennis racket even when there wasn’t one. Table 3 shows the technique reduces this gap by 28% (on average), which means now it’s 0.72*0.5% = 0.36% or 216 images. The improvement is thus 84 images out of 60,000 in the Just Spurious set (and overall ~100k images). The observations are equally unconvincing for “recall gap” since there are only 33 images in that split to begin with and even a perfect oracle can only achieve minor improvements.\n\n5. In the mitigation section on Page 4, the equation P(Spurious | Main) = P(Spurious | not Main) = 0.5 is wrong. Why is the RHS 0.5? A simple computation (P(S) = P(S|M)*P(M) + P(S|~M)P(~M)) will yield P(S) = 0.5 which doesn’t make sense. Why do we expect half the images to contain the spurious artifact?\n\n[1] Geirhos, Robert, et al. \"ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness.\" arXiv preprint arXiv:1811.12231 (2018).",
            "summary_of_the_review": "Overall, while the paper considers an interesting enough problem, the ideas are not well-developed, and the applications are unmotivated. There is no attempt to define what the spurious patterns might be, why some of them might be harmful and what goals might benefit from such augmentation. I am not inclined for this paper to be accepted.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper aims to find and mitigate the spurious correlations in the image classification task. The proposed approach find the pattern that causes different predictions on the original and a changed version of the image. It also proposes to mitigate the spurious correlation by retraining on the new purified dataset.\n\n",
            "main_review": "Strengths:\n1. The idea to find spurious correlation in image data is interesting. \n\n2. The writing is clear.\n\nWeakness:\n1. The identification can be wrong. The heuristic to find spurious correlation is by removing parts of the image to create a \"counterfactual\", if the prediction is different from the original version of the image, then the removed part is spurious. However, this method cannot distinguish causal parts and spurious parts. By removing the racket from the image will also make the new image to be different from the original image (if the original model uses the right racket to make the prediction). The proposed approach is fundamentally flawed.\n\n2. The benchmark is not a standard one. For example, [1] evaluates the spurious effect of the backgrounds in image classification. [2] studies the image data with contexts. The work should also include results on those.\n\n[1] Noise or Signal: The Role of Image Backgrounds in Object Recognition.\n[2] http://nico.thumedialab.com/",
            "summary_of_the_review": "The method is fundamentally flawed, and the evaluation is not standard.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "1: strong reject",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}