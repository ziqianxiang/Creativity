{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes a new adversarial training with the help of an auxiliary dataset. In order to avoid the negative transfer, the method also uses a confidence-based selection strategy. The method outperforms the baselines in this paper.  ",
            "main_review": "Strength\n+ The paper is easy to read and understand. The paper leverages an auxiliary dataset to increase the robustness. \n+ The paper proposes a confidence-based selection strategy to avoid negative transfer caused by domain discrepancy.\n\nWeakness\n- The main contribution is in the confidence-based selection but it does not seem to be very novel, which is just incremental to the existing adversarial training.\n- It is not fully convinced how the random labels can prevent negative transfer between domains. \n- The experiments are done only on small-scale datasets.",
            "summary_of_the_review": "The major concern is that there is not enough novel or technical contributions for the ICLR acceptance bar.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed a multi-domain adversarial training method called BiaMAT, which leverages auxiliary datasets instead of in-distribution datasets for improving the adversarial robustness for classification tasks on primary datasets. This work combines robust feature transfer and consistency transfer. It also avoids negative transfer of distributional discrepancy between auxiliary and primary data using a confidence-based selection strategy.",
            "main_review": "The paper is well written and looks technically sound. The proofs appear to be correct (although I was not able to verify them in precise detail). Overall, I have two main concerns for this paper.\n\n1)\tLack of novelty: \n\nThis work is very close to the work by Lee et. Al. 2021 which uses out-of-distribution (OOD) data augmentation for model generalization for both adversarial and standard training. Both studies used similar techniques to use auxiliary datasets for adversarial training. Even the notations, datasets, setups, and experiments are very close. Therefore, the contribution of this work looks incremental and not unique.\n\n2)\tLimited experiments:\n \nMore experiments are required to show the effectiveness of the proposed method. The authors are expected to compare the proposed method with more recent existing work (such as Lee et al. 2021, etc) on both in-distribution and out-distribution datasets. Currently the results are only compared with two papers published in 2019 and based on table 3 and 7, only CIFAR datasets are used for the comparison. Also it would be great if more diverse datasets used for these experiments to demonstrate how the model works when the auxiliary datasets have very different distribution compared to the primary dataset (what is the effect of negative transfer in such cases)\n\nOther comments:\n-\tMore related work and discussion on adversarial training, multi-domain adversarial training, and out-of-distribution (OOD) data training is required. ",
            "summary_of_the_review": "The topic is interesting and the paper is technically right. However, the proposed idea of using auxiliary datasets for adversarial training is not novel. Also the experiments were insufficiently convincing and could be more thorough. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "To improve the robustness of adversarial training on the primary classification task, this paper focuses on exploiting auxiliary datasets via a multi-domain learning framework. The main motivation is to treat various labelled datasets as auxiliary ones, although they may have distribution discrepancies as compared with the original dataset. Technically, this paper provides a novel confidence-based selection strategy to deal with the negative effect of domain discrepancy.\n\nOverall, to capture effective extra data, semi-supervised methods can only generate virtual labels for in-distributional data via a pre-trained model. This limits their applications on out-distributional data. Compared to previous semi-supervised methods, the main difference is that the authors use a pre-trained model to conduct sample selection for labelled datasets. As claimed by the authors, this can discard some negative samples to alleviate the negative transfer of extra datasets. ",
            "main_review": "Strength\n1) This paper proposes a novel sample selection strategy for existing datasets, which can select positive auxiliary data with the pre-trained teacher model. Under the multi-domain learning framework, the experimental results demonstrate some improvements than previous methods such as normal AT and Trades.\n2) This paper provides rich experimental results and analysis, which are beneficial for future studies. Besides, it contains one assumption and one theoretical proof for the key confidence-based selection. But I cannot confirm its validity.\n\nWeaknesses\n1) An intuitional toy exhibition may help readers to understand the proposed method. I found it is a bit difficult to follow the overall manuscript. One visualization such as the image of high-level feature maps may provide better insights into the proposed method.\n\n2) For experiments: \nOverall, the experiment setting gives the customized setting. However, I still have some minor concerns. \n\nIt might be not suitable to conduct one comparison with [Hendrycks et al. (2019a)] under the extra out-distributional setting (CIFAR-100, Places365, ImageNet, ImageNet-500k), because the extra out-distributional data are adverse to the unlabeled method. \n\nI cannot find the data augmentation settings (such as dropout and random cropping) in Appendix I (Implementation details) or other sections. One simple data augmentation is very effective for adversarial robustness according to [Bag of tricks for adversarial training. In ICLR, 2021]. They maybe override the potential promotion of the proposed method, such as one simple Dropout setting can improve about 4% robustness with WRN-40 on CIFIAR-10 in [A closer look at accuracy vs. robustness Yang et al., (2020)]. Therefore, more details may be better to present this work. \n\nAn open discussion\n\nGenerally speaking, multi-domain learning is usually appropriate to deal with the situation where different intra-class samples present cross-domain appearances, such as face recognition in cross-spectral scenarios (e.g. faces are from Near-infrared and visible domain). Here, one key constrain is that different samples belong to the same class although they belong to different domain distributions. The same identity can provide one limitation to cross-domain samples so that they can be mapped into a common subspace.  \n\nIn this paper, the proposed BiaMAT adapts a multi-domain learning framework, However, 1) it seems that there is not a constrain to ensure Assumption 1 (A common robust and non-robust feature space exists between the distributions of primary and auxiliary data). 2) Empirically, according to the setting of the multi-domain network learning, the claimed extra data only expand the primary multi-class problem with more classes, such as the primary CIFAR-10 classification is expanded with the extra data from CIFAR-100 into 110 classes. So It is difficult to understand the source assumption and improvement interpretation of the proposed method. \n\nFurther, if this assumption is not suitable for additional out-distributional learning, whether the improvements in the experimental section is actually derived from one data augmentation benefit of extra data, in which extra data can prevent the over-fitting problem by using the shared feature embedding module. ",
            "summary_of_the_review": "The focus of this manuscript is on how to use auxiliary data to boost the robustness of a deep model. This study further attempts to expand the scope of auxiliary data via an effective sample selection strategy. \n\nIn my opinion, it may be better to explore the fundamental reason for the trade-off problem between robustness and generalization rather than the design of a new training method to gain some moderate benefits from additional data. As we all know, adversarial training is time-consuming. The use of auxiliary data aggravates this awkward situation. It might be better to explore why the auxiliary data can help robustness learning and what we can learn from this. This is more helpful to understand the learning mechanism of an optimization-based model. \n\nConceptually, I cannot confirm the rationality of the radical assumption (Assumption 1). Therefore, the rationality of the method explanation is debatable. \n\nTechnically,  I think the confidence-based selection strategy is valid to select positive samples as auxiliary data. And the experiments do show some improvements. \n\nTherefore, I think the effect of the proposed selection strategy is effective. But this may not be derived from the initial narrative logic rather than one function of effective data augmentation. Because the extra data only extends the multi-domain learning framework into a new classification task with more classes.",
            "correctness": "3: Some of the paperâ€™s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}