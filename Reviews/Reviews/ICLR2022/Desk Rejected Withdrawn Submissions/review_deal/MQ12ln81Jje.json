{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper, the authors focus on increasing the depth of GNNs and maintaining the performance in the meanwhile. Starting with the DropEdge model, the authors propose an incremental improvement, which adds a certain ordering to reduce the randomness of dropping edge selections, called RankedDrop. Some experimental results show the superiority of RankedDrop over DropEdge. RankedDrop is straightforward and depends on existing technologies like PageRank, and the novelty and theoretical contribution of RankedDrop is limited. Moreover, the introduction of the proposed RankedDrop is ambiguous and the corresponding experiments are weak to some extent. For detailed improvements, please refer to the following sections.",
            "main_review": "Strengths: \n\nThe problem is important and interesting. In the real-world scenario, when increasing the depth of GNNs is indispensable for reducing the representation uncertainty, maintaining the performance at the same time is very necessary. \nBased on an existing model DropEdge, this paper proposes the RankedDrop to reduce the randomness during the edge selection for better performance. The RankedDrop is straight and seems to be easy to be realized.\nHowever, there are some unneglectable weaknesses are listed below.\n\nWeaknesses:\n\n(1) Limited Novelty and Technical Contribution. The authors claimed that they use the classic PageRank to compute scores for the node selection and basic random selection for the edge selection. The novelty and technical contribution of this paper are limited. To be more specific, the RankedDrop just gives the node selection with an ordering (computed by PageRank), the follow-up edge selection is still random. I may doubt the natural difference between DropEdge [2] with RankedDrop. Last year, several de-oversmoothing methods [1,3] are proposed and share the same intuition with the author, i.e., reduce the randomness during the dropping edge process.\n\n(2) Ambiguous Illustration. The introduction of this paper needs to be improved to a large extent. Some aspects are listed below. (i) For SWA, this part comes very suddenly. Currently, there is only one sentence describing the intuition of why using SWA, which is insufficient. Algorithm 1 is well-known, and the current context is enough. Therefore, the authors may want to emphasize more why SWA is indispensable, and what if only concern the original ranking of PageRank vectors. (ii) How do local information and global information collaborate? The authors claimed that the selection takes the global information of PageRank and the local information of node degrees. However, it seems only PageRank is used in the paper. Moreover, in Figure 1, how PageRank distribution of the whole graph is obtained? Is that aggregating the PageRank vector of every seed node? (iii) Some notation comes from nowhere, the authors may want to introduce them before using them, like S_i, SWA_s[n], and malus. (iv) Some details like, will the edges dropped in the last epoch will be added back for the next epoch? (v) some typos.\n\n(3) Weak Experiments. (i) From DropEdge, many attempts for deeper GNNs are proposed last year, and some of them share the same insight with RankedDrop, i.e., drop edges during the training process [1, 3]. And some use additional regularizers to realize deeper GNNs [2, 5]. Only setting one baseline is not adequate to show the superiority of RankedDrop. To be helpful, some baselines [1-5] are listed below, and all of them have the code available online. Baselines having similar intuitions [1, 3] should be compared at first. It would be good if other baselines could be compared to see the effectiveness of different intuitions.  (ii) Figure 2 and Figure 3 are not that convincing, vanilla GCN seems to have the competitive performance w.r.t training and validation loss. For example, in Figure 2, in Cora, GCN achieves less training loss and validation loss. Also in Pubmed of Figure 2, GCN seems to do the same as the DropEdge methods. The authors may want to increase the number of layers to see the variance of loss in a more grained way. (iii) The sampling of the number of layers is not sufficient, in the paper, the authors only consider 2, 4, and 8 layers. The authors may want to check the adequate sampling from the reference listed below. For example, in [2] 0-30 layers, in [3] 2-64 layers, in [4] 0-200 layers, and in [5] 0-30 layers. The author may want to increase the range and the granularity.\n\n[1] Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, Xu Sun: Measuring and Relieving the Over-Smoothing Problem for Graph Neural Networks from the Topological View. AAAI 2020\n\n[2] Lingxiao Zhao, Leman Akoglu: PairNorm: Tackling Oversmoothing in GNNs. ICLR 2020\n\n[3] Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, Yaliang Li: Simple and Deep Graph Convolutional Networks. ICML 2020\n\n[4] Meng Liu, Hongyang Gao, Shuiwang Ji: Towards Deeper Graph Neural Networks. KDD 2020\n\n[5] Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu: Towards Deeper Graph Neural Networks with Differentiable Group Normalization. NeurIPS 2020\n\n[6] Yimeng Min, Frederik Wenkel, Guy Wolf: Scattering GCN: Overcoming Oversmoothness in Graph Convolutional Networks. NeurIPS 2020\n\n[7] Kenta Oono, Taiji Suzuki: Optimization and Generalization Analysis of Transduction through Gradient Boosting and Application to Multi-scale Graph Neural Networks. NeurIPS 2020\n",
            "summary_of_the_review": "This paper is well-motivated, aiming to deal with over-fitting and over-smoothing deep GNN models. However, starting from DropEdge, just adding the ranking from PageRank limits the novelty and contribution of this paper. Moreover, some key parts of this paper are not clearly introduced, and the experiment is weak. To sum up, this paper is prone to be rejected.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors of this paper proposed RankedDrop, which is a followup work on DropEdge. Instead of the random edge dropping in DropEdge, RankedDrop uses global information from PageRank as well as local information from node degree to determine the edges to be dropped.",
            "main_review": "Pros:\n1. The problem of oversmoothing of GNNs is very important and worth studying, and the naive approach DropEdge does have a lot of space for improvements.\n2. This paper is overall clearly written and easy to follow.\n\nCons:\n1. This paper is missing the discussion of some very relavent papers. E.g., [1][2]\n2. I found the technical novalty of the proposed method quite marginal.\n3. In the experiments, the authors only compared with vanilla GNNs and DropEdge, while many highly correlated and more recent baselines on the exactly same problem exist. For example, NeuralSparse [1], GAugM [2], PTDNet [3].\n4. The experimental performances reported in Tables 2 and 3 showed marginal improvements, which are hard to compare without the confident intervals such as standard deviation. \n\n[1] Robust Graph Representation Learning via Neural Sparsification, ICML'20 \\\n[2] Data Augmentation for Graph Neural Networks, AAAI'21 \\\n[3] Learning to Drop: Robust Graph Neural Network via Topological Denoising, WSDM'21",
            "summary_of_the_review": "The idea is interesting. However, the contribution is marginal and experiments are very weak.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a method with a spatial-aware dropping-edge selection. The selection takes into\naccount the graph global information using PageRank, and graph local neighborhood information with node degree.",
            "main_review": "## Strengths\n\nThe authors' method obtain better performance compared with the baselines on full-supervised node classification tasks.\n\n## Weakness\n\n- The evaluated datasets are 'Cora, Citeseer, PubMed', more evaluation on other datasets could be better.\n- The reason that the proposed method can tackle the over smoothing and overfitting problem is not clear to me.\n- There seems to be no result of semi-supervised learning, although the author mentioned related experiments in section 3.5.1.",
            "summary_of_the_review": "The work is mainly to improve the existing work of DropEdge. The novelty, contribution, and experiments are limited.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes a novel edge-dropping method: RankedDrop to enhance the robustness of the training process for Graph Neural Networks.  ",
            "main_review": "`RankedDrop` uses the PageRank to calculate the score of each node and employs the SWA algorithm to make the node selection process during training.  Overall, this paper is well organized and easy to follow.\n\n## Weakness\nThe technical contribution is limited. Overall, `RankedDrop`  combines two existing techniques to perform edge sampling of GNNs. There is no theoretical analysis about how ` RankedDrop ` can alleviate the over-smoothing or why it can surpass the other sampling methods. Therefore, this combination seems trivial. The technical contribution is limited.\n\nThis paper only conducts the experiments on three small datasets which are weak for the modern GNN evaluations [1]. It’s better to evaluate the performance on more challenging datasets. \nMeanwhile, The authors only apply `RankedDrop`  to one GNN backbone: Graph Convolutional Networks. It is insufficient to validate the effectiveness of `RankedDrop` on a single backbone.\n\nThere are some small typos & mistakes in Algorithm 2.  \n\n[1] Pitfalls of Graph Neural Network Evaluation\n",
            "summary_of_the_review": "Overall, this paper needs to be improved from both the theoretical and experimental perspectives. I vote to reject this paper.  ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}