{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "In this paper, the authors propose a cluster-based personalized federated learning scheme. More formally, each user is assumed to have a local model $\\theta_i$, and these local models are regularized around a number of generalized models $\\\\{w_k\\\\}_{k=1}^K$. These generalized models are also determined by solving a $K$-means clustering problem with respect to the local models. In other words, the proposed framework solves a mixture of local and global models, similar to (Hanzely & Richtarik, 2020) or (Li et al., 2021), with the difference that the local models are regularized around solutions of a $k$-means clustering problem which is solved in parallel. \n\nthe authors provide convergence guarantees and generalization bounds as well as numerical experiments to justify their algorithm from both numerical and theoretical point of view. ",
            "main_review": "I find the idea of the paper interesting and intuitive. However, my main concern is that I cannot fully follow the derivations, mainly due to the inconsistency in the notation. For instance, the function $G$ is introduced to be a function of all models on page 3. But then, I cannot fully follow the notation in Algorithm 1 description, as $G$ seems to have only one generalized model as input. Moreover, in Assumption 2, what is $G_i$ and what is $G_k$? It seems that $G_i$ has something to do with local models, and $G_k$ corresponds to the generalized models, but I am not sure about it. \n\nSimilarly, I am not sure if I understand $\\Omega_I$ and $\\Omega_K$, defined at the beginning of Section 4. Could you explain them in more detail? It might also be helpful to use different notations (currently, they both use $w_i$).\n\nOn a different note, on page 6, the authors claim that Assumption 3 holds as the models are normalized during the training. Note that this could be misleading as normalizing the model will lead to a different algorithm with potentially different convergence properties. In other words, you need to either show the models remain bounded or consider projection/normalization in the analysis. \n\nMinor comments:\n- $P^t \\in \\mathbb{R}^{N \\times K}$ instead of $P^t \\in \\mathbb{R}^{K \\times N}$ in page 4.",
            "summary_of_the_review": "Overall, I find the idea behind the proposed formulation promising, but I haven't been able to parse the algorithm and the theoretical derivations fully. I have listed my main concerns above, and I am open to raising my score if the authors clarify the theoretical section and algorithm description. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a new method by combining clustered FL and personalised FL together. In particular, it simultaneously learns multiple global models by aggregating similar clients within the same cluster, and then conducts personalised modelling for each client. ",
            "main_review": "Strengths:\n\n1. It is an interesting idea and novel method to do a cluster-enhanced PFL.\n2. The proposed method is technique soundness. The detailed convergence rate and generalization error are derived, which is a plus.\nThis paper is well written.\n\n\nWeaknesses:\n\n1. Treating each client model as private data is useless.\n2. If we simply add a fine-tuning step into the existing clustered FL, they should also work well.\n3. The experiments should be enhanced by choosing more personalised FL settings and clustered FL baselines. \n\n\nQuestions and suggestions:\n\n1. In Algorithm 1, the variables of R and S are not defined. Moreover, in lines 5 and 10, the use of G(.) is inconsistent. The first G uses two matrices as inputs, and the second G uses model parameters w as input. \n\n2. Why do you choose K-means++ rather than K-means? According to Eq.2, the K-means should be the right one to solve the proposed objective function.\n\n3. The proposed algorithm treats each personalised model as private data, and then updates the generalised model on local clients. However, it seems useless. As stated in Algorithm 1, if the server received the updated generalised model, then it could easily infer the gradient of G(w) which is an L2 distance between the personalised model and the previous generalised model. After that, the server can infer the gradients of the personalised local model /theta. Therefore, the intention of treating personalised models as private data is not achieved. \n\n4. The global iteration is considered a discrete-time Markov chain. However, the transition matrix Q^t is not a static matrix. How does the Markov chain handle this dynamic transition matrix? Has these dynamics been analysed in any part of the paper?\n\n5. The baseline of FedAvg could be enhanced by incorporating a fine-tuning step to implement personalisation. For example, the paper below has discussed fine-tuning in FL.\n\nhttps://arxiv.org/abs/2108.07313\n\n6. As shown in Table 1, the CGPFL has no substantial improvement in comparison with IFCA - a clustered FL method. How about implementing an IFCA with personalised components that simply use IFCA’s final global models to conduct one-step fine-tuning at each corresponding client. Moreover, there are more clustered FL methods that are worth to be compared with.\n\nhttps://arxiv.org/abs/2002.10619 \n\nhttps://arxiv.org/abs/2004.11791 \n\nhttps://arxiv.org/abs/2108.08647\n\nhttps://arxiv.org/abs/2108.09749 \n\n \n7. In Fig 3, the optimal K is 12. However, the number of clients is 40. Can you please show the number of clients for each cluster, and then visualise the clusters in a 2D chart? \n\n8. In Table 2, what if the hyper-parameter lambda varies exponentially?\n\n9. Typos: \ngeneralizaation (first paragraph in Page 2)\nthe dimension of P^t should be N*K.\n",
            "summary_of_the_review": "This paper proposes an interesting method to do cluster-enhanced PFL. However, the experiment is not sufficient to support its claims, and there are some details that need to discussed.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper proposes CGPFL, a  cluster generalization framework to enhance better personalization. Existing personalized learning algorithms aim at finding a good enough global model that allows all clients to fine tune. This paper proposes to train K global models to allow for statistical diversity. The paper studies analytically the algorithm, and shows empirical performance. ",
            "main_review": "The paper addresses an interesting problem of improving FL by localized personalization through clustering. There is an analysis of convergence and a generalization bound. \n\nThe paper has a strong evaluation section against different popular and SoTA algorithms.\n\nWeaknesses: \n\n- The novelty of the work is misleading. The proposed idea is very similar to HypCluster, introduced by [MMRS20]. HypCluster also clusters users to allow for several global models. Then, in their experimental section, authors combine it with finetuning (this is missing in the related work, that suggest there is no personalization at all in this work). Further, similar regularization techniques are proposed by [SCST18]. \n- Notation changes completely  in section 4.3. making really hard to understand the statements. The notation starts with classic FL notation but then switches to the notation used in [MMRS20].\n- It is not clear how to extend this framework to a large number of users. Matrices become too large when N is in the order of millions. The authors could discuss how the algorithm can be adapted to work in practical settings. \n- It is claimed that CGPFL-Heur is intended to avoid tuning the hyperparameter K, but it seems to me that now one has to tune $\\mu$. \n- In the experimental side, it would be interesting to see the performance of the algorithm in more naturally federated datasets, like a Stackoverflow, or even EMNIST. \n\n\n\n[SCST18] Smith, V., Chiang, C. K., Sanjabi, M., & Talwalkar, A. (2017). Federated multi-task learning. arXiv preprint arXiv:1705.10467.\n[MMRS20] Mansour, Y., Mohri, M., Ro, J., & Suresh, A. T. (2020). Three approaches for personalization with applications to federated learning. arXiv preprint arXiv:2002.10619.\n",
            "summary_of_the_review": "In its current states, this paper studies an interesting problem in the field but it still needs to clearly state how this work is novel compared to existing clustering work in FL. Further several sections have to be clarified and notation has to be unified. Experiments are good but could be more representative of realistic FL settings. \n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper wants to introduce a new personalization approach for federated learning based on the clustering of clients. The clustering is being done on the model parameters space to categorize similar models together. They formulate this problem as a bilevel optimization and add a regularization term similar to pFedMe algorithm for the sake of personalization.  Using the clustering, they show that convergence rate can have $\\sqrt{K}$ speedup over non-clustered federated learning. Through several experimental results, mostly compared with pFedMe algorithm they show improvement on different datasets.",
            "main_review": "The main concern for the proposal of CGPFL, similar to the pFedMe is that adding the regularization term of $\\ell_2$ distance to the global model or the cluster center does not seem to be the goal of personalization. This regularization term, similar to FedProx [A] or to some extent SCAFFOLD [B] intends to keep the local model close to the global model and acts as a variance reduction step. This seems to be effective for general federated learning algorithms, however, it has the opposite goal of personalization, since it does not consider the local optimal of each client. However, this is less of an issue here since the cluster center are better utilized for each cluster data distribution. Hence, I expect to see more comparison with other PFL methods than pFedMe to have a better comparison. \n\nIn addition, they provide a generalization bound, however, they do not mention two other prior work in this domain [C] and [D], which provide extensive generalization analysis of their personalization approaches. There is no comparison with them in this regard and how they are improving their generalization bound.\n\nMoreover, in the convergence analysis, they are claiming that they can achieve $\\sqrt{K}$ speedup over other methods. This is the vanishing term in the convergence rate. However, from the experimental results in Figure 1, it seems that there is a gap between the non vanishing bias term in the convergence of CGPFL and pFedMe.  Is this validated by the theory as well? From the convergence analysis of pFedMe, this seems to be the case, but is this the case for other PFL methods? That is another reason, I think the experimental results should contain other PFL methods as well.\n\nAlso, there are some discrepancy on the results of for some methods mentioned in this paper and their reported numbers. For instance for APFL[C], for the logistic regression on MNIST with 2 classes per client (they have 100 client, which is harder than 40 clients in CGPFL), and they are getting about 97.5% accuracy on personalized models on validation data, while you report 92.69%. Also, for the CIFAR10 on CNN models, they report 89.33%, which is way different from what is reported here. This discrepancy should be addressed.\n\n\n[A] Li, Tian, et al. \"Federated optimization in heterogeneous networks.\" arXiv preprint arXiv:1812.06127 (2018).\n\n[B] Karimireddy, Sai Praneeth, et al. \"SCAFFOLD: Stochastic Controlled Averaging for On-Device Federated Learning.\" (2019).\n\n[C] Deng, Yuyang, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. \"Adaptive personalized federated learning.\" arXiv preprint arXiv:2003.13461 (2020).\n\n[D] Mansour, Yishay, et al. \"Three approaches for personalization with applications to federated learning.\" arXiv preprint arXiv:2002.10619 (2020).\n",
            "summary_of_the_review": "The proposed CGPFL seems to be an interesting proposal for federated learning. However, there are some issues regarding the personalization goal and comparison with SOTA that needs to be addressed.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}