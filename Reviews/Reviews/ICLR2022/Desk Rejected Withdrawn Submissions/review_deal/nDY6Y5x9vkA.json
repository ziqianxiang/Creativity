{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This work aims to design a patch generation strategy for image attacks which place the patch on the original image to fool the well-trained image classifier, and the patch generation process has no access to the dataset used to train image classifier. To solve the data-free problem, this work advances the existing method EoT [1] with two additional steps. One is to select the proxy dataset with high average patch saliency. Another is to conduct multiple-time patch update.",
            "main_review": "This work aims to design a patch generation strategy for image attacks which place the patch on the original image to fool the well-trained image classifier, and the patch generation process has no access to the dataset used to train image classifier. To solve the data-free problem, this work advances the existing method EoT [1] with two additional steps. One is to select the proxy dataset with high average patch saliency. Another is to conduct multiple-time patch update.\n\nHowever, I still have several concerns about the current version:\n1. There are so many abbreviations of the definitions. It is difficult for readers to directly get the point. It would be better to list these abbreviations in one Table for reference. Moreover, there are some minor grammatical errors to be revised.\n2. In the main content, this paper does not explicitly formulate the data-free adversarial patch generation problem. And I am confused about the definition of symbols such as “an input image $X \\in R^{d}$”. From the experiments, the image should be $X \\in R^{C\\times H\\times W}$.\n3. For the method, I am not clear why the selected dataset with the defined average patch saliency can guarantee patches’ fooling abilities for the unseen training dataset, and how to train the integrated gradient function in the patch saliency calculation. In addition, when comparing with EoT [1], updating the patch with multiple times is not significant difference.\n4.\tFor the experiment, the current version only compares it with EoT [1]. It is difficult to reflect the effectiveness of the proposed method. It would be better to compare it with more baselines.\n\n[1] Anish Athalye, Logan Engstrom, Andrew Ilyas, and Kevin Kwok. Synthesizing robust adversarial examples. In International conference on machine learning (ICML), 2018.\n",
            "summary_of_the_review": "There are some unclear parts in the current version (See the main review).",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper focuses on generating adversarial patches under the data-free scenario. Specifically, this paper proposes a two-stage pipeline: (1) select proxy dataset using patch saliency as a metric; (2) a novel adversarial patch generation method which not only updates the patch but also updates the image background during the generation procedure. The experiments show that the proposed method achieves better results than the baseline method.",
            "main_review": "The strengths: \n\n(1) the proposed method looks reasonable to me, so the results are reasonably good.\n\n(2) the problem, data-free adversarial patch generation, is interesting\n\nThe weaknesses:\n\n(1) The main concern is the paper writing issues. I spent a lot of time understanding this paper but still cannot guarantee my understanding is correct. I think one of the difficulties to understand this paper is because there are too many rare abbreviations, such as APG, APS, EoT, DF-EoT, TFR, UFR, PDS,  PG, etc. Although the readers could go back to find the definition of them, these abbreviations still make it difficult to read this paper smoothly.\n\n(2) Although the performance improved according to Table 2, it is still not clear if the proposed method leads to a larger computational cost -- it seems the proposed method is more complex than the baseline method.\n\n(3) If my understanding is correct, Section 3.3 is evaluating the proxy dataset selection stage while Section 3.4 is evaluating the adversarial patch generation stage. However, I don't find the final performance comparison between the baseline method and the full version of the proposed method (ie, proxy selection stage + patch generation stage)",
            "summary_of_the_review": "I like the topic of this paper. However, due to the weakness mentioned above, I think this paper is still improvable before publishing. Specifically, the writing does not meet the ICLR bar.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "Yes, Other reasons (please specify below)"
            ],
            "details_of_ethics_concerns": "I am not sure if Section 5 Acknowledge is appropriate during the peer-review stage.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper mainly studies the generation of adversarial patch in data-free scenarios with higher requirements on data privacy. In this two-stage framework, it first uses proxy dataset selection (PDS) method to calculate the average patch saliency (APS) of each available dataset, and then used patch generation (PG) method which applies the designed data-free Expectation over Transformation (DFEoT) based on the determined proxy dataset for patch generation.",
            "main_review": "Pros: \n1. From the perspective of significance, it is meaningful to study data-free scenarios of this paper, because deep learning models in real life often set a high protection level for data privacy in actual deployment.\n2. From the perspective of technical details, it is reasonable and intuitive to split the patch generation in the data-free scenario into the selection of the proxy data set and the subsequent patch generation.\n3. As for the calculation and application of patch saliency metric and its average version, the overall theoretical derivation is relatively rigorous. In addition, the author also considers the sensitivity of the initial value when the patch is generated, and the overall logic is relatively complete.\n\nAfter reading the paper I have some concerns as follow:\n1. The important value of the adversarial patch is its effectiveness on attacks in the physical environment. Although the calculation method in this paper is based on EOT, I think it is still necessary to verify the validity of the generated patches in real physical environment.\n2. Although the two-stage design is intuitive, is there some strong coupling between the selection of data sets and the generation of patches? If so, will the phased optimization not give full play to the interaction between the two factors to some extent? Of course, this is just my thinking. If there was a way to optimize both simultaneously rather than sequentially, would the attack result be better?\n",
            "summary_of_the_review": "In summary, this paper is meaningful. But the concerns should be addressed. ",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "Yes, Privacy, security and safety"
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}