{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "The paper propose a simple method for safe multi-task learning where there is no negative transfer or \"negative sharing\" among tasks. It jointly trains shared encoder, task-specific (private) encoders, gate, and decoder. The gate computes importance for each output of shared and task specific encoder and combine the outputs with simple convex combination. ",
            "main_review": "## Pros\n- The proposed method is simple and effective. It shows improvement of generalization performance on four benchmark datasets.\n- The authors provided generalization bound for the proposed method.\n\n## Cons\n- The proposed method is required to increase the number of parameters since it needs private encoder for each task and gate as well as the shared encoder. It consumes more memory and computation during training and test time. Although the authors propose light version of the model to save memory cost for test time, it cannot reduce extra computational cost during training. \n\n- As far as I understand the provided generalization bound (Theorem 1), I think there is a discrepancy between Theorem 1 and the experiments. Deep neural networks without any constraints are not usually Lipschitz continuous [1] but there is no constraint to enforce such Lipschitz continuity in model architecture or training procedure. Moreover the theorem assumes the loss to be bounded between 0 and 1, but it is not realistic assumption in practice. If I misunderstood anything, please correct me.\n\n- The proposed method is general but the experimental setup is too limited in that it focuses on three vision tasks and do not compare with other MTL baselines which tackles negative transfer such as [2,3,4]. I want to see some experimental results other than vision tasks.\n\n## Questions\n- Is $\\alpha_t$ is free variable which is not dependent on any input $x_t$?\n\n- Is improvement compared to baselines significant? Since I am not expert in vision domain, I am not sure it is meaningful improvement or not.\n\n[1] Scaman, Kevin, and Aladin Virmaux. \"Lipschitz regularity of deep neural networks: analysis and efficient estimation.\" Proceedings of the 32nd International Conference on Neural Information Processing Systems. 2018.\n\n[2] Pilault, Jonathan, and Christopher Pal. \"Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data.\" International Conference on Learning Representations. 2020.\n\n[3] Yu, Tianhe, et al. \"Gradient Surgery for Multi-Task Learning.\" Advances in Neural Information Processing Systems 33 (2020).\n\n[4] Wang, Zirui, et al. \"Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models.\" International Conference on Learning Representations. 2020.",
            "summary_of_the_review": "Overall, the proposed method is simple and effective, but it requires more computational cost. Moreover I am not sure the proposed method is validated thoroughly enough. Please address my concerns.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper presents a multi-task learning approach that avoids negative sharing in training deep neural networks.  A novel network architecture is proposed, which consists of a public encoder shared by all the tasks, private encoder for each task, and a gate for each task to combine encoded features from public and private encoders. Their experiment results indicate the proposed approach is effective on image recognition related tasks.",
            "main_review": "Strengths:\nA theoretic analysis on generalization bound is presented.\n\nExperiment results demonstrate that the proposed method can achieve their notion of safe (i.e., avoiding negative transferring) on learning problems used in their evaluation.\n\nWeakness:\nLike cross-stitching, an intrinsic limit of the proposed method is its limited scalability, N+1 separate networks that are in full scale need to be trained, where N is the number of tasks. \n\nThe proposed architecture lacks the flexibility to effectively handle learning problems where tasks share within multiple subgroups. In such a scenario, the shared network will be likely dominated by the largest subgroup and the sharing among tasks in smaller subgroups would not be effectively learned and utilized. \n\nIt is not clear to me why the method can be guaranteed “safe”. Even though private network was trained for each individual task, these networks were joined trained, so it is expected one could have impact on the other. I think this is the similar issue as in cross-stitching. More discussion is needed here. \n\nRouting based approaches, such as Rosenbaum et. al., ICLR, 2018, Bragman et. al., ICCV, 2019, and Strezoski et. al., ICCV, 2019 are closely related. They should be discussed and properly compared in their empirical evaluation. Also, including learning tasks from other domains besides computer vision could make the study more convincing.  \n",
            "summary_of_the_review": "The proposed approach is straight forward, the technique innovation is rather limited. Even though the reported results seem good, the method has limits, such as lack of scalability and ineffectiveness in handling multiple subgroups of tasks. More empirical study is desired. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper focuses on the negative sharing problem in multi-task learning, which has not been studied sufficiently in existing work. The authors propose the Safe Multi-Task Learning (SMTL) model and several of its variants to avoid negative sharing and achieve safe multi-task learning. Both theoretical analysis and comprehensive experimental results are provided to demonstrate the effectiveness of the proposed method.",
            "main_review": "Strengths:\n1) The authors try to solve the problem of negative transfer in multi-task learning, which is an interesting and meaningful topic.\n2) Theoretical analysis and experimental results on four benchmark datasets are provided to demonstrate the effectiveness of the proposed method.\nWeaknesses:\n1) Essentially, the proposed SMTL is a special case of an existing work (PS-MCNN [1]). PS-MCNN degenerates into SMTL after two steps of modification: 1) remove the interactions between SNet and TSNets in shallow layers, and 2) remove the deep layers of SNet. Therefore, the novelty of this work is marginal. The authors should compare SMTL with the more general PS-MCNN and demonstrate the superiority of SMTL both theoretically and experimentally. \n2) Clearly there is a benefit in the quantitative metrics across various datasets. However, in order to prove the better performance of SMTL is not from an increase in the number of parameters, there should be some discussion about the number of parameters added to the single task networks.\n3) Key parameters such as the initial value of αt should be varied and further analyzed.\n4) The authors should discuss about how much computation or memory can be actually saved by replacing SMTL with L-SMTL on each dataset.\n\n[1] J. Cao, Y. Li and Z. Zhang, \"Partially Shared Multi-task Convolutional Neural Network with Local Constraint for Face Attribute Learning,\" 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018, pp. 4290-4299, doi: 10.1109/CVPR.2018.00451.",
            "summary_of_the_review": "This paper studied an interesting topic: safe multi-task learning. However, the novelty of the proposed method is marginal, and issues such as the number of parameters increased, initial value of αt, and actual computation/memory saved by L-SMTL need to be further discussed.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper aims to solve the negative sharing problem, which is defined as that a multi-task learning model has inferior performance than single-task learning on some tasks, for multi-task learning. To address negative sharing, Safe Multi-Task Learning (SMTL) model is proposed. The model combines hard-sharing model and single-task learning together and is expected to achieve performance that not inferior than single-task learning.\n",
            "main_review": "Strengths:\n1. The negative sharing problem is interesting.\n\n2. The paper is well written.\n\nWeaknesses:\n1. The generalization bound proposed in this paper is same with that proposed in [1]. The only difference is that this paper replaces the hypothesis class. Furthermore, the proof is same as well. However, the hypothesis class of this paper is much larger than that in [1]. Based on the basic property of Gaussian complexity, the generalization bound of this paper is much loose than that in [1]. Then, there is a problem: why SMTL can have proper generalization performance when the generalization bound for SMTL is much looser that for hard-sharing MTL. The authors should give more theoretical analysis.\n\n2. SMTL’s model size is grow linearly with the number of tasks. It is not computational affordable when the number of tasks is large. \n\n3. SMTL requires much extra storage cost; however, its performance improvement is quite marginal. \n\n4. For the bi-level formulation of the SMTL, the analysis providing by this paper is puzzling. In the bi-level formulation, a part of training data is used to do validation; thus, the number of training samples reduces. With less training data, bi-level formulation can achieve comparable performance with the original SMTL. It verifies that the tune the hyperparameters on a validation set is necessary? Why bi-level formulation can achieve comparable performance with less training samples?\n\n5. In this paper, relevant/irrelevant are mentioned many times and regarded as a key factor that matters the performance of MTL. However, there is no serious definition for them. How to define the relevant/irrelevant. Why negative sharing occurs when some tasks are totally or partially irrelevant to other tasks? Although it is difficult to formally explain it, the authors should give some example or citations to illustrate it.\n",
            "summary_of_the_review": "The theoretical and technical contributions cannot reach the average level of ICLR. I stand for reject.\n",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This paper tackles the negative transfer effect in multi-task learning problems. For this, the authors propose to use a gate to combine the shared and private encoders to address the problem.\n\n ",
            "main_review": "The paper is fairly well-written, clearly motivated, and seems to be technically correct. The comparisons are shown on four benchmark datasets.\n\nMy main concerns with this paper are novelty and comparison/discussion on related works. The method seems to be a straightforward application of using shared and private encoder functions which have been used in multi-view and multi-domain learning problems [1-2]. \n\n[1] Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data, NeurIPS 2018.\n[2] End-to-end Training of Deep Probabilistic CCA on Paired Biomedical Observations, UAI 2020.\n\nThe main argument is to reduce the risk of negative transfer effect, which I think is a very valid motivation for this paper, however, experiments do only show the effectiveness of only one variant, i.e. L-SMTL_c on these four benchmarks and the others could not achieve the main goal of the paper. This raises the concern regarding the applicability of the model in real scenarios.\n\nApart from that, the paper missed multiple important baselines (SOTAs) [3-7] that both discussion and comparison are needed. I would also suggest including their dataset as well, especially for those that tackle the exactly similar issue.\n\n[3] UNDERSTANDING AND IMPROVING INFORMATION TRANSFER IN MULTI-TASK LEARNING ICLR 2020\n[4] Deep Multi-Task Learning for Joint Localization, Perception, and Predicti, CVPR 2021\n[5] Cross-stitch Networks for Multi-task Learning, CVPR 2016\n[6] End-to-End Multi-Task Learning with Attention, CVPR 2018\n[7] Loss-Balanced Task Weighting to Reduce Negative Transfer in Multi-Task Learning, AAAI 2019\n\nIn addition to the above comments, I believe the first stated contribution by the authors is not that much valid as the negative transfer effects have been introduced previously by [1, 3, 7]. Besides that, I believe there is no need to add additional terms when some terms are valid and previously used, for example proposing to sue \"negative sharing\" instead of \"negative transfer effect\". The negative transfer effect has been also defined in multi-domain learning where there is no direction.  Even the term \"negative transfer\" has been used by other papers even before Wang et al, 2019 for multi-task/view/domain learnings. \n\nUnlike the statement by the authors \"Negative sharing occurs when some tasks are totally or partially irrelevant to other tasks.\", I believe the negative transfer effect can be seen due to the data by itself [1]. More specifically, some sort of features or additional data for each task might cause this problem. \n\n- The performance improvement is very marginal as well.\n- The metric overall relative improvement does not seem to be informative as it combines different kinds of metrics without any care. \n- It is better to add a boolean switch to the right block diagram in figure 1.\n- I also did not find the Partially Safe Multi-Task Learning and the definition of $\\eta$ very informative. When the model might perform badly in part of the tasks, you cannot use it. The only way that it will be useful, is that the authors could predict which tasks do not work properly.\n- I suggest adding an ablation study similar to 1, showing that L-STML_c works better than the single model in the worst-case scenarios. \n- I would like to see what is the property of data and the tasks that cause the negative transfer effect. \n\n ",
            "summary_of_the_review": "The authors neither support their claims through the theoretical point of view nor provide an extensive comparison with SOTA methods. Even the experimental results do not support the main claims of the paper. Apart from that, the paper includes a wrong claim. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        }
    ]
}