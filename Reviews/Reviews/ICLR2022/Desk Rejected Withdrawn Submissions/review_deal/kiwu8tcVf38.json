{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "This paper proves that, under certain regularity conditions, the momentum buffer used in momentum SGD converges in the $L^2$ norm to the true gradient and that the covariance matrix of said momentum buffer converges to zero.",
            "main_review": "# Strengths\n\n- This paper proves a moderately interesting result. Namely, when \"normalized\" momentum is used with a discount rate ($\\alpha_t$ in this paper) converging to zero, and another regularity condition on $x_{t + 1} - x_t$ shrinking faster than $\\alpha_t$, then the difference between the momentum buffer and the true (non-stochastic) gradient vanishes to zero over time.\n\n# Weaknesses\n\n- It has been intuitively recognized for quite some time that the momentum buffer is, in some sense, an estimator of the current gradient with lower variance (but at the cost of higher bias). A formal proof under the restrictive conditions of Theorem 1 adds questionable value.\n- The cyclical step size justification seems exceptionally speculative. It does not follow from the results of this paper that one would want to cycle between high and low step sizes.\n- The empirical section borders on trivial. It is completely to be expected that $\\sigma_M^2$ will be well below $\\sigma_G^2$ for the values of $\\alpha$ used in the experiments. Other suitable aggregations of past recent stochastic gradients will exhibit the same behavior. I am not sure why this section merits two pages in the main text.\n\n# Other questions\n\n- \"Fortunately, in most practical schemes of SGD+M, the (periodically) exponentially decreasing step size scheduling together with the smoothness assumption can ensure the fulfillment of such a requirement.\": this seems off because most practical schemes of SGD+M do not have $\\alpha_t \\rightarrow 0$.",
            "summary_of_the_review": "Overall, I believe this paper is below the ICLR acceptance threshold. The proof of the main result is sound but said result does not contribute much to either theoreticians or practitioners.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The paper provides analysis for stochastic gradient descent with momentum (SGD+M), and proposes that SGD+M can be viewed as a variance-reduced stochastic gradient. Under certain assumptions, the authors prove that the momentum term in SGD+M vanishes asymptotically. Experiments on real datasets were conducted to verify the theory. \n",
            "main_review": "Strengths:\n\n(1) The main point of the paper that SGD+M can be alternatively viewed as a variance reduction method is interesting.\n\n(2) This new perspective may encourage further work analyzing SGD+M as variance reduction method.\n\n\nWeaknesses:\n\n(1) The rate of convergence (for the variance reduction) is not quantified, so it does not really explain the practical superiority of SGD+M over vanilla SGD. Analyzing the convergence rate of SGD+M (in the more usual sense) has been done a lot (e.g. [1]). \n\n(2) The assumption required by the paper may not be practical. In particular, the last requirement $\\|x^{k+1} - x^{k} \\|/\\alpha_k \\rightarrow 0$ in their assumption (5) of the main Theorem 1 needs  justification from the authors:\n- This assumption may be hard to check, when some algorithm is applied. The authors should provide the rationale behind this criteria, i.e. whether it should hold naturally in practice.\n- In fact, in their experiments of stochastic heavy-ball (SHB) method, their claim that \"the first scheme satisfies the requirements of Theorem 1\" does not seem to hold straightforwardly. Under the considered setting, this is equivalent to saying that $k^{0.5+\\epsilon} \\|x^{k+1} - x^{k} \\| \\rightarrow 0$. Please provide justification for this. \n- (Cont.) Based on paper's explanation that the setting is suggested by [1, Corollary 17], I think their $\\eta_k$ is equivalent to the authors' $\\alpha_k$. Note that [1, Corollary 17] is the corollary of [1, Theorem 13]. Now, from the proof of [1, Theorem 13] (especially [1, Lemma 22]), one can only have $\\lambda_{k+1} \\|x^{k+1} - x^{k} \\|^2 \\rightarrow 0$. Given the formula of $\\lambda_{k+1}$ in [1, (25)] and the authors' considered setting $\\eta_k= k^{-1/2-\\epsilon}$, one can get $\\lambda_k = \\Theta(k)$ (i.e. $\\Theta()$= within some constant factor). All in all, this means one will only be able to get $k^{0.5} \\|x^{k+1} - x^{k} \\| \\rightarrow 0$ instead of $k^{0.5+\\epsilon} \\|x^{k+1} - x^{k} \\| \\rightarrow 0$.\n- My point is just that direct results from [1] do not seem to immediately justify the authors' claim that the SHB experimental setting in the paper satisfies Theorem 1's requirement.\n\n\nMinor comment:\n\nIt is worth mentioning some recent work that could lift the bounded gradient assumption in the analysis of SGD+M, e.g. [2]. \n\n[1] Sebbouh, Othmane, Robert Mansel Gower, Aaron Defazio and IP Paris. “Almost sure convergence rates for Stochastic Gradient Descent and Stochastic Heavy Ball.” COLT (2021). https://proceedings.mlr.press/v134/sebbouh21a/sebbouh21a.pdf\n\n[2] Y. Liu, Y. Gao, and W. Yin, “An improved analysis of stochastic gradient descent with momentum,” NeurIPS (2020).\n",
            "summary_of_the_review": "Overall, the paper suggests an alternative perspective for analyzing stochastic gradient descent with momentum (SGD+M) and tries to explain the improvement of SGD+M over SGD in practice. However, no rate of convergence (for the variance reduction) is provided by the paper to explain its practical outperformance over plain SGD. Some assumptions made by the paper also can be hard to justify in practice. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "In this paper, the authors studied the effects of momentum for stochastic gradient descent. The authors claim an alternative view that interprets the momentum in SGD+M as a (biased) variance-reduced stochastic gradient. The authors claim that they rigorously prove that the momentum in SGD+M converges to the real gradient, with variance vanishing asymptotically. \n\nIn particular, the authors state that their analysis, surprisingly, shows that the accumulated error of in the momentum actually vanishes asymptotically when the iterates converge. The cancellation of the accumulated error can therefore be used to improve the local convergence speed analogous to variance-reduction stochastic methods.\n\n",
            "main_review": "1. My main concern is that the results shown in this paper are incorrect. It is known that if the momentum (1-\\alpha_t) is very close to 1, then SGD+M does very poorly in practice, which may not converge at all. Moreover, if (1-\\alpha_t) is iteration dependent, for instance, if (1-\\alpha_t) = t/(t+3), then the scheme (2) will diverge. This result has been proved, see the blog \"http://blog.mrtz.org/2014/08/18/robustness-versus-acceleration.html\" and the related references there.\n\n2. Another concern is \"Assumption 2\", if the algorithm diverges then certainly Assymptuion 2 does not hold. I think this might be related to the \"surprising\" theoretical results proved in this paper.\n\n3. Also, the theoretical advantage of SGD+M over SGD is still not clear in this paper. The authors are suggested to make this point clear.\n\n4. Almost no experiments to support the theoretical result. I'd suggest the authors conduct a few experiments: 1. Training neural networks, e.g., ResNets for CIFAR10/CIFAR100 classification, using SGD+M with a very close to 1 (say 0.999) momentum constant. 2. Do the same experiment above but using a nonconstant momentum parameter, e.g., 3/t with t be the iteration number.\n\nI have to reject this paper since I fear the results in this paper are very likely to be incorrect.",
            "summary_of_the_review": "In this paper, the authors studied the effects of momentum for stochastic gradient descent. The authors claim an alternative view that interprets the momentum in SGD+M as a (biased) variance-reduced stochastic gradient. The authors claim that they rigorously prove that the momentum in SGD+M converges to the real gradient, with variance vanishing asymptotically. \n\nIn particular, the authors state that their analysis, surprisingly, shows that the accumulated error of in the momentum actually vanishes asymptotically when the iterates converge. The cancellation of the accumulated error can therefore be used to improve the local convergence speed analogous to variance-reduction stochastic methods.\n\n\n1. My main concern is that the results shown in this paper are incorrect. It is known that if the momentum (1-\\alpha_t) is very close to 1, then SGD+M does very poorly in practice, which may not converge at all. Moreover, if (1-\\alpha_t) is iteration dependent, for instance, if (1-\\alpha_t) = t/(t+3), then the scheme (2) will diverge. This result has been proved, see the blog \"http://blog.mrtz.org/2014/08/18/robustness-versus-acceleration.html\" and the related references there.\n\n2. Another concern is \"Assumption 2\", if the algorithm diverges then certainly Assymptuion 2 does not hold. I think this might be related to the \"surprising\" theoretical results proved in this paper.\n\n3. Also, the theoretical advantage of SGD+M over SGD is still not clear in this paper. The authors are suggested to make this point clear.\n\n4. Almost no experiments to support the theoretical result. I'd suggest the authors conduct a few experiments: 1. Training neural networks, e.g., ResNets for CIFAR10/CIFAR100 classification, using SGD+M with a very close to 1 (say 0.999) momentum constant. 2. Do the same experiment above but using a nonconstant momentum parameter, e.g., 3/t with t be the iteration number.\n\nI have to reject this paper since I fear the results in this paper are very likely to be incorrect.",
            "correctness": "1: The main claims of the paper are incorrect or not at all supported by theory or empirical results.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "NA",
            "recommendation": "1: strong reject",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This submission aims to analyze the success of the standard SGD+Momentum algorithm by showing its variance reduction property. The novelty of this submission seems quite limited compared to the existing literature. \n",
            "main_review": "The variance reduction property of SGD+Momentum has been already studied in the literature, for example\n\n[re1] Mengdi Wang, Ethan X Fang, and Han Liu. Stochastic compositional gradient descent: algorithms for minimizing compositions of expected-value functions. Mathematical Programming 2017.\n\n[ref2] Guo, Zhishuai, et al. \"On Stochastic Moving-Average Estimators for Non-Convex Optimization.\" arXiv preprint arXiv:2104.14840 (2021).\n\nIt looks that most results of this submission can be covered by [ref2]. Moreover, [ref2] provides non-asymptotical convergence rate analysis, requires weaker assumptions (without Assumption 1 which is quite restrictive), and guarantees the variance reduction in a global scale instead of a local scale. \n\nI would like to see that the authors can address these concerns in their feedback. What are the relations and difference between this submission and [ref 2]? What are superiority over [ref 2]? \n\n\n\n",
            "summary_of_the_review": "This paper does not provide novel analysis compared to the literature, and the experiments seems standard. Therefore, I vote to rejecting this submission unless the authors can address my concerns. \n",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "empirical_novelty_and_significance": "1: The contributions are neither significant nor novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This work analyzes the variance of the momentum vector in SGD-M (which is regarded as an approximation to the true gradient) and shows that the variance reduces to zero under the assumptions that the iterates are converging and $\\alpha$ is properly chosen.",
            "main_review": "This work focuses on the SGD-M formulated as scheme (2) and shows that the momentum vector $m_t$ can be regarded as a biased approximation to the true gradient with its variance reducing to zero given that $x_t$ is converging and $\\alpha_t$ is properly chosen. This is an interesting perspective of the momentum, which has been similarly discussed in several previous works. However, the main issue is that the result, which I believe is correct, is too slight and requires overly strong assumptions.\n\nTheorem 1 is the main result, which assumes that $x_t$ converges almost surely. This assumption basically avoids the discussion on the choice of $\\eta_t$, which is too strong and makes the result not very meaningful. I think the main reason behind the vanishing variance is that scheme (2) writes the momentum $m_k$ as an exponential average of the past gradients. We may consider the situation where we choose a very small $\\eta_t$ such that the iterate is almost not moving away from the initial guess. In this case, the variance is reducing simply because more and more samples are made at the point. Skimming through the proofs, they all seem to be rather standard techniques.\n\nMoreover, the writing is not so clear and the paper contains several typos. The key assumptions should be clearly mentioned when describing the theoretical results. ",
            "summary_of_the_review": "The main theoretical result of this work is slight and requires overly strong assumptions, which makes the result not quite meaningful. The writing is also not so clear and the draft contains several typos. Thus, this work is clear reject to me. ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}