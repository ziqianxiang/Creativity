{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "Replay-based methods are used to solve the continual learning task, most of them focus on single-label\ncases. This paper addresses the imbalanced multi-label continual learning task and proposes a simple framework OCDM. This paper also proposes new versions of two benchmarks with more multi-label samples, and the experimental results show that OCDM outperforms the previous baselines on these two benchmarks by keeping the label distribution balanced in memory.",
            "main_review": "Multi-label continual learning is a more challenging task than the single-label one. Since the label distribution is imbalanced in multi-label classification, the performance of classes with few samples in memory could be limited. Therefore, it is crucial to control the label distribution in memory for multi-label continual learning. PRS is a related work that focuses on the multi-label cases, which uses complicated process and thus has long running time.\n\nThis paper proposes a simple framework OCDM, which uses a greedy algorithm to solve the sample selection problem and updates the memory to a target distribution. The target distribution is chosen to be balanced, under the assumption that the balanced label distribution in memory can be helpful for classes with few training samples.\n\nThis paper also proposes new versions of the two multi-label continual learning benchmarks used in PRS. These new benchmarks have more samples with multiple labels. The experimental results on the new benchmarks show that OCDM outperforms the previous baselines, and have lower running time than PRS. The empirical analyses show that balanced label distribution in memory can lead to better performance on the imbalanced multi-label benchmarks.\n\nWhereas the proposed OCDM do not outperform the baselines on the original benchmark NUSWIDEseq. Since this paper reconstruct the benchmarks by manually change the proportion of samples with multiple labels, it should also give more detailed analyses about how the proportion of samples with multiple labels influence the final performance. It could also investigate how the parameter ρ of the target distribution should be varied under different proportions of samples with multiple labels. That is to say, how the proportions of samples with multiple labels should influence the target distribution.\n\n**Typo**\n\n*The results on NUSWIDE **is** similar and ...* on page 8 and 9.\n\nIn the caption of Figure 6, *for each task* is misleading.\n",
            "summary_of_the_review": "This paper proposes a simple method to address the imbalanced multi-label continual learning task. The experimental results on the reconstructed benchmarks show that the proposed method is effective, whereas it do not outperform the baselines on the original benchmark NUSWIDEseq. This paper could be improve by giving more detailed analyses about how the the proportions of samples with multiple labels could influence the classification performance.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "This paper addresses the problem of multi-label continual learning: learning multi-label classification models from data streams with non-stationary distributions. This paper proposes a novel method for replay-based multi-label continual learning called \"Optimizing Class Distribution in Memory\" (OCDM). OCDM formulates the memory update mechanism as an optimization problem by casting the update process for online continual learning into a selection problem, which can control the class distribution in memory for online multi-label continual learning. OCDM proposes a greedy algorithm to solve the above optimization problem with linear time complexity. Experiments are conducted on two benchmark datasets: MSCOCO and NUSWIDE. The method is compared to three state-of-the-art methods and two baselines, and OCDM outperforms other state-of-the-art methods in terms of accuracy, and its speed is also much faster than PRS.",
            "main_review": "Strengths:\n- This paper addresses the problem of multi-label continual learning: learning multi-label classification models from data streams with non-stationary distributions.\n- This paper proposes a novel method for replay-based multi-label continual learning called \"Optimizing Class Distribution in Memory\" (OCDM).\n- OCDM formulates the memory update mechanism as an optimization problem by casting the update process for online continual learning into a selection problem, which can control the class distribution in memory for online multi-label continual learning.\n- OCDM proposes a greedy algorithm to solve the above optimization problem with linear time complexity.\n- Continual learning is an important problem that is relevant to the AI/ML communities and has important real world applications.\n- Multi-label continual learning is an understudied problem.\n- Multi-label continual learning introduces additional problems not faced by the single-label setting, specifically, it is much more difficult to maintain balanced samples from each label, which biases the memory used in replay.\n- The method seems appropriately framed by the literature.\n- The proposed optimization problem (Eq. 2) seems reasonable.\n- The target distribution definition seems reasonable.\n- The greedy approach to solving the optimization problem is linear in time complexity.\n- Experiments are conducted on two benchmark datasets: MSCOCO and NUSWIDE.\n- Details about the training procedure are provided.\n- The method is compared to three state-of-the-art methods and two baselines.\n- The metrics seem appropriate.\n- Experiments are repeated three times per dataset.\n- OCDM outperforms other state-of-the-art methods in terms of accuracy, and its speed is also much faster than PRS.\n- The authors provide code to validate the approach.\n\nWeaknesses/ Concerns:\n- This is not the first paper to consider multi-label continual learning using replay, but it is among the first several.\n- \"OCDM will add the new samples into the memory without any selection mechanism in order to make full use of memory space...\" Does this cause any issues; i.e., won't the resulting classification models be biased until there is a sufficiently balanced replay buffer/ could this lead to poor initialization of model parameters?\n- To solve the selection problem involves a greedy algorithm, so there is no guarantee the optimal replay buffer will be selected. It seems like the solution will improve as M increases if b is sufficiently small relative to M, but solutions could be bad if M is not sufficiently large (or b is too large in relation to M). Is there any bound on the quality of the solution found by the greedy algorithm on solving the selection problem in (Eq. 2)?\n- The method is only tested on one neural network architecture (Resnet101); it would be interesting to verify that it is compatible with different architectures.\n- It would be useful to see standard deviations in tables 1 and 2.\n- It would be interesting to see what happens if the network is trained from scratch instead of pre-trained on ImageNet as the imbalance might have more significant effects on the learned feature representations when initialized randomly.\n- It would be interesting to see experiments where the imbalance level is artificially controlled to see how the method behaves as imbalance is increased (vs/in addition to training the model and then doing a posthoc analysis of performance on different levels of imbalance as is done here).\n- \"Class Distribution in Memory after Training\" - you might want to summarize this as a single quantity (e.g., entropy of the discrete distribution for each method).\n- There are some important details missing. What loss function was used to train the multi-label classifier? Were any other continual learning tricks applied to reduce forgetting (e.g., elastic weight consolidation), or is it purely based on replay?\n- It seems like the imbalanced buffer issue might be able to alleviated somewhat if an imbalance aware loss function was used in conjunction with an imbalanced replay buffer (e.g., created by random selection of variables), or if an imbalance-aware sampling algorithm designed for multi-label problems was used when drawing from the replay buffer. Did you consider such approaches?\n\nAdditional Questions:\n- Is there any bound on the quality of the solution found by the greedy algorithm on solving the selection problem in (Eq. 2)?\n\nComment:\nEq. 4: Should the index of the summation be j, not i?",
            "summary_of_the_review": "Continual learning is an important problem that is relevant to the AI/ML communities and has important real world applications. Multi-label continual learning is an understudied problem that is more challenging than single-label continual learning. This approach is among the first to consider replay-based methods for multi-label continual learning. This paper proposes a novel method called \"Optimizing Class Distribution in Memory\" (OCDM), which formulates the memory update mechanism as an optimization problem by casting the update process for online continual learning into a selection problem. OCDM proposes a greedy algorithm to solve the above optimization problem with linear time complexity. Experiments are conducted on two benchmark datasets: MSCOCO and NUSWIDE. The method is compared to three state-of-the-art methods and two baselines, and OCDM outperforms other state-of-the-art methods in terms of accuracy, and its speed is also much faster than PRS. My major concerns lie with the fact that the greedy approach is not guaranteed to find global minimum of the proposed optimization problem, some key experimental details are missing, and there is limited discussion of approaches for multi-label continual learning outside of controlling the distribution of samples in the replay buffer (e.g., can standard multi-label algorithms be applied to an imbalanced buffer, or will it still fail?).",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "N/A",
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors study a multi-label continual learning (MLCL) problem through proposing OCDM algorithm, compare some closely-related SOTAs with faster learning speed to cater for streaming data. In my opinion, MLCL is indeed understudied.",
            "main_review": "1. strengths\n1.1. using label distribution to formulate continual distribution update in memory makes learning faster than previous PRS;\n1.2. the proposed OCDM outperforms PRS and etc in some metrics.\n\n2. weakness:\n2.1. Label distribution (LD) idea is NOT new at all, and at present, LD learning has had many works able to be gotten via public source, Especally importantly, LDL unifies Multi-label and multi-class learning, consequently, using LDL to formulate MLCL is straightforward! From LDL, we can find that there have existed many streaming methods with concept drift including real shift, e.g., \"Concept Drift Detection from Multi-Class Imbalanced Data Streams-ICDE2021“，”Continual Prototype Evolution-Learning Online from Non-Stationary Data Streams，arXiv:2009.00919“.\n2.2. \"replay-based methods have always shown superior performance\" needs a evidence.\n2.3. when data stream passes while labels are incomplete, how to deal with this scenario?\n2.4. the OCDM can be linear complexity, however, is this  consistent with the stream speed?\n2.5. the authors should state unique challenge for multi-label CL problem, particularly,can using label distribution/soft labels and hard labels yield a consistent result? more specifically, can label distribution guarantee theoretically that the top labels exactly correspond to the maxmima of the distribution? \n2.6. Is the defined optimization objective (2) submodular? if so, a greedy algorithm can be designed with good theoretical guarantee.",
            "summary_of_the_review": "As shown in \"Main Review\", due to that the weaknesses, particularly the novelty of this submission and the others, inclusing incomplete reviews and omission of label distribution learning works, I give the following  recommendation suggest.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "I do not fing such concerns.",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "This submission proposes a novel multi-label continual learning method, which formulates the memory update mechanism as an optimization problem and updates the memory by solving the problem. Authors claim that the proposed method is the second multi-label continual learning method up to now.",
            "main_review": "In this submission, authors claim that proposes the second multi-label continual learning method up to now, which formulates the memory update mechanism as an optimization problem and updates the memory by solving the problem. In summary, this paper is well written and easy to follow. The proposed method is simple, and experiments show that it is also effective. However, there are still some problems to be solved:\n\n1. In introduction, authors summarize the weakness of existing  continual learning methods with one sentence, \"However, most of these methods either fail to control the class distribution in the memory or can only be used for the single-label setting in which each sample in the data stream has only one label.\", however, after reading the technical details of the proposed method in Section 3, it seems that there is nothing special consideration in algorithm design for multi-label learning scenario. \n\n2. Authors claim that the proposed method is the second multi-label continual learning method up to now. I recommend the author to read the following two articles [a,b]:\n\n[a] Multi-Label Punitive kNN with Self-Adjusting Memory for Drifting Data Streams, In: ACM TKDD, 2019.\n\n[b] Multi-label Classification via Adaptive Resonance Theory-based Clustering, https://arxiv.org/abs/2103.01511\n\n\n3. In experiments, it is shown that best target distribution $\\bf p$ corresponds to a balanced one. This result is a little weird intuitively as the class distribution in the data stream is always imbalanced in multi-label setting. Because the target distribution $\\bf p$ is the key parameter for the proposed method, there should be some reasonable explanation for this issue.\n\n4. In Subsection 3.2.2, authors design a greedy algorithm to accomplish the selection procedure, which is one of main contributions of this submission. It is suggested to conduction some experiments in feedback phase to validate the effectiveness of this selection procedure. For example, just delete $b_t$ samples randomly from $M + b_t$ samples. For another example, according to the target distribution $\\bf p$, greedily repeat the following procedure: if one class includes too many samples, then randomly delete one sample from this class.\n",
            "summary_of_the_review": "From my perspective, the motivation is unclear, and the experiments should be enhanced. In summary, I think that this submission is below the standard I expect for an ICLR paper.",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}