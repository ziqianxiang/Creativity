{
    "Decision": "",
    "Reviews": [
        {
            "summary_of_the_paper": "In this article, the authors investigate the problem of data augmentation in graph contrastive learning. The authors propose an end-to-end learning framework for learning the distribution of data augmentation to achieve an automated learning for graph representation. Experiments are also conducted to demonstrate the effectiveness of the method.",
            "main_review": "Strengths: The problem faced by the paper is interesting and timely and the proposed approach seems reasonable. The article is well written, the method is clearly described, and the overall quality is good. The authors also provide the source code to facilitate experimental replication.\n\nWeakness: \n1. The proposed framework for learning graph augmentation end-to-end is relatively incremental and lacks innovation. End-to-end training by sampling across multiple data enhancement schemes does not convince me. I am more concerned about the stability of the training. Almost all parameters of the model are changing. It is easy to fall into collapse solutions by learning data augmentation methods for GCL. There is no analysis or experiments on the stability of training in the article. The initial values of the various data augmentation parameters are not mentioned either.\n2.\tI am concerned about the computational complexity of the model, using 3 GNN encoders and a GRU module throughout the framework, which is twice as many as the encoders used for ordinary graph contrastive learning. I hope the authors will have algorithmic complexity analysis. \n3.\tThe article has extensive redundant descriptions of methods and operations for graph data augmentation, such as the use of the same Gumbel-Softmax trick for sampling. Appropriate streamlining of unnecessary content could be considered.\n4.\tI am curious about the possible impact of reducing the number of data augmentations, such as using only structural augmentation or using only feature augmentation. Or reducing the number to only one data augmentation, is it still possible to learn the graph representation efficiently?\n5.\tThere are some formulas in the article that are difficult to understand, such as what is alpha and beta mean in the beginning of section 3. Why are the joint distribution draw from the two same graph sets? Augmented graphs are different with the original graphs.",
            "summary_of_the_review": "Thanks to the authors for their work, but I don't think the technical contribution of this article is enough to satisfy the bar of ICLR, so I give a rej.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes an end-to-end graph augmentation framework, namely LG2AR, that helps encoders learn generalizable representations, to achieve automation and adaptive augmentation. Specifically, L2GAR introduces a probabilistic policy that learns a distribution and then samples two congruent graph views through probabilistic augmentation heads. Finally, L2GAR achieves state-of-the-art results compared to existing methods on various node/graph classification datasets. ",
            "main_review": "[Strengths]\n\n1. The paper is well written and clearly organized.\n2. Comparisons to JOAO are provided. Whereas JOAO only validates the effectiveness of adaptive augmentation at the graph level, L2GAR extends it to node-level tasks. More importantly, whereas JOAO achieves only subtle improvement over the benchmark algorithm GraphCL, L2GAR demonstrates significant advantages on all datasets.\n3. Different from previous methods, such as JOAO, which uses bi-level optimization with high complexity, L2GAR solves this problem and enables end-to-end optimization.\n\n[Weaknesses]\n1. Except for the general idea of learning graph augmentation end-to-end, it seems that most components in the Sec.3 are off-the-shelf methods. For example, the proposed probabilistic policy is directly achieved by two existing approaches (Deep set and RNN), and the Gumbel-Top-k trick is used to sample the learned probability by the proposed augmentation heads (e.g., the node dropping head), which enables end-to-end training. Meanwhile, more analysis or the motivation of proposed methods are needed. For example, theoretical or practical analysis (e.g., in SimSiam [1] and AutoMix [2]) can be adopted to explain why the proposed LG2AR does not require bi-level optimization.\n2. Since the proposed LG2AR is an automatic augmentation method for self-supervised graph representation learning, it is better to compare with more learnable graph augmentation approaches (such as GCA [3] and ADGCL [4]) rather than many supervised methods. Moreover, it is better to adopt more evaluation protocols besides the linear classification evaluation.\n3. Each proposed component and conclusion should be supported by ablation experiments. For example, the proposed node dropping head using Gumbel-Top-k trick performs better than Bernoulli sampling with Gumbel-Softmax trick in Sec.3.3, regularizing the encoders by randomly alternating between training the base and augmentation encoders helps the base encoder to generalize better in Sec.3.5. Moreover, the given reasons why the proposed method does not collapse into trivial solutions in Sec.4.4 seem too general, and more experiments are required. The base encoder and augmentation modules are modeled by different parameters but optimized end-to-end by the same objective. Thus, I guess that the randomly alternating update of network parameters in Sec.3.5 might be the main reason.\n4. To make the gradients flow back to the policy module, L2GAR multiplies the final graph representations by their associated augmentation probabilities predicted by the policy. However, as shown in Figure 2, the frequency values of augmentation selections are very small, which may change the data distribution after multiplying the representation directly, leading to instability of the optimization.\n5. In Figure 1, the definitions of the two \"sample\" operations seem to be different and need to be more clearly distinguished.  \n6. According to the description in subsection 3.2, this paper only proposes a batch-specific augmentation. Why can't a unique augmentation strategy, i.e. node-specific augmentation, be defined for each sample in a batch?\n7. While GRU is a general-purpose module, from the perspective of paper completeness, its properties need to be discussed to distinguish it from the deep set-based scheme.\n8. The parameter of policy is defined as \\mu in the subsection 3.2, but it is \\eta in Figure 1, please use the notation consistently.\n9. The design of the discriminator is very important for the model, but this paper only uses a simple dot product scheme. Can the model performance be further improved if other methods, such as cosine similarity, are used?\n10. The learned augmentation selections should be compared with trial-and-error augmentation selections, as JOAO has done, to show that L2GAR can indeed learn the ground-truth augmentation distribution.\n11. In the paper, the authors discuss about hyperparameter sensitivity, but only provide analysis and conclusions without any experimental results, which is not convincing.\n12. How to analyze the convergence of the proposed framework theoretically?\n13. In Figure 2, the frequency values of the augmentation selections are very small, indicating that the proposed method does not yield sparse solutions, does it mean that the training has not yet converged?\n\nReferences\n[1] Exploring Simple Siamese Representation Learning. In CVPR, 2021.\n[2] Unveiling the Power of Mixup for Stronger Classifiers. In arxiv, 2021.\n[3] Graph Contrastive Learning with Adaptive Augmentation. In WWW, 2021.\n[4] Adversarial Graph Augmentation to Improve Graph Contrastive Learning. In arxiv, 2021.\n",
            "summary_of_the_review": "The paper is very clearly written and well organized. The authors present an interesting framework with good results, especially how a well-designed data enhancement strategy in the unsupervised case can  significantly improve the performance of graph methods. However, there are still many problems in the paper that need to be addressed (see [weaknesses] above). I would like to see how the problems can be addressded in rebuttal and respond accordingly.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "None",
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes an end-to-end graph augmentation framework for graph representation learning with contrastive learning. Specifically, the authors introduced a policy sampler and node/edge sampler for each policy. The authors showed empirically that the LG2AR pipeline outperforms previous SOTA on various benchmarks.",
            "main_review": "Strengths:\n\n1. The paper is written clearly and easy to follow.\n\n2. The empirical improvements seem pretty significant compared against previous SOTAs.\n\nWeaknesses:\n\n1. The novelty seems limited to me, as the whole effort to introduce differentiable sampler to replace.\n\n2. According to the ablation study, it occurs to me that even random policy performs reasonably well (very similar to the final model and much better than other baselines), which casts doubt on the effectiveness of the proposed modules\n\n3. The authors mentioned that the proposed pipeline is sensitive to hyperparameters settings. What's the gap if we tweek the hyperparameter by a little? Do the authors use the same set of parameters across different datasets?\n\nAdditional Questions: \n\n1. Does  LG2AR and GraphCL use the same set of models, loss functions and hyperparameters in the ablation study? My understanding is at least loss function is different. Is it better to use a vanilla version of LG2AR, i.e., removing all the probabilistic samplers a better ablation study? I'm curious does the vanilla version performs better or worse than GraphCL. \n\n---- Post Rebuttal ----\n\nI thank the authors for the clarification. Most of the concerns were resolved. My main concern left is novelty - the techniques are very standard to achieve this fully differentiable approach. Combing the reviews from all the other reviewers, I think this submission is still a borderline reject. Thanks. ",
            "summary_of_the_review": "Good results, limited novelty, sensitive hyperparameters and some questions on ablation studies ",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}