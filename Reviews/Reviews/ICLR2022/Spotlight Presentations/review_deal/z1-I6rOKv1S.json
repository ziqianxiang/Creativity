{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Spotlight)",
        "comment": "The paper proposes a framework for training autoregressive flows based on proper scoring rules. The proposed framework is shown to be a computationally appealing alternative to maximum-likelihood training, and is empirically validated in a wide variety of applications.\n\nAll three reviewers are positive about the paper and recommend acceptance (one weak, two strong). The reviewers describe the paper as well written and well motivated, and recognize the paper's contribution as significant.\n\nOverall, this is a nice and promising methodological exploration of flow-model training that is worth communicating to the ICLR community."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "The paper proposes an interesting approach for estimating densities and providing uncertainty estimates for these densities. The paper extends normalizing flows in several ways: (1) by using objective functions based on proper scoring; (2) by using autoregressive quantile flows; and (3) by defining quantile flow regression.",
            "main_review": "Strong points:\n- The proposed objective functions (quantile loss and continuous ranked probability score) appear well-motivated and have nice theoretical properties.\n- The generalization to quantile flows is well-motivated and well-described.\n- The implementation of all methods is clearly described.\n- The paper is well-structured and introduces complex topics well.\n- The analyses of the UCI datasets are comprehensive.\n\nMajor concerns:\n- Since the manuscript proposes several new objective functions and architectures, it would be nice to have comprehensive experiments on synthetic data. In particular,\n    - how well does the method for quantile function regression capture the true quantile function in a univariate case?\n    - do the prediction intervals behave as expected from the theory?\n    - how well does the method estimate the cdf at various points (e.g., the median, the 25th and 75th percentiles)?\n    - compare this method vs maximum likelihood in terms of timing and accuracy\n- Some of the terms aren't defined (e.g., the column headings in Table 3, Table 4)\n\nMinor concerns:\n- check throughout for typos",
            "summary_of_the_review": "I vote for accepting the paper subject to some additional experiments.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposes a novel framework for training flow models named Autoregressive Quantile Flows (AQF). The proposed method utilizes a new objective by evaluating forecasts with proper scoring rules, including the continuous ranked probability score and the check score. The advantages of the proposed objective are 1) it could avoid the explicit calculation of the determinant of the Jacobian matrix and 2) it could also provide uncertainty estimation for predictions. Experiments on multiple tasks including regression, object detection, time series forecasting, and generation validate the effectiveness of this framework.",
            "main_review": "The strengths of this article are as follows:\n1. The proposed objective is novel, which does not need to compute the inverse of the Jacobian, which is intractable in most cases. Moreover, it enables complicated transformers like deep neural networks to be applied in flow models and simplifies the implementation, thus having good potential for future applications.\n2. Benefit from the design of objective functions, the proposed framework supports a sampling-based training paradigm. Such a mechanism embraces a broader range of loss functions to the flow framework.\n3. It is also interesting to see that the proposed quantile flows could also provide the distribution estimation of model outputs, which can be applied to provide uncertainty of predictions. \n\nDespite the main contributions of the article, it could still be improved from the following aspects: \n1. Providing more detailed descriptions of the evaluation metrics for better understandability.\n2. Some typos are found:\n  - In the second paragraph of subsection 2.2, “the quality of forecasts if often...” -> “the quality of forecasts is often...”.\n  - In eq. (1), “F_\\theta (y_i)” -> “F_\\theta (y)”.\n  - In the third paragraph of subsection 6.1, a period is missing at the end of the first sentence.\n3. Please cite the source of datasets or provide links. Also, please unify the reference format and cite the following paper: \nSandler, Mark, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. \"Mobilenetv2: Inverted residuals and linear bottlenecks.\" The IEEE conference on computer vision and pattern recognition, pp. 4510-4520. 2018.\n",
            "summary_of_the_review": "This article provides a novel and interesting idea to improve flow models in multiple aspects. I think this work can inspire other researchers in the community, so I tend to accept the paper after some minor modifications.\n\nPost-Rebuttal\n----\nThe paper has its merits and the authors have revised the manuscript according to the comments. \n\nThus, I keep the score and recommand acceptance.",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "4: The contributions are significant, and do not exist in prior works.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper proposed a quantile regression method for uncertainty estimation based on autoregressive quantile flow. The flow model can be trained in both forward and reverse setting using different loss functions, and the quantile flow framework can be combined with other linear or non-linear transformations. The authors have conducted diverse empirical evaluations on objective detection (bounding box regression), time series forecasting, and generative models to demonstrate the advantage of the proposed method.",
            "main_review": "Overall, the proposed autoregressive quantile flow is a reasonable application of normalizing flow in quantile regression. It is also extendable to various different flow transformations and applicable to a wide variety of regression problems. However, this paper has not provided a very clear and strong motivation of why using normalizing flow (or autoregressive flow in particular) for uncertainty estimation, given there are many models that can be trained by gradient-based methods, one can simply replace their objective functions by quantile/CRPS loss. By choosing an appropriate model according to data property, the performance should also be no worse than normalizing flow. Moreover, many other approaches (e.g., diffusion model) also support forward and reverse training, which is not a unique feature of this method. In addition, the authors may also want to explain the procedure more clearly by adding an algorithm box into the main paper.",
            "summary_of_the_review": "This paper has proposed a normalizing flow-based method to address the predictive uncertainty in regression problems. The significance of novelty can be further improved before it can be accepted.\n\n## Update after Rebuttal\n\nThe authors have addressed most of the concerns. It would be better to clarify the difference with diffusion models in the main paper. Good luck!",
            "correctness": "3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}