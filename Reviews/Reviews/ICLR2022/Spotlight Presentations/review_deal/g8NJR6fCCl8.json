{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Spotlight)",
        "comment": "The paper proposes two new generalized additive models (GAM) based on neural networks and referred to as NODE-GAM and NODE-GA2M. An empirical analysis shows that the proposed and carefully designed architectures perform comparably to several baselines on medium-sized datasets while outperforming them on larger datasets. Moreover, it is shown that the differentiability of the proposed models allows them to benefit from self-supervised learning. \n\nReviewers agreed on the technical significance and novelty of the proposed models and valued the clever design of the new architectures. Most concerns and open questions could be answered in the rebuttal and by changes in the revised manuscript. Based one the suggestions of one reviewer new experiments comparing the proposed models to NAM were added, which improved the paper further.  The paper should be accepted."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "\n- The authors develop the NODE-GAM and NODE-GA$^2$M architectures by modifying the previously-developed NODE architecture with constraints and a gating mechanism to ensure that, both within each tree and across layers, the model is only allowed to learn feature interactions of order 1 (for NODE-GAM) or 2 for (NODE-GA$^2$M).\n- They show that their proposed NODE-GAM and NODE-GA$^2$M architectures perform comparably to the baselines of Explainable Boosting Machines, tree-based GAM/GA$^2$M and the traditional spline-based GAMs on medium-sized datasets while outperforming them on larger datasets. They also show that NODE-GAM can benefit from self-supervised learning by pretraining a model to reconstruct the original input from a masked input.\n- They apply NODE-GAM and NODE-GA$^2$M to real-world datasets and showcase the patterns uncovered.",
            "main_review": "The authors added a comparison to NAM without bagging and provided more context for the advantages of their approach relative to other works. As a result, I am increasing my score.\n\n----\n\nStrengths\n- The authors put a lot of thought into designing the architectures of NODE-GAM and NODE-GA$^2$M. I appreciated the clever tricks adopted, like the gating mechanism and the annealing to constrain to 1 feature, as well as the small extensions to NODE like adding attention and regularization.\n- The authors similarly put careful thought into extracting the interactions. I especially appreciate the application of the \"purification\" technique (Lengerich et al. 2020), which addresses an ambiguity problem that has bothered me about approaches like these in the past.\n\nWeaknesses\n- The biggest weakness for me is primarily some missing baselines that I would be interested in seeing. In reading this paper, I felt there was an \"elephant in the room\" question lurking in my mind about why a much simpler neural-network-based architecture, such as the \"univariate\" networks present in the \"Neural Interaction Detection\" (NID) paper for modeling main effects (Fig 2 in https://arxiv.org/pdf/1705.04977.pdf; not cited) was not applied. I believe this is similar to the approach taken in the NAM paper as well (https://arxiv.org/pdf/2004.13912.pdf; cited). Regarding the NAM paper, the authors write \"NAM requires training on tens to hundreds of neural networks and requires an extensive hyperparameter search...in addition, NAM's shape graphs are too smooth after bagging\". As a reader, having seen the \"univariate networks\" used in the NID paper (which, to my knowledge, were not trained with tens to hundreds of networks), I'm left wondering \"what happens if you use fewer neural networks and don't use bagging\"? I'm sure other difficulties arise in this case - perhaps the model used in the NID paper is also not good at modeling abrupt changes - but it would be helpful to the reader to showcase to what extent this is an issue in practice. I get the sense that the authors are familiar with a lot of not-well-documented limitations of other approaches that led them to develop the NODE-GAM architecture, and it would be helpful if these limitations were made explicit.\n- Still on the subject of prior work/baselines, I am interested to hear how this approach compares to the \"Neural Interaction Transparency\" (NIT) approach (https://proceedings.neurips.cc/paper/2018/hash/74378afe5e8b20910cf1f939e57f0480-Abstract.html) - it does not seem as though NIT is cited in this work. To quote from the abstract of NIT: \"NIT is also flexible and efficient; it can learn generalized additive models with maximum $K$-order interactions by training only $O(1)$ models\" - so it seems quite topical.\n\nMinor\n- There are a few very noticeable typos scattered around (e.g. \"Mathamatically\" at the bottom of page 2, \"distirbution\" at the top of page 5).\n- In equation 7, it looks like the attention weights $a_{\\hat{i}i}$ are not indexed by the layer $l$ - is this just missing notation? Presumably the attention weights vary depending on the layer?\n- I was a bit confused by the sentence \"To allow two-way interactions, for each tree we introduce two logits $\\boldsymbol{F}^1$ and $\\boldsymbol{F}^2$ instead of just one, and let $\\boldsymbol{F}^c = \\boldsymbol{F}^{\\lfloor c/2 \\rfloor }$ for $c > 2$\". Maybe the authors meant to write $\\boldsymbol{F}^c = \\boldsymbol{F}^{(c \\mod 2) + 1}$ so that $\\boldsymbol{F}^c$ alternates between $\\boldsymbol{F}^1$ and $\\boldsymbol{F}^2$? $\\lfloor c/2 \\rfloor$ can take on values beyond 1 and 2.\n- In the section on regularization, the authors mention that adding a constant corresponding to the log of the class imbalance is needed for the $l_2$ penalty to work because \"$l_2$ induces the model output to 0\". Wouldn't it be easier to solve this by adding an (unregularized) learnable bias term to the output?\n",
            "summary_of_the_review": "Overall, I think a lot of careful thought went into this paper and the design of the NODE-GAM and NODE-GA$^2$M architectures is clever enough to be inspiring in its own right. However, the missing comparisons, particularly to the \"univariate networks\" for modeling main effects from the \"Neural Interaction Detection\" paper (which is the first thing that tends to come to mind when I think of a \"neural network based GAM\"), leave me hesitant to recommend the paper outright. I hence currently rate it as only marginally below the acceptance threshold, but expect that can easily change on revision.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "The authors proposed novel architectures for neural GAM and GA2M, which preserves the interpretability of GAM and leveraging the deep learning architectures for performance gains. The new method was assessed on 14 different dataset which covers a wide variety of prediction tasks. The performance of methods (NODE-GAM and NODE-GA2M) were comparable with the other GAM methods. Compared to other similar methods, the proposed method has a better scale ability, and better performance on larger datasets.",
            "main_review": "For the design of the new architecture, the authors made three major changes to the NODE architectures. However, it was not very clear to me the considerations behind, e.g. why avoiding features interactions in a tree. It will be great if the authors can provide evidence, either theoretical or empirical, to support the suggested designs.",
            "summary_of_the_review": "The paper proposed an interesting architecture for interpretable deep learning models. However, based on the empirical results, the method does not seem to be superior or only marginally better than traditional methods such as the spline model.\n",
            "correctness": "2: Several of the paperâ€™s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "5: marginally below the acceptance threshold",
            "confidence": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        },
        {
            "summary_of_the_paper": "Generalized Additive Models (GAMs) are a class of interpretable models with a long history of use in these high-risk domains, but they lack desirable features of deep learning such as differentiability and scalability. \n\nThe authors propose a neural GAM (NODE-GAM) and neural GA2M (NODE-GA2M) that scale well and perform better than other GAMs on large datasets, while remaining interpretable.\n\nPopov et al. (2019) developed NODE that mimics an ensemble of decision trees, but suffers from lack of interpretability similarly to other ensemble and deep learning models. Agarwal et al. (2020) developed a Neural Additive Model (NAM) whose deep learning architecture is a GAM, but does not scale well.\n\nThe authors combine the above mentioned 2 approaches via a 3 step process:\n1. Instead of letting the ODT feature function be a weighted sum of features, they make it pick only one feature.\n2. Within each tree, they make a logit layer the same across all depths to remove interactions between features.\n3. Finally, they avoid the DenseNet connection between two trees that focus on different features.\n\nThe authors then output performance on 6 popular binary classification datasets (Churn, Support2, MIMIC2, MIMIC3, Income, and Credit) and 2 regression datasets (Wine and Bikeshare). Looking at the experiments, their NODE GA^2M version seems to perform similar to the compared state of the art.\n\nThe authors additionally perform an ablation experiment by testing their method's semi supervised learning capabilities, show that it is able to learn on mask data and be fine tuned on a limited labeled dataset.\n\nFinally, the conclusion has arguments to support the interpretability of GAMs and to defend their model's interpretability",
            "main_review": "Pros:\n- I believe that there is well backed motivation for work based off of the plentiful literature review.\n- There is novel integration of 2 methods previously not combined before\n- A variety of datasets seem to show that the proposed method is useful.\n- Code is available for reproducibility.\n\nCons: The only issues I have with this are things that could improve clarity.\n- If it is possible, I would love to see a full algorithm of NODE-GAM for clarity and understanding of each novel step\n- I would rather the the argument for the interpretability be moved to the introduction / literature review section rather than in the conclusion for flow. Then, the authors could summarize their work in the conclusion instead.",
            "summary_of_the_review": "I would tend to accept this paper as it is novel enough and supported by empirical experiments.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "Not applicable",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "8: accept, good paper",
            "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
        }
    ]
}