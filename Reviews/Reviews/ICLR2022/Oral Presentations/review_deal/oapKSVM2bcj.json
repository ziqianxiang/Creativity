{
    "Decision": {
        "title": "Paper Decision",
        "decision": "Accept (Oral)",
        "comment": "All reviewers agree that this paper is a useful and valuable contributions to ML engineering.\n - insightful analysis .. highly user friendly operator design\n - \"useful and I can see it having large adoption in the community of scientific computing\" ... \"\n - \"Personally I tend to buy these advantages of einops\" ... \"However, there is a lack of solid empirical study to validate the effectiveness and efficiency of the design\"\n - \"a useful and appealing new coding tool.\"\n\nThe negative reviewers appear fixated on the (true) observation that the paper does not look like a conventional ICLR paper, thati it \"reads like a technical blog\", and \"lacks rigour\".\nI belive it is fair and measured to state that these reviews may be considered to exhibit aspects of gatekeeping: requiring more \"mathiness\" that does not help the paper, or more \"rigour\" through user studies that are in fact less valuable than the reviewers' own observations \"I could see myself...\", \"I tend to buy...\".\n\nThis is a paper about design, not about models or algorithms (although the algorithmic work is good).  It is about the design of tools that we all use, and about the decisions and thought processes that led to that design.  A reviewer decries \"many non-rigorous claims\".  These are claims about the usability of existing systems, and mostly appear in the discussion and footnotes, as the authors note in rebuttal.  Of course, one could have run user studies to back up each claim, but I am just as convinced by the examples shown in the paper.  It matters not to me what some users corralled into a user study thought.  It matters what I and my colleagues will think, and I am now sure to recommend einops to colleagues.  I would not have met it had the paper not been submitted to ICLR, and hence I am certain it should be accepted, so more can see that we care not just about mathiness, but actually enabling progress in our field.\n\nThe job of a conference like ICLR is to expose researchers and practitioners in machine learning to ideas and techniques that may advance their research and practice.  Programming, and the translation of mathematical ideas to efficient computer code, are fundamental to all of machine learning, and hence programming models are very much suitable for presentation to an ICLR audience.  I am certain that this paper, and the technology it describes, are more important to ICLR readers than knowing that if module A is co-trained with module B, then combined with compression C, the SOTA on some arbitrary benchmark is increased by 0.31 +/- 1.04. \n\nReviewer gRMH says \"there is no code\", but the code has been in the open for three years; it is an accident of our misapplication of the principles of blind review that the reviewer felt they could not search for the code, and that the authors felt they could not bring to bear the evidence that three years of real-world usage have brought.  \n\nReviewers say the work is just an extension of einsum, while noting that the extension is useful and nontrivial.  Yes, it is an extension, and the paper's examples show how it yields more compact code that is also more readable and maintainable.\n\nI could add more examples, but in short, I tend to side with the authors' response at almost every point.  At the same time, the final version of the paper has been strengthened by this dialectic, and I expect further strenghtening through exposure to the ICLR community.\n\nTo the authors: Listing 1 is useful, but should be in an appendix.  Instead, add examples of ellipses on P5, and show more inline examples in general.  The paper would be strengthened by another pass over the English -- after the decision is made I would be happy to volunteer to help."
    },
    "Reviews": [
        {
            "summary_of_the_paper": "Operators are key elements in deep learning (TensorFlow, PyTorch, etc) or scientific computing (NumPy) frameworks.\nThis paper introduces a generic, convenient and elegant way of massively describing large portion of frequently used operators\nunder a unified framework, EinOps, inspired by einsum, or the Einstein summation convention.\nUnder this convention, key components like multi-head attention in modern neural networks can be expressed\nwith fewer lines of code. The major contribution of this work includes:\n- Presents a set of novel and highly expressive notations to represent hundreds of operators\nin modern deep learning frameworks;\n- Develops a library that interprets the proposed notations and offloads them to existing implementations\nin NumPy or TensorFlow, PyTorch;\n- Demonstrates significantly improved readability and debuggability with the proposed notations\n",
            "main_review": "**Strength of the work.** First of all, the paper provides a handful of case studies with insightful analysis on\nuser experience on the existing design of operators, and then based on those studies it derives a series\nof notations for highly user friendly operator design. By providing various comparison between\nexisting ones on real-world, the paper leads to a convincing proof of the strength of\nthe proposed notation for deep learning researchers' daily usecases, in terms of expressiveness,\nelegance, usability and debuggability.\n\nSecond, the paper comes with solid engineering efforts that offload the computation to underlying\nlibraries, including NumPy, TensorFlow, PyTorch, MXNet, Keras etc. Effectively, with the solid engineering\neffort, the library serves as a meta framework that can be reused across backends with close-to-zero\nengineering overhead. The paper also explores some techniques like caching to reduce the execution overload\nof runtime dispatching.\n\nThird, by the \"stringly-typed\" abstraction of operators, the proposed notation enforces more explicit\nprogramming of the semantics of tensor axes, as well as more runtime checking to catch correctness issues.\nThis is particularly helpful among deep learning practitioners who are already exposed to a set of conventions\n(e.g. \"NCHW\") to write the right code. The typed operators, instead of typed tensors (e.g. NamedTensor),\nprovides the guarantee that users only need to type important part of their code as a drop-in replacement of the existing\ncode fragments without having to worry about refactoring the entire codebase. This is again particularly helpful\nfor deep learning practitioners\n\n**Weakness.** With the proposed notation, compiler-based approaches, e.g. TVM, MLIR, haven't been explored to further boost performance,\nalthough such opportunities are real and tangible. For example in TVM, the Tensor Expression (TE) can be considered as \na generalized form of EinOps, and it could bring extra performance gain to the users. Therefore, it would be desirable to integrate\nwith those compiler backends to assist with potential performance.\n\nThe normal definition of the EinOps notation, while demonstrated in many examples, are not carried out formally.\nFor example, brackets `()` in the notation may serve different purposes under `rearange`, `reduce` and `repeat`,\non the left- and right-hand side of the notation. It may refer to tiling one dimension, or composition of new dimensions,\nor removing a dimension, etc. Another example that needs more clarity is stack/concatenate where there are multiple\ntensors involved, and might be desirable to state formally on the constraints implied in this particular case.\n\nLast, while the notation is very flexible in expressing layout-related operations, it is yet under-explored on\nexpressing the common operators that deep learning researchers may care about, namely, many variants of convolution.\n\n**Correctness.** The reviewer is not aware of any correctness issue in all demos and figures in this paper.\n\n**Clarity.** The paper is overall rich in detailed and insightful explanation. There is some minor clarity issues as pointed out in the weakness section.\n\n",
            "summary_of_the_review": "In summary, the paper demonstrates clearly an elegant and novel notation to represent a large portion of operators in deep learning workloads, and developed a meta-framework with solid engineering. The reviewer recommends to consider the acceptance of the paper as a novel good deep learning meta-framework.",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "details_of_ethics_concerns": "The reviewer is not aware of any ethical concerns in this paper",
            "recommendation": "8: accept, good paper",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper extends the Einstein summation notation (einsum) of Numpy to introduce some additional features: \n\n- naming axes arbitrarily (i.e., with more than a single character);\n- controlling how groups of axes are flattened (called \"rearranging\" in the paper);\n- repeating axes;\n- reducing axes with different operations other than the sum.\n\nThe notation is implemented in a Python library called \"einops\" that works with different backends for tensor computation (PyTorch, TensorFlow, Jax, etc.). ",
            "main_review": "There are numerous issues with the paper, which I will try to summarize below. \n\nI should mention that, since no code was included in the submission, my assessment of this work is based entirely on the paper and the ideas expressed therein. I am not judging the work based on technical aspects related to the library except for those described in the paper.\nHowever, a complete assessment of the paper should also include a code review (see my first comment in the \"Weaknesses\" section).\n\n**Strenghts**\n\n1. I am a great fan of einsum notation for expressing tensor operations and I agree with the authors on the value of extending the notation as they did. I could see myself, as a practitioner, using the \"rearrange\" function (I thought that the example of reshaping an array of images into a 4x4 grid on page 6 was nice).\nAs an engineering feature, the einops package could be useful.\n\n2. Using the library seems to make the code less verbose in the examples provided in the paper. This gives a reasonable advantage in terms of the readability and maintainability of the code (although this is a purely subjective assessment, as I argue below).\n\n3. The fact that the library supports multiple backends is a plus, although I have some concerns about some design choices discussed in the paper (see below).\n\n**Weaknesses**\n\nUnfortunately, I think that there are considerable flaws in the paper, the motivation behind it, and the described implementation of the library. \nI will try to summarize everything in the following points.\n\n1. While I agree that much of machine learning is based on tensor manipulation, this paper is not suitable for publication at ICLR. \nEven if we were to focus only on tensor manipulation as a machine learning exclusive, better venues exist for this kind of paper, like the JMLR Open Source Software track. There, the paper could be reviewed along with the code (which was not included in this submission even if it is a crucial part of the authors' contributions).\nI realize that libraries like TensorFlow and PyTorch had a paper published at some top conferences like ICLR, but it's clear that their novelty and impact on the community was incomparably larger at the time of publication. \n\n2. The motivation for the paper is weak. I will give some examples of claims made by the authors to motivate einops that I don't think hold up:\n    - Users have to remember axes order: this is largely solved by einsum, not einops exclusively.\n    - Control over data layout: einops does not solve the issue, it just gives a simpler interface to control it. \n    - Einops is declarative and self-documenting: einsum too, einops simply extends the paradigm. \n\n3. The contributions of the paper are not enough to consider a publication. \n\n    The paper should describe the notation in detail, but it doesn't. Instead, it is halfway between a description of the notation and a documentation for the package. The result is that it works badly as both. Some examples: \n\n    - The notation is never formally described, for instance as a grammar, and one must look at examples to infer the form of a correct string.\n    - Many features like anonymous axes and ellipsis indexing are essentially ignored, even if they are a key part of the notation.\n    - A comparison with einsum is missing, which confuses the reader and does not highlight some features that are present in einsum but not einops (for example, computing the trace and the implicit notation).\n\n    Also, the authors claim that they \"align the interface with einsum to allow smooth simultaneous usage\" but this is misleading. Einops is clearly inspired from einsum and simply adds some features (while also removing others, as I said above).\nIn this regard, throughout the paper the authors seem to imply that einops solves problems (like that of rearranging) that were previously unsolvable (e.g., second paragraph of page 6). This is also misleading since einops is merely an interface/API to existing functions. \n\n4. The example on page 4 concerning convolution is unclear.\nFor example: when convolutions rely on axes order, the user is not \"expected\" at any time to use named axes for other operations.\nIt is also not clear what kind of \"name checks\" would be prevented by assigning fixed names to the axes in convolution, and how einops overcomes this issue. \nI might have misunderstood this whole paragraph, so please correct me if I'm wrong.\n\n    In this regard, if the interaction with \"neural layers\" is a primary motivation for developing the library, the feature should be discussed more in depth (it is only briefly mentioned once, towards the end, with no explanation).\n\n5. There are many non-rigorous/subjective claims. I have found at least five: \n\n    - Footnote 4: \"New users frequently continue trying to imagine the tensors layout in memory.\" -- On what grounds are the authors making this claim without any references? Have the authors conducted user studies? \n    - Page 9: \"Caching plays an important role in einops high performance\" -- Since there are no performance benchmarks, how is performance quantified here? I assume that the performance of einops is equal to or worse than the backend, given the extra overhead. Is it faster than equivalent einsum operations? Can the authors quantify the \"important role\" of caching?\n    - Page 9: \"einops was also referred once as a good intermediate solution\" -- By whom? How is this whole reported conversation meaningful to the reader?\n    - Page 9: \"Design of such system is much harder than it sounds: previous ideas failed\" -- What does it mean that designing is hard and how can the authors be sure that it wasn't due to their own limitations? Whose previous ideas have failed and in what context? \nI am obviously not implying anything about the programming and engineering abilities of the authors, I am merely pointing out that claims like this should not be made in a scientific paper.\n    - Page 9: \"We observed that einops notation gets picked up for describing tensors with packed dimensions\" -- Again, did the authors perform a user study to make this claim? And, in any case, did einops notation get picked up more easily than einsum notation? If so, why?\n\n**Other minor issues**\n\n6. Figure 1: the example assumes that the reshape is done by hardcoding the dimensions and that the programmer will make a typo that \"luckily\" does not crash. First, we don't know how often this kind of bug happens and, second, this issue can be easily bypassed by accessing the actual shapes (like the authors do on page 6, line 2-3 of the code block at the bottom). I wouldn't use this as a primary motivation for the rearranging function.\n\n7. Page 4, third bullet point: the authors imply that the code should crash, but in fact it is a perfectly well-formed expression that should not crash. Again, the authors should not assume the likelihood of a bug or what the users want to do.\n\n8. Page 7: \"Einops alleviates necessity to introduce a function, as arguments describe input, output, and the transformation itself\". This is a claim in support of the readability of einops, although it holds for einsum already. While I partially agree, einsum/ops notation could also be seen as less beginner-friendly because it requires the users to know the syntax. For example `arr.flatten()` seems (subjectively) more descriptive than `rearrange(\"ab->()\", arr)`, especially if one doesn't already know einsum notation.\n\n**Comments on the implementation details**\n\n9. The choice of automatically detecting the backend from the input is arguable. \nQuoting from the famous Zen of Python by Tim Peters: \"Explicit is better than implicit\" and \"In the face of ambiguity, refuse the temptation to guess.\"\n\n    For example, a situation could happen in which a Numpy array is given as input to a TensorFlow-based user-defined function. \nSince TensorFlow knows to automatically convert arrays to tensors at runtime, this is standard and expected behaviour. \nReplacing the initial call of this imaginary function with an einops-based one would result in the first operation happening in Numpy and not TensorFlow. \n\n    I advise the authors to adopt a paradigm like that of multi-backend projects like Keras in which the users decide explicitly what backend to use (through a config file or by making the backend explicit at import time -- e.g., `from einops.torch import ...`). \n\n10. Can the authors provide an example of how they improved the exception message for broadcasting w.r.t. the one from Numpy? How is it easier to understand?\n\n**Suggestions**\n\nAfter revising the paper, the authors should consider submitting it to an appropriate venue for open source contributions. \n\nThe revision should make it more clear that einops is an extension of einsum and should highlight the concrete additions and limitations of the proposed einops. \n\nThe authors should make the paper more rigorous: the notation should be formalized, the claims about usability should be removed unless backed up by user studies, and the motivation of the paper/library should be rethought. \nThe paper could also focus less on examples (which are more suitable for the documentation).",
            "summary_of_the_review": "**Positive aspects**\n\n- The proposed extension of einsum is useful and I can see it having large adoption in the community of scientific computing.\n\n**Negative aspects**\n\n- I don't believe that ICLR is the correct venue for a paper like this. \n\n- The novelty and quality of the paper are rather limited. \n\n- The motivation for the paper is weak and much of the advantages brought by the proposed \"einops\" were already brought by the original \"einsum\" notation. \n\n- The presentation is, at times, confusing.\n\n- There are many non-rigorous claims that cannot be tolerated in a scientific publication.\n\n- There are some design choices that could lead to unexpected problems when using the library. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
        },
        {
            "summary_of_the_paper": "In this paper, a new Python toolbox called EINOPS (Einstein Operations) is introduced. The proposed toolbox allows for applying tensor operations on a single tensor data, such as reshaping, reducing (max, mean, etc), repeating, permuting, and others; in such a way that it improves code readability and flexibility. The paper illustrates about current issues on available solutions, typically in numpy and shows how EINOPS solves those issues. Also, the toolbox supports widely used frameworks such as Pytorch, TensorFlow and others providing framework-independent minimalist API for tensor structure manipulations.",
            "main_review": "Strengths:\n-\tThe proposed toolbox allows for simple and easy to read code tensor manipulation operations and operates with most popular Python frameworks.\n-\tThe usage of indices names is more flexible compared to already existing ones in the einsum operation in numpy and Pytorch, which are known to have some limitations, e.g. number of dimensions is limited by the number of letters.\n-\tIt is very useful for using Tensor Networks where number of interacting tensors are usually big and can have a large number of dimensions. \n\nWeaknesses:\n-\tThe paper does not provide any advance in theory or new algorithm for machine learning. It is limited to introduce a useful and appealing new coding tool.\n-\tThe paper does not mention its application for computing and manipulating Tensor Networks, missing a very important usage for which there is a growing audience eager to have such convenient tool.\n-\tEINOPS does not consider operations involving two or more tensors\n-\tA comparison in terms of computation cost is missing in the paper\n",
            "summary_of_the_review": "I found the tool very useful for any application involving tensors with Python. The paper is focused on deep learning applications. However, I am sure it is also very useful for dealing with Tensor Networks (TNs), where many core tensors are interconnected. The paper lack of a description of its application to TN contractions, for example. \n\nIt seems that current implementation only consider operations on single tensors. I would suggest to include also operations on two or more tensors, similarly to einsum in numpy and Pytorch, but using a more flexible indices labelling.\n\nA comparison with previously available solutions, via numpy or Pytorch, for example, in terms of computation cost is missing in the paper, making it difficult to evaluate if there is some price to pay.\n",
            "correctness": "4: All of the claims and statements are well-supported and correct.",
            "technical_novelty_and_significance": "3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "6: marginally above the acceptance threshold",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        },
        {
            "summary_of_the_paper": "This paper introduces einops, a tensor manipulating library in Python, to efficiently support multidimensional tensor manipulations widely adopted in deep learning. \nHighlighted advantages of einops include:  \n+ providing semantic check for tensor operations; \n+ including high expressiveness and flexibility for tensor manipulating interfaces;\n+ supporting multiple backend runtimes efficiently; \n+ making tensor manipulating code more readable and reliable, and etc..",
            "main_review": "First, this paper studies efficient programming paradigms for multi-dimensional array operation, which is an important intermediate layer for modern ML systems, especially for deep learning systems. Personally I tend to buy these advantages of einops claimed by the author, including:\n\n+ providing semantic check for tensor operations; \n+ including high expressiveness and flexibility for tensor manipulating interfaces;\n+ supporting multiple backend runtimes efficiently; \n+ making tensor manipulating code more readable and reliable, and etc..\n\nThese claims sound very promising and valuable as a ML toolkit. \n\nHowever, there are some fundamental concerns I have for the paper: \n\n+ The writing is problematic as an academic paper. Comprehensively, this paper reads like a technical blog, which tries to introduce and advertise a Python library; some statements in this paper are casual, i.e., in the end of Section 7, the author says \"We intentionally omit discussion of user conveniences provided by einops package: anonymous axes, ellipsis, list inputs and neural layers.\", although I would not doubt about it if reasonable amount of evidence (e.g., empirical study or analysis) was presented, this sentence sounds a little ungrounded. Further, the organization of the paper can be polished as well. To be specific, I do not get why Section 2 & Section 3 are split, it seems that both sections are talking about the issues and limitations of STOA systems. \n+ There is a lack of reasonable amount of empirical study to justify the statements about the contribution of the work. For example, the author claims that einops \"significantly improves code readability and flexibility\" in the abstract, I would expect some user-study (which could invite a group of participants to accomplish some programming tasks about tenor manipulation with and without einops and measure some objective or subjective metrics for evaluation) to justify this claim---note that this is pretty standard in first-tier PL/SE volumes, it would be easy to find hundreds of such papers and adopt such methodology for evaluation. The current Section 5 can be considered as good motivating examples, but it is not sufficient to support this claim following the principle of scientific study. The efficiency evaluation of the implementation is also missing, e.g., it is important to learn how much overhead is introduced by imposing einops over the backend systems, e.g., what is the runtime gap between einops implementations and direct usage of the backend systems' interfaces.\n+ Lastly, I feel lost about the discussion about the difference between einops and numpy einsum. As far as I learn, the interface looks similar (at least from coding examples). As so, I would expect some clear and concrete statements about the distinguish components of einops (different from einsum).",
            "summary_of_the_review": "This paper introduces an interesting tensor manipulating library in Python, supporting Einstein-notation style operations over multi-dimensional arrays for deep learning. The library manages to run the convenient interface over different popular deep learning frameworks. \n\nHowever, there is a lack of solid empirical study to validate the effectiveness and efficiency of the design and clear discussion about the difference from the existing tool, i.e., einsum. ",
            "correctness": "2: Several of the paper’s claims are incorrect or not well-supported.",
            "technical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "empirical_novelty_and_significance": "2: The contributions are only marginally significant or novel.",
            "flag_for_ethics_review": [
                "NO."
            ],
            "recommendation": "3: reject, not good enough",
            "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
        }
    ]
}