{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "This paper is unfortunately quite unclear and unreadable and nowhere near ready for any conference.\n I would advise the authors to 1) restructure their paper to present first some type of context and identify a problem that they are trying to solve, 2) explain what novel method they propose to solve the identified problem and why this method is promising and how it relates to existing methods, 3) explain what their experiments are trying to do and what the results of the experiments are, 4) enlist someone fluent in English to help with writing and re-reading.\n A way to do this is to find a set of well-cited papers in the same domain with similar ideas and see how they are structured, then try to follow similar outlines."
    },
    "Reviews": [
        {
            "title": "Presentation hinders work.",
            "rating": "2: Strong rejection",
            "review": "The paper is still extremely poorly written and presented despite multiple reviewers asking to address that issue. The frequent spelling mistakes and incoherent sentences and unclear presentation make reading and understanding the paper very difficult and time consuming. Consider getting help from someone with good english and presentation skills.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "hard to understand what is going on",
            "rating": "3: Clear rejection",
            "review": "The authors seems to have proposed a genetic algorithm for learning the features of a convolutional network (LeNet-5 to be precise). The algorithm is validated on some version of the MNIST dataset. \n\nUnfortunately the paper is extremely hard to understand and it is not at all clear what the exact training algorithm is. Neither do the authors ever motivate why do such a training as opposed to the standard back-prop. What are its advantages/dis-advantages? Furthermore the experimental section is equally unclear. The authors seem to have merged the training and validation set of the MNIST dataset and use only a subset of it. It is not clear why is that the case and what subset they use. In addition, to the best of my understanding, the results reported are RMSE as opposed to classification error. Why is that the case? \n\nIn short, the paper is extremely hard to follow and it is not at all clear what the training algorithm is and how is it better than standard way of training. The experimental section is equally confusing and unconvincing. \n\nOther comments: \n-- The figures still say LeCun-5\n-- The legends of the plots are not in english. Hence I'm not sure what is going on there. \n-- The paper is riddled with typos and hard to understand phrasing. ",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "still difficult to understand",
            "rating": "3: Clear rejection",
            "review": "Unfortunately, this paper is very difficult to understand.  The current version of this paper seems improved compared to the initial version, but still far from a finished level.  I'd encourage the authors to keep editing over the language and presentation.\n\nI also think it would be good to also try answering some of the following questions very clearly in the paper:\n\n- What is the advantage, if any, of the proposed algorithm over SGD?  What is the motivation and goal of the work beyond MNIST benchmarking?\n\n- Why are few training examples used?  Is this a scenario in which the system might have an advantage?\n\n- Concretely describe the genetic algorithms terminology used in the algorithm descriptions, and what each term means in the context of the convolutional network.\n\n- Try to make sure that the method, as described, can be understood by a reader without much prior background on genetic algorithms.\n\n- A single experiment on MNIST is too small to adequately describe the algorithm performance.  Consider using a second or third dataset and/or experimental application.\n\nMuch work is still needed on the paper's writing before it can be understood well enough.  I hope that some of this might be useful in helping to improve. I would encourage the authors to try to find outside readers, preferably fluent in English, to work with on a frequent basis before resubmitting to another venue.\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}