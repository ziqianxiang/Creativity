{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "Interesting paper but not over the accept bar."
    },
    "Reviews": [
        {
            "title": "Interesting thought experiment, but strong concerns about the practicality of the approach",
            "rating": "5: Marginally below acceptance threshold",
            "review": "The submission proposes to modify the typical GAN architecture slightly to include \"encrypt\" (Alice) and \"decrypt\" (Bob) modules as well as a module trying to decrypt the signal without a key (Eve).  Through repeated transmission of signals, the adversarial game is intended to converge to a system in which Alice and Bob can communicate securely (or at least a designated part of the signal should be secure), while a sophisticated Eve cannot break their code.  Examples are given on toy data:\n\"As a proof-of-concept, we implemented Alice, Bob, and Eve networks that take N-bit random plain-text and key values, and produce N-entry floating-point ciphertexts, for N = 16, 32, and 64.  Both plaintext and key values are uniformly distributed.\"\n\nThe idea considered here is cute.  If some, but not necessarily all of the signal is meant to be secure, the modules can learn to encrypt and decrypt a signal, while an adversary is simultaneously learned that tries to break the encryption.  In this way, some of the data can remain unencrypted, while the portion that is e.g. correlated with the encrypted signal will have to be encrypted in order for Eve to not be able to predict the encrypted part.\n\nWhile this is a nice thought experiment, there are significant barriers to this submission having a practical impact:\n1) GANs, and from the convergence figures also the objective considered here, are quite unstable to optimize.  The only guarantees of privacy are for an Eve that is converged to a very strong adversary (stronger than a dedicated attack over time).  I do not see how one can have any sort of reliable guarantee of the safety of the data transmission from the proposed approach, at least the paper does not outline such a guarantee.\n2) Public key encryption systems are readily available, computationally feasible, and successfully applied almost anywhere.  The toy examples given in the paper do not at all convince me that this is solving a real-world problem at this point.  Perhaps a good example will come up in the near future, and this work will be shown to be justified, but until such an example is shown, the approach is more of an interesting thought experiment.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Very creative application of adversarial training to cryptography with some weaknesses in the toy examples",
            "rating": "6: Marginally above acceptance threshold",
            "review": "The paper deals with an interesting application of adversarial training to encryption. It considers the standard scenario of Alice, Eve and Bob, where A and B aim to exchange messages conditioned on a shared key, while Eve should be unable to encrypt the message. Experiments are performed in a simple symmetric 16 bit encryption task, and an application on privacy. The concepts, ideas and previous literature are quite nicely and carefully presented.\n\nThe only major concern I have - and I apologize to the authors for not raising this earlier - are the experiments in section 3. In particular, I don't quite get the scenario. The reasoning here seems to be as follows: given information < A, B, C, D >, I want to give the public the value of D (e.g. movies watched) without releasing information about C (e.g. gender). In this scenario, Eve would need to be able to reconstruct D as good as possible without gaining information about C. What is described in section 3, however, is that D and D-public are both reconstructed by Bob, but why would Bob reconstruct the latter (he is not public, in particular because he is allowed to reconstruct C, which is not tested here)? Also, Eve only tries to estimate C, thus rendering the scenario not different in any way to the scenario considered in section 2.\n\nI have two more minor concerns:\n\n1) As raised in the pre-review, Eve should actually be stronger then Alice and Bob in order to be able to compensate for the missing key. The authors noted they have been doing these experiments and are going to add the results.\n\n2) In any natural encryption case I would expect the length of the key to be much shorter then the length of the message. This, however, could potentially make the scenario much easier for Eve (although I doubt any of the results will change if the key is long enough).\n\nI like the creative application of adversarial training to a completely different domain, and I believe it could be the starting point of a very interesting direction in cryptographic systems or in privacy applications (although it is unclear whether the weak guarantees of neural network based approaches can ever be overcome). At the same time the application in the privacy setting leaves me quite confused, and the symmetric encryption example is not particularly strong either. I'd appreciate if the authors could address the major concern I raised above, and I will be quite happy to raise the score in case this confusion can be resolved.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This paper proposed to use GAN for encrypted communications.\n\nIn section 2, the authors proposed a 3 part neural network trained to encode and decode data. This model does not have any practical value except paving the way for describing the next model in section 3: it is strictly worse than any provable cryptography system.\n\nIn section 3, the authors designed a task where they want to hide part of the data, which has correlated fields, while publishing the rest. However, I'm having trouble thinking of an application where this system is better than simply decorrelating the data and encrypting the fields one wants to hide with a provable cryptography system while publishing the rest in plain text.",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}