{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR committee final decision",
        "comment": "This approach taken in this paper is topical, especially since the importance of sampling and generating diverse samples is increasingly discussed in work on generative models. There were several concerns from reviewers, in three areas particularly: connection and comparison to related work; lack of clarity and understanding of the paper; experiments that are not sufficiently convincing. These have been addressed to some extent by the authors, discussing in more detail the related work, especially in connection to Rezende et al., and GSN of Bengio et al., and with improved figures. But these points are still of concern especially in terms of assessing sample diversity in relation to much of the recent work on richer variational posterior methods and other techniques. For these reasons, the paper is not yet ready for acceptance at this years conference."
    },
    "Reviews": [
        {
            "title": "Review",
            "rating": "3: Clear rejection",
            "review": "The authors argues that the standard ancestral sampling from stochastic autoencoders (such as the Variational Autoencoder and the Adversarial\nAutoencoder) imposes the overly-restrictive constraint that the encoder distribution must marginally match the latent variable prior. They propose, as an alternative, a Markov Chain Monte Carlo approach that avoids the need to specify a simple parametric form for the prior.\n\nThe paper is not clearly written. Most critically, the notation the authors use is either deeply flawed, or there are simple misunderstanding with respect to the manipulations of probability distributions. For example, the authors seem to suggest that both distributions Q(Z|X) and Q(X|Z) are parametrized. For this to be true the model must either be trivially simple, or an energy-based model. There is no indication that they are speaking of an energy-based model. Another example of possible confusion is the statement that the ratio of distributions Q(Z|X)/P(Z) = 1. I believe this is supposed to be a ratio of marginals: Q(Z)/P(X) = 1. Overall, it seems like there is a confusion of what Q and P represent. The standard notation used in VAEs is to use P to represent the decoder distribution and\nQ to represent the encoder distribution. This seems not to be how the authors are using these terms. Nor does it seem like there is a single consistent interpretation. \n\nThe empirical results consist entirely of qualitative results (samples and reconstructions) from a single dataset (CelebA). The samples are also not at all up to the quality of the SOTA models. The interpolations shown in Figures 1 and 3 both seems to look like interpolation in pixel space for both the VAE model and the proposed DVAE. \n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "rating": "3: Clear rejection",
            "review": "The authors propose to sample from VAEs through a Markov chain [z_t ~ q(z|x=x_{t-1}), x_t ~ p(x|z=z_t)]. The paper uses confusing notation, oversells the novelty, ignoring some relevant previous results. The qualitative difference between regular sampling and this Gibbs chain is not very convincing, judging from the figures. It would be a great workshop paper (perhaps more), if the authors fix the notation, fix the discussion to related work, and produce more convincing (perhaps simply upscaled?) figures.\n\nComments: \n - Rezende et al's (2014) original VAE paper already discusses the Markov chain, which is ignored in this paper\n - Notation is nonstandard / confusing. At page 1, it’s unclear what the authors mean with “p(x|z) which is approximated as q(x|z)”.\n- It’s also not clear what’s meant with q(z). At page 2, q(z) is called the learned distribution, while p(z) can in general also be a learned distribution.\n- It’s not true that it’s impossible to draw samples from q(z): one can sample x ~ q(x) from the dataset, then draw z ~ q(z|x).\n- It's not explained whether the analysis only applies to continuous observed spaces, or also discrete observed spaces\n- Figures 3 and 4 are not very convincing.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "",
            "rating": "3: Clear rejection",
            "review": "This paper attempts to learn a Markov chain to estimate a probability distribution over latent variables Z, such that P(X | Z) can be eased to generate samples from a data distribution.\n\nThe paper in its current form is not acceptable due to the following reasons:\n1. No quantitative evaluation. The authors do include samples from the generative model, which however are insufficient to judge performance of the model. See comment 2.\n2. The description of the model is very unclear. I had to indulge in a lot of charity to interpret what the authors \"must be doing\". What does Q(Z) mean? Does it mean the true posterior P(Z | X) ? What is the generative model here? Typically, it's P(Z)P(X|Z). VAEs use a variational approximation Q(Z | X) to the true posterior P(Z | X). Are you trying to say that your model can sample from the true posterior P(Z | X)?\n\nComments:\n1. Using additive noise in the input does not seem like a reasonable idea. Any justification of why this is being done?\n2. Approaches which learn transition operators are usually very amenable to data augmentation-based semi-supervised learning. I encourage the authors to improve their paper by testing their model on semi-supervised learning benchmarks.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}