{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "This paper provides two approaches to question answering: pointing to spans, and use of match-LSTM. The models are evaluated on SQuAD and MSMARCO. The reviewers we satisfied that, with the provision of additional comparisons and ablation studies submitted during discussion, the paper was acceptable to the conference, albeit marginally so.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "",
            "rating": "6: Marginally above acceptance threshold",
            "review": "SUMMARY.\nThis paper proposes a new neural network architectures for solving the task of reading comprehension question answering where the goal is answering a questions regarding a given text passage.\nThe proposed model combines two well-know neural network architectures match-lstm and pointer nets.\nFirst the passage and the questions are encoded with a unidirectional LSTM.\nThen the encoded words in the passage and the encoded words in the questions are combined with an attention mechanism so that each word of the passage has a certain degree of compatibility with the question.\nFor each word in the passage the word representation and the weighted representation of the query is concatenated and passed to an forward lstm.\nThe same process is done in the opposite direction with a backward lstm.\nThe final representation is a concatenation of the two lstms.\nAs a decoded a pointer network is used.\nThe authors tried with two approaches: generating the answer word by word, and generating the first index and the last index of the answer.\n\nThe proposed model is tested on the Stanford Question Answering Dataset.\nAn ensemble of the proposed model achieves performance close to state-of-the-art models.\n\n\n----------\n\nOVERALL JUDGMENT\n\nI think the model is interesting mainly because of the use of pointer networks as a decoder.\nOne thing that the authors could have tried is a multi-hop approach. It has been shown in many works to be extremely beneficial in the joint encoding of passage and query. The authors can think of it as a deep match-lstm.\nThe analysis of the model is interesting and insightful.\nThe sharing of the code is good.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review: Interesting combination of existing approaches with encouraging results",
            "rating": "6: Marginally above acceptance threshold",
            "review": "The paper looks at the problem of locating the answer to a question in a text (For this task the answer is always part of the input text). For this the paper proposes to combine two existing works: Match-LSTM to relate question and text representations and Pointer Net to predict the location of the answer in the text.\n\nStrength:\n-\tThe suggested approach makes sense for the task and achieves good performance, (although as the authors mention, recent concurrent works achieve better results)\n-\tThe paper is evaluated on the SQuAD dataset and achieves significant improvements over prior work.\n\n\nWeaknesses:\n1.\tIt is unclear from the paper how well it is applicable to other problem scenarios where the answer is not a subset of the input text.\n2.\tExperimental evaluation\n2.1.\tIt is not clear why the Bi-Ans-Ptr in Table 2 is not used for the ensemble although it achieves the best performance.\n2.2.\tIt would be interested if this approach generalizes to other datasets.\n\n\nOther (minor/discussion points)\n-\tThe task and approach seem to have some similarity of locating queries in images and visual question answering. The authors might want to consider pointing to related works in this direction.\n-\tI am wondering how much this task can be seen as a “guided extractive summarization”, i.e. where the question guides the summarization process.\n-\tPage 6, last paragraph: missing “.”: “… searching This…”\n\n\n\nSummary:\nWhile the paper presents an interesting combination of two approaches for the task of answer extraction, the novelty is moderate. While the experimental results are encouraging, it remains unclear how well this approach generalizes to other scenarios as it seems a rather artificial task.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "More analyses / ablation studies / insights needed regarding the functioning of the proposed model",
            "rating": "7: Good paper, accept",
            "review": "Summary:\nThe paper presents a deep neural network for the task of machine comprehension on the SQuAD dataset. The proposed model is based on two previous works -- match-LSTM and Pointer Net. Match-LSTM produces attention over each word in the given question for each word in the given passage, and sequentially aggregates this matching of each word in the passage with the words in the question. The pointer net is used to generate the answer by either generating each word in the answer or by predicting the starting and ending tokens in the answer from the provided passage. The experimental results show that both the variants of the proposed model outperform the baseline presented in the SQuAD paper. The paper also shows some analysis of the results obtained such as variation of performance across answer lengths and question types.\n\nStrengths:\n1. A novel end-to-end model for the task of machine comprehension rather than using hand-crafted features.\n2. Significant performance boost over the baseline presented in the SQuAD paper.\n3. Some insightful analyses of the results such as performance is better when answers are short, \"why\" questions are difficult to answer.\n\nWeaknesses/Questions/Suggestions:\n1. The paper does not show quantitatively how much modelling attention in match-LSTM and answer pointer layer helps. So, it would be insightful if authors could compare the model performance with and without attention in match-LSTM, and with and without attention in answer pointer layer.\n2. It would be good if the paper could provide some insights into why there is a huge performance gap between boundary model and sequence model in the answer pointer layer.\n3. I would like to see the variation in the performance of the proposed model for questions that require different types of reasoning (table 3 in SQuAD paper). This would provide insights into what are the strengths and weaknesses of the proposed model w.r.t the type reasoning required.\n4. Could authors please explain why the activations resulting from {h^p}_i and {h^r}_{i-1} in G_i in equation 2 are being repeated across dimension of Q. Why not learn different activations for each dimension? \n5. I wonder why Bi-Ans-Ptr is not used in the ensemble model (last row in table 2) when it is shown that Bi-Ans-Ptr improves performance by 1.2% in F1.\n6. Could authors please discuss and compare the DCR model (in table 2) in the paper in more detail?\n\nReview Summary: The paper presents a reasonable end-to-end model for the task of machine comprehension on the SQuAD dataset, which outperforms the baseline model significantly. However, it would be good if more analyses / ablation studies / insights are included regarding -- how much attention helps, why is boundary model better than sequence model, how does the performance change when the reasoning required becomes difficult.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}