{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "Reviewers agreed that the problem was important and the method was interesting and novel. The main (shared) concerns were preliminary nature of the experiments and questions around scalability to more classes. \n \n During the discussion phase, the authors provided additional CIFAR-100 results and introduced a new approximate but scalable method for performing inference. I engaged the reviewers in discussion, who were originally borderline, to see what they thought about the changes. R2 championed the paper, stating that the additional experiments and response re: scalability were an improvement. On the balance, I think the paper is a poster accept.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Training with Noisy Labels",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This work address the problem of supervised learning from strongly labeled data with label noise. This is a very practical and relevant problem in applied machine learning.  The authors note that using sampling approaches such as EM isn't effective, too slow and cannot be integrated into end-to-end training. Thus, they propose to simulate the effects of EM by a noisy adaptation layer, effectively a softmax, that is added to the architecture during training, and is omitted at inference time. The proposed algorithm is evaluated on MNIST and shows improvements over existing approaches that deal with noisy labeled data.\n\nA few comments.\n1. There is no discussion in the work about the increased complexity of training for the model with two softmaxes. \n\n2. What is the rationale for having consecutive (serialized) softmaxes, instead of having a compound objective with two losses, or a network with parallel losses and two sets of gradients?\n\n3. The proposed architecture with only two hidden layers isn't not representative of larger and deeper models that are practically used, and it is not clear that shown results will scale to bigger networks. \n\n4. Why is the approach only evaluated on MNIST, a dataset that is unrealistically simple.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting paper but lack of experiments",
            "rating": "7: Good paper, accept",
            "review": "The paper addressed the erroneous label problem for supervised training. The problem is well formulated and the presented solution is novel. \n\nThe experimental justification is limited. The effectiveness of the proposed method is hard to gauge, especially how to scale the proposed method to large number of classification targets and whether it is still effective.\n\nFor example, it would be interesting to see whether the proposed method is better than training with only less but high quality data. \n\nFrom Figure 2, it seems with more data, the proposed method tends to behave very well when the noise fraction is below a threshold and dramatically degrades once passing that threshold. Analysis and justification of this behavior whether it is just by chance or an expected one of the method would be very useful. \n\n ",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "This paper investigates how to make neural nets be more robust to noise in the labels",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper looks at how to train if there are significant label noise present.\nThis is a good paper where two main methods are proposed, the first one is a latent variable model and training would require the EM algorithm, alternating between estimating the true label and maximizing the parameters given a true label.\n\nThe second directly integrates out the true label and simply optimizes the p(z|x).\n\nPros: the paper examines a training scenario which is a real concern for big dataset which are not carefully annotated.\nCons: the results on mnist is all synthetic and it's hard to tell if this would translate to a win on real datasets.\n\n- comments:\nEquation 11 should be expensive, what happens if you are training on imagenet with 1000 classes?\nIt would be nice to see how well you can recover the corrupting distribution parameter using either the EM or the integration method. \n\nOverall, this is an OK paper. However, the ideas are not novel as previous cited papers have tried to handle noise in the labels. I think the authors can make the paper better by either demonstrating state-of-the-art results on a dataset known to have label noise, or demonstrate that a method can reliably estimate the true label corrupting probabilities.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}