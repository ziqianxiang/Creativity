{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "This paper presents two ways that MMDs can be used to aid the GAN training framework. The relation to current literature is clearly explained, and the paper has illuminating side-experiments. The main con is that it's not clear if MMD-based training will be competitive in the long run with more flexible, but harder-to-use, neural network based approaches. However, this paper gives us a conceptual framework to evaluate new proposals for related GAN training procedures.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "interesting paper",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper provides an interesting idea to use the optimized MMD for generative model evaluation and learning. Starting from the test power, the authors justified the criterion. Moreover, they also provided an efficient implementation of perturbation tests for empirical MMD. \n\nPros:\n\n1) The criterion is principled which is derived from the test power. \n2) The criterion can be used to detect the difference template by incorporating ARD technique. \n3) By exploiting kernel in the objective, the generated algorithm, t-GMMN, training can be improved from the GMMN.\n\nCons:\n\n1) How to train the provided t objective is not clear. \n2) The algorithm is only tested on MNIST dataset as model criticism and learning objective. Comprehensive empirical comparison to the state-of-the-art criteria, e.g., log-likelihood, and other learning objectives is missing. ",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting paper with a good theoretical section",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "A well written paper that proposes to use MMD to distinguish generated and reference data. The primary contribution of this paper is to derive a way to optimize the MMD kernels to maximize the test power of the two sample test. \n\nPros\n\nPrincipled approach; derivations start from first principles and the theoretical results will probably be applicable to other applications of two sample tests.\n\nWell written; puts the contributions and related approaches into context and explains connections to previous work; especially to GANs.\n\nCons: I donâ€™t expect that this work will have a big impact in the field:\n\nThe two sample test are still quadratic in the number of samples. \n\nExperiments only on toy data sets and on binarized MNIST\n\nIt would be interesting to know in what way this approach fails on e.g. image data (or other complex, high dimensional data where neural network generalize well). I could imagine that the neural network based discriminators in GANs generalize better than kernel based MMD methods. I would like to see follow up work that investigates this in more detail (and potentially profes my intuition wrong).\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good paper",
            "rating": "7: Good paper, accept",
            "review": "This is an interesting paper containing three contributions:\n\n1) An expression for the variance of the quadratic-time MMD estimate, which can be efficiently minimized for kernel selection.\n\n2) Advanced computational optimizations for permutation tests for the quadratic MMD statistic.\n\n3) Crystal-clear examples on the importance of reducing the variance in two-sample testing (Figure 2)\n\nRegarding my criticisms,\n\n1) The conceptual advances in this submission are modest: the use of MMD to train generative models, as well as the importance of variance-reduction in MMD were already known.\n\n2) The quadratic-time MMD test may lead to a discriminator that is \"too good\" in practical applications. Since MMD quickly picks up on pixel-level artifacts, I wonder if its use would be possible to train generators properly on realistic (non-binarized) data. This of course could be addressed by regularizing (smoothing) the kernel bandwidths, and for sure raises an interesting question/trade-off in generative modeling. \n\nOverall, the submission is technically sound and well-written: I recommend it for publication in ICLR 2017.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}