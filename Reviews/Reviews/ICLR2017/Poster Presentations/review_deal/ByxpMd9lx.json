{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "One weak and one positive review without much concrete substance. The third review is positive, but the experiments are not that convincing: the gains from transfer are small in table 3 and in table 2 it is unclear how strong the baselines are. Given how competitive ICLR is, the area chair has no alternative than to unfortunately reject this paper.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Accept",
            "rating": "7: Good paper, accept",
            "review": "Authors' response well answered my questions. Thanks!\nEvaluation not changed.\n\n###\n\nThis paper proposes a hierarchical framework of transfer learning for sequence tagging, which is expected to help the target task with the source task, by sharing as many levels of representation as possible. It is a general framework for various neural models. The paper has extensive and solid experiments, and the performance is competitive with the state of the art on multiple benchmark datasets. The framework is clear by itself, except that more details about training procedure, i.e. sec-3.3, need to be added. \n\nThe experimental results show that for some task pairs {s,t}, this framework can help low-resource target task t, and the improvement increases with more levels of representations can be shared. Firstly, I suggest that the terms *source* and *target* should be more precisely defined in the current framework, because, due to Sec-3.3, the s and t in each pair are sort of interchangeable. That is, either of them can be the *source* or *target* task, especially when p(X=s)=p(X=t)=0.5 is used in the task sampling. The difference is: one is low-resourced and the other is not. Thus it could be thought of as multi-tasking between tasks with imbalanced resource. So one question is: does this framework simultaneously help both tasks in the pair, by learning more generalizable representations for different domains/applications/languages? Or is it mostly likely to only help the low-resourced one? Does it come with sacrifice on the high-resourced side? \n\nSecondly, as the paper shows that the low-resourced tasks are improved for the selected task pairs, it would also be interesting and helpful to know how often this could happen. That is, when the tasks are randomly paired (one chosen from a low-resource pool and the other from a high resource pool), how often could this framework help the low-resourced one?\n\nMoreover, the choice of T-A/T-B/T-C lies intuitively in how many levels of representation *could* be shared as possible. This implicitly assumes share more, help more. Although I tend to believe so, it would be interesting to have some empirical comparison. For example, one could perhaps select some cross-domain pair, and see if T-A > T-B > T-C on such pairs, as mentioned in the authorâ€™s answer to the pre-review question. \n\nIn general, I think this is a solid paper, and more exploration could be done in this direction. So I tend to accept this paper. ",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting research direction, but the scientific advances are limited and the experiments are not very convincing.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "The authors propose transfer learning variants for neural-net-based models, applied to a bunch of NLP tagging tasks.\n\nThe field of multi-tasking is huge, and the approaches proposed here do not seem to be very novel in terms of machine learning: parts of a general architecture for NLP are shared, the amount of shared \"layers\" being dependent of the task of interest.\n\nThe novelty lies in the type of architecture which is used in the particular setup of NLP tagging tasks.\n\nThe experimental results show that the approach seems to work well when there is not much labeled data available (Figure 2). Table 3 show some limited improvement at full scale.\n\nFigure 2 results are debatable though: it seems the authors fixed the architecture size while varying the amount of labeled data; it is very likely that tuning the architecture for each size would have led to better results.\n\nOverall, while the paper reads well, the novelty seems a bit limited and the experimental section seems a bit disappointing.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Accept",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "This paper presents a clear hierarchical taxonomy of transfer learning methods as applicable to sequence tagging problems. This contextualizes and unifies previous work on specific instances of this taxonomy. Moreover, the paper shows that previously unexplored places in this taxonomy are competitive with or superior to the state of the art in key benchmark problems.\n\nIt'd be nice to see this explored further, such as highlighting what is the loss as you move from the more restrictive to the less restrictive transfer learning approaches, but I believe this paper is interesting and acceptable as-is.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}