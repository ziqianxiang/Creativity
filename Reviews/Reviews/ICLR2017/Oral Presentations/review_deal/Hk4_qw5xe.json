{
    "Decision": {
        "title": "ICLR committee final decision",
        "comment": "The paper provides a detailed analysis of the instability issues surrounding the training of GANs. They demonstrate how perturbations can help with improving stability. Given the popularity of GANs, this paper is expected to have a significant impact.",
        "decision": "Accept (Oral)"
    },
    "Reviews": [
        {
            "title": "review of ``TOWARDS PRINCIPLED METHODS FOR TRAINING GENERATIVE ADVERSARIAL NETWORKS'' ",
            "rating": "7: Good paper, accept",
            "review": "SUMMARY \nThis paper addresses important questions about the difficulties in training generative adversarial networks. It discusses consequences of using an asymmetric divergence function and sources of instability in training GANs. Then it proposes an alternative using a smoothening approach. \n\nPROS \nTheory, good questions, nice answers. \nMakes an interesting use of concepts form analysis and differential topology. \nProposes avenues to avoid instability in GANs. \n\nCONS \nA bit too long, technical. Some parts and consequences still need to be further developed (which is perfectly fine for future work). \n\nMINOR COMMENTS\n\n- Section 2.1 Maybe shorten this section a bit. E.g., move all proofs to the appendix. \n\n- Section 3 provides a nice, intuitive, simple solution. \n\n- On page 2 second bullet. This also means that P_g is smaller than the data distribution in some other x, which in turn will make the KL divergence non zero. \n\n- On page 2, ``for not generating plausibly looking pictures'' should be ``for generating not plausibly looking pictures''.  \n\n- Lemma 1 would also hold in more generality. \n\n- Theorem 2.1 seems to be basic analysis. (In other words, a reference could spare the proof). \n\n- In Theorem 2.4, it would be good to remind the reader about p(z). \n\n- Lemma 2 seems to be basic analysis. (In other words, a reference could spare the proof). \nSpecify the domain of the random variables. \n\n- relly - > rely \n\n- Theorem 2.2 the closed manifolds have boundary or not? (already in the questions)\n\n- Corollary 2.1, ``assumptions of Theorem 1.3''. I could not find Theorem 1.3. \n\n- Theorem 2.5 ``Therefore'' -> `Then'? \n\n- Theorem 2.6 ``Is a... '' -> `is a' ? \n\n- The number of the theorems is confusing. \n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "very interesting submission",
            "rating": "10: Top 5% of accepted papers, seminal paper",
            "review": "This is a strong submission regarding one of the most important and recently introduced methods in neural networks - generative adversarial networks. The authors analyze theoretically the convergence of GANs and discuss the stability of GANs. Both are very important. To the best of my knowledge, this is one of the first theoretical papers about GANs and the paper, contrary to most of the submissions in the field, actually provides deep theoretical insight into this architecture. The stability issues regarding GANs are extremely important since the first proposed versions of GANs architecture were very unstable and did not work well in practice. Theorems 2.4-2.6 are novel and introduces mathematical techniques are interesting. I have some technical questions regarding the proof of Theorem 2.5 but these are pretty minor.\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "good submission",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "This paper makes a valuable contribution to provide a more clear understanding of generative adversarial network (GAN) training procedure. \n\nWith the new insight of the training dynamics of GAN, as well as its variant, the authors reveal the reason that why the gradient is either vanishing in original GAN or unstable in its variant. More importantly, they also provide a way to avoid such difficulties by introducing perturbation. I believe this paper will inspire more principled research in this direction. \n\nI am very interested in the perturbation trick to avoid the gradient instability and vanishment. In fact, this is quite related to dropout trick in where the perturbation can be viewed as Bernoulli distribution. It will be great if the connection can be discussed.  Besides the theoretical analysis, is there any empirical study to justify this trick? Could you please add some experiments like Fig 2 and 3 for the perturbated GAN for comparison? ",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}