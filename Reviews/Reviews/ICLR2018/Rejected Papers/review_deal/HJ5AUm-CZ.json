{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "Thank you for submitting your paper to ICLR. The reviewers agree that the idea of sharing the approximating distribution across sets of variables is an interesting one and that the Omniglot experiments are thorough. However, although the authors make the nice addition of some simple examples during the revision period and a new table of quantitative results on Omniglot, the consensus is that the experimental results are not quite persuasive enough for publication. Adding a second dataset, such as mini-imagenet or the youtube faces dataset, would make the paper very strong."
    },
    "Reviews": [
        {
            "title": "Conceptually only incremental; but generally good paper.",
            "rating": "6: Marginally above acceptance threshold",
            "review": "The paper presents some conceptually incremental improvements over the models in “Neural Statistician” and “Generative matching networks”. Nevertheless, it is well written and I think it is solid work with reasonable convincing experiments and good results. Although, the authors use powerful PixelCNN priors and decoders and they do not really disentangle to what degree their good results rely on the capabilities of these autoregressive components.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An interesting work on having VAEs for few-shot generation. Some tuning is need though, I think.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "- Good work on developing VAEs for few-shot learning.\n- Most of the results are qualitative and I reckon the paper was written in haste.\n- The rest of the comments are below:\n\n- 3.1: I got a bit confused over what X actually is:\n -- \"We would like to learn a generative model for **sets X** of the form\".\n --\"... to refer to the **class X_i** ...\".\n -- \"we can lower bound the log-likelihood of each **dataset X** ...\"\n\n- 3.2: \"In general, if we wish to learn a model for X in which each latent variable ci affects some arbitrary subset Xi of the data (**where the Xi may overlap**), ...\": Which is just like learning a Z for a labeled X but learning it in an unsupervised manner, i.e. the normal VAE, isn't it? If not, could you please elaborate on what is different (in the case of 3.2 only, I mean)? i.e. Could you please elaborate on what's different (in terms of learning) between 3.2 and a normal latent Z that is definitely allowed to affect different classes of the data without knowing the classes?\n\n- Figure 1 is helpful to clarify the main idea of a VHE.\n\n- \"In a VHE, this recognition network takes only small subsets of a class as input, which additionally ...\": And that also clearly leads to loss of information that could have been used in learning. So there is a possibility for potential regularization but there is definitely a big loss in estimation power. This is obviously possible with any regularization technique, but I think it is more of an issue here since parts of the data are not even used in learning.\n\n- \"Table 4.1 compares these log likelihoods, with VHE achieving state-of-the-art. To\": Where is Table 4.1??\n\n- This is a minor point and did not have any impact on the evaluation but VAE --> VHE, reparameterization trick --> resampling trick. Maybe providing rather original headings is better? It's a style issue that is up to tastes anyway so, again, it is minor.\n\n- \"However, sharing latent variables across an entire class reduces the encoding cost per element is significantly\": typo.\n\n- \"Figure ?? illustrates\".\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting, though still avoiding the toughest questions",
            "rating": "7: Good paper, accept",
            "review": "This paper presents an alternative approach to constructing variational lower bounds on data log likelihood in deep, directed generative models with latent variables. Specifically, the authors propose using approximate posteriors shared across groups of examples, rather than posteriors which treat examples independently. The group-wise posteriors allow amortization of the information cost KL(group posterior || prior) across all examples in the group, which the authors liken to the \"KL annealing\" tricks that are sometimes used to avoid posterior collapse when training models with strong decoders p(x|z) using current techniques for approximate variational inference in deep nets.\n\nThe presentation of the core idea is solid, though it did take two read-throughs before the equations really clicked for me. I think the paper could be improved by spending more time on a detailed description of the model for the Omniglot experiments (as illustrated in Figure 3). E.g., explicitly describing how group-wise and per-example posteriors are composed in this model, using Equations and pseudo-code for the main training loop, would have saved me some time. For readers less familiar with amortized variational inference in deep nets, the benefit would be larger.\n\nI appreciate that the authors developed extensions of the core method to more complex group structures, though I didn't find the related experiments particularly convincing. \n\nOverall, I like this paper and think the underlying group-wise posterior construction trick is worth exploring further. Of course, the elephant in the room is how to determine the groups across which the posteriors can be shared and their information costs amortized.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}