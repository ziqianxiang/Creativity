{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "All 3 reviewers consider the paper insufficiently good, including a post-rebuttal updated score.\nAll reviewers + anonymous comment find that the paper isn't well-enough situated with the appropriate literature.\nTwo reviewers cite poor presentation - spelling /grammar errors making hte paper hard to read.\nAuthors have revised the paper and promise further revisions for final version.\n"
    },
    "Reviews": [
        {
            "title": "Interesting motivation and formulation",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper introduces a machine learning adaptation of the active inference framework proposed by Friston (2010), and applies it to the task of image classification on MNIST through a foveated inspection of images. It describes a cognitive architecture for the same, and provide analyses in terms of processing compression and \"confirmation biases\" in the model.\n– Active perception, and more specifically recognition through saccades (or viewpoint selection) is an interesting biologically-inspired approach and seems like an intuitive and promising way to improve efficiency. The problem and its potential applications are well motivated.\n– The perception-driven control formulation is well-detailed and simple to follow.\n– The achieved compression rates are significant and impressive, though additional demonstration of performance on more challenging datasets would have been more compelling\n\nQuestions and comments:\n– While an 85% compression rate is significant, 88% accuracy on MNIST seems poor. A plot demonstrating the tradeoff of \naccuracy for compression (by varying Href or other parameters) would provide a more complete picture of performance. Knowing baseline performance (without active inference) would help put numbers in perspective by providing a performance bound due to modeling choices.\n– What does the distribution of number of saccades required per recognition (for a given threshold) look like over the entire dataset, i.e. how many are dead-easy vs difficult?\n– Steady state assumption: How can this be relaxed to further generalize to non-static scenes?\n– Figure 3 is low resolution and difficult to read.\n\nPost-rebuttal comments:\n\nI have revised my score after considering comments from other reviewers and the revised paper. While the revised version contains more experimental details, the paper in its present form lacks comparisons to other gaze selection and saliency models which are required to put results in context. The paper also contains grammatical errors and is somewhat difficult to understand. Finally, while it proposes an interesting formulation of a well-studied problem, more comparisons and analysis are required to validate the approach.\n",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Promising work about the analogy between active vision and the free energy principle but currently quite preliminary",
            "rating": "3: Clear rejection",
            "review": "It is rather difficult to evaluate the manuscript. A large part of the manuscript reviews various papers from the active vision domain and subsequently proposes that this can directly be modeled using Friston’s free energy principle, essentially, by “analogy”, as the authors state. This extends up to page 4. I would argue, that this is quite a stretch, as the free energy principle is essentially blind to the idea of rewards and preferable states such that all tasks are essentially evaluated in terms surprise reduction. This is very much different from large part of the cited classic active vision literature. The authors furthermore introduce a simplification of the setting, i.e. that nothing changes in a scene during saccadic exploration, which is rather unusual for active vision problems. \nThe authors provide some detail about the actual implementation of their model, section 4, but the in depth details required at ICLR are missing. No comparisons to other gaze selection models or saliency models are given. \nFurthermore, the manuscript seems to suggest, that the simulation results are somehow related to human vision as it is stated:\n“The model provides apparently realistic saccades, for they cover the full range of the image and tend to point over regions that contain class-characteristic pixels.”\nbut no actual comparisons or evaluations are provided. ",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Incremental. Needs editing.",
            "rating": "3: Clear rejection",
            "review": "In this paper, the authors present a computational framework for the active vision problem. Motivating the study biologically, the authors explain how the control policy can be learned to reduce the entropy of the posterior belief, and present an application (MNIST digit classification) to substantiate their proposal.\n\nI am not convinced about the novelty and contribution of the work. The active vision/sensing problem has been well studied and both the information theory and Bayes risk formulations have already been considered in previous works (see Najemnik and Geisler, 2005; Butko and Movellan, 2010; Ahmad and Yu, 2013).\n\nThe paper is also rife with spelling mistakes and grammatical errors and needs a thorough revision. Examples: foveate inspection the data (abstract), may allow to (motivation), tu put it clear (motivation), on contrary to animals retina (footnote 1), minimize at most the current uncertainty (perception-driven control), center an keep (fovea-based implementation), degrade te recognition (outlook and perspective). The citations are in non-standard format (section 1.2: Kalman (1960)).\n\nOverall, I think the paper considers an important problem but the contribution to the state of the art is minimal, and editing highly lacking. \n\n1. J Najemnik and W S Geisler. Optimal eye movement strategies in visual search. Nature, 434(7031):387–91, 2005.\n2. N J Butko and J R Movellan. Infomax control of eye movements. IEEE Transactions on Autonomous Mental Development, 2(2):91–107, 2010.\n3. S Ahmad and A J Yu. Active sensing as Bayes-optimal sequential decision-making. Uncertainty in Artificial Intelligence, 2013.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}