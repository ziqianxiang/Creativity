{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "This work introduces a new type of structured attention network that learn latent structured alignments between sentences in a fully differentiable manner, which allows the network to learn not only the target task, but also the latent relationships. Reviewers seem partial to the idea of the work, and it's originality, but have issues with the contributions. In particular:\n\n- The reviewers note that the gains in performance from using this approach are quite small and do not outperform previous structured approaches."
    },
    "Reviews": [
        {
            "title": "Review",
            "rating": "6: Marginally above acceptance threshold",
            "review": "Summary:\nThis paper introduces a structured attention mechanisms to compute alignment scores among all possible spans in two given sentences. The span representations are weighted by the spans marginal scores given by the inside-outside algorithm. Experiments on TREC-QA and SNLI show modest improvement over the word-based structured attention baseline (Parikh et al., 2016).\n\nStrengths:\nThe idea of using latent syntactic structure, and computing cross-sentence alignment over spans is very interesting. \n\nWeaknesses:\nThe paper is 8.5 pages long.\n\nThe method did not out-perform other very related structured attention methods (86.8, Kim et al., 2017, 86.9, Liu and Lapata, 2017)\n\nAside from the time complexity from the inside-outside algorithm (as mentioned by the authors in conclusion), the comparison among all pairs of spans is O(n^4), which is more expensive. Am I missing something about the algorithm?\n\nIt would be nice to show, quantitatively, the agreement between the latent trees and gold/supervised syntax. The paper claimed “the model is able to recover tree structures that very closely mimic syntax”, but it’s hard to draw this conclusion from the two examples in Figure 2.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An intriguing idea, a few weaknesses however.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper describes the use of latent context-free derivations, using\na CRF-style neural model, as a latent level of representation in neural\nattention models that consider pairs of sentences. The model implicitly\nlearns a distribution over derivations, and uses marginals under this\ndistribution to bias attention distributions over spans in one sentence\ngiven a span in another sentence.\n\nThis is an intriguing idea. I had a couple of reservations however:\n\n* The empirical improvements from the method seem pretty marginal, to the\npoint that it's difficult to know what is really helping the model. I would\nliked to have seen more explanation of what the model has learned, and\nmore comparisons to other baselines that make use of attention over spans.\nFor example, what happens if every span is considered as an independent random\nvariable, with no use of a tree structure or the CKY chart?\n\n* The use of the \\alpha^0 vs. \\alpha^1 variables is not entirely clear. Once they\nhave been calculated in Algorithm 1, how are they used? Do the \\rho values\nsomewhere treat these two quantities differently?\n\n* I'm skeptical of the type of qualitative analysis in section 4.3, unfortunately.\nI think something much more extensive would be interesting here. As one\nexample, the PP attachment example with \"at a large venue\" is highly suspect;\nthere's a 50/50 chance that any attachment like this will be correct, there's\nabsolutely no way of knowing if the model is doing something interesting/correct\nor performing at a chance level, given a single example. ",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Structured alignment networks",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper proposes a model of \"structured alignments\" between sentences as a means of comparing two sentences by matching their latent structures. Overall, this paper seems a straightforward application of the model first proposed by Kim et al. 2017 with latent tree attention.\n\nIn section 3.1, the formula for p(c|x) looks wrong: c_{ijk} are indicator variables. but where are the scores for each span? I think it should be c_{ijk} * \\delta_{ijk} under the summations instead.\n\nIn the same section, the expression for \\alpha_{ij} seems to assume that \\delta_{ijk} = \\dlta_{ij} regardless of k. I.e. there are no production rule scores (transitions). This seems rather limiting, can you comment on that?\n\nIn the answer selection and NLI experiments, the proposed model does not beat the SOTA, and is only marginally better than unstructured decomposable attention. This is rather disappointing.\n\nThe plots in Fig 2 with the marginals on CKY charts are not very enlightening. How do this marginals help solving the NLI task?\n\nMinor comments:\n- Sec. 3: \"Language is inherently tree structured\" -- this is debatable...\n- page 8: (laf, 2008): bad formatted reference",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}