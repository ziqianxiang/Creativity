{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "This work is incremental compared to previous work, solving very specific challenges, and would probably appeal to only a very limited fraction of ICLR's audience. "
    },
    "Reviews": [
        {
            "title": "Review of \"BC SbT NMF\"",
            "rating": "6: Marginally above acceptance threshold",
            "review": "In this paper, the authors present an adaptation of space-by-time non-negative matrix factorization (SbT-NMF) that can rigorously account for the pre-stimulus baseline activity. The authors go on to compare their baseline-corrected (BC) method with several established methods for dimensionality reduction of spike train data.\n\nOverall, the results are a bit mixed. The BC method often performs similarly to or is outperformed by non-BC SbT-NMF. The authors provide a possible mechanism to explain these results, by analyzing classification performance as a function of baseline firing rate. The authors posit that their method can be useful when sensory responses are on the order of magnitude of baseline activity; however, this doesn't fully address why non-BC SbT-NMF can strongly outperform the BC method in certain tasks (e.g. the step of light, Fig. 3b). Finally, while this method introduces a principled way to remove mean baseline activity from the sensory-driven response, this may also discount the effect that baseline firing rate and fast temporal fluctuations can have on the response (Destexhe et al., Nature Reviews Neuroscience 4, 2003; Gutnisky DA et al., Cerebral Cortex 27, 2017).",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A baseline subtracted Tucker2 modeling approach with non-negativity to model time binned spike trains of recordings of neural activity. The paper is technically sound but the work appears somewhat incremental.",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This study proposes the use of non-negative matrix factorization accounting for baseline by subtracting the pre-stimulus baseline from each trial and subsequently decompose the data using a 3-way factorization thereby identifying spatial and temporal modules as well as their signed activation. The method is used on data recorded from mouse and pig retinal ganglion cells of time binned spike trains providing improved performance over non-baseline corrected data. \n\nPros:\nThe paper is well written, the analysis interesting and the application of the Tucker2 framework sound. Removing baseline is a reasonable step and the paper includes analysis of several spike-train datasets. The analysis of the approaches in terms of their ability to decode is also sound and interesting.\n\nCons:\nI find the novelty of the paper limited: \nThe authors extend the work by (Onken et al. 2016) to subtract baseline (a rather marginal innovation) of this approach. To use a semi-NMF type of update rule (as proposed by Ding et al .2010) and apply the approach to new spike-train datasets evaluating performance by their decoding ability (decoding also considered in Onken et al. 2016).\n\nMultiplicative update-rules are known to suffer from slow-convergence and I would suspect this also to be an issue for the semi-NMF update rules. It would therefore be relevant and quite easy to consider other approaches such as active set or column wise updating also denoted HALS which admit negative values in the optimization, see also the review by N. Giles\nhttps://arxiv.org/abs/1401.5226\nas well as for instance:\nNielsen, Søren Føns Vind, and Morten Mørup. \"Non-negative tensor factorization with missing data for the modeling of gene expressions in the human brain.\" Machine Learning for Signal Processing (MLSP), 2014 IEEE International Workshop on. IEEE, 2014.\n\nIt would improve the paper to also discuss that the non-negativity constrained Tucker2 model may be subject to local minima solutions and have issues of non-uniqueness (i.e. rotational ambiguity). At least local minima issues could be assessed using multiple random initializations.\n\nThe results are in general only marginally improved by the baseline corrected non-negativity constrained approach. For comparison the existing methods ICA, Tucker2 should also be evaluated for the baseline corrected data, to see if it is the constrained representation or the preprocessing influencing the performance. Finally, how performance is influenced by dimensionality P and L should also be clarified.\n\nIt seems that it would be naturally to model the baseline by including mean values in the model rather than treating the baseline as a preprocessing step. This would bridge the entire framework as one model and make it potentially possible to avoid structure well represented by the Tucker2 representation to be removed by the preprocessing.\n\n\n\nMinor: \nThe approach corresponds to a Tucker2 decomposition with non-negativity constrained factor matrices and unconstrained core - please clarify this as you also compare to Tucker2 in the paper with orthogonal factor matrices.\n\nDing et al. in their semi-NMF work provide elaborate derivation with convergence guarantees.  In the present paper these details are omitted and it is unclear how the update rules are derived from the KKT conditions and the Lagrange multiplier and how they differ from standard semi-NMF, this should be better clarified. \n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review of baseline-corrected space-by-time non-negative matrix factorization for decoding single trial population spike trains",
            "rating": "6: Marginally above acceptance threshold",
            "review": "In this contribution, the authors propose an improvement of a tensor decomposition method for decoding spike train. Relying on a non-negative matrix factorization, the authors tackle the influence of the baseline activity on the decomposition. The main consequence is that the retrieved components are not necessarily non-negative and the proposed decomposition rely on signed activation coefficients. An experimental validation shows that for high frequency baseline (> 0.7 Hz), the baseline corrected algorithm yields better classification results than non-corrected version (and other common factorization techniques). \n\nThe objective function is defined with a Frobenius norm, which has an important influence on the obtained solutions, as it could be seen on Figure 2. The proposed method seems to provide a more discriminant factorization than the NMF one, at the expense of the sparsity of spatial and temporal components, impeding the biological interpretability.  A possible solution is to add a regularization term to the objective function to ensure the sparsity of the factorization.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}