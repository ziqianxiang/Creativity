{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "While the reviewers all seem to think this is interesting and basically good work, the Reviewers are consistent and unanimous in rejecting the paper.\nWhile the authors did provide a thorough rebuttal, the original paper did not meet the criteria and the reviewers have not changed their scores."
    },
    "Reviews": [
        {
            "title": "Review of \"Deep Learning Inferences with Hybrid Homomorphic Encryption\"",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The paper presents a means of evaluating a neural network securely using homomorphic encryption. A neural network is already trained, and its weights are public. The network is to be evaluated over a private input, so that only the final outcome of the computation-and nothing but that-is finally learned.\n\nThe authors take a binary-circuit approach: they represent numbers via a fixed point binary representation, and construct circuits of secure adders and multipliers, based on homomorphic encryption as a building block for secure gates. This allows them to perform the vector products needed per layer; two's complement representation also allows for an \"easy\" implementation of the ReLU activation function, by \"checking\" (multiplying by) the complement of the sign bit. The fact that multiplication often involves public weights is used to speed up computations, wherever appropriate. A rudimentary  experimental evaluation with small networks is provided.\n\nAll of this is somewhat straightforward; a penalty is paid by representing numbers via fixed point arithmetic, which is used to deal with ReLU mostly. This is somewhat odd: it is not clear why, e.g., garbled circuits where not used for something like this, as it would have been considerably faster than FHE.\n\nThere is also a work in this area that the authors do not cite or contrast to, bringing the novelty into question; please see the following papers and references therein:\n\nGILAD-BACHRACH, R., DOWLIN, N., LAINE, K., LAUTER, K., NAEHRIG, M., AND WERNSING, J. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy. In Proceedings of The 33rd International Conference on Machine Learning (2016), pp. 201–210.\n\nSecureML: A System for Scalable Privacy-Preserving Machine Learning\nPayman Mohassel and Yupeng Zhang\n\nSHOKRI, R., AND SHMATIKOV, V. Privacy-preserving deep learning. In\nProceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security (2015), ACM, pp. 1310–1321.\n\nThe first paper is the most related, also using homomorphic encryption, and seems to cover a superset of the functionalities presented here (more activation functions, a more extensive analysis, and faster decryption times). The second paper uses arithmetic circuits rather than HE, but actually implements training an entire neural network securely.\n\n Minor details:\n\nThe problem scenario states that the model/weights is private, but later on it ceases to be so (weights are not encrypted).\n\n\"Both deep learning and FHE are relatively recent paradigms\". Deep learning is certainly not recent, while Gentry's paper is now 7 years old.\n\n\"In theory, this system alone could be used to compute anything securely.\" This is informal and incorrect. Can it solve the halting problem?\n\n\"However in practice the operations were incredibly slow, taking up to 30 minutes in some cases.\" It is unclear what operations are referred to here.\n\n\n\n\n\n\n\n\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Deep Learning Inferences with Hybrid Homomorphic Encryption",
            "rating": "4: Ok but not good enough - rejection",
            "review": "Summary:\nThis paper proposes a framework for private deep learning model inference using FHE schemes that support fast bootstrapping.\nThe main idea of this paper is that in the two-party computation setting, in which the client's input is encrypted while the server's deep learning model is plain.\nThis \"hybrid\" argument enables to reduce the number of necessary bootstrapping, and thus can reduce the computation time.\nThis paper gives an implementation of adder and multiplier circuits and uses them to implement private model inference.\n\nComments:\n1. I recommend the authors to tone down their claims. For example, the authors mentioned that \"there has been no complete implementation of established deep learning approaches\" in the abstract, however, the authors did not define what is \"complete\". Actually, the SecureML paper in S&P'17 should be able to privately evaluate any neural networks, although at the cost of multi-round information exchanges between the client and server.\n\nAlso, the claim that \"we show efficient designs\" is very thin to me since there are no experimental comparisons between the proposed method and existing works. Actually, the level FHE can be very efficient with a proper use of message packing technique such as [A] and [C]. For a relatively shallow model (as this paper has used), level FHE might be faster than the binary FHE.\n\n2. I recommend the author to compare existing adder and multiplier circuits with your circuits to see in what perspective your design is better. I think the hybrid argument (i.e., when one input wire is plain) is a very common trick that used in the circuit design field, such as garbled circuit [B], to reduce the depth of the circuit. \n\n3. I appreciate that optimizations such as low-precision and point-wise convolution are discussed in this paper. Such optimizations are very common in deep learning field while less known in the field of security.\n\n[A]: Dowlin et al. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy.\n[B]: V. Kolesnikov et al. Improved garbled circuit: free xor gates and applications. \n[C]: Liu et al. Oblivious Neural Network Predictions via MiniONN transformations.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "This paper proposes a hybrid Homomorphic  encryption system that is well suited for privacy-sensitive data inference applications with the deep learning paradigm. The research methodology is well organized, its rationale well explained and supports the stated problem resolution, the obtained results are interesting  and the paper is well written (commendable). ",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This paper proposes a hybrid Homomorphic encryption system that is well suited for privacy-sensitive data inference applications with the deep learning paradigm. \nThe paper presents a well laid research methodology that shows a good decomposition of the problem at hand and the approach foreseen to solve it. It is well reflected in the paper and most importantly the rationale for the implementation decisions taken is always clear.\n\nThe results obtained (as compared to FHEW) seem to indicate well thought off decisions taken to optimize the different gates' operations as clearly explained in the paper. For example, reducing bootstrapping operations by two-complementing both the plaintext and the ciphertext, whenever the number of 1s in the plain bit-string is greater than the number of 0s (3.4/Page 6).\n\nResult interpretation is coherent with the approach and data used and shows a good understanding of the implications of the implementation  decisions made in the system and the data sets used.\nOverall, fine work, well organized, decomposed, and its rationale clearly explained. The good results obtained support the design decisions made.\nOur main concern is regarding thorough comparison to similar work and provision of comparative work assessment to support novelty claims.\n\nNota: \n     - In Figure 4/Page 4: AND Table A(1)/B(0), shouldn't  A And B be 0?\n     - Unlike Figure 3/Page 3, in Figure 2/page 2, shouldn't  operations' precedence prevail (No brackets), therefore 1+2*2=5?",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}