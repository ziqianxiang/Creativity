{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "meta score: 4\n\nThe paper has been extensively edited during the review process - the edits are so extensive that I think the paper requires a re-review, which is not possible for ICLR 2018\n\nPros:\n - potentially interesting and novel approach to prefix encoding for character level CNN text classification\n - some experimental comparisons\nCons:\n - lacks good comparison with the state-of-the-art, which makes it difficult to determine conclusions\n - writing style lacks clarity.\n\nI would recommend that the authors continue to improve the paper and submit it to a later conference.\n"
    },
    "Reviews": [
        {
            "title": "Main idea lacks significance",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The paper proposed to encode text into a binary matrix by using a compressing code for each word in each matrix row. The idea is interesting, and overall introduction is clear.\n\nHowever, the work lacks justification for this particular way of encoding, and no comparison for any other encoding mechanism is provided except for the one-hot encoding used in Zhang & LeCun 2015. The results using this particular encoding are not better than any previous work.\n\nThe network architecture seems to be arbitrary and unusual. It was designed with 4 convolutional layers stacked together for the first layer, while a common choice is to just make it one convolutional layer with 4 times the output channels. The depth of the network is only 5, even with many layers listed in table 5.\n\nIt uses 1-D convolution across the word dimension (inferred from the feature size in table 5), which means the convolutional layers learn intra-word features for the entire text but not any character-level features. This does not seem to be reasonable.\n\nOverall, the lack of comparisons and the questionable choices for the networks render this work lacking significance to be published in ICLR 2018.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review",
            "rating": "2: Strong rejection",
            "review": "This paper proposes a new character encoding scheme for use with character-convolutional language models. This is a poor quality paper, is unclear in the results (what metric is even reported in Table 6), and has little significance (though this may highlight the opportunity to revisit the encoding scheme for characters).",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "The manuscript needs updating. The current state is not good enough.",
            "rating": "3: Clear rejection",
            "review": "The manuscript proposed to use prefix codes to compress the input to a neural network for text classification. It builds upon the work by Zhang & LeCun (2015) where the same tasks are used.\n\n\nThere are several issues with the paper and I cannot recommend acceptance of the paper in the current state. \n- It looks like it is not finished.\n- the datasets are not described properly. \n- It is not clear to me where the baseline results come from.\n They do not match up to the Zhang paper (I have tried to find the matching accuracies there).\n- It is not clear to me what the baselines actually are or how I can found more info on those.\n- the results are not remarkable. \n\nBecause of this, the paper needs to be updated and cleaned up before it can be properly reviewed. \n\nOn top of this, I do not enjoy the style the paper is written in, the language is convoluted. \nFor example: “The effort to use Neural Convolution Networks for text classification tasks is justified by the possibility of appropriating tools from the recent developments of techniques, libraries and hardware used especially in the image classification “\nI do not know which message the paper tries to get across here. \nAs a reviewer my impression (which is subjective) is that the authors used difficult language to make the manuscript look more impressive.\nThe acknowledgements should not be included here either. \n\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}