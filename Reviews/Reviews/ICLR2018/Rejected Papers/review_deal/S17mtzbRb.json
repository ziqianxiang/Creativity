{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The paper proposes two regularizers for encouraging \"clustered feature embeddings\" (use of \"disentangled\" in the title is misleading). Reviewers have raised points about the lack of proper motivation and justification of the regularizers. There are also concerns on the experiments conducted to evaluate the method, including for hierarchical classification setting. Missing comparison with relevant baselines has also been pointed out as a weakness. I feel the work is not yet mature. "
    },
    "Reviews": [
        {
            "title": "Needs comparison to other baselines",
            "rating": "5: Marginally below acceptance threshold",
            "review": "Summary\nThis paper proposes two regularizers that are intended to make the\nrepresentations learned in the penultimate layer of a classifier more conforming\nto inherent structure in the data, rather than just the class structure enforced\nby the classifier. One regularizer encourages the weights feeding into the\npenultimate layer to be dissimilar and the other encourages the activations\nacross samples (even if they belong to the same class) to be dissimilar.\n\nPros\n- The proposed regularizers are able to separate out the classes inherent in the\n  data, even if this information is not provided through class labels. This is\nvalidated on several datasets using visualizations as well as quantitative\nmetrics based on mutual information.\n\nCons\n- It is not explained why it makes sense to first convert the weight vectors\n  into probability distributions by applying the softmax function, and then\nmeasuring distances using KL divergence between the probability distributions.\nIt should be explained more clearly if there is there a natural interpretation\nof the weight vectors as probability distributions. Otherwise it is not obvious\nwhy the distance between the weight vectors is measured the way it is.\n\n- Similarly, the ReLU activations are also first converted into probability\n  distributions by applying a softmax. It should be explained why the model does\nthis, as opposed to simply using dot products to measure similarity.\n\n- The model is not compared to simpler alternatives such as adding an\n  orthogonality regularization on the weights, i.e., computing W^TW and making\nthe diagonals close to 1 and all other terms 0. Similar regularizers can be\napplied for activation vectors as well.\n\n- The objective of this paper seems to be to produce representations that are\n  easy to separate into clusters. This topic has a wealth of previous work. Of\nparticular relevance are methods such as t-SNE [1], parametric t-SNE [2], and\nDEC [3]. The losses introduced in this paper are fairly straight-forward.\nTherefore it would be good to compare to these baselines to show that a simple\nloss function is sufficient to achieve the objective.\n\n- Disentangling usually refers to disentangling factors of variation, for\n  example, lighting, pose, and object identity which affect the appearance of a\ndata point. This is different from separability, which is the property of a\nrepresentation that makes the presence of clusters evident. This paper seems to\nbe about learning separable representations, whereas the title suggests that it\nis about disentangled ones. \n\nQuality\nThe design choices made in the paper (such as the choice of distance function)\nis not well explained. Also, given that the modifications introduced are quite\nsimple, it can be improved by doing more thorough comparisons to other\nbaselines.\n\nClarity\nThe paper is easy to follow.\n\nOriginality\nThe novel aspect of the paper is the way distance is measured by converting the\nweights (and activations) to probability distributions and using KL divergence\nto measure distance. However, it is not explained what motivated this choice.\n\nSignificance\nThe objective of this model is to produce representations that are separable, which\nis of general interest. However, given the wealth of previous work done in\nclustering, this paper would only be impactful if it compares to other hard\nbaselines and shows clear advantages.\n\n[1] van der Maaten, Laurens and Hinton, Geoffrey. Visualizing\ndata using t-SNE. JMLR, 2008.\n\n[2] van der Maaten, Laurens. Learning a parametric embedding\nby preserving local structure. In International Conference\non Artificial Intelligence and Statistics, 2009.\n\n[3] Junyuan Xie, Ross Girshick, and Ali Farhadi. Unsupervised deep embedding for\nclustering analysis. ICML 2016.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Desperately seeking neural network representations to be more useful for clustering tasks",
            "rating": "4: Ok but not good enough - rejection",
            "review": "The paper proposes techniques for encouraging neural network representations to be more useful for clustering tasks. The paper contains some interesting experimental results, but unfortunately lacks concise motivation and description of the method and quality of writing.\n\nIntroduction:\nThe introduction is supposed to present the problem and the 'chain of events' that led to this present work, but does not do that. The first paragraph contains a too length explanation that in a classification task, representations are only concerned about being helpful for this task, and not any other task. The paragraph starting with 'Consider the case...', describes in detailed some specific neural network architecture, and what will happen in this architecture during training. The main problem with this paragraph is that it does not belong in the introduction. Indeed, other parts of the introduction have no relation to this paragraph, and the first part of the text that related to this paragraph appears suddenly in Section 3. The fact that this paragraph is two thirds of the introduction text, this is very peculiar.\n\nFurthermore, the introduction does not present the problem well: \n1) What does is a better representation for a clustering task?\n2) Why is that important?\n\nMethod:\nThere are a few problematic statements in this part:\n\"The first loss component L_single works on a single layer and does not affect the other layers in the network\". This is not exactly true, because it affect the layer it's related to, which affect upper layers through their feedforward input or bottom layer through the backward pass. \n\"Recall from the example in the introduction that we want to force the model to produce divergent representations for the samples that belong to the same class, but are in fact substantively different from each other\". It is not clear why this is a corollary of the example in the introduction (that should be moved to the method part). \n\"this loss component may help to learn a better representation only if the input to the target layer still contains the information about latent characteristics of the input data\". What does this mean? The representation always contains such information, that is relevant to the task at hand...\nAnd others. The main problem is that the work is poorly explained: starting from the task at hand, through the intuition behind the idea how to solve it. \n\nThe experiments parts contains results that show that the proposed method is superior by a substantial margin over the baseline approaches. However, the evaluation metrics and procedure are poorly explained; What are Adjusted Mutual Information (AMI) and Normalized Mutual Information  (NMI)? How are they calculated? Or at least, the mutual information between what and what are they measuring?\n\n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper proposes two regularization terms to encourage learning disentangled representations.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This paper proposes two regularization terms to encourage learning disentangled representations. One term is applied to weight parameters of a layer just like weight decay. The other is applied to the activations of the target layer (e.g., the penultimate layer). The core part of both regularization terms is a compound hinge loss of which the input is the KL divergence between two softmax-normalized input arguments. Experiments demonstrate the proposed regularization terms are helpful in learning representations which significantly facilitate clustering performance.\n\nPros:\n(1) This paper is clearly written and easy to follow.\n\n(2) Authors proposed multiple variants of the regularization term which cover both supervised and unsupervised settings.\n\n(3) Authors did a variety of classification experiments ranging from time serials, image and text data.\n\nCons:\n(1) The design choice of the compound hinge loss is a bit arbitrary. KL divergence is a natural similarity measure for probability distribution. However, it seems that authors use softmax to force the weights or the activations of neural networks to be probability distributions just for the purpose of using KL divergence. Have you compared with other choices of similarity measure, e.g., cosine similarity? I think the comparison as an additional experiment would help explain the design choice of the proposed function.\n\n(2) In the binary classification experiments, it is very strange to almost randomly group several different classes of images into the same category. I would suggest authors look into datasets where the class hierarchy is already provided, e.g., ImageNet or a combination of several fine-grained image classification datasets.\n\nAdditionally, I have the following questions:\n(1) I am curious how the proposed method compares to other competitors in terms of the original classification setting, e.g., 10-class classification accuracy on CIFAR10. \n(2) What will happen for the multi-layer loss if the network architecture is very large such that you can not use large batch size, e.g., less than 10? \n\n(3) In drawing figure 2 and 3, if the nonlinear activation function is not ReLU, how would you exam the same behavior? Have you tried multi-class classification for the case “without proposed loss component” and does the similar pattern still happen or not?\n\nSome typos:\n(1) In introduction, “when the cosine between the vectors 1” should be “when the cosine between the vectors is 1”.\n\n(2) In section 4.3, “we used the DBPedia ontology dataset dataset” should be “we used the DBPedia ontology dataset”. \n\nI would like to hear authors’ feedback on the issues I raised.\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}