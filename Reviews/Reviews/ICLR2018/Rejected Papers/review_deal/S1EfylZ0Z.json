{
    "Decision": {
        "decision": "Reject",
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The authors propose to detect anomaly based on its representation quality in the latent space of the GAN trained on valid samples.\n\nReviewers agree that:\n- The proposed solution lacks novelty and similar approaches have been tried before.\n- The baselines presented in the paper are primitive and hence do not demonstrate the clear benefits over traditional approaches.\n"
    },
    "Reviews": [
        {
            "title": "anomaly detection scheme using GANs",
            "rating": "4: Ok but not good enough - rejection",
            "review": "Authors propose an anomaly detection scheme using GANs. It relies on a realistic assumption: points that are badly represented in the latent space of the generator are likely to be anomalous. Experiments are given in a classification and unsupervised context.\nIn the introduction, authors state that traditional algorithms \"often fail when applied to high dimensional objects\". Such claim should be supported by strong references as oc-svm or k-pca based anomaly detection algorithms (see Hoffman 2007) perform well in this context.\nOC-SVM is a well-known technique that gives similar performances: authors fail at convincing that there are advantages of using the proposed framework, which do not strongly differs from previously published AnoGAN.\nThe underlying assumption of the algorithm (points badly represented by GANs are likely to be anomalous) justifies the fact that anomalies should be detected by the algorithm (type-I error). What is the rationale behind the type-II error? Is it expected to be small as well? What happens with adversarial examples for instance?\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "interesting paper with minor weakness",
            "rating": "6: Marginally above acceptance threshold",
            "review": "The paper is about doing anomaly detection for image data. The authors use a GAN based approach where it is trained in a standard way. After training is completed, the generator's latent space is explored to find a representation for a test image. Both the noise variable and generator model is updated using back propagation to achieve this. The paper is original, well written, easy to follow and presented ideas are interesting. \n\nStrengths:\n- anomaly detection for images is a difficult problem and the paper uses current state of the art in generative modeling (GAN) to perform anomaly detection.\n- experiments section includes non-parametric methods such as OC-SVM as well as deep learning methods including a recent GAN based approach and the results are promising. \n\nWeaknesses:\n - It is not clear why updating the generator during the anomaly detection helps. On evaluating on a large set of anomalies, the generator may run a risk of losing its ability to generate the original data if it is adjusted too much to the anomalies. The latent space of the generator no longer is the same that was achieved by training on the original data. I don't see how this is not a problem in the presented approach.\n- The experimental results on data with ground truth needs statistical significance tests to convince that the benefits are indeed significant. \n- It is not clear how the value of \"k\" (number of updates to the noise variable) was chosen and how sensitive it is to the performance. By having a large value of k, the reconstruction loss for an anomalous image may reduce to fall into the nominal category. How is this avoided?",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Experimental baselines are too primitive.",
            "rating": "4: Ok but not good enough - rejection",
            "review": "In the paper, the authors proposed using GAN for anomaly detection.\nIn the method, we first train generator g_\\theta from a dataset consisting of only healthy data points.\nFor evaluating whether the data point x is anomalous or not, we search for a latent representation z such that x \\approx g_\\theta(z).\nIf such a representation z could be found, x is deemed to be healthy, and anomalous otherwise.\nFor searching z, the authors proposed a gradient-descent based method that iteratively update z.\nMoreover, the authors proposed updating the parameter \\theta of the generator g_\\theta.\nThe authors claimed that this parameter update is one of the novelty of their method, making it different from the method of Schlegl et al. (2017).\nIn the experiments, the authors showed that the proposed method attained the best AUC on MNIST and CIFAR-10.\n\nIn my first reading of the paper, I felt that the baselines in the experiments are too primitive.\nSpecifically, for KDE and OC-SVM, a naive PCA is used to reduce the data dimension.\nNowadays, there are several publicly available CNNs that are trained on large image datasets such as ImageNet.\nThen, one can use such CNNs as feature extractor, that will give better low dimensional expression of the data than the naive PCA.\nI believe that the performances of KDE and OC-SVM can be improved by using such feature extractors.\n\nAdditionally, I found that some well-known anomaly detection methods are excluded from the comparison.\nIn Emmott et al. (2013), which the authors referred as a related work, it was reported that Isolation Forest and Ensemble of GMMs performed well on several datasets (better than KDE and OC-SVM).\nIt would be essential to add these methods as baselines to be compared with the proposed method.\n\nOverall, I think the experimental results are far from satisfactory.\n\n\n### Response to Revision ###\nIt is interesting to see that the features extracted from AlexNet are not helpful for anomaly detection.\nIt would be interesting to see whether features extracted from middle layers are helpful or they are still useless.\nI greatly appreciate the authors for their extensive experiments as a response to my comments.\nHowever, I have decided to keep my score unchanged, as the additional experiments have shown that the performance of the proposed method is not significantly better than the other methods.\nIn particular, in MNIST, GMM performed better.",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}