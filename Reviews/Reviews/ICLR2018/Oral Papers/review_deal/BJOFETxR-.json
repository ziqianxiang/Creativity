{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "There was some debate between the authors and an anonymous commentator on this paper.  The feeling of the commentator was that existing work (mostly from the PL community) was not compared to appropriately and, in fact, performs better than this approach.  The authors point out that their evaluation is hard to compare directly but that they disagreed with the assessment.  They modified their texts to accommodate some of the commentator's concerns; agreed to disagree on others; and promised a fuller comparison to other work in the future.\n\nI largely agree with the authors here and think this is a good and worthwhile paper for its approach.\n\nPROS:\n1. well written\n2. good ablation study\n3. good evaluation including real bugs identified in real software projects\n4. practical for real world usage\n\nCONS:\n1. perhaps not well compared to existing PL literature or on existing datasets from that community\n2. the architecture (GGNN) is not a novel contribution",
        "decision": "Accept (Oral)"
    },
    "Reviews": [
        {
            "title": "Interesting software mining application with substantial validation",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "This paper presents a novel application of machine learning using Graph NN's on ASTs to identify incorrect variable usage and predict variable names in context. It is evaluated on a corpus of 29M SLOC, which is a substantial strength of the paper.\n\nThe paper is to be commended for the following aspects:\n1) Detailed description of GGNNs and their comparison to LSTMs\n2) The inclusion of ablation studies to strengthen the analysis of the proposed technique\n3) Validation on real-world software data\n4) The performance of the technique is reasonable enough to actually be used.\n\nIn reviewing the paper the following questions come to mind:\n1) Is the false positive rate too high to be practical?  How should this be tuned so developers would want to use the tool?\n2) How does the approach generalize to other languages? (Presumably well, but something to consider for future work.)\n\nDespite these questions, though, this paper is a nice addition to deep learning applications on software data and I believe it should be accepted.\n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Beautiful application, nicely evaluated.  Evaluation could be a bit better, but easily fixed.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "Summary:  The paper applies graph convolutions with deep neural networks to the problem of \"variable misuse\" (putting the wrong variable name in a program statement) in graphs created deterministically from source code.  Graph structure is determined by program abstract syntax tree (AST) and next-token edges, as well as variable/function name identity, assignment and other deterministic semantic relations.  Initial node embedding comes from both type and tokenized name information.  Gated Graph Neural Networks (GGNNs, trained by maximum likelihood objective) are then run for 8 iterations at test time.\n\nThe evaluation is extensive and mostly very good.  Substantial data set of 29m lines of code.  Reasonable baselines.  Nice ablation studies.  I would have liked to see separate precision and recall rather than accuracy.  The current 82.1% accuracy is nice to see, but if 18% of my program variables were erroneously flagged as errors, the tool would be useless.  I'd like to know if you can tune the threshold to get a precision/recall tradeoff that has very few false warnings, but still catches some errors.\n\nNice work creating an implementation of fast GGNNs with large diverse graphs.  Glad to see that the code will be released.  Great to see that the method is fast---it seems fast enough to use in practice in a real IDE.\n\nThe model (GGNN) is not particularly novel, but I'm not much bothered by that.  I'm very happy to see good application papers at ICLR.  I agree with your pair of sentences in the conclusion: \"Although source code is well understood and studied within other disciplines such as programming language research, it is a relatively new domain for deep learning. It presents novel opportunities compared to textual or perceptual data, as its (local) semantics are well-defined and rich additional information can be extracted using well-known, efficient program analyses.\"  I'd like to see work in this area encouraged.  So I recommend acceptance.  If it had better (e.g. ROC curve) evaluation and some modeling novelty, I would rate it higher still.\n\nSmall notes:\nThe paper uses the term \"data flow structure\" without defining it.\nYour data set consisted of C# code.  Perhaps future work will see if the results are much different in other languages.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Creative and interesting",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "The paper introduces an application of Graph Neural Networks (Li's Gated Graph Neural Nets, GGNNs, specifically) for reasoning about programs and programming. The core idea is to represent a program as a graph that a GGNN can take as input, and train the GGNN to make token-level predictions that depend on the semantic context. The two experimental tasks were: 1) identifying variable (mis)use, ie. identifying bugs in programs where the wrong variable is used, and 2) predicting a variable's name by consider its semantic context.\n\nThe paper is generally well written, easy to read and understand, and the results are compelling. The proposed GGNN approach outperforms (bi-)LSTMs on both tasks. Because the tasks are not widely explored in the literature, it could be difficult to know how crucial exploiting graphically structured information is, so the authors performed several ablation studies to analyze  this out. Those results show that as structural information is removed, the GGNN's performance diminishes, as expected. As a demonstration of the usefulness of their approach, the authors ran their model on an unnamed open-source project and claimed to find several bugs, at least one of which potentially reduced memory performance.\n\nOverall the work is important, original, well-executed, and should open new directions for deep learning in program analysis. I recommend it be accepted.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}