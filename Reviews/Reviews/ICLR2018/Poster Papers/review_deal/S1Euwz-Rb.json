{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "PROS:\n1. Good results on CLEVER datasets\n2. Writing is clear\n3. The MAC unit is novel and interesting.\n4. Ablation experiments are helpful\n\nCONS:\nThe authors overstate the degree to which they are doing \"sound\" and \"transparent\" reasoning.  In particular statements such as \"Most neural networks are essentially very large correlation engines that will hone in on any statistical, potentially spurious pattern that allows them to model the observed data more accurately. In contrast, we seek to create a model structure that requires combining sound inference steps to solve a problem instance.\" I think are not supported.  As far as I can tell, the authors' do not show that the steps of these solutions are really doing inference in any sound way\n\nI also found the interpretability section to be a bit unconvincing.  The reviewers and I discussed this and there was some attempt to assess what the operations were actually doing but it is not clear how the language and the image attention are linked.\n\nI wonder whether the learned control activations are abstract and re-used across problems the way that the accompanying functional solution's primitives are.  Have you looked at how similar the controls are across problems which are identical except for a different choice of attributes?  To me, one of the hallmarks of a truly \"compositional\" solution is one in which the pieces are re-used across problems, not just that there is some sequence of explicit control activations used to solve each individual problem.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Review",
            "rating": "7: Good paper, accept",
            "review": "This paper describes a new model architecture for machine reasoning. In contrast\nto previous approaches that explicitly predict a question-specific module\nnetwork layout, the current paper introduces a monolithic feedforward network\nwith iterated rounds of attention and memory. On a few variants of the CLEVR\ndataset, it outperforms both discrete modular approaches, existing iterated\nattention models, and the conditional-normalization-based FiLM model. \n\nSo many models are close to perfect accuracy on the standard CLEVR dataset that\nI'm not sure how interesting these results are. In this respect I think the\ncurrent paper's results on CLEVR-Humans and smaller fractions of synthetic CLEVR\nare much more exciting.\n\nOn the whole I think this is a strong paper. I have two main concerns. The\nlargest is that this paper offers very little in the way of analysis. The model\nis structurally quite similar to a stacked attention network or a particular\nfixed arrangement of attentive N2NMN modules, and it's not at all clear based on\nthe limited set of experimental results where the improvements are actually\ncoming from. It's also possible that many of the proposed changes are\ncomplementary to NMN- or CBN-type models, and it would be nice to know if this\nis the case.\n\nSecondarily, the paper asserts that \"our architecture can handle\ndatasets more diverse than CLEVR\", but runs no experiments to validate this. It\nseems like once all the pieces are in place it should be very easy to get\nnumbers on VQA or even a more interesting synthetic dataset like NLVR.\n\nBased on a sibling comment, it seems that there may also be some problems with\nthe comparison to FiLM, and I would like to see this addressed.\n\nOn the whole, the results are probably strong enough on their own to justify\nadmitting this paper. But I will become much more enthusiastic about if if the\nauthors can provide results on other datasets (even if they're not\nstate-of-the-art!) as well as evidence for the following:\n\n1. Does the control mechanism attend to reasonable parts of the sentence?\n\nHere it's probably enough to generate a bunch of examples showing sentence\nattentions evolving over time.\n\n2. Do these induce reasonable attentions over regions of the image?\n\nAgain, examples are fine.\n\n3. Do the self-attention and gating mechanisms recover the right structure?\n\nIn addition to examples, here I think there are some useful qualitative\nmeasures. It should be possible to extract reasonable discretized \"reasoning\nmaps\" by running MST or just thesholding on the \"edge weights\" induced by\nattention and gating. Having extracted these from a bunch of examples, you can\ncompare them to the structural properties of the ground-truth CLEVR network\nlayouts by plotting a comparison of sizes, branching factors, etc.\n\n4. More on the left side of the dataset size / accuracy curve. What happens if\n   you only give the model 7000 examples? 700? 70?\n\nFussy typographical notes:\n\n- This paper makes use of a lot of multi-letter names in mathmode. These are\n  currently written like $KB$, which looks bad, and should instead be\n  $\\mathit{KB}$.\n\n- Variables with both superscripts and subscripts have the superscripts pushed\n  off to the right; I think you're writing these like $b_5 ^d$ but they should\n  just be $b_5^d$ (no space).\n\n- Number equations and then don't bother carrying subscripts like $W_3$, $W_4$\n  around across different parts of the model---this isn't helpful.\n\n- The superscripts indicating the dimensions of parameter matrices and vectors\n  are quite helpful, but don't seem to be explained anywhere in the text. I\n  think the notation $W^{(d \\times d)}$ is more standard than $W^{d, d}$.\n\n- Put the cell diagrams right next to the body text that describes them (maybe even\n  inline, rather than in figures). It's annoying to flip back and forth.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Looks good but needs clarification",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper proposes a recurrent neural network for visual question answering. The recurrent neural network is equipped with a carefully designed recurrent unit called MAC (Memory, Attention and Control) cell, which encourages sequential reasoning by restraining interaction between inputs and its hidden states. The proposed model shows the state-of-the-art performance on CLEVR and CLEVR-Humans dataset, which are standard benchmarks for visual reasoning problem. Additional experiments with limited training data shows the data efficiency of the model, which supports its strong generalization ability.\n\nThe proposed model in this paper is designed with reasonable motivations and shows strong experimental results in terms of overall accuracy and the data efficiency. However, an issue in the writing, usage of external component and lack of experimental justification of the design choices hinder the clear understanding of the proposed model.\n\nAn issue in the writing\nOverall, the paper is well written and easy to understand, but Section 3.2.3 (The Write Unit) has contradictory statements about their implementation. Specifically, they proposed three different ways to update the memory (simple update, self attention and memory gate), but it is not clear which method is used in the end.\n\nUsage of external component\nThe proposed model uses pretrained word vectors called GloVE, which has boosted the performance on visual question answering. This experimental setting makes fair comparison with the previous works difficult as the pre-trained word vectors are not used for the previous works. To isolate the strength of the proposed reasoning module, I ask to provide experiments without pretrained word vectors.\n\nLack of experimental justification of the design choices\nThe proposed recurrent unit contains various design choices such as separation of three different units (control unit, read unit and memory unit), attention based input processing and different memory updates stem from different motivations. However, these design choices are not justified well because there is neither ablation study nor visualization of internal states. Any analysis or empirical study on these design choices is necessary to understand the characteristics of the model. Here, I suggest to provide few visualizations of attention weights and ablation study that could support indispensability of the design choices.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Needs more analysis and qualitative evaluation",
            "rating": "7: Good paper, accept",
            "review": "Summary: \nThe paper presents a new model called Compositional Attention Networks (CAN) for visual reasoning. The complete model consists of an input unit, a sequence of the proposed Memory, Attention and Composition (MAC) cell, and an output unit. Experiments on CLEVR dataset shows that the proposed model outperforms previous models.\n\nStrengths: \n— The idea of building a compositional model for visual reasoning and visual question answering makes a lot of sense, and, I think, is the correct direction to go forward in these fields.\n— The proposed model outperforms existing models pushing the state-of-the-art.\n— The proposed model is computationally cheaper and generalizes well with less training data as compared to existing models.\n— The proposed model has been described in detail in the paper.\n\nWeaknesses: \n— Given that the performance of state-on-art on CLEVR dataset is already very high ( <5% error) and the performance numbers of the proposed model are not very far from the previous models, it is very important to report the variance in accuracies along with the mean accuracies to determine if the performance of the proposed model is statistically significantly better than the previous models.\n— It is not clear which part of the proposed model leads to how much improvement in performance. Ablations studies are needed to justify the motivations for each of the components of the proposed model.\n— Analysis of qualitative results (including attention maps, gate values, etc.) is needed to justify if the model is actually doing what the authors think it should do. For example, the authors mention an example on page 6 at the end of Section 3.2.2, but do not justify if this is actually what the model is doing.\n— Why is it necessary to use both question and memory information to answer the question even when the question was already used to compute the memory information? I would think that including the question information helps in learning the language priors in the dataset. Have the authors looked at some qualitative examples where the model which only uses memory information gives an incorrect answer but adding the question information results in a correct answer?\n— Details such as using Glove word embeddings are important and can affect the performance of models significantly. Therefore, they should be clearly mentioned in the main paper while comparing with other models which do not use them.\n— The comparisons of number of epochs required for training and the training time need fixed batch sizes and CPU/GPU configurations. Is that true? These should be reported in this section.\n— The authors claim that their model is robust to linguistic variations and diverse vocabulary, by which I am guessing they are referring to experiments on CLEVR-Humans dataset. What is there in the architecture of the proposed model which provides this ability? If it is the Glove vectors, it should be clearly mentioned since any other model using Glove vectors should have this ability.\n— On page 6, second paragraph, the authors mention that there are cases which necessitate the model to ignore current memories. Can the authors show some qualitative examples for such cases?\n— In the intro, the authors claim that their proposed cell encourages transparency. But, the design of their cell doesn’t seem to do so, nor it is justified in the paper.\n\nOverall: The performance reported in the paper is impressive and outperforms previous state-of-the-art, but without proper statistical significance analysis of performance, ablation studies, analysis of various attention maps, memory gates, etc. and qualitative results, I am not sure if this work would be directly useful for the research community.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}