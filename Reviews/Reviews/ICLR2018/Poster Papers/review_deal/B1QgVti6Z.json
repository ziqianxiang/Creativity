{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "Based on the positive reviews, I recommend acceptance. The paper analyzes when empirical risk is close to the population version, when empirical saddle points are close to the population version and empirical gradients are close to the population version.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "This theoretical paper lacks rigor and references.",
            "rating": "3: Clear rejection",
            "review": "This paper studies empirical risk in deep neural networks. Results are provided in Section 4 for linear networks and in Section 5 for nonlinear networks.\nResults for deep linear neural networks are puzzling. Whatever the number of layers, a deep linear NN is simply a matrix multiplication and minimizing the MSE is simply a linear regression. So results in Section 4 are just results for linear regression and I do not understand why the number of layers come into play? \nAlso this is never explicitly mentioned in the paper, I guess the authors make an assumption that the samples (x_i,y_i) are drawn i.i.d. from a given distribution D. In such a case, I am sure results on the population risk minimization can be found for linear regression and should be compare to results in Section 4.\n\n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An interesting attempt on uniform convergence of general DNNs",
            "rating": "7: Good paper, accept",
            "review": "This paper provides the analysis of empirical risk landscape for GENERAL deep neural networks (DNNs). Assumptions are comparable to existing results for OVERSIMPLIFED shallow neural networks. The main results analyzed: 1) Correspondence of non-degenerate stationary points between empirical risk and the population counterparts. 2) Uniform convergence of the empirical risk to population risk. 3) Generalization bound based on stability. The theory is first developed for linear DNNs and then generalized to nonlinear DNNs with sigmoid activations.\n\nHere are two detailed comments:\n\n1) For deep linear networks with squared loss, Kawaguchi 2016 has shown that the global optima are the only non-degerenate stationary points. Thus, the obtained non-degerenate stationary deep linear network should be equivalent to the linear regression model Y=XW. Should the risk bound only depends on the dimensions of the matrix W?\n\n2) The comparison with Bartlett & Maassâ€™s (BM) work is a bit unfair, because their result holds for polynomial activations while this paper handles linear activations. Thus, the authors need to refine BM's result for comparison.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review of empirical landscape",
            "rating": "7: Good paper, accept",
            "review": "Overall, this work seems like a reasonable attempt to answer the question of how the empirical loss landscape relates to the true population loss landscape.  The analysis answers:\n\n1) When empirical gradients are close to true gradients\n2) When empirical isolated saddle points are close to true isolated saddle points\n3) When the empirical risk is close to the true risk.\n\nThe answers are all of the form that if the number of training examples exceeds a quantity that grows with the number of layers, width and the exponential of the norm of the weights with respect to depth, then empirical quantities will be close to true quantities.  I have not verified the proofs in this paper (given short notice to review) but the scaling laws in the upper bounds found seem reasonably correct. \n\nAnother reviewer's worry about why depth plays a role in the convergence of empirical to true values in deep linear networks is a reasonable worry, but I suspect that depth will necessarily play a role even in deep linear nets because the backpropagation of gradients in linear nets can still lead to exponential propagation of errors between empirical and true quantities due to finite training data.  Moreover the loss surface of deep linear networks depends on depth even though the expressive capacity does not.   An analysis of dynamics on this loss surface was presented in Saxe et. al. ICLR 2014 which could be cited to address that reviewer's concern.  However, the reviewer's suggestion that the results be compared to what is known more exactly for simple linear regression is a nice one. \n\nOverall, I believe this paper is a nice contribution to the deep learning theory literature. However,  it would even better to help the reader with more intuitive statements about the implications of their results for practice, and the gap between their upper bounds and practice, especially given the intense interest in the generalization error problem.   Because their upper bounds look similar to those based on Rademacher complexity or VC dimension (although they claim theirs are a little tighter) - they should put numbers in to their upper bounds taken from trained neural networks, and see what the numerical evaluation of their upper bounds turn out to be in situations of practical interest where deep networks show good generalization performance despite having significantly less training data than number of parameters.  I suspect their upper bounds will be loose, but still  - it would be an excellent contribution to the literature to quantitatively compare theory and practice with bounds that are claimed to be slightly tigher than previous bounds.  Even if they are loose - identifying the degree of looseness could inspire interesting future work. \n",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}