{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "\nThis submission explores recent theoretical work by Shwartz-Ziv and Tishby on explaining the generalization ability of deep networks. The paper gives counter-examples that suggest aspects of the theory might not be relevant for all neural networks.\n\nThere is some uncertainty surrounding the results where mutual information is estimated empirically. Even state-of-the-art estimation methods might lead to misleading empirical results. However, the submission appears to follow reasonable practice following previous work, making the reported results at least suggestive. They warrant reporting for further study and discussion.\n\nThe reviewers generally found the paper interesting enough for acceptance, however strong objections were posted by Tishby. A lengthy public exchange resulted between the groups of authors. Not every part of this exchange is resolved. It is not clear whether Tishby's group would be able to fix the full-connected ReLU demonstration in this paper, or whether the authors of this submission have anything to say about Tishby's ReLU+convnet demonstration. By accepting this work, we are not declaring where this debate will end. However, we felt the current submission is a constructive part of ongoing discussion in the literature on furthering our theoretical understanding of neural networks.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "An interesting and probably controversial paper, discussing the limitations of the information bottleneck theory for deep learning.",
            "rating": "7: Good paper, accept",
            "review": "The authors address the issue of whether the information bottleneck (IB) theory can provide insight into the working of deep networks. They show, using some counter-examples, that the previous understanding of IB theory and its application to deep networks is limited.\n\nPROS: The paper is very well written and makes its points very clearly. To the extent of my knowledge, the content is original. Since it clearly elucidates the limitations of IB theory in its ability to analyse deep networks, I think it is a significant \ncontribution worthy of acceptance. The experiments are also well designed and executed. \n\nCONS: On the downside, the limitations exposed are done so empirically, but the underlying theoretical causes are not explored (although this could be potentially because this is hard to do). Also, the paper exposes the limitations of another paper published in a non-peer reviewed location (arXiv) which potentially limits its applicability and significance.\n\nSome detailed comments:\n\nIn section 2, the influence of binning on how the mutual information is calculated should be made clear. Since the comparison is between a bounded non-linearity and an unbounded one, it is not self-evident how the binning in the latter case should be done. A justification for the choice made for binning the relu case would be helpful.\n\nIn the same section, it is claimed that the dependence of the mutual information I(X; T) on the magnitude of the weights of the network explains why a tanh non-linearity shows the compression effect (non-monotonicity vs I(X; T)) in the information plane dynamics. But the claim that large weights are required for doing anything useful is unsubstantiated and would benefit from having citations to papaers that discuss this issue. If networks with small weights are able to learn most datasets, the arguments given in this section wouldn't be applicable in its entirety.\n\nAdditionally, figures that show the phase plane dynamics for other non-linearities e.g. relu+ or sigmoid, should be added, at \nleast in the supplementary section. This is important to complete the overall picture of how the compression effect depends on having specific activation functions.\n\nIn section 3, a sentence or two should be added to describe what a \"teacher-student setup\" is, and how it is relevant/interesting.\n\nAlso in section 3, the cases where batch gradient descent is used and where stochastic gradient descent is used should be \npointed out much more clearly. It is mentioned in the first line of page 7 that batch gradient descent is used, but it is not \nclear why SGD couldn't have been used to keep things consistent. This applies to figure 4 too. \n\nIn section 4, it seems inconsistent that the comparison of SGD vs BGD is done using linear network as opposed to a relu network which is what's used in Section 2. At the least, a comparison using relu should be added to the supplementary section.\n\nMinor comments \nThe different figure styles using in Fig 4A and C that have the same quantities plotted makes it confusing.\nAn additional minor comment on the figures: some of the labels are hard to read on the manuscript.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "important contribution to deep learning theory",
            "rating": "7: Good paper, accept",
            "review": "A thorough investigation on Info Bottleneck and deep learning, nice to read with interesting experiments and references. Even though not all of the approach is uncontroversial (as the discussion shows), the paper contributes to much needed theory of deep learning rather than just another architecture. \nEstimating the mutual information could have been handled in a more sophisticated way (eg using a Kraskov estimator rather than simple binning), and given that no noise is usually added the discussion about noise and generalisation doesn't seem to make too much sense to me. \n\nIt would have been good to see a discussion whether another measurement that would be useful for single-sided saturating nonlinearities that do show a compression (eg information from a combination of layers), from learnt representations that are different to representations learnt using double-sided nonlinearities. \n\nRegarding the finite representation of units (as in the discussion) it might be helpful to also consider an implementation of a network with arbitrary precision arithmetic as an additional experiment. \n\nOverall I think it would be nice to see the paper accepted at the very least to continue the discussion. ",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An ongoing debate",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper presents a study on the Information Bottleneck (IB) theory of deep learning, providing results in contrasts to the main theory claims. According to the authors, the IB theory suggests that the network generalization is mainly due to a ‘compression phase’ in the information plane occurring after a ‘fitting phase’ and that the ‘compression phase’ is due to the stochastic gradient decent (SDG). Instead, the results provided by this paper show that: the generalization can happen even without compression; that SDG is not the primary factor in compression; and that the compression does not necessarily occur after the ‘fitting phase’. Overall, the paper tackles the IB theory claims with consistent methodology, thus providing substantial arguments against the IB theory. \n\nThe main concern is that the paper is built to argue against another theoretical work, raising a substantial discussion with the authors of the IB theory. This paper should carefully address all the raised arguments in the main text. \n\nThere are, moreover, some open questions that are not fully clear in this contribution:\n1)\tTo evaluate the mutual information in the ReLu networks (sec. 2) the authors discretize the output activity in their range. Should the non-linearity of ReLu be considered as a form of compression? Do you check the ratio of ReLus that are not active during training or the ratio of inputs that fall into the negative domain of each ReLu? \n2)\tSince one of today common topics is the training of deep neural networks with lower representational precision, could the quantization error due to the low precision be considered as a form of noise inserted in the network layers that influences the generalization performance in deep neural networks? \n3)\tWhat are the main conclusions or impact of the present study in the theory of neural networks? Is it the authors aim to just demonstrate that the IB theory is not correct? Perhaps, the paper should empathize the obtained results not just in contrast to the other theory, but proactively in agreement with a new proposal. \n\nFinally, a small issue comes from the Figures that need some improvement. In most of the cases (Figure 3 C, D; Figure 4 A, B, C; Figure 5 C, D; Figure 6) the axes font is too small to be read. Figure 3C is also very unclear.\n",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}