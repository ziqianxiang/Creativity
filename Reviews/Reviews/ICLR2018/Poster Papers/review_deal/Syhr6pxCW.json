{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The paper proposes a novel method for conditional image generation which is based on nearest neighbor matching for transferring high-frequency statistics. The evaluation is carried out on several image synthesis tasks, where the technique is shown to perform better than an adversarial baseline.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Nice approach on conditional image generation",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "review": "Overall I like the paper and the results look nice in a diverse set of datasets and tasks such as edge-to-image, super-resolution, etc. Unlike the generative distribution sampling of GANs, the method provides an interesting compositional scheme, where the low frequencies are regressed and the high frequencies are obtained by \"copying\" patches from the training set. In some cases the results are similar to pix-to-pix (also in the numerical evaluation) but the method allows for one-to-many image generation, which is a important contribution. Another positive aspect of the paper is that the synthesis results can be analyzed, providing insights for the generation process. \n\nWhile most of the paper is well written, some parts are difficult to parse. For example, the introduction has some parts that look more like related work (that is mostly a personal preference in writting). Also in Section 3, the paragraph for distance functions do not provide any insight about what is used, but it is included in the next paragraph (I would suggest either merging or not highlighting the paragraphs).\n\nQ: The spatial grouping that is happening in the compositional stage, is it solely due to the multi-scale hypercolumns?  Would the result be more inconsistent if the hypercolumns had smaller receptive field?\n\nQ: For the multiple outputs, the k neighbor is selected at random?\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Shines Light on Deficiencies in Conditional GAN: borderline accept",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper presents a pixel-matching based approach to synthesizing RGB images from input edge or normal maps. The approach is compared to Isola et al’s conditional adversarial networks, and unlike the conditional GAN, is able to produce a diverse set of outputs.\n\nOverall, the paper describes a computer visions system based on synthesizing images, and not necessarily a new theoretical framework to compete with GANs. With the current focus of the paper being the proposed system, it is interesting to the computer vision community. However, if one views the paper in a different light, namely showing some “blind-spots” of current conditional GAN approaches like lack of diversity, then it can be of much more interest to the broader ICLR community.\n\nPros: \nOverall the paper is well-written\nMakes a strong case that random noise injection inside conditional GANs does not produce enough diversity\nShows a number of qualitative and quantitative results\n\nConcerns about the paper:\n1.) It is not clear how well the proposed approach works with CNN architectures other than PixelNet\n2.) Since the paper used “the pre-trained PixelNet to extract surface normal and edge maps” for ground-truth generation, it is not clear whether the approach will work as well when the input is a ground-truth semantic segmentation map.\n3.) Since the paper describes a computer-vision image synthesis system and not a new theoretical result, I believe reporting the actual run-time of the system will make the paper stronger. Can PixelNN run in real-time? How does the timing compare to Isola et al’s Conditional GAN?\n\nMinor comments:\n1.) The paper mentions making predictions from “incomplete” input several times, but in all experiments, the input is an edge map, normal map, or low-resolution image. When reading the manuscript the first time, I was expecting experiments on images that have regions that are visible and regions that are masked out. However, I am not sure if the confusion is solely mine, or shared with other readers.\n\n2.) Equation 1 contains the norm operator twice, and the first norm has no subscript, while the second one has an l_2 subscript. I would expect the notation style to be consistent within a single equation (i.e., use ||w||_2^2, ||w||^2, or ||w||_{l_2}^2)\n\n3.) Table 1 has two sub-tables: left and right. The sub-tables have the AP column in different places.\n\n4.) “Dense pixel-level correspondences” are discussed but not evaluated.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Simple and effective baseline for conditional image generation",
            "rating": "7: Good paper, accept",
            "review": "This paper proposes a compositional nearest-neighbors approach to image synthesis, including results on several conditional image generation datasets. \n\nPros:\n- Simple approach based on nearest-neighbors, likely easier to train compared to GANs.\n- Scales to high-resolution images.\n\nCons:\n- Requires a potentially costly search procedure to generate images.\n- Seems to require relevant objects and textures to be present in the training set in order to succeed at any given conditional image generation task.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}