{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "All reviewers agree that the proposed method is novel and experiments do a good job in establishing its value for few-shot learning. Most the concerns raised by the reviewers on experimental protocols have been addressed in the author response and revised version.",
        "decision": "Accept (Poster)"
    },
    "Reviews": [
        {
            "title": "Official Reviewer 2",
            "rating": "7: Good paper, accept",
            "review": "This paper proposes to use graph neural networks for the purpose of few-shot learning, as well as semi-supervised learning and active learning. The paper first relies on convolutional neural networks to extract image features. Then, these image features are organized in a fully connected graph. Then, this graph is processed with an graph neural network framework that relies on modelling the differences between features maps, \\propto \\phi(abs(x_i-x_j)).  For few-shot classification then the cross-entropy classification loss is used on the node.\n\nThe paper has some interesting contributions and ideas, mainly from the point of view of applications, since the basic components (convnets, graph neural networks) are roughly similar to what is already proposed. However, the novelty is hurt by the lack of clarity with respect to the model design.\n\nFirst, as explained in 5.1 a fully connected graph is used (although in Fig. 2 the graph nodes do not have connections to all other nodes). If all nodes are connected to all nodes, what is the different of this model from a fully connected, multi-stream networks composed of S^2 branches? To rephrase, what is the benefit of having a graph structure when all nodes are connected with all nodes. Besides, what is the effect when having more and more support images? Is the generalization hurt?\n\nSecond, it is not clear whether the label used as input in eq. (4) is a model choice or a model requirement. The reason is that the label already appears in the loss of the nodes  in 5.1. Isn't using the label also as input redundant?\n\nThird, the paper is rather vague or imprecise at points.  In eq. (1) many of the notations remain rather unclear until later in the text (and even then they are not entirely clear). For instance, what is s, r, t. \n\nThe experimental section is also ok, although not perfect.  The proposed method appears to have a modest improvement for few-shot learning. However, in the case of  active learning and semi-supervised learning the method is not compared to any baselines (other than the random one), which makes conclusions hard to reach.\n\nIn general, I tend to be in favor of accepting the paper if the authors have persuasive answers and provide the clarifications required.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Novel idea for few-shot learning",
            "rating": "7: Good paper, accept",
            "review": "This paper introduces a graph neural net approach to few-shot learning. Input examples form the nodes of the graph and edge weights are computed as a nonlinear function of the absolute difference between node features. In addition to standard supervised few-shot classification, both semi-supervised and active learning task variants are introduced. The proposed approach captures several popular few-shot learning approaches as special cases. Experiments are conducted on both Omniglot and miniImagenet datasets.\n\nStrengths\n- Use of graph neural nets for few-shot learning is novel.\n- Introduces novel semi-supervised and active learning variants of few-shot classification.\n\nWeaknesses\n- Improvement in accuracy is small relative to previous work.\n- Writing seems to be rushed.\n\nThe originality of applying graph neural networks to the problem of few-shot learning and proposing semi-supervised and active learning variants of the task are the primary strengths of this paper. Graph neural nets seem to be a more natural way of representing sets of items, as opposed to previous approaches that rely on a random ordering of the labeled set, such as the FCE variant of Matching Networks or TCML. Others will likely leverage graph neural net ideas to further tackle few-shot learning problems in the future, and this paper represents a first step in that direction.\n\nRegarding the graph, I am wondering if the authors can comment on what scenarios is the graph structure expected to help? In the case of 1-shot, the graph can only propagate information about other classes, which seems to not be very useful.\n\nThough novel, the motivation behind the semi-supervised and active learning setup could use some elaboration. By including unlabeled examples in an episode, it is already known that they belong to one of the K classes. How realistic is this set-up and in what application is it expected that this will show up?\n\nFor active learning, the proposed method seems to be specific to the case of obtaining a single label. How can the proposed method be scaled to handle multiple requested labels?\n\nOverall the paper is well-structured and related work covers the relevant papers, but the details of the paper seem hastily written.\n\nIn the problem set-up section, it is not immediately clear what the distinction between s, r, and t is. Stating more explicitly that s is for the labeled data, etc. would make this section easier to follow. In addition, I would suggest stating the reason why t=1 is a necessary assumption for the proposed model in the few-shot and semi-supervised cases.\n\nRegarding the Omniglot dataset, Vinyals et al. (2016) augmented the classes so that 4,800 classes were used for training and 1,692 for test. Was the same procedure done for the experiments in the paper? If yes, please update 6.1.1 to make this distinction more clear. If not, please update the experiments to be consistent with the baselines.\n\nIn the experiments, does the \\varphi MLP explicitly enforce symmetry and identity or is it learned?\n\nRegarding the Omniglot baselines, it appears that Koch et al. (2015), Edwards & Storkey (2016), and Finn et al. (2017) use non-standard class splits relative to the other methods. This should probably be noted.\n\nThe results for Prototypical Networks appear to be incorrect in the Omniglot and Mini-Imagenet tables. According to Snell et al. (2017) they should be 49.4% and 68.2% for miniImagenet. Moreover, Snell et al. (2017) only used 64 classes for training instead of 80 as utilized in the proposed approach. Given this, I am wondering if the authors can comment on the performance difference in the 5-shot case, even though Prototypical Networks is a special case of GNNs?\n\nFor semi-supervised and active-learning results, please include error bars for the miniImagenet results. Also, it would be interesting to see 20-way results for Omniglot as the gap between the proposed method and the baseline would potentially be wider.\n\nOther Comments:\n\n- In Section 4.2, Gc(.) is defined in Equation 2 but not mentioned in the text.\n- In Section 4.3, adding an equation to clarify the relationship with Matching Networks would be helpful.\n- I believe there is a typo in section 4.3 in that softmax(\\varphi) should be softmax(-\\varphi), so that more similar pairs will be more heavily weighted.\n- The equation in 5.1 appears to be missing a minus sign.\n\nOverall, the paper is novel and interesting, though the clarity and experimental results could be better explained.\n\nEDIT: I have read the author's response. The writing is improved and my concerns have largely been addressed. I am therefore revising my rating of the paper to a 7.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good paper with interesting approach",
            "rating": "7: Good paper, accept",
            "review": "This paper studies the problem of one-shot and few-shot learning using the Graph Neural Network (GNN) architecture that has been proposed and simplified by several authors. The data points form the nodes of the graph with the edge weights being learned, using ideas similar to message passing algorithms similar to Kearnes et al and Gilmer et al. This method generalizes several existing approaches for few-shot learning including Siamese networks, Prototypical networks and Matching networks. The authors also conduct experiments on the Omniglot and mini-Imagenet data sets, improving on the state of the art.\n\nThere are a few typos and the presentation of the paper could be improved and polished more. I would also encourage the authors to compare their work to other unrelated approaches such as Attentive Recurrent Comparators of Shyam et al, and the Learning to Remember Rare Events approach of Kaiser et al, both of which achieve comparable performance on Omniglot. I would also be interested in seeing whether the approach of the authors can be used to improve real world translation tasks such as GNMT. ",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}