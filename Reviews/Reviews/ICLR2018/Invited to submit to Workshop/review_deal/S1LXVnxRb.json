{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "We encourage the authors to improve the mentioned aspects of their work in the reviews.\n",
        "decision": "Invite to Workshop Track"
    },
    "Reviews": [
        {
            "title": "Lack of Novelty ",
            "rating": "3: Clear rejection",
            "review": "This paper proposes to use Cross-Corpus training for biomedical relationship extraction from text.  \n\n- Many wording issues, like citation formats, grammar mistakes, missing words, \n  e.g., Page 2: it as been\n \n- The description of the methods should be improved. \n  For instance, why the input has only two entities? In many biomedical sentences, there are more than two entities. How can the proposed two models handle these cases? \n\n- The paper just presents to train on a larger labeled corpus and test on a task with a smaller labeled set. Why is this novel? \n  Nothing is novel in the deep models (CNN and TreeLSTM).  \n\n- Missing refs, like: \n A simple neural network module for relational reasoning, Arxiv 2017",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review",
            "rating": "4: Ok but not good enough - rejection",
            "review": "SUMMARY.\n\nThe paper presents a cross-corpus approach for relation extraction from text.\nThe main idea is complementing small training data for relation extraction with training data with different relation types.\nThe model is also connected with multitask learning approaches where the encoder for the input is the same but the output layer is different for each task. In this work, the output/softmax layer is different for each data type, while the encoder is shared.\nThe authors tried two different sentence encoders (cnn-based and tree-lstm), and final results are calculated on the low resource dataset. \n\nExperimental results show that the tree-rnn encoder is able to capture valuable information from auxiliary data, while the cnn based does not.\n\n----------\n\nOVERALL JUDGMENT\nThe paper shows an interesting approach to data augmentation with data of different type for relation extraction.\nI would have appreciated a section where the authors explain briefly what relation extraction is maybe with an example.\nThe paper is overall clear, although the experimental section has to be improved I believe.\nFrom section 5.2 I am not able to understand the experimental setting the authors used, is it 10-fold CV? Did the authors tune the hyperparameters for each fold?\nAre the results in table 3 obtained with tree-lstm? \nWhat kind of ensembling did the authors chose for those experiments?\nThe author overstates that their model outperforms the state-of-the-art models they compare to, but that is not true for the EU-ADR dataset where in 2 out of 3 relation types the proposed model performs on par with the state-of-the-art model.\nFinally, the authors used only one auxiliary dataset at the time, it would be interesting to see whether using all the auxiliary dataset together would improve results even more.\n\nI would suggest the author also to check and revise citations (CNN's are not Collobert et al. invention, the same thing for the maximum likelihood objective) and more in general to improve the reference on relation extraction literature.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper describes cross-corpus studies using Tree-LSTM and MCCNN-based RE models in the biomedical domain. Experimantal results show that some combinations of different corpora lead to better performance.",
            "rating": "5: Marginally below acceptance threshold",
            "review": "This is a well-written paper with sound experiments. However, the research outcome is not very surprising. \n\n- Only macro-average F-scores are reported. Please present micro-average scores as well.\n- The detailed procedure of relation extraction should be described. How do you use entity type information? (Probably, you did not use entity types.)\n- Table 3: The SotA score of EU-ATR target-disease (i.e. 84.6) should be in bold face.\n- Section 5.3: Your system scorers in Table 3 are not consistent with Table 2 scores. \n- Page 8. \"Our approach outperforms ...\" The improvement is clear only for SNPPhenA and EU-ADR durg-disease.\n\nMinor comments:\n\n- TreeLSTM --> Tree-LSTM\n- Page 7. connexion --> connection\n- Page 8. four EU-ADR subtasks --> three ...\n - I suggest to conduct transfer learning studies in the similar settings.\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}