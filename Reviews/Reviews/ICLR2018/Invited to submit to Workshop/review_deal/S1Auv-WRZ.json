{
    "Decision": {
        "title": "ICLR 2018 Conference Acceptance Decision",
        "comment": "The paper based on cGAN developed a data augmentation GAN to deal with unseen classes of data. The paper developed new modifications to each component and designed network structure using ideas from state-of-the-art nets. As pointed out by reviewer 1 & 2, the technical contribution is not sufficient. We hence recommend it to workshop publication.",
        "decision": "Invite to Workshop Track"
    },
    "Reviews": [
        {
            "title": "This paper considers the data-augmentation problem which is very interesting. However, I don't see enough contribution in the current version.",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This paper proposes a conditional Generative Adversarial Networks that is used for data augmentation. In order to evaluate the performance of the proposed model, they use Omniglot, EMNIST, and VGG-Faces datasets and uses in the meta-learning task and standard classification task in the low-data regime. The paper is well-written and consistent. \n\nEven though this paper learns to do data-augmentation (which is very interesting ) rather than just simply applies some standard data augmentation techniques and shows improvements in some tasks, I am not convinced about novelty and originality of this paper, especially on the model side. To be more specific, the paper uses the previously proposed conditional GAN as the main component of their model. And for the one-shot learning tasks, it only trains the previously proposed models with these newly augmented data. \n\nIn addition, there are some other works that used GAN as a method for some version of data augmentation:\n- RenderGAN: Generating Realistic Labeled Data\n  https://arxiv.org/abs/1611.01331\n-Data Augmentation in Emotion Classification Using Generative Adversarial Networks\nhttps://arxiv.org/abs/1711.00648\n\nIt is fair to say that their model shows improvement on the above tasks but this improvement comes with a cost of training of GAN network. \n\nIn summary, the idea of the paper is very interesting to learn data-augmentation but yet I am not convinced the current paper has enough novelty and contribution and see the contribution of paper as on more the application side rather than on model and problem side. That said I'd be happy to hear the argument of the author about my comments. ",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper is good at using the GAN for data augmentation for the one shot learning, and have demonstrated good performance for a variety of datasets.",
            "rating": "6: Marginally above acceptance threshold",
            "review": "This paper is good at using the GAN for data augmentation for the one shot learning, and have demonstrated good performance for a variety of datasets.\nHowever, it seems that the main technique contribution is not so clear. E.g., it is not clear as shown in Figure 3, what is key novelty of the proposed DAGAN, and how does it improve from the existing GAN work. It seems that the paper is a pipeline of many existing works.\nBesides, it will also be interested to see whether this DAGAN can help in the training of prevailing ImageNet and MS COCO tasks.",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The proposition is technically sound and the novelty is significant. However, the illustration is not clear enough and need improving.",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "review": "In this paper, the authors have proposed a GAN based method to conduct data augmentation. The cross-class transformations are mapped to a low dimensional latent space using conditional GAN. The paper is technically sound and the novelty is significant. The motivation of the proposed methods is clearly illustrated. Experiments on three datasets demonstrate the advantage of the proposed framework. However, this paper still suffers from some drawbacks as below:\n(1)\tThe illustration of the framework is not clear enough. For example, in figure 3, it says the GAN is designed for “class c”, which is ambiguous whether the authors trained only one network for all class or trained multiple networks and each is trained on one class.\n(2)\tSome details is not clearly given, such as the dimension of the Gaussian distribution, the dimension of the projected  noise and .\n(3)\tThe proposed method needs to sample image pairs in each class. As far as I am concerned, in most cases sampling strategy will affect the performance to some extent. The authors need to show the robustness to sampling strategy of the proposed method.\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}