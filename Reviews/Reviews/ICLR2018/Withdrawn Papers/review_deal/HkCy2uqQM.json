{
    "Decision": "",
    "Reviews": [
        {
            "title": "The paper presents a substandard work on a very old subject: complex-valued neural networks",
            "rating": "2: Strong rejection",
            "review": "The paper intends to show that complex and real valued neural network are different and lead to different results on similar tasks, the complex valued network being more appropriate to 'difficult' problems and datasets.\nThe work seems to have been written in a rush leading to a big number of typos and quickly filled experiment tables (7 and 8 are full of zeros ?). The only valid conclusion is that real and complex valued neural network cannot be directly compared using the same number of parameters. Some theoretical aspect or at least some intuition should be more in depth detailed to understand when one should be better than the other. \n\nConcerning the novelty the paper is in the same spirit as https://arxiv.org/abs/1705.09792 but with weaker experiments, theoretical justifications and no valid conclusion.\n",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "review of \"Complex- and Real-Valued Neural Network Architectures\"",
            "rating": "3: Clear rejection",
            "review": "The authors show how techniques typically applied to real-valued networks (e.g. with real-valued inputs and parameters) can be straighforwardly generalized to complex-valued networks (e.g. with complex-valued inputs and parameters).  The authors then provide several evaluations of complex-valued networks on some standard ML benchmark tasks. They find that the complex-valued networks do not in general perform better than real-valued networks. \n\n====================\nClarity:  I found the paper clear and easy to understand.  In a number of places there are clear signs of sloppiness (e.g. undefined citations).   I found the undefined citations in the middle of page 2 frustrating, since I'd have liked to follow up on those citations as comparison points for this work. \n\nQuality: The mathematical formulas describing basic complex analysis ideas (e.g.  derivatives of complex functions, definitions of complex versions of standard activation functions) seem reasonable to me.   The general approach of assigning a parameter budget to ensure fairness in comparison between complex and real-valued networks seems reasonable --- although of course, since all results should be reported on cross-validated testing subsets anyhow,  parameter equalization is not the only approach to fair evaluation.   \n\nOriginality:  It seems very unclear to me what is added in this paper in comparison to works like (e.g.) Trabelsi (2017).  That and other recent work have provided some systematic evaluations of complex-valued networks, and shown their utility in a number of cases.   The current paper's authors talk about previous work not being well-controlled for number of parameters.   However, at least in some key cases in the recent literature, parameter numbers *were* controlled (see e.g. Table 4 of Trabelsi (2017)).  So I'm not really sure what is being added here. \n\nSignificance:   The paper does not make a great case for caring about complex-valued networks.  Of course, negative results are of value, but it doesn't seem like much is at stake in this work to begin with.   It's not like people expected complex-valued networks to somehow be extremely effective for the tasks discussed here -- so the failure to be better than the real-valued alternatives seems unremarkable.   The paper also doesn't illustrate any novel results on tasks for which it would be reasonable to assume that complex-valued inputs would be particularly important.  (The authors reference some signal processing tasks in the introduction, but don't actually show any results on such tasks.)    \n\n",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Unclear contribution",
            "rating": "4: Ok but not good enough - rejection",
            "review": "This work re-evaluates complex-valued neural networks: complex weights, complex activation functions.\n\nThe paper acknowledges that complex networks are not new, and that the findings of previous authors is that complex networks perform less well than real-valued alternatives.\n\nThe paper reports a comparison of real-valued and complex-valued neural networks, controlling for storage capacity (with an interesting discussion of controlling for capacity in terms of computational inference).\n\nThe paper concludes with \"Overall the complex-valued neural networks do not perform as well as expected.\" I didn't understand this conclusion, because previous work found complex-valued neural networks to be inferior, which is consistent with the results reported here. I did not see support in this paper for the claim in the abstract that special architectures make complex networks work better, or that they are well suited to particular data sets.\n\nThe empirical results are only presented in table-of-numbers format (graphical comparisons would be easier to understand), and tables 5-8 are all zero, which doesn't make sense for these classification tasks.",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}