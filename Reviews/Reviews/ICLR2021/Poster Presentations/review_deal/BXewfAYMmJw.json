{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper presents a \"conceptual  advance connecting causality, disentangled representation learning, invariant representations and robust classification\". Authors propose to decompose the image generation process to independent mechanism that can be composed (foreground masks (shapes), forground texture, and backgrounds), allowing for a specific image to generate counterfactuals , by changing some variations factors, while keeping other fixed. One can use interventional data to augment classifiers, this can lead in certain cases to improvement in accuracy and in other in improving the robustness. \n\nThere was concerns about the clarity of the paper regarding the structured causal model considered and its applicability beyond image generation, experimental protocol for choosing hyperparameters (loss scaling and ratios of real data and interventional samples ) and some missing references. The rebuttal of the authors and their updated paper reflected comprehensively all those concerns and addressed them, highlighting limitations of the method and adding more examples of its failures. \n\nI liked the ideas and concepts in  this paper , and it will be exciting to generalize such generative approach to other domains, this  work is a first step. I think it will be good addition to ICLR program "
    },
    "Reviews": [
        {
            "title": "Interesting conceptual connection between causality, disentangled representation learning, invariant representations and robust classification",
            "review": "This paper presents an interesting conceptual advance connecting causality, disentangled representation learning, invariant representations and robust classification.\nThe authors propose a Counterfactual Generative Network (CGN), which is basically \"modular\" generative adversarial network that can independently control the generation of independent factors of variations in the data corresponding to Independent Mechanism, i.e. independent factors in the structural causal model of the data. In the context of generating natural images like those comprising the ImageNet dataset, the CGN once trained can be used to generate high-quality counterfactual images with direct control over of factors of variations determining the content of an image shape, texture, and background. These generated samples obtained by independently and uniformly sampling over factors of variation can be used to train a classifier to achieve out-of-domain robustness. The authors show indeed show in simulation that this procedure works as a data augmentation procedure that increases out-of-domain robustness while only marginally degrades the overall accuracy. As the authors explain, this can be thought of as a generalization of \"domain randomization\".\nAdditionally, CGN can be used as a generative model of high-quality binary object masks and unsupervised image inpainting.\nThe authors also carry out extensive ablation studies that quantify the contribution of the different training costs for CGN to the overall quality (measures as Inception Score) of the generated counterfactual images. \nThis is first and foremost an \"idea paper\" putting forth a very interesting conceptual proposal. This is then empirically validated on out-of-distribution classification tasks in different versions of colored MNIST, and a coarse grained subsed of ImageNet.\nA natural question for the authors is whether and by how much this type of data augmentation might help in realistic large-scale classification scenarios. Another natural question would be to quantify the effect of the counterfactual data augmentation in terms of trade-off between performance on in-distribution and out-of-distribution samples.\nLastly, it would be interesting to know whether the authors have any thought on how to generalize their architecture to other setting, i.e. how to isolate Independent Mechanisms in a general domain and what type of domain knowledge is necessary to do that effectively.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Official Blind Review #3",
            "review": "--- Summary ---\n\nThis paper proposes a new generative model that generate images from 3 seperate aspects: foreground masks (shapes), forground texture, and backgrounds. Then they convexly mix these 3 aspects into one image. By doing so, they can vary each aspect individually without changing other aspects, enabling the model to generate counterfactual images. For example, we can generate a cat shape with telephene texture and sea background, which would not exist in natural images. They show that in several colorful MNISTs datasets their methods can generate new combinations of images. In ImageNet, by using the pre-trained BigNet GAN as backbones and pretrained U-Net for foreground object masks, they can distill the knowledge in BigNet into these 3 seperate aspects and generate counterfactual natural images.\n\n--- Pros ---\n\n1. Intersting ideas of combining pre-trained models with novel loss function that helps disentangle these 3 aspects.\n2. Plausible and intriguing counterfactual examples.\n3. Strong improvements in colorful MNIST datasets.\n\n--- Major comments ---\n\n1. The claim that \"we are able to reduce the gap while achieving hig accuracy on IN-9\" is not true. In Table 4, the method IN+CGN has lower accuracy than IN alone, and it reduces the gap by lowering the original performance in Mixed-same. So it does not actually improve the performance.\n\n2. The above makes me wonder the ImageNet experiment does not actually generate plausible enough images that help improve accuracy, probably due to its unnatural image generation as evidenced by relatively low IS scores (130). \nEspecially seeing there are 6 lambdas to tune listed in Appendix B.3 and other hyperparameters like learning rates etc, this method might not be very practical in high-dimensional natural images. Maybe authors can be honest about it. Or illustrate what's the best way to tune this method, what has been attempted etc.\n\n3. The current setting seems to a bit limited that requires a single foreground and background. For example, designing independent mechanisms for medical imaging might not be easy with no exact foreground/background boundaries.\n\n4. In Table 3, maybe authors can evaluate on some difficult ImageNet datasets like ImageNet-A to assess if the performance improves.\n\n--- Minor comments ---\n\n1. The loss descriptions in Appendix B should be moved to main text to help readers understand the method. Details like how to pick $\\tau$ for shape loss should be mentioned.\n\n2. The name \"pre-masks\" is confusing that originally I think it's a binary mask, but instead it's a colorful image.\n\n3. More failure examples in Appendix E will better help readers understand its limitations.\n\n4. The figure 5 and the Appendix D should also include the final image that combines m, f and b to better assess its improvement over the training stages. Also, having an arrow in Figure 5 or specifying epochs might better help readers understand it is showing the transitions.\n\n5. The caption in Figure 24 is wrong: should be columns instead of rows.\n\n--- Evaluations ---\n\nOverall I like this paper. The method is interesting to read and the examples are interesting. The experiments are thorough and do show some improvements in colorful MNISTs. The method, unfortunately, does not seem to work that well in ImageNet, and does not improve generalization performance. I encourage the authors to be upfront about the limitations of this method and write better descriptions of loss and hyperparameters tuning. ",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Contribution Disconnected from Narrative, Missing Key Reference",
            "review": "The main idea of the paper, i.e., using independent causal mechanisms to generate interventional images, has already been explored by Kocaoglu et al. in Causalgan: Learning causal implicit generative models with adversarial training, ICLR'18. Same as here, the authors there also \"view image generation as a causal process\" and \"structure a generator network as a structural causal model (SCM)\" and use a conditional gan to generate the image from the labels. The generation used here based on three variables, i.e., shape, texture and background seem to be a special case. Therefore, the authors should definitely cite this work. \n\nMy general remark is that there is very little causality in the approach. The causal structure that is used in the generation of data is not different than a conditional GAN. This makes the claims in the introduction very disconnected from the actual methodology and the experiments in my opinion.\n\n\" we can intervene on a subset of them and generate counterfactual images \"-> What the authors call counterfactual images are actually interventional images from a causal point of view. Please consider changing \"counterfactual\" to \"interventional\" throughout the paper. This will help clarify the distinction between interventional and counterfactual layers in Pearl's hierarchy. \n\n\"From a causal perspective, we maximize the average causal effect (ACE) of one IM on the classifierâ€™s decision, while minimizing the ACE of all other IMs.\"\nCan you formalize this claim? This does not seem trivial.\n\nCould you explain \"alpha blending\"? This step is not motivated well and seems specific to the used dataset. \n\nEven though the ImageNet experiments look impressive, I believe the main factor for success is in the deterministic and manually defined composition mechanism. Furthermore, I believe this composition is doing most of the disentangling during training. \n\nForeground and background segmentation use an existing method U2-Net which is used to create masks, or values for the variables used in the graph. \n\nThe intuition on comparing with other methods is missing. For example, why do you think training a classifier on interventionally augmented data performs better than IRM? Shouldn't this depend on the number of environments and degree of correlation? These are not reported. \n\n\"We, therefore, follow an augmentation strategy, i.e., we augment ImageNet with additional counterfactual images.\"\nHow many samples are added to the original data? I believe the amount of augmentation relative to the original dataset size is important.\n\n \n%% AFTER REBUTTAL %%  \nThank you for all the updates.\n\nI would like to thank the authors for their humility in the rebuttal and for clarifying the paper's contributions. Accordingly, I will increase my score. However, I still believe Section 3.1's contribution, and the follow-up of using this to improve classifier robustness, is useful only for a very specific type of data and it is hard to assess its value from a practical point of view. \n\nThe fact that the authors were able to showcase that such counterfactual data augmentation improves classification is, although expected, useful in itself. However, performance improvement is only evident in colored MNIST, relative to GAN augmentation. Furthermore, R4 points out the important issue that the relevant causal feature is assumed to be known in the experiments. This information is normally not available and must be inferred by the classifier. The additional experiments provided by the authors during the rebuttal are welcome but they should be in the main paper rather than the appendix since this is the main setting where spurious correlations create problems. I believe the experimental section should put more weight on this setting.\n\nIn light of all this, I will provide a borderline score leaning towards rejection. \n\nI encourage the authors to expand section 3 to settings that do not restrict the images to have one foreground object and a single background. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting approach but the presentation needs improvement",
            "review": "Deep neural network brittleness can be attributed to their tendency to latch on to spurious correlations in the training dataset. The proposal in the paper is to learn to generate samples where these correlations can be eliminated. To this end, the authors, distill trained conditional big gan into a transformation with explicit modules to capture the shape, texture of the foreground object, and the background. The distilled network is called Counterfactual Generator Network (CGN). Thus, an image can be generated with a background of one class, the shape of another class, and the foreground texture of a different class. Then a classifier with multiple heads is learned where each head predicts a class based on only one of the factors among shape, texture, and background. \n\nThe proposed approach is motivated by the assumption of independent mechanisms where different modules of the causal data generating process are independent of each other. Once the decomposition of a training image into shape, texture, and background is obtained, any component can be swapped to generate counterfactual data.\n\nPros:\n+ The solutions provided to extract object masks, background and texture are interesting and scale to Imagenet dataset.\n+  Shows that augmenting the training dataset with the generated counterfactual images can help improve robustness. \n \nCons + Questions:\n- The presentation of the paper can be improved. It is not always clear if the causal structure is assumed to known. In Sec 2.2 SCM is defined, but the SCM for the MNIST or Imagenet is not provided. Do all the nodes in the CGN share the same noise or exogenous variables?\n- The proposed method appears to assume that the causal structure is known. In this, it assumes it is made up of three nodes shape, texture, and background, and thus can limit the counterfactual generation ability. Many semantic changes cannot be achieved as evidenced by the fact that the counterfactual images are not realistic. \n- in the invariant MNIST classification task it appears that the results are based on the assumption that the invariant feature - shape is known apriori. In practice, this information is not available. IRM does not assume this knowledge, so it does not seem comparison with IRM is fair in this case.\n- Some related work that seems to be missing [1][2]\n\n[1] Kocaoglu, Murat, et al. \"Causalgan: Learning causal implicit generative models with adversarial training.\" arXiv preprint arXiv:1709.02023 (2017).\n\n[2] Kaushik, Divyansh, Eduard Hovy, and Zachary C. Lipton. \"Learning the difference that makes a difference with counterfactually-augmented data.\" arXiv preprint arXiv:1909.12434 (2019).\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}