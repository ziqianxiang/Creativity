{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The authors use Empowerment for morphology optimisation, a quite novel idea. After initial unclarities and various improvements on the submission, the reviewers unanimously voted for acceptance of the paper.  "
    },
    "Reviews": [
        {
            "title": "Official Blind Review #3",
            "review": "The paper presents an approach that evolves morphologies for virtual creatures that can reach as many states in their environment as possible. The approach is based on an information-theoretic objective that rewards morphologies for reaching diverse states and at the same time performing behaviours that are predictable. \n\nWhile the paper is interesting there are a few issues that should be addressed:\n- The approach relies on randomly sampled actions. How would it scale to more complex tasks that require non-random actions to be solved? Additionally, most of the morphologies are relatively simple, compared to some of the other work in evolving virtual creatures. Is it possible to scale the approach to produce more complex morphologies?\n- \"This is at odds with biological morphologies that seek to be functional over the largest subset of their environment as possible. \" -> I would argue the opposite. Biological morphologies are very much specialist to work well in their particular niche. \n- The approach does not seem completely task-agnostic since the actions are sampled from different distributions for each task (e.g. sine/cosine). \n- The disadvantages and limitations of the approach should be discussed in more detail\n- \"We implement a variant of the task supervised Neural Graph Evolution (NGE) algorithm from Wang et al. (2019) without value based population pruning to better isolate the effects of reward supervision. “ -> how well does it work with value-based population training?\n- How does the approach compare to quality diversity approaches that also aim to produce many morphologies in a single run, e.g. Novelty Search with Local Competition (\"Evolving a Diversity of Virtual Creatures through Novelty Search and Local Competition\" Lehman et al.)? \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting research in evolving robot morphologies",
            "review": "The paper presents a method to evolve morphologies of a robotic system without explicit reward and using an empowerment-like quantity. The thus obtained morphologies can get higher rewards in task settings when RL algorithms are applied.\n\nThe story and presentation of the paper are clear. I also like the results and think it is interesting, maybe more for a conference like ALife than ICLR though.\n\nStrengths:\n- Interesting way to estimate the information criterion using a GNN\n- formulation of a morphology-empowerment\n- analysis and ablations justify the design choices and the method\n- good results (on self-given tasks)\n\nWeaknesses:\n- the mathematical formulation is sloppy in many places\n- the morphologies are compared on different sequences. It might be interesting to know how much variance the estimation of Eq 1 has when sampling a different batch of action-sequences\n\nI think when the problems with the formulation are fixed and the typos are removed the paper can be much stronger.\n\nRelated work: As you quantity is very close to the Empowerment definition, I think the original work by the Polani group should be cited, e.g. \"Empowerment: A universal agent-centric measure of control\", Klyubin, Polani, Nehaniv\nAn interesting combination could be to use task agnostic live-time adaptation, such as predictive information maximization (Information Driven Self-Organization of Complex Robotic Behaviors, PLoSOne) or related work could be combined.\n\nProblems in the mathematical formulation:\nPage 3, first equation (before (1)): What is the expectation taken over? \nYou write about q_theta being a classifier, but most of the paper reads like you have continuous actions. This should be clarified early on that you assume discrete actions/ action-primitives for finding the morphologies.\nEq 1: j appears in the right but without any specification. \nYou write that you take expectations of joints, but what is p(j), so the probability of a joint. I think you want to add a sum over the joints $j$ or something. What is |J|?\n\n\nDetails:\n- Sec 1: Second, Using (capital)\n- Sec 3.1: Notice that left untouched, the...\n- Sec 3.1: By assuming actions are uniform A_j?\n- Action Distr: The appendix should contain information about the action sequences you are using.\n- GNN Classifier: the the \n- Sec 3.3: slowest step in for simulation....\n- Sec 4.4: \"meta\" action: use the same label as in Fig 5  (global action)\n- Table 3: ..TAME and a similar \n- Sec 5: You write randomly sampled actions, but you have highly structured action-primitives \n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review of TAME",
            "review": "Summary:\n\nThis paper develops a general morphology evolution algorithm, and demonstrates its utility in a setting where morphologies are encoded as graphs. The methodology is grounded in a theoretical notion of empowerment, and theory is introduced that extends empowerment to the case of morphology. The morphology evolution itself requires no task-specific signals, but yields morphologies that generalize well to several tasks of interest.\n\n\nStrong points:\n\nThe extension of empowerment to morphologies is novel, interesting, and well-motivated.\n\nThe use of random actions is satisfying in that it is initially counter-intuitive, but well-grounded, and in line with other recent advances based in generating interesting things from random input (e.g., GANs).\n\nThe introduced space of morphologies is quite general and can capture some very interesting designs.\n\nThe ablations in Figure 5 and Table 3 are very helpful in validating the theory. Table 3 in particular verifies how empowerment can provide an advantage over more naiive diversity metrics.\n\n\n\n\nWeak points:\n\nThere are some key gaps in related work literature.\n\nOne is NS-LC (Evolving a Diversity of Creatures through Novelty Search and Local Competition,), which was used to evolve explicitly diverse high-performing morphologies (and is an example of the broader category of quality diversity algorithms). The goal of that work is different: to collect diverse morphologies, instead of finding one that is maximally general, but the methodology is related. There is generally a lack of references in the description of the evolutionary algorithm (EA) used in the paper. Is this similar to algorithms used to evolve other sorts of open-ended structures? E.g., open-ended neural network design (e.g., Evolving Deep Neural Networks)? Or EAs that include generation-by-generation updates of a model like the classifier used in this paper? E.g., surrogate-assisted methods? \n\nThere is also a missing link to recent advances in self-supervised methods.\n\n“we reset q_phi every 12 generations to prevent over-fitting to older morphologies” Worth mentioning the connection of this to ideas like experience replay in RL and removing the oldest individual in Regularized Evolution.\n\nThe theory motivates the use of random actions, but the experiments use a highly restricted set of actions that are well-suited to the eventual tasks of interest, which takes away from the promise of generality and task-agnosticism of the method. Should we expect these specialized “predefined action sequences” to generalize to a wide variety of morphologies and tasks, or does the experimenter need to design these by hand depending on the tasks?\n\n“each joint action is given by a cosine function of one of two possible frequencies and one of two possible phases”. What are these frequencies and phases? So, each joint has 4 possible controllers. Are combinations of joints with these controllers sufficient for performing arbitrary tasks?\n\nSimilarly, the tasks in the paper are also closely-aligned with the empowerment objective. That is, the state space is low-dimensional, and task is measured in a 1- or 2-dimensional slice of the state space. Can we expect the approach could generalize to more complex tasks? E.g., can the approach handle a task that combines locomotion and reach, i.e., navigate to randomly sampled goals when the agent is not tethered? Why not evolve a single morphology that can solve all the classes of tasks in experiments (except cheetah)? Isn’t this the promise of the method?\n\nThe changes from NGE to NGE-like make the method more comparable to TAME, but the paper should elaborate on what the missing parts do and whether TAME could take advantage of them. E.g., what is “value based population pruning” and why doesn’t TAME use it? What is NerveNet and why doesn’t TAME use it? Why was NGE-like run for 8 seeds instead of 12? Because it’s slower? Why are NGE-like and TAME run on different numbers of cores?\n\nOne key baseline missing is single-task or multi-task version of the EA that TAME uses, but simply using task fitness instead of empowerment. This would give a sense of how the task-specific variant of your underlying EA compares to NGE, and validate whether the EA is at least powerful enough to take advantage of task signals when they are available.\n\n\n\nMinor comments:\n\n“Additionally, morphologies with better exploration will be able to learn to solve tasks more quickly.” Is there existing work that shows this or some other explanation? It makes intuitive sense, but may not be true in general.\n\nIn Eq. 1, looks like “log|J|” should be “log|A_j|”, and the expectation “E” should be formatted as in the previous lines.\n\nShould TAME Cheetah be bold in Table 1 since it is within the margin of NGE-like?\n\nIn “How does Tame compare to task supervised methods?”: “We hypothesize that this” -> Clarify what “this” is and why NGE-like is good on Cheetah (because the morphology space is more limited or structured?).\n\n-------\nBased on the author response, the rating has been updated (see comments below).\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "review for \"Task-Agnostic Morphology Evolution\"",
            "review": "The paper introduces an algorithm for optimizing the robot morphology in a simulated environment. The key idea is that instead of finding a morphology and a controller for a specific task, they propose to search for a morphology that can reach a large variety of states in a predictable way. Specifically, they developed an objective function that maximizes the mutual information between the actions and the final states of the robot. The proposed algorithm is demonstrated on a few simulated locomotion and manipulation tasks.\n\nThe paper is well written and the problem that the work is addressing is significant in my point of view.\n\nWhat I like about the work:\n1. The idea of optimizing morphology in a task-agnostic way is interesting.\n2. The proposed formulation and algorithm seems concrete and reasonable.\n3. The proposed algorithm seems effective for the designed experiments presented and compares favorably to baseline methods.\n\nMy concerns about the work:\n1. The proposed objective only considers reachability of the robot, but not the efficiency of completing the task. A good baseline would be whether the optimized design works better than some human-designed morphology. For example, does the optimized result outperform the hopper, halfcheetah, and the 2d manipulator from OpenAI gym environments?\n2. Is the algorithm sensitive to the choice of the regularizer lambda that balances adding limbs and prediction accuracy?\n3. The actions used to explore the environment is quite simplistic (sinusoidal-based for locomotion and constant for manipulation). Though it works for the presented problems, it's not clear if it will work for more complex problems. For example, if we want to design a biped robot that does not fall to the ground, random exploration would likely give us a very narrow range of states.\n\nIn general I think the paper introduces an interesting idea. It would be a good contribution to ICLR if my concerns above could be addressed.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}