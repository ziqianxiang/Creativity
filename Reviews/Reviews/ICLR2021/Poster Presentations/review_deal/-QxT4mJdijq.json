{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper proposes an approach to meta-learning symmetries. While several approaches have recently emerged with similar goals, and sometimes greater convenience and empirical performance, the proposed approach has some interesting characteristics, such as changing properties of the architecture to extrapolate these symmetries. There was a quite a spread of opinions about the paper, the empirical results were not strong, and updates to the paper focused on helpful text additions, but did not substantively improve the evaluation or experiments. Notwithstanding, the paper is conceptually interesting, there are no major flaws, and there is sufficient support for it."
    },
    "Reviews": [
        {
            "title": "Meta-learning equivariance by layers with a symmetry matrix and filter, and meta-learning invariance from augmented data",
            "review": "This work (i) meta-learns equivariances in neural networks by reparameterizing fully connected layers into a symmetry matrix and filter parameters, \nand (ii) meta-learns invariances from augmented data.\n\nStrengths:\n+ The work implements (i) by a layer and custom inner loop optimizer using the higher-order optimization library [1]\nand (ii) by augmenting benchmark datasets [2].\n+ The work learns partial translational symmetry, euqivariance to rotation and flips\n+ The work performs important ablation studies, such as testing reparameterization with and without meta-learning by using multi-task learning instead.\n\n\nWeaknesses:\n- Mostly toy examples\n\n- Rather than baking-in inductive biases into the network by encoding equivarainces, \nother approaches such as the vision Transformer [3] learn inductive biases from data:\nlearning local, medium, and long range connections, discovering architectures which supersede CNNs, learning filters, \nand demonstrating that CNNs are a curve on an attention distance vs. network depth plane.\nAdding a reference to this line of work may improve the introduction.\n\n- Minor changes:\nFigures 1,2, and 3 may be improved.\nAlgorithm 2 may be sufficiently described in words.\nTypos on page 14 may be fixed.\nlines 9-10 should read \"chosen to have\" and \"theoretically meta-learned\"\nline 32 should read \"each $\\pi(i)$ translates the filter\"\n\n\n[1] Generalized inner loop meta-learning, Grefenstette et al, 2019.\nhttps://github.com/facebookresearch/higher\n\n[2] Torchmeta: A meta-learning library for PyTorch, Wurfl et al, 2019.\nhttps://github.com/tristandeleu/pytorch-meta\n\n[3] An image is worth 16x16 words: Transformers for images recognition at scale, Dosovitskiy et al, 2020\nhttps://arxiv.org/pdf/2010.11929.pdf\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Very interesting approach to learned network equivariance",
            "review": "OVERVIEW:\nThe authors present a meta-learning approach for network equivariance where the key idea is that equivariance to a finite group of transformations can be achieved by identifying the sharing pattern of weights. Their proposition claims that a fully connected layer $\\phi: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ with weights $W$ can be factorized into a symmetry matrix $U$ and filter parameters $v$ where the symmetry matrix encodes desired group-convolutions: $\\text{vec}(W) = U v, \\hspace{1em} v \\in \\mathbb{R}^k, U \\in \\mathbb{R}^{mn \\times k}$. Within the meta-learning framework, they learn both $U$ and $v$ as part of the outer and inner steps respectively. They demonstrate that they are able to recover the translational equivariance baked into traditional convolutions using this approach including the expected symmetry pattern (shown in Fig. 4). They are also able to demonstrate this two more scenarios: (i) for a group of translation, discrete $45^\\circ$ rotation and reflection, and (ii) for Augmented-Omniglot and Augmented-MiniImagenet, providing empirical evidence that their proposed approach learns meaningful information for network equivariance.\n\nPROS:\n- I really liked the idea of equivariance captured as a symmetry pattern (or weight sharing) and being able to learn it from data using meta-learning. This is very interesting and exciting with the ability to \"learn\" rather than \"hope\" that equivariance is learned from appropriately augmented data. \n- A proof of Proposition 1 is presented in the Appendix which is a nice contribution in my opinion.\n- I liked the visualizations of the symmetry pattern for translation equivariance and the filters for discrete rotation equivariance (in appendix). They are visual evidence of achieving what is expected from the proposed approach.\n- The experiment in Section 5.2 is helpful in backing up the claim of \"hybrid\" equivariance where you are able to learn translations + discrete rotations. This is achievable by appropriate filter design for simpler groups (mostly 2D) like in Harmonic-Nets [Worrall et al] but can get complicated for interesting groups like SO(3) & SE(3).\n\nCONS:\n- The biggest concern for me are that the experiments are largely on synthetic data which has been randomly generated (Sections 5.1 and 5.2). The only real data experiment is on Aug-Omniglot and Aug-MiniImagenet for a few-shot classification task. Equivariance has been demonstrated to be effective on real data in two setups that I am aware of: (a) 3D Model classification with spherical convolutions like in Cohen & Welling, [Esteves et al](https://arxiv.org/abs/1711.06721), (b) Azimuth and scale estimation on Google Earth images [Henriques and Vedaldi](http://proceedings.mlr.press/v70/henriques17a.html). Applying the proposed method to one of these experimental setups will be very helpful in convincing the readers of their use on real data.\n- Is the proposed approach learning local equivariance (like with harmonic filters) or global equivariance (like with warped convolutions where transforming the image into polar coordinates gives it rotation and scale equivariance)?\n- From the proof of Proposition 1, it becomes clear why the restriction to a finite group. The question I have is what is needed to move into more general (continuous) groups like SO(2), SO(3), SE(3)? Will an approximation (into some finite pattern with tiling) be good enough? I think that it is a possible future research direction but I am interested in knowing your thoughts about it.\n- The methods the authors compare against are meta-learning methods which makes sense given the broader framework the work is in. However, I would like a comparision with other network equivariance via filter design algorithms. I don't expect better results but some discussion of comparable performance without the handcrafted design or the ability to learn equivariance for groups without a handcrafted filter available will be a huge plus.\n\nREASON FOR RATING:\nI like the paper and it makes a very good contribution in an important area. It is however held back by the lack of experiments on real data and comparision with other established equivariance works leading to my current rating.\n\nUPDATE:\nI have read the author feedback and other reviews/discussions. I have updated my rating to 8 from 7 reflect it.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An insightful paper with promising results",
            "review": "In this paper, the authors propose MSR, a parametrization of convolutional kernels that allows for meta-learning symmetries shared between several tasks. Each kernel is represented as a product of a structure matrix and a vector of the kernel weights. The kernel weights are updated during the inner loop.  The structure matrix is updated during the outer loop.  \n\nStrengths\n1. The paper is interesting and is easy to read. The figures help a lot in understanding the discussed ideas. \n2. The authors demonstrate that the proposed method outperforms the baseline meta-learning models. They empirically prove that MSR indeed learns valuable symmetries from the set of tasks and the provided data.\n3. The related work as well as the experimental part allow for a clear positioning of the proposed approach. It demonstrates a valuable connection between meta-learning and building equivariant models.\n\nI did not find any major weaknesses in the presented paper.\n\nQuestions\n1. A matrix $W$ of size $8\\times8$ can be reparametrized in several ways. The corresponding vector $v$ can be of size $1, 2, 4, \\dots 64$. Do you consider the size of the vector as a hyperparameter? If so, how to choose it? \n2. If we consider the case of the exact flip symmetry, then the length of $\\text{vec}(W)$ must be even. One half encodes the original weight and the other half encodes the flipped weight. So we end up with a constraint between the shape of the matrix and the structure of the symmetry group. The same argument applies to all other symmetry groups. What happens if the constraint is not satisfied? Can we learn a flip symmetry for $W$ of size $7 \\times 2$? How $U$ will look in this case?\n\nI enjoyed reading the paper. It is insightful, well-written, and demonstrates several valuable results both theoretical and experimental. \n\n### Decision\nThe authors answered all my questions. My decision stays the same.\n",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "### Summary:\nThe paper presents a meta-learning algorithm to learn/encode equivariance into deep nets. The main idea is to decompose the model parameters into two parts, a spatial sharing pattern, and the trainable weights. When transferring to a new task, the sharing pattern is fixed and only the remaining trainable weights are tuned. They authors motivated this approach stating that data augmentation may not be practical for robotics application which requires training in the real-world. For experiments, they consider a synthetic dataset where they can recover the equivariance and also k-shot classification tasks on datasets augmented with crops, rotations, and reflections.\n\n### Decision:\nI recommend a borderline reject for this paper. I have some questions with the claimed contribution, and details in the experimental section that should be answered before I can recommend an acceptance.\n\n### Supporting Arguments:\n1.\tOverall, I think the paper is interesting and relevant to the community. However, there are some questions that should be addressed.\n2.\tThis paper demonstrates that through their reparametrization, parameter-sharing, the network can be \"equivariant to any finite symmetry group\". This result is similar to the work by Ravanbakhsh et al., (2017), which they also show the sharing-patterns encode equivariance properties. Due to its relevance, I believe a more careful discussion should be included and not just cited as “theoretical work has characterized the nature of equivariant layers for various symmetry groups”.\n\n3.\tFor the experiments, I think a necessary to have a baseline that treats both U,v as trainable parameters. I wonder if it is necessary to train U and v separately on train and val; Maybe the performance gain comes just from the fact that U is trainable, i.e., this model architecture benefits learning. \n\n4.\tWhat are the reported +/- in the Tables? Is it the standard deviation over several random initialization runs? \n\n5.\tJust to confirm, “test-sets” in Aug-Omniglot and Aug-MiniImagenet are augmented as well? If yes, are there still performance gain without the augmentation?\n\n6.\tAre the baselines in Table 3 trained with data-augmentation as well? The paper states “benchmarks are identical to prior work (Finn et al., 2017)”; does that mean without data augmentation? Also, what happens if both train and val sets are augmented for Alg. 2?\n\n7.\tThere seem to be some learning rate, step sizes, and architecture tuning as described in supplementary materials. How are these hyperparameters searched? What metric is being used to pick them and what ranges were considered?\n\n### Additional feedback:\n- Figure 2. Is a little bit blurry?\n- Maybe also mention the issue of  data augmentation with real-world data in the introduction? It wasn’t clear to me the challenges with data augmentation until much later in the paper.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}