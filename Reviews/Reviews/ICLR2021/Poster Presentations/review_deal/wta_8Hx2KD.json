{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "Symmetries play an important role in physics, and more and more papers show that they also play an important role in statistical machine learning. In particular, employing symmetries might be the key to improve training and predictive performance of machine learning models.  In this context, the present paper shows how previous physical knowledge can be leveraged to improve neural network performance, in particular within Deep dynamic models. To this end, they show how to incorporate equivariance into resnets and u-nets for dynamical systems. On a technical level, as pointed out by the reviews and also clearly mentioned by the authors, the basic building blocks are well known in the literature. However, dynamical systems also raises their own challenges resp. laws when it comes to modelling symmetries, as the authors argue in the paper and also clarified in the rebuttal. For instance, it pays off to adapt the techniques known from the literature deal better with scale, magnitude and uniform motion equivariance. This is a solid contributions and will help many other who want to apply DNNs to dynamic and physical models. "
    },
    "Reviews": [
        {
            "title": "an interesting problem but the presentation needs significant improvements",
            "review": "This work incorporates symmetries into a convolutional neural network to improve generalization performance and prediction accuracy. The work incorporates various symmetries by designing equivariant neural networks and demonstrate their superior performance on 2D time series prediction both theoretically and experimentally. \n\nThis work studies an interesting and important question in deep learning. However, the reviewer feels that the paper in the current form is difficult to follow with many places unclear. The overall result is based on a combination of previous work on equivariant convolutional neural network, the reviewer finds it hard to parse (the t and obtain a general methodology (or systematic approach) for dealing with symmetry from the work, and there is no high-level message conveyed in this work.\n\nBelow are some more detailed comments:\n\nIn Section 3.1, Equivariant Convolutions.: the result in (1) is quite unclear without much background provided. Equivariant ResNet and U-net: what is the implication on skip connection with no effects for network equivariance? Not clear.\nFor Section 3.2 - 3.5, the reviewer finds it very hard to follow the proposed approaches for dealing with each symmetry. (Perhaps this is because the reviewer has limited domain background in equivariant CNN) In general, the reviewer has it very hard to follow and interpret the proposed methods for dealing with each symmetry, and there is very little background provided.\n3. It would be better if the author can provide more numerical results on real data other than simulated data. In Table 3, it seems that some of the methods with symmetry consideration are even worse than vanilla ResNet and U-net. This is a bit confusing.\n\nOverall, the reviewer feels that the study is interesting with improved ways of dealing with symmetry for learning complex physical dynamics, but the work needs significant improvement in presentations.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Novelty in modeling physical dynamics with symmetry",
            "review": "This paper studies improving the modeling of physical dynamics with equivariant neural networks. In particular, this paper focuses on a new type of data governed by physical models. Several special symmetry groups are considered to better characterize the system, including uniform motion equivariance, resolution-independent scaling, and resolution-dependent scaling, etc. Simulation results show that the proposed equivariant model yields better accuracy and physical consistency than the non-equivariant models even with data augmentation, given the type of distributional shift is known. Results on the real-world data show some of the equivariant models can generalize better than the non-equivariant models.\n\nPros\n* The idea of using equivariant networks in physical dynamics seems well-motivated. In cases global alignment is difficult and the distributional shift is unknown, improving generalization by  incorporating known symmetries seems to be a natural idea. \n\n* Although the idea of equivariant networks has been proposed before, the proposed treatments tailored to the modeling physical dynamics are new. \n\nCons\n\n* It is claimed the data is governed by the differential equation, which has several symmetry properties. However, how the \"ResNet and U-net\" networks are used to solve the dynamics prediction problem is missing from the main text. Maybe due to the same reason, the connections to the differential equations are unclear. This paper is not quite self-contained.  \n\n* The content is targeted to a narrow audience. \n \nQuestions: \n\n- Is data augmentation available as a baseline for experiments in Table 3? \n\n- It seems different kinds of symmetries are incorporated separately - not sure if this is a limitation. If a system is known to satisfy multiple symmetries, is it possible to incorporate all of them together in a network? \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Redesign of CNN to make it symmetric as physical dynamics",
            "review": "Physical dynamics have symmetry properties, which can be leveraged by neural networks for better accuracy and generalization. This paper takes 2D Navier-Stokes (NS) equation as an example and re-design the convolutions in networks. Simulations and experiments on real data are conducted to verify that the new models are effective. \n\nThe common logic of the work is reasonable. However, the novelty and technical contribution is limited. 1) the symmetries of NS equations are well-studied and borrowed from [37]. 2) The design of Equivariant networks, i.e., Equivariant ResNet and U-Net are incremental comparing to [9,10] and [47]. \n\nSome further questions: 1. Are the proposed re-design for uniform motion equivariance in eqn (2) and that for scale equivariance in eqn (5) compatible? Can we design networks that simultaneously have multiple kinds of symmetry? Even potentially to automatedly learn the symmetry of the unknown systems? It is more attractive to me than the current approach. 2. What is the detailed implementation of Augm in Table 1? How many augmentation for each instance on average? Will the performance increase with the number of augmentation? Is it possible to do Augm for Ocean dynamic? More experiments will firmly validate the superiority of the proposed method over the data augmentation approach. 3. Shall we keep convolution, which are original designed for image, in physical dynamics? \n\nSec 2.1-2.3 are hard to follow. Fortunately, I can get the main idea with almost skip this part. Maybe this part is not necessarily in that rigorous. Otherwise, please move some theoretical results into the body to highlight the technical contribution. \n\nOverall, this paper proposed methods to make CNN to be symmetric as (NS equation) dynamics. The technical contribution need be highlighted.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Fluid dynamics models that incorporate physical symmetries generalize well under distribution shift, but the role of equivariance isn't yet directly validated.",
            "review": "Summary: The paper demonstrates that incorporating equivariance (i.e. symmetries) into model for predicting fluid dynamics improves its performance, especially when the test distribution is transformed by those symmetry groups. Leveraging the recent literature on equivariant CNNs, the paper proposes a CNN model that is equivariant with respect to known symmetries of the Navier-Stokes equations (time/space translation, rotation, uniform motion, and scaling). This approached is validated on 2 datasets on fluid dynamics: a synthetic dataset on Rayleigh-Benard convection and a real-world ocean dynamics dataset. On the synthetic dataset, the proposed models demonstrate better performance under distribution shift. On the real-world dataset, the models yields predictions that are more accurate and physically consistent.\n\n======\n\nStrengths:\n1. The problem setting and datasets are realistic and could have high impact. Given the growing importance of machine learning in physical dynamics and climate science, better understanding on how to incorporate prior knowledge (symmetries) could lead to better modeling.\n2. The claim of generalization under distribution shift is well-validated. The paper identifies 5 types of symmetries of Navier-Stokes equations, and in the synthetic dataset perturbs the test set by applying transforms from these symmetry groups. The experiment results show that models that incorporate those symmetries perform better on this perturbed dataset (though it's unclear how a model that incorporates one symmetry, e.g. scale symmetry, performs on test set that was transformed by another symmetry, e.g., rotation.)\n\nWeaknesses:\n1. The claim of model equivariance is not directly validated. Even though the main claim that incorporating equivariance leads to better generalization, model equivariance is never measured directly. There could be components of the model that are not equivariant, such as pooling or convolution with stride 2. At least the U-net architecture uses stride 2, so it might not be equivariance. It would be interesting if the degree of equivariance could be measured, to see how that relates to the generalization ability.\n2. Sample complexity claim is not validated. In the abstract, the proposed models are claim to \"enjoy favorable sample complexity\". However, there is no experiment validating this claim. For example, with varying amount of data, how do the models perform?\n3. The need for separate models for each of the different symmetries. For each of rotation, uniform motion, and scale symmetries, there is a model that incorporates such symmetry. However, it's unclear if these could be combined. In the conclusion, it is claimed that \"all of our equivariant models can be combined\". But the conclusion also states that \"there does not exist a single model with equivariance to the full symmetry group of the Navier-Stokes equation\".\n4. [Minor] Limited novelty. It's not clear how the proposed models different from equivariant CNNs in the literature [9, 10, 11, 47]. For symmetries not covered in existing work (e.g. uniform motion), the proposed equivariant model seems ad-hoc. However, I do recognize that making all existing architectures work for this realistic problem is non-trivial, so this is only a minor weakness.\n\n======\n\nOverall, I'm on the fence about accepting/rejecting. The proposed model is shown to generalize well under specific distribution shift, but the main claim about the role of equivariance is not yet validated directly. Addressing this concern would make the paper stronger.\n\n======\n\nAdditional feedback and questions:\n- Visualization in Figure 1 is great.\n- The intro mentions Noether's theorem about the correspondence between symmetry and conserved quantity. Is there any evidence that the proposed models conserve some quantity?\n\n====\nAfter rebuttal: Thank you for addressing my concerns. \n- I believe the claim of equivariance leading to improved generalization (weakness 1 above) has now been validated more directly. \n- Regarding the validation of sample complexity claim: a more direct investigation of performance against training set size, for equivariant and non-equivariant models, would be more convincing. I understand that augmenting data does increase the training set size by a factor of 3, but the training set is then not iid so it's not clear what the \"effective size\" of training set is. In any case I do believe that equivariance reduces sample complexity.\n\nOverall, I vote for accepting.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}