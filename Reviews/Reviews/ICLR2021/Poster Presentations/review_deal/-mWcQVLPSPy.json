{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "Three experts in the field recommend accepting the paper (ratings 7,7,6) after the author response, appreciating the improvements the authors made.\n[Note: The AC is mainly disregarding R3's rating, as R3 did not respond to the early request of the AC to clarify their review, did not respond to the authors request for clarification, and did not participate in any discussion past their initial short review.]\n\nThe solid experimental evaluation and an original methodology for zero-shot learning speak for accepting the paper.\n\n[The area chair is certain about accepting the paper, but not fully confident if it should be Poster or Spotlight.]\n\n\n\n\n"
    },
    "Reviews": [
        {
            "title": "AnonReviewer2 [Edited after the author's response]",
            "review": "*Paper Summary*\nThe authors propose a novel computational pipeline to tackle a well-known problem in zero-shot learning: although multiple visual instances are available for the classes and categories to be recognized, one and only one semantic embedding is available to describe the classes/categories while using side information like attributes or relevant textual information. To cope with that problem, authors learn visual and semantic prototypes which are then adopted to perform gradient descent over a graph in which the topological relationship among similar/dissimilar classes are preserved. In the experimental validation, the proposed method shows its superiority among a number of prior methods in zero-shot learning, including discriminative and generative methods. \n\n*Pros*\n* The computational pipeline is novel and very original with respect to prior work, which mainly focuses on feature generating mechanisms\n* Several state-of-the-art approaches are outperformed on 3 classical benchmark datasets for zero-shot learning (AWA2, CUB, aPY)\n\n*Cons*\n* **Sensitivity**. The method is depending upon a number of hyper-parameters (such as the threshold $\\varepsilon$ for the visual/semantic neighbor graphs or the softmax temperature $\\gamma$). \n* **About datasets**. Although tiered-ImageNet is a popular benchmark in few-shot learning, there are methods which provide experimental results on the full ImageNet, such as [Kampffmetyer et al., Rethinking Knowledge Graph Propagation for Zero-Shot Learning, CVPR 2019]. It is not fully clear to which extent the proposed variants of tiered-ImageNet, adapted for zero-shot learning, would improve upon the existing ImageNet specs. \n\n*Minor Comments*\nThe references (Xian et al. 2019a) and (Xian et al. 2019b) refer to the same paper. \n\n*Pre-Rebuttal Evaluation* I think the method is novel and original, and it is adopting a very original direction which is dissimilar for mainstream approaches in zero-shot learning. My only questions relate to the computational sensitivity of the proposed method, which needs some further experimental shreds of evidence. Also, the datasets selected by authors need some clarifications, in both why a new benchmark was introduced and why. It would be great to have more experimental pieces of evidence on other benchmark datasets which are usually considered in zero-shot learning (such as the ''standard'' ImageNet or classical datasets such as SUN -- see (Xian et al. 2019a) -- or FLO -- see (Xian et al. 2018). If the two prior aspects will be addressed by the Authors, I would be more than happy to call for a full acceptance. \n\n*Post-Rebuttal Evaluation [FINAL]*\n\n\nI have thoroughly inspected the revised manuscript and read the response provided by authors. I was pleased in registering that my two requests were taken into consideration by authors who provided a solid sensitivity analysis and additional experimental evidences on ImageNet. Therefore, taking this into account, I am now convinced in raising my original score (5: Marginally below acceptance threshold) to a full acceptance (7: Good paper, accept). ",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting idea but ablation studies are weak and raises many questions",
            "review": "This paper focuses on improving zero-shot classification by reducing the bias of the classifier towards seen classes. The bias occurs since the embedding is trained with visual examples from the seen classes, while using only the attribute information from unseen classes for testing. Authors propose an isometric propagation network that build a graph in both visual and semantic space, performs some steps of propagation, and then uses the updated prototypes for training a classifier. They use attention to construct the graph and also use attention to regularize the graph edges between the two spaces to be isometric. Authors also propose to use an episodic training method to improve learning. \n\nPros:\n- Paper is well motivated and targets an important problem in ZSL\n- Achieves SOTA results on standard benchmarks and proposed large scale benchmarks \n- Show ablation studies for the proposed components\n- Idea of using prototypes that are more informative than either semantic or visual attributes/features is interesting\n\nCons/Questions\n- The paper could have been better written. It was hard to follow at some points\n- Section 4: \"In this paper, we bridge the three spaces via class... \" Is it three or two spaces\n- I was not convinced with the results in the ablation studies.  For most cases the harmonic mean is close the best value- which raises questions about how much these additional contributions are helping and what exactly is resulting in improvement over the baseline. The mode without any propagation achieves H=70.7 in table2(b). How do the method achieves 70.7 (which is more than most SOTA methods) without any propagation. Similarly the consistency loss only seems to be improving performance by 2.9% over H=70.1. Either these ablation studies are not set properly or the baseline is already high. \n- How much is the episodic training helping? \n- Can the authors provide a baseline the only uses the semantic features and then learning the classifier in Eq (8). Also, did the authors try using the prototypes in an embedding based classifier\n- Why is the classifier in Eq (8) referred to as a KNN classifier.  \n\nOverall I find the idea interesting but I am giving a borderline rating due to several unanswered questions and lack of strong ablation studies highlighting the effectiveness of the proposed idea. \n\nFinal rating- I am satisfied with the author's response and updating my ratings. ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting interaction between visual and semantic prototypes with good results; writing needs to be improved",
            "review": "**Summary of paper**\nIn this paper Zero Shot Classification is studied using prototypes. Each class is represented with a visual and semantic prototype, and at test time compared to a visual example + prototype for a(n unseen) test class. The most similar test class is chosen. In this work a novel method is proposed to construct the prototypes, which are trained in an episode learning setting. On various benchmarks the proposed method performs better than existing method for the generalized zero-shot classification task (seen + unseen) test classes.\n\n\n**Strengths**\n1. This paper combines semantic and visual prototypes via a kind of attention method for (unseen) test classes (Eq 2), and at train time via a KL divergence, yielding more visual&semantic prototype neighbours. That is interesting way of combining the two spaces. Could the attention module directly use both spaces, and not only via a KL loss?\n\n2. The proposed method obtains good results on different benchmark tasks.\n\n**Weaknesses**\n1. Notation is not always clear, and partly undefined. Below a list of some examples:\n  * Eq 1: given that D is fixed for a class (at any iteration, not only at [0]), this seems to be the simple projection: W P, where W depends on the iteration, so may be W[0] should be used. Note that is unclear why the visual prototypes should be mapped to the semantic prototypes. The reverse is equally explainable. [Please make clear that W is shared among all prototypes].\n  * Eq 2 (and below): a^s and c^s are not defined. \n  * Eq 2: How is P^v_z defined? When similar to Eq 1, then there is a double projection with W.\n  * Eq 8: If w and b are not class dependent (ie depend on Py), then at least b do not add anything to the argmax. \n  * Pr (below Eq 8) is undefined.\n  * Section 4.5: unclear what parameters are trained here (W, W1, W2, b1, w, b)? Unclear how important the episode training is compared to 'standard' training. \n2. Relation to other methods are unclear. For example, the label/graph propagation is not related to other methods. The episodic learning is not related to other method (in ZSL), also its importance is only implicitly visible from the experimental results (by comparing the ablations with results from the main table).\n3. Unjustified claims and missing experiments:\n * A new large scale benchmark to train end-to-end is introduced [Section 5.1 paragraph 'Two new large-scale benchmarks'], but in 5.2 it is stated 'we use pre-trained classifiers without fine-tuning'. Besides many more papers on ZSL have conducted experiments on (subsets of) ImageNet.\n  * Claim in Sect 5.3 'For example IPN brings 10% improvement to H-metric on AWA2', according to Table 1: 72.9 vs 71.5. That is a 1% improvement. \n  *  'Initialisation of visual prototypes of unseen classes is important' [P7, Sect 5.3] (currently done using Eq 2). But it is left unclear how this is studied, concluded. \n * The method relies on a few hyper-parameters (temperature, threshold, episode learning N, K, learning weight (lambda), and the number of propagation steps), these are not studied, but for eg the propagation steps it is claimed that more steps perform better. This should be studied.\n * There are a few alternatives to the same idea (ie how to use the neighbour propagation in the two spaces) which are not explored.\n\n\n **Minor**\n- The anonymous GitHub repository is not available (404 error)\n- Figure 1: It seems that a nearest prototype classifier is used instead of the depicted nearest neighbour classifier \n- Typo: Page 3, Sect 4, first sentence: 'we bridge the three spaces' --> two?\n- Page 4, Sect 4.1: It is unclear what the geometry structure of  semantic prototypes are and how these are preserved.\n- Page 8, Sect 6, first sentence: 'each space ans across two' --> and\n\n\n**Conclusion**\nThis paper proposes a novel method to learn semantic and visual prototypes for zero-shot classification, which uses episodic learning. The prototypes are propagated over a visual/semantic neighbours graph. That is an interesting approach and experimentally the method obtains good results on various benchmarks. The influence of some of the key  parameters of the method are not studied, nor the disentanglement between the episodic training and the prototype propagation. This combined with the many (minor!) flaws and unclarities in the paper yields my rating of marginally below the acceptance threshold.\n\n** Post Rebuttal**\nThe paper has been improved based on the reviews, I think this paper is now ok to accept.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Please find below for the detailed comments",
            "review": "This paper proposes an Isometric Propagation Network (IPN) for ZSL. The proposed IPN aims to learn to strengthen the relation between classes within each space and align the class dependency in the two spaces. IPN achieves the state-of-the-art performance on three popular ZSL benchmarks.\n\nStrengths:\n1. The explanation of the objective function and the main formula is clear.\n2. The introduction of related work is very organized.\n\nWeaknesses:\n1. The motivation and the advantages of IPN are unclear.\n2. Most compared methods are out of data. Some generative or discriminative ZSL methods proposed in CVPR’20 or ECCV’20 are not compared.\n3. More experimental results besides ZSL results and H value should be given to show the advantages of IPN.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}