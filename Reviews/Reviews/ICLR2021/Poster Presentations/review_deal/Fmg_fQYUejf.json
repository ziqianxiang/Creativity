{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper is presenting an important empirical finding. When the learning algorithms are initialized with the same point, the continual and multitask solutions are connected by linear and low-error paths. Motivated by this finding, the paper proposes a new continual learning algorithm based on path regularization. The paper received unanimously good scores. I agree with the reviews and recommend acceptance. "
    },
    "Reviews": [
        {
            "title": "The paper studies continual learning from the perspective of multi-task learning and shows that a linear path of low error regime connects the found local minima of the subsequent tasks  with that of multi-task learning. ",
            "review": "The paper starts by that observing the local minima obtained in a multi task scenario are connected with a linear path of low error regime to the local minima of each task in a continual learning scenario in contrast to the path between the different minima of tasks incrementally learned, provided the both training of multi task and continual learning have started from the same initialization. The paper studies and shows this mode connectivity empirically. It further discusses and analyses the factors behind this connectivity while noting that this is valid when tasks have shared structure in which local minima can be found nearby.\nMotivated by these observations, the paper proposes a new solution to the continual learning problem. This is done by defining a new loss that forces this connectivity between the minima of  the previous task and the current task. As this requires evaluating the loss of a previous task, an experience replay of stored previous samples is used.  The paper shows improved performance in comparison to existing methods on different benchmarks of 20 tasks long each.\nWhile I enjoy reading the paper, I think the clarity of the text can be enhanced specifically when referring to figures. The second reference to figure 2, comments on the Euclidean distance without explaining where this is shown in the figure and that was not so clear in the figure caption either. Figure 7, it is not clear what corresponds to the Naïve SGD and what corresponds to the MC SGD.\nOn the empirical evaluation, I wonder how stable SGD would perform if was given access to the same replay buffer?  It would be also interesting to show the comparison of the path with Stable SGD since it is supposed to find wider local minima where other tasks minima are likely to be nearby.\nI assume that split cifar 100 is multi-head, would the proposed solution shows similar advantages in the shared head scenario?\n",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "The question of how MTL and CL solutions are connected is well motivated, answered satisfactorily, and leveraged to motivate an effective approach to CL",
            "review": "############## Summary ##############\n\nThis submission asks the question of how the minima found by batch multi-task learning compare to those of continual learning. It empirically finds the they are connected via linear interpolation through a manifold of low error, and leverages this fact to come up with a clever new algorithm for continual learning that performs better than various existing continual learning baselines on three benchmark data sets.\n\n############## Strengths ##############\n\n1. The question of how to connect multi-task to continual learning solutions is well motivated via simple introductory experiments.\n2. The answer to this question, that there is a linear mode connectivity, motivates a simple, elegant, and effective algorithm.\n\n############## Weaknesses ##############\n\n1. The paper could benefit from substantial editing to make it clearer and easier to follow. I found myself having to re-read various sections to properly understand how the different parts of the paper were connected.\n2. The empirical evaluation is done only on three benchmarks. It could be valuable to add evaluations on additional data sets, like Omniglot (https://github.com/brendenlake/omniglot).\n\n############## Recommendation ##############\n\nI recommend this paper for acceptance, but urge the authors to substantially revise their manuscript to make it more approachable. I believe this paper to be self-contained, with a clear question being asked, which hadn't been asked before: how are the solutions to multi-task and continual learning methods connected. The authors find that there is linear connectivity between these solutions, and use this fact to motivate a simple yet effective continual learning algorithm.\n\n############## Arguments ##############\n\nThe question of whether and how the solutions to multi-task and continual learning are connected is highly relevant. While most prior literature had assumed that some distance metric in the parameter space was the correct way to measure their connection, this work is motivated by the experiments in Fig. 2, which show that these metrics are not quite appropriate. Instead, the authors show that linear mode connectivity better explains how multi-task and continual learning solutions are related.\n\nThe manuscript then deviates to an analysis of when this type of connectivity holds by analyzing second-order Taylor approximations. I had to re-read this section (Section 3) multiple times in order to find what the relevance of it was to the submission. My conclusion was that the point is that the fact that the parameter vectors move in directions of low curvature means that interpolation in those directions doesn't increase the loss by much. This fact seems to be somewhat hidden in the text. I encourage the authors to place emphasis on what their analysis is attempting to find before diving into it in depth, as it is easy to lose the reader if they are not aware of where the analysis is going from the start.\n\nThe proposed algorithm is clever and simple: it leverages past data not only to approximate the loss of the previous tasks on the new solution, but also to add a regularization encouraging a low-loss linear path between the solutions. Although the authors experiment with very few data sets, I believe they sufficiently show the applicability of their method and the fact that it performs well. It would be interesting to see how differently the method would perform if instead of the MC regularization, the authors used the EWC one. This would help avoid conflating the claim \"regularization + replay is best\" from \"MC regularization + replay is best\". Similarly, it would be relevant to reproduce Figure 7 with the solutions found by baselines, to assess whether they also find linear connectivity solutions. The claims would be stronger if the authors showed that baselines don't find linearly connected solutions.\n\n\n\n############## Additional feedback ##############\n\nThe following points are provided as feedback to hopefully help better shape the submitted manuscript, but did not impact my recommendation in a major way.\n\n\nIntro\n- It seems like the authors interchangeably used en-dash and em-dash. They also used en-dash to open, but not close, a statement.\n- What confounding factors are removed by doing w1 --> w1,w2 other than initialization? The text makes it sound like there's more but no other is discussed.\n- Contribution 3: benchmark --> benchmarks\n- I believe compressed related work sections or those pushed to the appendix make it hard to place the contribution in context. I encourage the authors to expand this section in the main paper.\n\nSec 3\n- I had two main questions when reading this section:\n    - Why doesn't EWC find such a low curvature path, if it precisely penalizes deviations in directions of high curvature?\n    - Why can't we just use the proper Taylor expansion instead of Euclidean distance then, to measure forgetting, instead of mode connectivity?\n    -These two questions were answered towards the end of the section by showing that this is not a sufficient condition, and are then explicitly addressed by suggesting that second-order approximations are a promising direction for future work. I encourage the authors to clarify this before diving into the analysis, so the reader knows what to look for when reading this section.   \n- The caption for Fig. 5 doesn't explain difference between b and c, which is only somewhat explained in text later.\n\nSec 4\n- Regularization only considers low-loss path between the solution to the immediately previous task and the current solution (but not the solutions to all past tasks), assuming that the immediately previous solution contains sufficient information. Was this empirically tested? The EWC authors claim that using only the previous model in their setting is insufficient [1], so it would be interesting to see if there's a similar effect here.\n\nAppendices\n- Very complete: additional results, justification of experimental setting.\n\nStyle, grammar:\n- appendix X --> Appendix X\n- second order Taylor --> second-order Taylor expansion/approximation\n- minima is often used as a singular, which should be minimum\n- regularization based --> regularization-based\n- rehearsal based --> rehearsal-based\n- Inconsistent italization of i.e.\n- few shot learning --> few-shot learning\n\n\n[1] Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., ... & Hassabis, D. (2018). Reply to Huszár: The elastic weight consolidation penalty is empirically valid. Proceedings of the National Academy of Sciences, 115(11), E2498-E2498.\nChicago ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Connection between MTL and CL is very nice!",
            "review": "Summary\n\nThe paper studies the relation between the geometry of solutions of continual (CL) and multi-task learning (MTL). Towards this end, the authors empirically identify that all the solutions of CL (i.e. solutions obtained after each task) and MTL are connected by a linear region of low error. This is a very interesting finding and, to my knowledge, has not been studied previously in the CL literature. Based on this observation, the authors propose a memory and regularization-based CL method, MC-SGD, that ensures that the final CL solution is linearly connected to all the task’s solutions. The authors further demonstrate that the solution of the MTL lies in the region where the Hessian of the loss function is low and hence the regularization-based approaches that make use of curvature information (e.g.) EWC, are a promising direction for CL. Experiments are conducted on Permuted and Rotated MNIST, Split CIFAR benchmarks. MC-SGD performs strongly compared to other baselines. \n\nPositives\n\n1- I quite enjoyed reading the paper. It is very well-written and insightful. \n\n\n2- Sections 2.1 and 3 are very nice. The finding, albeit empirical, that the solutions of multi-task and continual learning are linearly connected could prove to be very important for future research in CL. \n\n\n3- Experimental results are very strong. I am frankly quite surprised that the gain on top of ER is that much. Although the authors mention it in Section 5 that they use a similar setup as in the other works, I just want to clarify the number of epochs here. If my understanding of their work is correct then Chaudhry et al., in all their work use a single-epoch setup where Farajtabar et al., used multiple epochs. Do you use single or multiple epochs?\n\n\nNegatives\n\nI don’t have any major concerns about the work except for a few nitpicks and questions. \n\n\n1- See the multiple-epochs remark above. \n\n\n2- Fig.5: Can you compute all the eigenvectors and show whether the cosine similarity in the eigenvectors corresponding to the smallest eigenvalues actually increase when you go towards the multi-task solution. You can reduce network size if compute is the problem. \n\n3- Eq.5 (or similarly Eq. 3): It seems that one needs the solution of task t $\\hat{w}_t$ for this loss to work. If one just receives the task t how would one obtain this solution? Do you do this in two steps? Where, in step 1, you just compute the $\\hat{w_t}$ starting from $\\bar{w}_{t-1}$, and then, in step 2, you use the $\\hat{w_t}$ obtained from step 1 to compute the final $\\bar{w}_{t}$?\n\n4- Fig. 7: Might want to highlight in the legend which path is CL and which is MC. \n\n5- Page 5, 6th to last line, ~oneself~ itself",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}