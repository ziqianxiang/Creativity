{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper use Group convolutional neural networks in both generators and discriminator of GANs, and demonstrates advantages of this approach when training with a relatively small sample size. While the novelty is limited in the work  as it simply applies G-CNN for GANs , I believe this application is interesting and  the authors have applied it to many GAN image synthesis applications (conditional generation , pix2pix) on various benchmarks, which gives  evidence of  the potential of GCNNs in generative modeling. Accept"
    },
    "Reviews": [
        {
            "title": "Review of ICLR Paper 1928: Written well but needs some improvements",
            "review": "# Review of ICLR Paper 1928\n\n## Group Equivariant Generative Adversarial Networks\n\nThis manuscript addresses the problem of artificially generating images for which the label should be unaffected by certain symmetries and/or translations. To address this problem, the authors use the Group Equivariant Convolutional Neural Networks of Cohen \\& Welling (2016) as the generator and/or discriminator in a Generative Adversarial Network. They conduct a sequence of experiments on smaller data sets--four real and one synthetic--exhibiting varying levels of symmetry, which together suggest that Group Equivariant GANs may be more effective than traditional convolutional networks in the low data setting.\n\nMy assessment of this manuscript is that it sits right on the threshold separating acceptance and rejection. On one hand, the writing is remarkably clear of grammatical errors and the authors are evidently deeply familiar with GAN literature. On the other hand, the paper's novelty is minimal and the mathematical descriptions of some important parts of the manuscript are insufficient. Group Equivariant Networks were introduced in 2016, and in the original paper those authors demonstrated the efficacy and training efficiency of these networks. In this manuscript, the authors' contribution can be summarized as placing this architecture in a GAN and observing similar improvements, which is unsurprising and in my assessment a marginal contribution.\n\nI've summarized further concerns below.\n\n- Section 2.1, the Preliminaries section, makes the fundamental concepts extremely hard to understand. \n    - \"Equivariant\" and \"invariant\" are not defined.\n    - Please provide a citation for the plane symmetry groups $p4$ and $p4m$.\n    - The phrase \"an image is a function $f$ on a rectangular grid $\\mathbb{Z}^{2}$\" is ambiguous. Use the notation $f: \\mathbb{Z}^{2} \\to \\mathbb{R}$. However, you later mention that $f$ has $K$ channels, in which case $f: [K] \\times \\mathbb{Z} \\times \\mathbb{Z} \\to \\mathbb{R}$. Regardless, I'm confused.\n    - Which operation defines your group? You have sums and product and compositions, so this should be clarified.\n    - Define a filter $\\psi$.\n    - The $g^{-1} y = y - g$ on page 3 is confusing. How can this work when $g \\in p4$ is a rotation and not a translation?\n    - On the whole, I find this section inadequate. The Cohen paper introduces these concepts well, so I encourage you to stick closer to the mathematics introduced there.\n- \"We finally max-pool over the set of transformations to obtain the generated image $x \\in \\mathbb{Z}^{2}$\". An image is a function, not a pair of integers.\n- \"The group-equivariant discriminator receives an inputs $x \\in \\mathbb{Z}^{2}$\" Again, an image is not a pair of integers.\n- Table two is problematic for me. Your Group-Equivariant networks have less parameters, and you are operating in a self-professed limited data environment. Shouldn't I expect that the networks with less parameters exhibit less overtraining?\n- What are the details of how you conducted the ablation study? What layers and/or features did you remove?\n- I am not convinced that, in table 2, the potential for augmentation leaking means that the CNN with standard augmentation is \"inapplicable\". Why don't you just let the FID evaluation measure its performance, which should be higher if the network has captured symmetries incorrectly?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Needs a little more",
            "review": "This paper presents a method for incorporating inductive symmetry priors into the network architectures of GANs. The authors propose replacing standard CNNs with group-equivariant CNNs in either the generator or discriminator or both. The method is evaluated by comparing generated images to originals using Frechet distance for a number of datasets. \n\nThe paper is well written and comprehensive. Its main contribution seems to be the adaptation of some common GAN techniques to the group-equivariant case. \n\nThe experiments are fairly convincing, although I would like to see more discussion about when to use the group convolution in the discriminator vs generator vs both, as this seems to make a difference for different datasets. I am not an expert and am unsure if Frechet distance is the right metric here, but it seems to be common at least. \n\nThe authors say they compare their method to one of the two main, state-of-the-art GAN designs. It would be interesting to see a comparison with other flavours of GAN also. Given the empirical nature of the paper, I think this would be a more convincing argument (i.e. group-convolutions can improve GANs not just BigGAN).  It would also be interesting to see how the different methods perform given different amounts of training time. \n\nIn general I like this paper, though I think the experiments could be more comprehensive (as noted above). That being said, it is not immediately clear to me that this is enough of a contribution to be accepted, since it is just applying existing methods in the group-equivariant case. As I've said though, I am not an expert in GANs, and I would be open to increasing my rating if more knowledgeable reviewers disagree on this point.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Interesting approach that could be enriched.",
            "review": "Short summary of the paper:\n\nThis paper proposes a new type of architecture that incorporates group-equivarient layers into the discriminator and the generator of a GAN. This group shall be a group of symmetry of the signals to generate, and in this paper, the authors focus on the group generated by translations, pi/2-rotations and reflexions. They also employ linear upsampling, and they show that with no specific ad-hoc tricks(here, class-conditional batch norm & spectral normalisation), it is possible to train competitive GANs with such priors. The experiments are conducted on datasets which have exactly two symmetries (translation or roto-translation), like rotated-MNIST, or approximatively one like Food-101, or CIFAR-10. The major contribution of this paper is experimental, showing better per-class synthesis and claiming one needs less data thanks to those priors.\n\nPros:\n- This is an interesting attempt to incorporate group structure in GANs which can only benefit to the community.\n- Various experiments are conducted which positively support the insights of the paper, measured thanks to a visual fidelity metric.\n\nCons:\n- I think the formalism could be more complete and rich. Several points are not addressed, like dealing with more complicated groups that imply an inexact covariance but are still groups of variability. Currently, I find it too elementary.\n- From the experimental points of view, I thought small data meant to use at least an order of magnitude less samples than the original dataset for training GANs. At least, it would have been nice to show a more complete plot, in order to understand the tendency is a really limited sample setting, rather than 3 data points for 33%, 66% and 100% of the data.\n- I would have appreciated to understand the methodology to pick the hyper parameters. In a supervised context, I understand that one performs a grid search on a validation set which is a subset of the training set. Here, the way to pick an architecture is unclear to me. For instance and in one word, it should be clear if modifying an architecture to make it G-convolutional friendly.\n\nSpecific remarks/questions:\n- I find quite strange to see no Mallat's citation, whereas the first works on invariance in image processing/CNNs is from his group and since at least 2010 if not older ( https://www.di.ens.fr/data/publications/papers/Eusipco2010InterConfPap.pdf ). Furthermore, I noticed some generative models based on a scattering transform ( https://arxiv.org/abs/1805.06621 / https://arxiv.org/abs/1809.06367 ), yet they do not work substantially better than other architectures whereas the scattering transform employed there leads to no loss of information. It indicates that group a framework might not be the ultimate key to generating images. Consequently, I would substantially lower the claim \"to our knowledge, we are the first to introduce group equivariance to GANs, and use geometric considerations in both generator and discriminator\".\n- This leads to a second remark: the groups of equivariance which are used correspond roughly to horizontal and vertical reflexions. They are not natural groups to consider for image variabilities (like small rotations, or small deformations) Consequently, it is natural that applying a data augmentation strategy based on those groups would \"hurt\" the performance.\n- Again, the group-a priori is quite limited: it's not a generic group which is used, but a very small subset subgroup of the rotation. This is probably due to aliasing but one can wonder how to extend this method to real group of variabilities (deformations, rotation, scaling) This should be discuss, or at least tried, even if it doesn't work.\n-  It is written that the authors tried to learn \"a transformation from G to Z^2\" that could be learned. I think the formalism here is important: it is a representation from G to L^2(Z^2) that one would like to design. I think it would be also nice to develop more this aspect in the paper or not to mention it at all.\n- The number of samples used isn't really impressive. 33% of the data isn't order of magnitude smaller than the original dataset thus I find the small data claims strange; what happens if less data is used for instance?\n- Why isn't the linear  averaging along the group in the G-equivariant architectures, and why is it only w.r.t. translations? I'm slightly confuse by the combination of the max-pool and global average pool.\n- I was wondering if the authors tried to manipulate the orbits of the generated signal: could one use the same \"displacement\" (or rotation) in the latent space to sample two rotated images from each other with the generator?\n\nSuggestions for improving the paper:\n- I believe a significant improvement could be obtain from a more careful formalism to handle complex groups of variability of images.\n- I would add slightly more elements about the experimental process, for being more reproducible.\n- I think it'd be okay to show some negative results.\n\n[Post-rebuttal] I've read the rebuttal, which answers to many points I raised. I've reflected it in my score.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting application of G-CNNs to image synthesis, but limited novelty.",
            "review": "Summary:\nThe submission concerns an application of group convolutions (Cohen & Welling, 2016) to the image synthesis setting, where images are produced by the generator of a GAN. The two GAN components are augmented mainly by a straightforward replacement of \"regular\" convolutions by group convolutions, in addition to some other training tricks of the trade (gradient penalty, spectral normalization). Experiments indicate somewhat lower FID scores on both synthetic and real settings. The method is seen as useful especially for the low data regime case.\n\nReview:\nDespite the conceptual simplicity of the presented approach (\"replace convolutions by group convolutions\") I found the method itself a novel combination of existing concepts. I can also imagine that getting the such modified architecture(s) to work in practice can be quite tricky; hence the additional GAN training measures that were adopted in the training setup.\n\nOverall, however, I see novelty and impact to be fairly limited, as all insights come from empirical evaluation, which is notoriously difficult for visual synthesis applications. The authors provide both visual results as well as quantitative results mostly on the basis of FID measurements which aim to evaluate the quality of the images. Experiments seem sound and results are clearly presented. \n\nAlthough the authors claim in the discussion section that visual fidelity and sample complexity are meaningfully improved, I miss an attempt at quantitative analysis of this claim, either through algorithmic metrics or user studies. There are also no statements on the trade-off between sample fidelity, training difficult and amount of (training or inference time) compute. Since one of the strengths of the approach may be in the limited data regime, I would have liked to see stronger evidence of a major impact there; I can't quite see such a trend in the numbers of Table 1.\n\nOverall I see the work performed and results achieved by the submission as good, but a stronger verification of the main claims would make the submission even stronger for the main conference track.\n\n[Update post-rebuttal: I thank the authors for addressing some of the concerns raised by the reviewers. My stance remains, also given the outcome of e.g. the 10% experiment -- verification of the main claims remains difficult. My score already reflects that I'd be happy to see the submission accepted.]",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}