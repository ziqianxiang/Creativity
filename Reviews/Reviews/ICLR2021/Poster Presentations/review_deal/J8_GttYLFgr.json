{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper proposes and studies a new SO(2)-equivariant convolution layer for vehicle and pedestrian trajectory prediction. The experiments are detailed and demonstrate the effectiveness of the approach in relation to non-equivariant models."
    },
    "Reviews": [
        {
            "title": "Writing should be improved, many details missing",
            "review": "The authors present a novel approach to trajectory prediction, where they use rotationally-invariant continuous convolutions. They present background on such convolutions and discuss a way to efficiently store and compute them,\nI found the paper not really well written, with a number of notation not being explained or skipped. I went over several relevant citations that the authors provided which helped, but some parts still remain unclear to me. I may not have understood all the math presented, which is the reason I lowered my confidence.\n\nMore comments:\n- The writing could be improved significantly. The authors introduce a lot of notation and concepts without really defining them well. E.g., K goes from K(.) to K(.,.) to K(.)(.,.), and similarly for rho_1 and rho_reg. I may be missing some background knowledge here, but I do feel that this should be much smoother and better explained nevertheless.\n- E.g., here they also introduce phi, theta, and other notation, but what that corresponds to in the trajectory prediction aspect is not explained or discussed. Or T in Section 4.5.\n- The authors mention physically-consistent predictions, but the method doesn't really contribute directly to that aspect of the prediction problem. Nor is it evaluated and discussed deeper. This should be removed or discussed more.\n- Same goes for \"transparency\", it is not really discussed deeper.\n- The authors don't explain well what are the actual model inputs that they use. This is glossed over, while usually works spend a lot of time here. They just say that they use histories and map info, but how exactly is unclear.\n- The authors also say that, unlike some competitors, they predict for all actors. This was also unclear how exactly. Or how are interactions taken into account. The explanations are very vague indeed.\n- Why are the scenes in Fig 6 not exactly the same, some actor locations are different? And especially for CtsConv where the actor is completely different it seems?\n- Curious how was the training done? Did you have to do some augmentation with scene rotations and imposing of the constraints?\nIn general, the discussion can be improved significantly. I marked my grade as 5 as I don't want to block the paper just because I didn't understand all the items, but I would be fine with mark 4 as well assuming the other reviewers have concerns along similar lines as myself.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Review",
            "review": "Summary:\n\nThe paper proposes a continuous convolution equivariant with respect to SO2 for trajectory prediction.\nRotational equivariance is achieved by a weight sharing scheme within kernels in polar coordinates.\nThe proposed scheme approximates rotational equivariance well and has similar or better performance on\nthe trajectory prediction tasks than models without equivariance while using fewer parameters.\n\n\n\nScore:\n\nI tend to accept for this paper. Rotational equivariance is an important problem that can hinder the broad application of ConvNets to sparse and continuous data where often graph networks are used. \nTrajectory prediction is a good application for rotational equivariance and the paper is written very general allowing the method to be transferred to other problems.\nAlthough some interesting comparisons with existing methods are missing, overall the experiments can show well the advantages of the proposed convolutions and are convincing.\n\n\n\nStrengths:\n\nCombining weight sharing with interpolation is a good idea to avoid unnecessary evaluations of the kernel at runtime.\n\nFigure 3 is very helpful but the font size for the labels should be optimized.\n\nThe experiments about physical consistency and the equivariance error answer important questions about the method.\n\n\n\nWeaknesses:\n\nThere are no direct comparisons to other equivariant convolutions, e.g. a comparison with Tensor field networks.\nAlthough the presented method is specialized for SO2, a comparison would be helpful to demonstrate the efficiency of the implementation. \n\nThere is also no information about the runtime and memory efficiency of the convolutions.\nTable 2 shows the number of parameters but the different models may have a different memory footprint during inference.\n\nThe Background section is a bit short. Adding some references to the literature on rotational equivariance in this section would be helpful.\n\n\n\nQuestions:\n\nA7 mentions that all models are trained for the same number of iterations.\nDid all models converge within 15k/30k iterations?\nIf not what is the performance of each model after convergence?\n\nAre the models without equivariant convolutions trained with data augmentations?\n\nWhat is the complexity class of the convolution with torus kernel?\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A Well-written paper, but the idea is not new.",
            "review": "The polar-coordinate convolution has been proposed by multiple previous literatures, e.g. “Polar Transformer Networks” and “Rotational Rectification Network: Enabling Pedestrian Detection for Mobile Vision”. \n\nFor self-driving system, one should be able to get the global pose of your vehicle, then correct the global rotation of your scene based on the global pose. This should be a more practical solution to this issue. To me, this paper is overcomplicated as of a solution to the problem.\n\nThe theory part is well-written and easy to understand.\n\nExperiment is not strong enough though. I want to see how each of your variances add up in increased accuracy in ECCO network, e.g. experiments about stacking up “Weight sharing by orbits and stabilizers”, “polar coordinate kernels” and “hidden layers as regular representations”. Also, for the final model comparison (Table 2), I would like to see how ECCO compares to state-of-the-art other than VectorNet.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Interesting work but with flaws",
            "review": "--- Summary\n\nThis paper presents a novel Equivariant Continous COnvolution (ECCO) method for vehicle and pedestrian trajectory prediction. ECCO extends the previous continuous convolution method and makes it rotationally equivariant. To achieve that, they constrain the convolution kernel function K and make only the K(0, r) component freely trainable, and use it to derive the other components. They also propose a torus kernel that can be used on functions on circles. They evaluated their approach on two real-world trajectory prediction datasets, Argoverse and TrajNet++. They compared to basic baselines including constant velocity, nearest neighbor, and LSTM, as well as CtsConv (non-equivariant continuous convolution) and VectorNet. Results show that ECCO achieves significantly lower prediction errors than CtsConv and has fewer model weights. However, their prediction error is slightly higher than VectorNet at 2s and 3s.\n\n\n--- Strengths\n\n- The proposed ECCO trajectory prediction approach is novel in that the previous approaches are either not rotationally equivariant or only run on a single actor.\n\n- Making convolution operations rotationally equivariant can be very useful to many applications where rotations on the input aren't supposed to affect the outputs. The ECCO method proposed in this paper is very general, and I think it can be applied to the other applications as well.\n\n- With weight-sharing, the ECCO method greatly reduces the number of weights. The evaluation result also shows that the reduction of the trainable weights makes the model more data efficient.\n\n\n--- Major issues and suggestions\n\n- Actually, most of the state-of-the-art trajectory prediction approaches are already rotationally equivariant because they usually rotate their input scene to have the target actor that they are predicting always face up (e.g., in VectorNet). I think the only non-equivariant approaches are those one-shot approaches that predict all actors in the scene simultaneously. This work is interesting in that it is both one-shot and rotationally equivariant. However, from the evaluation results, it is not clear to me why predicting all actors in the scene simultaneously is a desired property. ECCO in fact has higher prediction errors than VectorNet. The inference speed can be a potential win, but the inference speed numbers are shown in the evaluation, unfortunately.\n\n- The evaluation baseline setup paragraph says \"VectorNet only predicts a single agent at a time, which is not directly comparable with ours\". I don't get why it is not directly comparable. In fact, VectorNet has lower prediction errors than ECCO at 2s and 3s. If the inference speed is an issue, the paper should show it with numbers.\n\n- The \"Parameter Efficiency\" paragraph says \"The number of parameters has strong implications in memory usage, battery consumption and compute speed.\" Why not just measure and show the memory usage and compute speed numbers?\n\n- The paper claims that trajectories predicted by the ECCO method are more physically realistic, but I don't see any results in the paper demonstrating this.\n\n\n--- Other comments\n\n- Section 3.2 is a little hard to understand. For example, what is S^1, what is GL, and what is L^2(SO(2))? I think providing more background or some references would be useful.\n\n\n--- Response to author's answers\n\n> The “target actor points up” method can be used to predict multiple agents by running repeatedly, these predictions are each independent, whereas in reality future trajectories for vehicles are mutually dependent. Two cars may have independently likely trajectories, but if they intersect, they are unlikely to occur together.\n\nYes, this is a commonly used argument used by works that predict all actors in the scene simultaneously. However, whether the claimed benefit is achieved by the proposed model is yet to be proved. The fact that the proposed model has higher prediction errors than the state-of-the-art single-actor prediction model makes me doubt whether this is true.\n\nThank you for updating the paper with the inference time numbers. These results are really useful.\n\n> For runtimes on the same test machine, ECCO runs 684ms versus 1103ms for VectorNet.\n\n1103ms is really high a latency for any real-time robotics system. For completeness, could you also include the number of actors that are predicted by VectorNet in 1103ms?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}