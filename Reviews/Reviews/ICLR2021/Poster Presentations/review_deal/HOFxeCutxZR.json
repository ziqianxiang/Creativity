{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "All the reviewers rate the paper above the bar. They like the experiment results and think the proposed latent space editing approach makes intuitive sense. While several weakness points were raised, including a lack of continuous editing comparison and sometimes vague descriptions, they were not considered major to reject the paper. After consolidating the reviews and rebuttal, the AC agrees with the reviewer assessment and recommends accepting the paper."
    },
    "Reviews": [
        {
            "title": "Recommend to a clear accept ",
            "review": "#### Summary:\nThe paper proposes a new simple, yet powerful and alternative method of editing the semantic attributes of images generated using pre-trained GAN models as well as a pre-trained regressors. The approach allows for the manipulation of single or multiple various image attributes, while preserving the identity of the original image in contrast to the baseline method of Shen et. al 2019. The method focuses on the manipulation of the latent space, in contrast to the popular image space editing methods. \n\nThe paper is easy to read and understand. The authors have presented their method and analysis which are clear and understandable, supported quite well with the provided examples and figures.\n\n#### Strengths:\nExperiments are conducted on various datasets and compared to various methods - supervised and unsupervised\nTheir method is able to consistently preserve the image content (in case of scenes) and identity (in case of faces) \nShowing inversion results along the transformation shows the robustness and tractable nature of their method.  \n\n#### Weakness:\nIt is not entirely clear how the local transformation are discovered for different z values independently, or rather what the difference is in discovering the global transformation vs discovering the local transformation\n\n\n#### Questions to the Authors:\n1. In comparison with the Voynov & Babenko model, how many of the directions that their model was able to find did you look at?\n2. What is the accuracy / results of the performance metric of the different used pre-trained regressors? Given that the perceptual losses were used while training, the regressors’ performance values could shed some light in this direction.  ",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper presented a latent-space editing framework for semantic image manipulation. The pre-training of regressor R should be given in more details.",
            "review": "This paper presented a latent-space editing framework for semantic image manipulation. The idea is interesting and plausible, and experiments also show its effectiveness. However, I still have some concerns:\n\n1. The pre-training of regressor R should be given in more details. \n2. The results of the proposed method heavily depends on the GAN inversion. However, it can be seen from Fig. 6 that some details are still lost by GAN inversion.\n3. In term of simultaneous multiple attribute transformations, it is interesting to refer to the following reference to guarantee the latent consistency in the proposed framework:\n[r1] Inducing Optimal Attribute Representations for Conditional GANs, ECCV 2020.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This work produces very interesting results, but the manuscript seems to need substantial revisions.",
            "review": "This paper presents a new approach for the semantic image editing task by allowing the controllable transformation on the latent space. Authors proposed to integrate an attribute regression network for training the transformation functions. The local transformation T is learned from a simple MLP conditioned on the latent vector z. Two outputs of the regression module for the original latent vector z and the transformed one z+T*epsilon are used to minimize the cross-entropy loss. Experiments validate the effectiveness of the proposed method in terms of manipulation quality.\n\n* Pros\n1) Local transformation function T would be a more appropriate choice for transforming the latent vector.\n\n* Cons\n1) The manuscript contains lots of vague parts.\n- Generator G, discriminator D, and regressor R are all pre-trained. How did you obtain the pre-trained regressor R?\n- ‘Joint-distribution sampling and training’ part in Section 3.2 is hard to understand. More details would be needed, including its practical implementation and pros over the separate binary sampling.\n- This method requires using inversion results. Does the accuracy of the inversion results affect the performance of the proposed method?\n\n2) An ablation study on the joint-distribution sampling would be needed to validate their effectiveness.\n\n3) It seems that editing control (e.g., +Night or +Snow) is related to how to sample the epsilon vector as shown in Figure 2. Did you use the sampling strategy that is adaptive with respect to the given editing control? For instance, when editing images into a night scene, how do the method sample the epsilon vector? It seems that there is no such functionality in Algorithm 1. Please revise the manuscript by specifying this part.\n\n4) Table 2 seems to measure the cosine similarity, while Table 1 evaluates the change of the attributes. How did you calculate the change of the attributes?\n\n5) The results in Figure 8 (a) are based on the global transformation T with the proposed losses. Did you obtain these results using MLP direction functions or simple linear-layer direction functions?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "claims are not well validated",
            "review": "In this paper, the authors propose an image attribute editing method by manipulating the GAN latent vector. Specifically, this paper uses a pre-trained GAN to synthesize images, a pre-trained regressor to get the image attributes, and trains a network T to find meaningful latent-space directions. It then edits image attributes by modifying the input latent vector, described as z' = z + T(z)ε. The experimental results show that the proposed method performs better than other selected methods to some degree.\n\nStrengths: \n1) The idea of controllable editing is intuitive and interesting.\n2) Quantitative results on face datasets (Tab. 1 and Tab. 2) show its superiority over other selected methods.\n3) Visualization results on both the natural scene and face datasets show its effectiveness on the parts to be edited (e.g. clouds for “remove clouds” and mouth for “add smile”).\n\nWeaknesses: \n1) Visualization results on natural scene datasets show that its ability to maintain image identity needs to be improved. For example, the image identities in Fig. 3 are changed during the editing, like the mountains' shapes in row 1 and trees' shapes in row 3.\n2) The authors claim that their edits are disentangled, but the visualization results on face datasets don’t support this point very well. For example, the baselines unexpectedly add \"glasses\" when aging the face in Fig. 4. However, the proposed method also adds glasses on the man's right eye (figure on the bottom right corner). \n3) Lack of comparisons of continuous image editing with other methods.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}