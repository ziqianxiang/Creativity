{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "The paper touches upon explainable anomaly detection. To that extend, it modified hypersphere classifier towards fully convolutional data description (FCDD). This is, as also pointed out by two of the reviewers a direct application of a fully convolutional network within the hyperspherical classifier. However, the paper  also shows how to then upsample the receptive field using a strided transposed convolution with a fixed Gaussian kernel. Both together with tackling explainable anomaly detection is important. Moreover, the empirical evaluation is quite exhaustive and shows several benefits compared to state-of-the-art. So, yes, incremental, but incremental for a very interesting an important case. "
    },
    "Reviews": [
        {
            "title": "Recommendation to Reject",
            "review": "########################################################################## \nSummary:\n\nThis paper presents a modified approach, on top of an existing method (DSVDD), for anomaly detection with a state of the art achievement in the unsupervised setting. In my opinion, the model itself is not a novel innovation. However, it fails when sprious image features exist. \n\n\n##########################################################################\nReasons for score: \n\nThis paper has evidence to show better performance comparing to other, in terms of explanation.  But, however, to me personally, it doesn't meet a high standard, as the method is just a modification of what's already existing. And the heatmap as an explanation, demonstrated that model did pick up some superficial features for detection, such as color.  Lastly, as the authors also called out in the last session, it's not robust enough to overcome spurious features, which can be big problem for real applications. \n\n\n\n##########################################################################\nQuestions during rebuttal period: \n \nPlease address and clarify the cons above \n \n\n ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "This paper addresses the topic of explainability in Deep One-Class Classification. A new method, Fully Convolutional Data Description (FCDD), is presented in which the mapped samples themselves are explainable heatmaps. It is shown that FCDD can provide transparent explanations of anomalies while being better or close to the state of the art on standard AD-benchmarks. ",
            "review": "### **Evaluation**\n- The paper is tackling the topic of explainable Deep One-Class-Classification. In contrast to comparable methods, like for example gradient-based heatmaps, FCDD has a spatial context. This fact facilitates the interpretability. \n- The approach is well-motivated and compares well to the state of the art AD-methods.\n- The paper provides sophisticated theoretical as well as empirical insights. \n\n\n### **Detailed Comments for Authors**\n- The visualisations given in the paper are well suited for the addressed problem. The Appendix gives a good insight into the functioning of the FCDD as well as the decision process of the networks. However, in figure 18. the output for \"toothbrush\" is shown a huge anomaly blob for all samples, while the ground truth shows just minimal areas. Why is that the case? \nIn contrast to this, the mean AUC in table 2 is 0.94 (and 0.95 for semi-supervised FCDD), which is quite good comparing to the visual impression. \n- The section addressing the \"Clever Hans\" effect was a good addition, since it shows another perspective of the usage of the methods while clearly showing the learned characteristics. It might be beneficial to explain in more detail, why using the \"horse\" class as anomaly class, since it is kind of in inverse logic (it makes sense, but while reading one had to think twice about it). \n- For the heatmap-overviews given, it might be valuable to have a comparison of one sample of the nominal class and multiple of the anomaly one. In this way, the trained class is shown and directly comparable to the anomalies.  \n\n#### **Strong points of the submission.** \n- Very well written paper, which is easy to follow, based is based not least on good visualisation.\n- The paper provides a good and detailed description of the theoretical concepts.\n- It is positive that the examples also pointing some weaknesses of FCDD, like not recognising the anomaly, while simultaneously comparing to other methods. The method shows its strength in the spacial context. Given the extended appendix, the authors deliver a critical view on the possibilities as well as the potential limitations.    \n\n#### **Weak points of the submission.** \n- the conclusion is quite sparse, and even missing an own section.\n\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An elegant and simple approach to deep one-class classification that provides explainable decisions",
            "review": "This paper presents a one-class classification method using a fully convolutional model and directly using the output map as an explanation map. The method is dubbed FCDD for fully convolutional data descriptor. FCDD uses a hypersphere classifier combined with a pseudo-Huber loss. FCDD is trained using outliers exposure (OE) from a different but related dataset. The empirical study consists of 3 parts:\n * a quantitative comparison of anomaly detection (AD) with SOT methods on three datasets: Fashion-MNIST, CIFAR-10 and ImageNET. The proposed method is shown to be competitive with SOT.\n * a qualitative study showing that the explanation provided by FCDD is more useful compared to other methods.\n * a quantitative comparison of the explanation performance on the MVTec-AD dataset. This shows that FCDD beats other SOT approaches and can also be easily adapted to accept actual anomalies examples, which results in even improved numbers.\n\nPROS:\n\n * The paper is very well written (excellent grammar!) and easy to follow, with clear, complete and concise explanations. \n \n * The method is simple and elegant. It should be easy to reproduce it.\n \n * The results are competitive with SOT for AD and beats it for the quality explanation (with the caveat below).\n\nCONS:\n\n * The novelty is incremental: Combining fully-convolutional CNN with a hypersphere classifier.\n\n * The comparison with other methods for MVTEC is only with published results. FCDD uses a confetti noise to create OE examples. However, it is not clear which OE methods (if any) were used in the published results. Therefore it is not clear if the improved SOT comes from a better OE method or from the FCDD itself.\n\n *  The paper also describes a fixed-kernel (Gaussian) upsampling method using strided transposed convolutions, which I find unnecessary to be added to the paper.\n\n * the qualitative examples on figure 1 should be compared with other methods. \n \n * fig 5 should show the nominal class for visual reference.\n \n \n Overall this is a well written paper, presenting a simple and reproducible approach to explainable AD that beats the SOT. \n \n ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}