{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper is devoted to \"dyadic fairness\" in representation learning. All the reviewers agreed that the contribution is novel, original and technically sound. However, all the reviewers agreed that the paper should be improved in terms of presentation -- for two reviewers, presentation/clarity issues were at the core of their weak rejects. The most positive reviewers highlighted that the problem is still understudied despite the flurry of work on fair machine learning in the last years and therefore the contribution deserves to be accepted. If there is room, this paper can be accepted as a poster."
    },
    "Reviews": [
        {
            "title": "Review of dyadic fairness",
            "review": "This paper discusses fairness problems in graph embedding for link prediction to mitigate problems such as graph segregation related to sensitive attributes. The paper uses a variational graph autoencoder to learn an embedding, and predicts links based on distance in this embedded space. The notion of dyadic fairness refers to statistical constraints on link prediction between/across sensitive attribute groups, such as parity for positive predictions or false negatives. The learning algorithm updates a weighted adjacency matrix with nonzero entries preserving the observed adjacency structure of the graph, while optimizing edge weights to tradeoff between utility and dyadic fairness of edges predicted from the weights. The paper compares the proposed method to a baseline and a competing fair graph embedding method on several example datasets to show good performance on utility, fairness, and diversity of inter/intra-group link predictions.\n\nI recommend accepting this paper because it focuses on a problem where there is relatively little previous work, introduces a novel approach, and shows empirically that the approach is competitive. I have a few questions or comments which, if addressed, could improve my rating of the paper.\n\n0. Is it really necessary to constrain the nonzero entries of the adjacency matrix based on observed edges? The paper suggests \"adding fictitious links might mislead the directions of message passing,\" but is there any reason to believe the resulting errors would be any worse than errors from other sources of uncertainty in the problem? It seems possible to me, a priori, that an algorithm without this constraint might achieve both better utility and fairness under some conditions on some examples. This might be worth exploring or mentioning, even if the present paper makes the design choice of keeping this constraint.\n\n1. It is not clear to me exactly how the theoretical findings motivate the algorithm. Perhaps this would be clearer with a better explanation related to my previous point about the structural constraint.\n\n2. In the theoretical analysis, immediately after Corollary 4.1, the paper states \"Multiple layers of GNNs can be reasoned out similarly.\" This seems like quite a stretch without providing further justification. \n\n3. It is a little confusing to determine the meaning of \"proportion\" on the horizontal axis in Figure 2.\n\n4. For the experiments, it's not clear to me why the category of an article should be considered a sensitive attribute in citation networks. Perhaps there is an explanation of the fairness concern in citation networks that would make this more obvious. Instead of so many citation networks, the experiments might be improved with social networks having sensitive attributes like race, religion, or political identification, where there are social science reasons to be especially concerned about social network segregation. I believe there is less reason to believe there will be a high degree of network segregation on the basis of gender than on the basis of those other sensitive attributes, so I would suggest not limiting the sensitive attribute to only gender in the social network examples.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting paper for understanding graph representation fairness and an alternative strategy to mitigate the potential bias",
            "review": "##########################################################################\n\nSummary:\n\nThis work studied how the connections in graph data affect 'dyadic fairness' when applying GNN for representation learning on homogenous graphs. Inspired by the theoretical findings, the authors proposed a method (FairAdj) on top of VGAE to adjust adjacency weight matrix as a separate step to address the fairness-utility trade-off. The effectiveness of the proposed method is demonstrated through extensive experiments on different real-world datasets.\n\n##########################################################################\n\nStrength:\n\n- Fairness of graph representation learning is a relevant and emerging research topic\n- The analysis and the proposed method are technically sound and the experiments are executed well\n- Many interesting insights are obtained from the theoretical analysis\n\n##########################################################################\n\nWeakness:\n\n- The overall presentation can be further improved.\n- Current analysis and method are conducted at homogeneous graph only\n- Efficiency / Time complexity analysis is not provided\n\n##########################################################################\n\nDetailed Comments and Questions:\n\nThis is an overall good work which contributes some interesting insights around graph representation fairness, a solid method to mitigate potential bias, and a series quantitative experiments to demonstrate its effectiveness. I also enjoyed reading this work and felt inspired. Overall I vote for *accept* but there are also a few points which could be further improved.\n\n- The overall presentation is a bit dry and tough to digest. Specifically it's a bit difficult to understand dyadic fairness from high-level and differentiate this concept with other algorithmic fairness work on graph data. Might be helpful to highlight the formal definition of this and the corresponding insights.\n\n- Current analysis and method are conducted at homogeneous graph and the analysis is concluded on 1-layer GNN scenario, would be better to open discussions for future work\n\n- One missing part of the proposed mitigation strategy is around the time efficiency analysis. For practical reason, how its efficiency (specifically the two-step iteration for adjusting the adjacency matrix) compared to a typical adversarial approach? \n\n- What I'm further curious about is how the theoretical findings can be extended to 1) multi-hop/layer GNN and 2) bipartite graph such as the typical user-item recommendation setting. For 2) seems not very obvious; for 1) I did see a great practical value as in real-world applications it is very common to go beyond 1-layer network (which is also a way to obtain superior utility), specifically what does corollary 4.1 imply? does that mean with small L, we are expecting to see tighter upper bound with the network goes deeper?\n\n##########################################################################\n\nTypos:\n\n- Remark 1: \"linke\" -> \"link\"\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Clarifications needed to understand the objective and assumptions",
            "review": "Quality:\nThe work overall is of \"okay\" quality, my concerns are listed at the end of this review.\n\nClarity:\nI believe the presentation can be improved. Specifically, the problem setting can be better explained in the introduction, where terms like \"dyadic fairness\" or \"homogeneous graph\" are thrown without much details. Perhaps a practical example can help understanding the problem under analysis.\n\nSignificance:\nLink prediction is an important problem in the analysis of social/citation networks, thus, the topic of the work is relevant to the community. In addition, the problem is analyzed under fairness considerations which increases the significance.\nThe results, however, are not strong in my opinion (at least from my first review of the paper).\n\nQuestions:\nMy next questions might come from misunderstandings, in which case I would like to clarify:\n\n* Why is homogeneous graph said to be the focus of the analysis in the introduction but, later on, it is not even mentioned in the technical results. Was that assumption being used? did it matter at all?\n* Authors state that the goal is to have link predictions that are independent of the sensitive attributes. Why does minimizing the norm of the difference of averages of node vectors of each group imply predictions being independent of the sensitive attribute?\nNot having a good explanation for this would undermine the work a lot.\n* The references in Section 2 seem rather arbitrary, for instance, in \"fair machine learning\" I do not see the work \"learning fair representations\" (Zemel et al. 2013). I wonder why it was not referred or rather why are the listed references there preferred over other works?\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "This paper considers the problem of performing link prediction in a way that satisfies demographic parity through Graph Neural Networks. The authors propose an algorithm to modify the weights on the graph adjancency matrix such that the resulting GNN-based link predictions are satisfy the fairness definition. They evaluate this algorithm on several real-world datasets. The experiments demonstrate that the proposed algorithm increases fairness as measured by demographic parity at the expense of accuracy.\n\nThis paper is quite dense and difficult to read. There is little exposition to provide the intuition for what the authors are doing, especially for the reader who is unfamiliar with the particular techniques used. The motivation is also not completely clear to me -- while there are definitely instances where people are interested in demographic parity as a constraint, I don't necessarily see how link prediction in particular is one of those instances.\n\nFrom a technical perspective, the work appears to be novel and sound. The experiments show that the proposed algorithm achieves what it sets out to do, in comparison with baselines.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}