{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper proposes a graph information bottleneck (GIB) framework for subgraph recognition, including the proposal of a MI objective as well as a bi-level optimization scheme for minimizing said objective. The paper receive mixed reviews, with two reviewers in favor of acceptance and two reviewers in favor of rejection. \n\nOne negative reviewer was too short to judge and had low-confidence. I think most of the concerns arise from lack of understanding of the work and the authors adequately address this on the rebuttal. The authors are encouraged to make minor modifications for clarity. In particular, classical IB considers random variables x, z, y, and learns latent representation z that is maximally informative about output y and sufficiently informative about input x. Therefore, it is natural to expect that the input to GIB is a random graph. \n\nThe other negative reviewer finds the paper lacks novelty and points to multiple references. The positive reviewers also ask about the connection with additional references. Im my opinion, the authors do an excellent job at clarifying the differences with all prior work mentioned by the reviewers, including the closest one, a GIB paper in NerurIPS 2020. In my view, the present submission contains sufficient novelty relative to prior work, specifically as it focuses on a different problem (sub-graph) and proposes a different optimization method. That being said, I think it is absolutely essential that the author responses be added to the paper. In other words, the final version must add citations to the relevant work mentioned by the reviewers and clarify the differences.\n\nAll other comments from the two remaining reviewers are very positive: the reviewers find the paper contributes with \"quite interesting information theoretic objective functions that actually work on multiple graph learning tasks\" and \"makes a clear theoretical contribution to the field as well as provides sufficient empirical evaluation.\" I share the views of the positive reviewers and recommend acceptance, subject to the authors incorporating their responses to the reviewers' comments."
    },
    "Reviews": [
        {
            "title": "Clearly Below Threshold",
            "review": "Authors propose to apply information bottleneck to network structured data which is represented by graphs whose nodes are assigned features. \nThe idea seems promising but the authors need to improve their manuscript considerably. In particular, the probabilistic model underlying the IB framework needs to be made clear right from the start. Which random graphs do you consider ? \n\n- \"... GCN outputs the node embeddings X from the following process:... \" what does that mean ? \n- \"...the GIB seeks for the most informative yet compressed representation Z by optimizing the following objective .. \" what is the domain of the optimization problem here ? and what do you mean precisely by \"compresse representation\" ",
            "rating": "2: Strong rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "A good paper with a clear theoretical contribution and rigorous empirical evaluation - clear accept recommendation with medium reviewer confidence",
            "review": "# Summary \nThe paper introduces the Graph Information Bottleneck (GIB) which aims to learn the most-informative compressed representation $Z$ given graph $G$ with associated label $Y$. Further, it defines GIB-Subgraph which aims to learn the compressed representation as the subgraph $G_{sub}$ which maximizes the mutual information within the family of subgraphs ${\\cal G}_sub$ of $G$. The paper introduces bi-level optimization objective which has the following parts: \n\n(a) optimizing the mutual information loss $L_{cls}$ between the subgraph representation $G_{sub}$ and the graph label $Y$ using the backbone GNN followed by aggregation of subgraph node embeddings $X_{sub}$ and cross-entropy loss when comparing to graph labels. \n\n(b) approximates the mutual information $L_{MI}$ between the original graph and a subgraph $I(G, G_{sub})$ using statistics network $f_{\\phi}$ which uses the backbone GNN to obtain graph embeddings (using mean/sum or pooling over node embeddings) followed by MLP over concatenated embeddings of $G$ and $G_{sub}$. \n\nThe procedure retrains the graph-subgraph mutual information estimator in the inner loop for each step (eqn. 10) before updating the parameters of the backbone GNN and the subgraph selection MLP and finally updating the subgraph-label MI estimator ($L_{cls}$). In order to obtain compact subgraphs, the paper introduces a regularization term $L_{con}$ closely related to graph cut. \n\nThe papers shows empirically on downstream task of graph classification that adding the GIP objective improves classification accuracy. Further, on graph interpretation task, the authors show that the GIP objective improves the similarity of the retrieved subgraphs using domain-specific metrics. The authors also evaluate on graph denoising on the MUTAG dataset.\n\n# Recommendation \nI vote for a strong accept. This paper is well-written, makes a clear theoretical contribution to the field as well as provides sufficient empirical evaluation. \n\n# Questions to the authors \n- I would have liked to see in the supplementary material an example of the algorithm on a toy graph example (similar to case study A). \n\n- I wonder does the initialization have an influence on the final chosen subgraph nodes. Does $S$ (node-assignment) (always/almost always?) saturate  as mentioned on page 5? \n\n- What is the influence of the ${\\cal L}_{con}$ on the size of the final chosen subgraph. A table showing the size of final subgraphs (in term of output of MLP $\\theta_2$ in Figure 1) might be helpful, though this is partially addressed in Table 4. \n\n- For completeness, it would be good to provide in the supplementary material the properties of the datasets used e.g., number of graphs, mean/max/min number of nodes, edges, dimension of node features, dimension of edge features (if any), etc. \n\n- It would have been good to see plots showing the convergence of the different losses as part of the bi-level optimization iterations. \n\n- [optional] On the graph denoising experiment, it might be good to add more concrete evaluation both on larger graphs e.g. on graph families such as Power-Law, SBM as well as non-uniform edge addition. \n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "The idea is lack of novelty. The contribution is insufficient. A Clear Rejection.",
            "review": "The submission proposed to use Graph Information Bottleneck (GIB) for the subgraph recognition problem in deep graph learning. Basically, it makes use of bi-level optimization to find a subgraph that well encode the information for graph classification task. The major claim is that the resulting subgraph is more robust for the learning. \n\n1). My major concern is on the novelty part. The submission is lack of novelty. First, the Graph Information Bottleneck (GIB) is used to learn a robust GNN against adverbial attack in the paper accepted in this year NeurIPS.\nGraph Information Bottleneck\nTailin Wu · Hongyu Ren · Pan Li · Jure Leskovec\nNeurIPS 2020.\nThe only difference is the submission uses the GIB principal to learn a subgraph. As for the subgraph selection, much work can be found. Basically, the edge dropping or node dropping  is popularly studied recently. By simple search, we can find DropEdge in ICLR’20, NeuralSparse in ICML’20, DropNode in NeurIPS’20. The only difference is they are modeling general GNN, while this submission is only focusing on graph classification. As for the subgraph selection, is there any superiority of the proposed methods over NeuralSparse which uses gumbel-softmax?\n\nDropEdge: DropEdge: Towards Deep Graph Convolutional Networks on Node Classification \nICLR’20.\n\nNeuralSparse: Robust Graph Representation Learning via Neural Sparsification.\nICML’20.\n\nDropNode: A Flexible Generative Framework for Graph-based Semi-supervised Learning\nNeurIPS’20.\n\n\n\n2). The submission is not well presented. Many notations are not defined before use. For example, in 4.2,\nδyi (y)δ(Gsub,i), what is meaning of δ? What is the meaning of G_sub, i ?\n\n\n3). The experiments are not sufficient. The list methods are most famous GNNs but not SOTAs for graph classification task. Graph neural tangent kernel (GNTK), End-to-end graph classification (DCGNN) , Convolutional network for graphs (PATCHY-SAN). Besides, the graph kernel methods, like Graphlet kernel (GK), Weisfeiler-Lehman Graph Kernels (WLGK), and Propagation kernel (PK) are not compared.\n\nDCGNN: Zhang, Muhan, Cui, Zhicheng, Neumann, Marion, & Chen, Yixin. 2018. An End-to-End Deep Learning Architecture for Graph Classification. In: The Thirty-Second AAAI Conference on Artificial Intelligence\n\n4). The results reported seems much worse than results reported in other paper. For example, in the paper below. We can easily see the best result in MUTAG is 93.28±3.36, while the submission gives only 0.844 ± 0.141, in Proteins, best result is 77.47±4.34 while the submission gives only 0.749 ± 0.051. Similar case shows in DD dataset.\n\nStructural Landmarking and Interaction Modelling: on Resolution Dilemmas in Graph Classification,\nhttps://arxiv.org/pdf/2006.15763.pdf\n\n5). Typos:\nIn 4.1, “a informative representation”==>”an informative representation”\nIn 4.3, “S is 2-dimensional vector”==>”S is a 2-dimensional vector”\n\n\n6). The authors does not report or discuss the running time complexity of the algorithm. Since the framework needs bi-level optimization, it is supposed to discuss how fast the algorithm will converge.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting Information Theoretic Objective Functions for Graph Learning",
            "review": "Summary:\n\nI think this is a nice paper that successfully used information theoretic objective functions for graph representation learning. The authors leveraged the DONSKER approximation of mutual information for a global information bottleneck loss used on the input-space instead of learned latent-space. To help stabilise optimisation, the authors also use bi-level optimisation with more iterations on the inner $I(G, G_{sub})$ as well as automatic masks learning through their $L_{con}$ loss. The authors also showed many experiments on graph classification, denoising, and interpretation tasks. \n\nReason for the Score:\n\nYet, I think the authors could improve on the related work coverage. For example, I found a paper published in last year's ICLR that seems quite related but not cited or compared in this paper. I hope the authors could spend a bit more time to add the relevant methods and possibly compare against them.\n\nPro:\n- Quite interesting information theoretic objective functions that actually work on multiple graph learning tasks.\n- Figure 1 is quite helpful for understanding the story quickly.\n- Relatively well written and easy to follow the ideas.\n\nCon / Questions:\n- In Eq.13. Given that $\\textbf{$\\textit{S}$}$ are probability values, did the authors add a non-linearity such as sigmoid after the MLP ?\n- The proposed method seems quite related to last year's ICLR paper $\\textit{InfoGraph}$ which I think the authors should probably cite and maybe compare and contrast as well. For example, your proposed Eq.11 seems quite similar to $\\textit{InfoGraph}$'s Eq.6. (https://openreview.net/pdf?id=r1lfF2NYvH)\n\n\n-----------------------------------------------------------------\nPost Rebuttal:\n\nMany thanks for the authors to update their original paper addressing my questions and concerns.\nI have now updated the score.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}