{
    "Decision": {
        "title": "Final Decision",
        "decision": "Accept (Poster)",
        "comment": "This paper is concerned with finding causal relations from temporal processes and extends the Convergent Cross Mapping (CCM) method.  It focuses on finding information of chaotic dynamical systems from short, noisy and sporadic time series, and the idea of using the latent space of neural ODEs to replace the delay embeddings in CCM seems interesting. All reviewers like the idea. Please try to make the paper more self-contained and provide some of the justifications suggested by the reviewers."
    },
    "Reviews": [
        {
            "title": "Review of \"Latent convergent cross mapping\"",
            "review": "##################################################\n\nSummary:\nThe paper provides an interesting extension to the convergent cross mapping methods. It proposes a latent process model to learn the directions of causal mechanisms from time series observed at irregular intervals. The method is also developed to be suitable for the situation where the time series are observed at short segments. \n\n##################################################\n\nPros:\nThe Neural ODE method is interesting and novel. It solves the problem of having irregular time series in the applications where the dynamic systems have been extensively studied and represented by ODEs.\n\n##################################################\n\nCons:\n1. The causality established by looking at H_x and H_y is not fully described vigorously. There has been much recent work in the traditional causal inference literature where latent variables are involved. However, the theoretical results are generally difficult to establish. In the context of this paper, more justification is needed to convince readers that you can replace X and Y with their (estimated) latent process counterparts. Do you need to assume there is enough information to exactly reconstruct the latent process? Will you run into model misspecification problem of the latent process as both time series are short?\n\n2. In the conclusion it is claimed the method can detect causal directions even in the case of hidden confounders. I do not see from the main text where this property is discussed. Case 2 of the simulation seems to be correspondong to this statement, but is Z[t] hidden in the simulation? If so it should be made clearer. But in general, I do not quite see how the lack of casual arrows from X to Y can be recovered when there is a hidden confounder Z. Maybe it is possible in some particular cases. Can you clarify? \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Good work, but I have some concerns in terms of experiments and complexity of the method.",
            "review": "This work proposes latent CCM, a causal discovery method for short, noisy time series with missing values. The method checks whether there exists CCM between latent processes of the time series without computing delay embeddings. Empirical results show the proposed method is more accurate in finding the right causal direction in various datasets.\n\nOne of my major concerns is: Is it necessary to learn continuous time latent representation? As time series are not continuous. It would not be useful to go beyond the granularity of the original time series. And solving the problem of missing value does not necessarily require “continuous time latent representation”. Also in the Double Pendulum results, the authors claim the improvement over the multispatial CCM is because the proposed model shares the same parameters across time windows, not because of the continuity of the model. So, it would be interesting to see an ablation study with a model which is based on GRU but without Neural ODEs.\n\nIn 4.3.2, the authors mentioned, “We used 80% of available windows for training and used the remaining 20% for hyperparameter tuning”. It would be better to specify what criterion is used for model selection. In addition, one good practice in this kind of causal direction discovery is to anonymize the two time series in training and validation (avoid using the ground truth in model selection), it is not clear if the authors followed this routine.\n\nIt would be interesting to report the computational complexity (time and space) of the proposed method. In addition, it would be appreciated if the authors can also report the runtime comparison between the algorithms.\n\nIt would also be better if the choice of baselines can be more comprehensive. For example, the authors can try to include algorithms beyond the CCM family such as PCMCI [1] and VARLINGAM [2].\n\nIn terms of writing and presentation, It would be better to make the content self-contained and make the use of terminologies consistent. For example, the authors did not explain terms like \"synchrony\" and \"confounding case\" etc.\n\n\n[1] Runge, Jakob, Peer Nowack, Marlene Kretschmer, Seth Flaxman, and Dino Sejdinovic. \"Detecting and quantifying causal associations in large nonlinear time series datasets.\" Science Advances 5, no. 11 (2019): eaau4996.\n\n[2] Hyvärinen, Aapo, Kun Zhang, Shohei Shimizu, and Patrik O. Hoyer. \"Estimation of a structural vector autoregression model using non-gaussianity.\" Journal of Machine Learning Research 11, no. 5 (2010).\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Relevant and novel paper for causal inference in dynamical systems, needs some clarification on critical aspects",
            "review": "The paper introduces Latent Convergent Cross Mapping (Latent CCM) that combines Neural ODEs with ideas from dynamical systems to detect causation between time series. The latent spaces learnt using Neural ODEs, and more specifically GRU-ODE-Bayes, are used to infer the direction of the causal links between two time series X[t] and Y[t]. \n\nQuality, clarity, originality and significance:\nPro: The paper is very well written, and the idea is interesting and quite novel. Inferring causation in time series is a significant problem in all areas involving dynamical systems.  Cons: As described below, there are a few critical conceptual aspects about the purpose of the method that need to be clarified, mainly related to the distinction between dynamical systems and time series. \n\nOne aspect that I find confusing is the lack of a clear distinction between the concepts of “dynamical systems” and “time series”. They seem to be used interchangeably, but there is a difference as time series are generated from dynamical systems. Thus, two different time series can still describe the same dynamical system, for example its different dimensions. The original paper for CCM states: “CCM uses Takens embedding to detect if two variables belong to the same dynamical system.”  The current paper seems to state that it can detect causation not only between two time series, but also between two different dynamical systems. I believe this is a critical aspect and should be clarified and justified. If it is between two time series, do they need to be generated by the same dynamical system?\n\nThe idea of using the latent space of a neural ODE to replace the delay embeddings in CCM is very nice, but I wonder if we can say that there is a one-on-one mapping between the time series from Neural ODE and the latent space? If this is not case, can we say that we can infer causation? Lemma 3.1 goes in this direction, but it depends on the existence of $\\alpha_H$ and $(k, \\tau)$. How easy/difficult is it to find $\\Phi$ that is injective? This is not clear to me.\n\nDifferent concepts (irregular, sporadic, incomplete, partially observed, missing, non-fully-observed) are used to define incomplete observations. In dynamical systems theory, “partial observations” often refers to the fact that only some of the dimensions of the dynamical system/attractor are observed. Having missing data is different: it might be that all dimensions are observed, but not at every timestep. Using a consistent terminology is needed, otherwise too many concepts to describe the same things (and potentially different things) make reading confusing because this can refer to missing/incomplete information on either the samples or the features/dimensions.\n\nThe plots in Fig. 1 are a bit too crowded, the missing data/points could be plotted with a lighter color, and indicate that the dots are the observed data in the caption (that was not clear to me right away). Going back to the discussion of time series vs. dynamical system, $X[t]$ and $Y[t]$ in Fig. 1 seem to be from the same dynamical system, is it the same Lorenz attractor with the same parameters? \n\nThe paper states that it doesn’t use delay embedding, however by using segments in a way it is doing something very similar to delay embedding because it uses information about the past trajectory of a point as one single input to identify the latent space. This could also potentially explain why using different segments helps to find the latent state space. Could the authors extend on this connection? Do the authors believe that the method would work if only the individual points would be given as input, and not segments?\n\nSect. 3: are $d_X$ and $d_Y$ different? I don’t see clearly the connection with the do operation, as it is not mentioned afterwards? Would be good to clarify what $t_X$ and $t_Y$ are, it is not very intuitive.\n\nSect. 3.3: How could one check or guarantee that the “hidden representation is a complete representation of the state-space”? It would be great to give some details on GRU-ODE-Bayes as this is the method used. \n\nLemma 3.1.: Should it be $dH(t)/dt$? Before, the subscript for $\\Phi$ was $\\phi$ not $g(\\phi)$. What is the difference?\n\nSect. 4.2.: What are the “both aspects”? Why 100 samples for Corr_0, and could the authors explain a bit more the reasoning behind the choice of the score? Intuitively, I would have thought a score that is a percentage between the two correlations would be easier to interpret, but maybe I am wrong?\n\nSect. 4.3.1: Which is the quadratic potential? What happens for noisy observations? Have the authors tried adding noise and see if the causal inference still works?\n\nFig. 3: should be Y -> X instead of X-> Y\n\nSect. 4.5: What do the authors mean by folds here, is there a cross validation step? In the Neural activity paragraph, it should be A and B instead of X and Y.\n\nTable 1: Could the authors name the methods and describe them briefly? The acronym MVGP is only explained in the appendix. In the first case, for Latent CCM, the score is significantly smaller than 1, and very close to zero. Is there a bound/threshold under which we cannot say that we infer causality?\n\nWhat is the connection between this paper and the work presented in Rubanova et al, 2019: Latent ODEs from irregularly-sampled time series?\n\n-----------------------------------\nRebuttal: Thank you to the authors for considering the comments and for the changes. I am happy with the response, and have increased the score accordingly. \n\nFig. 5 could be changed similarly to Fig. 1 for visual clarity. The authors mention in the response that both GRU-ODE-Bayes and Rubanova et al. 2019 can be used interchangeably, but there is no reference to the latter. ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Extension of CCM to short time series using latent neural ODEs",
            "review": "### Summary\nThis paper studies short, chaotic time series and uses the Taken's theorem to discover the causality between two time series. The main challenge is that for short time series, the delay embedding is not possible. Thus, the authors propose to fit a latent neural ODE and theoretically argue that they can use the Neural ODE embeddings in place of the delay maps. The authors provide two sets of experiments, both on simulation data. Unfortunately, they never tested the algorithm on real data.\n\n### Feedback\n* The main confusion about this paper is the correlation function. $Corr(X, Y)$ is a symmetric function, likewise, the $S_{c X\\to Y}$  defined on page 6 is symmetric too. How can we infer the direction of causality using a symmetric metric?\n* The authors also do not describe why the $S_{c X\\to Y}$ is an appropriate metric because it just finds the small sample bias in the estimation of $Corr(X, Y)$. Thus, it should be susceptible to the choice of the 100 data points. What is the expected value of this metric?\n* The authors argue that their method works for short time series. But they use 100 data points as the initial point in Figure 2. Time series with length 100 is considered long in many applications.\n* In Lemma 3.1, can you elaborate on how strong the following assumption is? How likely is it to hold for time series data in domains such as healthcare, finance, and natural sciences? \n    > “If there exists one observation function $\\alpha_H$ along with a valid couple $(k; \\tau)$ (in the Takens’ embedding theorem sense) such that the map $\\Phi(H(t))$ is injective,”\n* The neural activity data is a point process. The ODE described in the paper is not an appropriate model for it. For example, associating the activity pattern with the missing values is inappropriate. Please use another ODE for this case.\n* It would be nice to have a non-chaotic synthetic dataset and show the results of the proposed algorithm on it.\n* The data generation in Section 4.3.2 uses missing totally at random. In reality, this seldom happens. The authors should use more realistic models for missing data.\n* Please add markers to Figure 2.\n* The authors are recommended to comment on how to apply their method to multivariate time series.\n* Generally, sticking to the causality literature, I suggest the authors put the assumptions under which the results are causal in a clear statement. See for example the following paper for the statement of the assumptions:\n    * Kennedy, E. H., Ma, Z., McHugh, M. D., & Small, D. S. (2015). Nonparametric methods for doubly robust estimation of continuous treatment effects. _Journal of the Royal Statistical Society. Series B: Statistical Methodology_, 79(4), 1229–1245.\n\n-----\n### Post-Response Update\nAfter reading the authors' response and given the changes made in the paper, I increase my rating by one point.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}