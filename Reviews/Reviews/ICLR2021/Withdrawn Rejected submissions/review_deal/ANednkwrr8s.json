{
    "Decision": "",
    "Reviews": [
        {
            "title": "Leaning heavily to reject",
            "review": "The paper proposes a method to \"pre-process\" or restore images that contain adversarial perturbations, so that the restored outputs lead to correct classifications by a classification / segmentation network. This restoration network f(), for a classification network g(), is learned on a set of examples with adversarial noise, to ensure that the output of g(f(.)) is correct.\n\n### Concerns\n\n- A bulk of the motivation and related work discussion in the paper covers traditional denoising and image restoration approaches. However, given that the goal of this work is to remover adversarial noise, the focus should be on related research on defense against adversarial perturbations. The first paragraph lists a number of these works, but does not meaningfully discuss how they might relate to this paper.\n\n- In particular, the proposed method is essentially a form of adversarial re-training (e.g., see Madry et al., 2017). Adversarial retraining essentially involves re-training the classification network (i.e., g(.)) on perturbed examples. In this work, the \"effective\" classification network is the combination of g and f, where only f is being trained on the perturbations.\n\n- The last line of the intro paragraph says, \"Thus, rather than having a differentiation between targeted and untargeted image perturbations, a strategy for reducing both to improve the performance of the models is desirable.\" Again, for this case, it isn't clear why one would want to use a \"restoration\" network rather than just fine-tune the classification network on these kinds of degradations (adversarial or otherwise).\n\n- In the evaluation on MNIST (which considers adversarial perturbations), there is no comparison to any other adversarial defense method. There are no comparisons in any of the experiments to fine-tuning the classification network directly on corrupted image data.\n\n- For adversarial perturbations on MNIST, the experiments do not contain results on performance when uses FGSM not just on the classification network g() but rather back-propagates them through the proposed restoration network f() as well. This is required to establish whether the method is actually adding any robustness, or whether it's just changing the kind of perturbations that would work in the presence of the restoration network.\n\n- Notably, while the paper does better than \"direct supervision\" in terms of accuracy, it does worse in terms of PSNR. In this context, it is worth discussing denoising and image restoration algorithms that are trained with both L2 and \"perceptual\" losses---the latter penalizing difference between mid-layer activations of a classifier network for the restored image and the ground-truth.\n\n### Minor Comments\n\n- The y-axis label of Fig 3(a) says \"Title\". Please fix.\n- Please note in the caption of Table 1 that the numbers correspond to classification accuracy.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good motivation but lack of formalism and clarity in the technique",
            "review": "[Summary] This work addresses the problem of how to avoid performance degradation of a model  when perturbed samples are used. The core idea (as in other frameworks following similar philosophy) of the technique is to search for information that is invariant to a given perturbation(s) framed in an indirect supervised framework. \n\n\n[Cons]\n-- The ability of a model to handle perturbed data is of interest for the community.\n-- The work is driven by a good motivation\n\n\n[Pros]\n\n-- The paper opens with a big motivation. However, the level of novelty is unclear.  \n-- A major drawback of the paper is the lack of formalism to describe the approach.\n-- The paper also contains several strong yet unsupported claims. \n\nDetailed comments for authors:\n\n-- [Lack of formalist]  Whilst the motivation is interesting, it is unclear what is the main contribution/novelty in the current paper. This is mainly because of the lack of formalism when describing the technique.\nThis raise up several question:\ni) there are several unsupported claims for example ‘if the fraction S_c is less than or equal to 1/2’ not explanation on the assumptions -- that is, the main content on the paper is based on   (2)-(5)  however there are not further details on the assumptions and the limitations. The core part in the paper are based on such expressions that are not enough and well-elaborated to appreciate the novelty in the paper. \n‘We propose to solve this problem using sparse indirect supervision provided in form of $z_i=g_\\phi(y_i)$ ...useful in scenarios where obtaining zi is easier as compared to yi’ However, in several part of the text one can see that y_i is dependant on z_i. What is ‘the observed variable’ interpretation? There are no insights for such. \n\n\n[Experimental setting] The experimental setting is not well-explained which can be perceived as no more than case studies which demonstrate only limited advantages in both qualitative and quantitative terms. There is a lack of strong discussion and findings that somehow weakens the paper. \nThe experimental setting lacks clarification in several parts of the design. For example authors stated ‘with varying severity levels in five categories namely noise, blur, weather, digital, and extrathe .’   whilst noise and blurring are clear to be such a type of ‘corruption’ it is unclear what ‘weather’ ‘digital’... means in the context? \n-- The datasets used in the experiments such as CIFAR-10 are quite limited to appreciate the benefit of the technique in the classification task. \n-- There is no discussion on the findings and what reflect the numerical values from the tables and plots displayed in the paper. \n-- The baseline descriptions are not enough. Authors should include further details to have a sensation of the level the fairness in the comparisons.\n\n[Other comments] Figures such as Fig 3 authors need to update the axis label ‘Title’. The figures 1 and 2 should be improved. It is unclear the message that the authors want to transmit. I strongly suggest a thorough language revision. \n\n Whilst the motivation is supported, the lack of formalism of the technique along with the discussion on the findings turn down the paper.  Paper organisation needs to be improved. The ideas in the paper are not linked in a smooth way. \n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Using high-level computer task losses for image enhancement is not new according to a missing ref, Reducing the number of clean data may not be general for other cases. ",
            "review": "This manuscript propose an indirect supervision method (segmentation or classification) to train an image enhancement network. It claimed that the proposed method only requires a small amount of clean images for pretraining high level computer vision task losses. This manuscript explores various perturbations such as noise, blur, weather, digital, and extrathe that are quite interesting.\n\n1) there are a number of missing references that are closely related to the work of this manuscript:\n[Liu2018] Liu et al., When Image Denoising Meets High-Level Vision Tasks: A Deep Learning Approach, IJCAI 2018.\n[Liu2020] Liu et al., Connecting Image Denoising and High-Level Vision Tasks via Deep Learning, IEEE Trans Imag Proc 2020.\nThese two works proposed to use high-level computer vision losses for semantic segmentation to train denoisers for better performance. Even though these works are not focusing on reducing the requirement of clean images, unfortunately these works seems to undermine the novelty of the proposed work in this manuscript. \n[Johnson2016] Johnson et al., Perceptual Losses for Real-Time Style Transfer and Super-Resolution, ECCV 2016.\nThis work performed other image enhancements by using so-called perceptual losses that uses high-level features extracted from pretrained networks (classification). This is also closely related to the proposed method that also seems to degrade the novelty of the proposed work in this manuscript.\n\n2) I am not sure if the proposed method really requires a small number of clean ground truth images for good performance. All examples are relatively simple tasks that requires a small amount of clean images such as 10 class-classification (MNIST, CIFAR-10) or binary segmentation for skin cancer that do not have to require large volume of ground truth for training. What if we have other computer vision tasks that require much more ground truth such as semantic segmentation as in [Liu2018, Liu2020] or classification with 1000 classes as in [Johnson2016]. I suspect that in those cases, the proposed method might converge to these previous works in terms of the requirement of clean images. Thus, I am not sure if the claim on using small number of clean ground truth images can be extended to these more complex high level computer vision tasks. If we need more clean images, can't we just use them to directly train image enhancement networks? Unfortunately, it is hard to explain this point in the current form of this manuscript.\n\n3) I am not sure if I can agree with the conjecture of this manuscript: will it be easier to obtain class labels / segmentation labels without noise than to obtain clean images? Even though this conjecture seems reasonable for MNIST, CIFAR-10, I am not sure if it is even for ISIC skin cancer data. How about semantic segmentations or large-scale classifications with multiple objects? If this conjecture is not true, then the contribution of this manuscript could be significantly undermined. Even though the conjecture is partially true, the authors may have to investigate the effect of having noisy high-level computer vision task labels (e.g., wrong classification label, inaccurate segmentation labels) for the final trained enhancement networks. The theoretical explanation on it in \"Mitigating perturbations\" sub-section in pages 3-4 does not seem to consider errors in classification labels.\n\n4) This work seems to have limited choices for image enhancement networks due to the loss in Equation (7). Can the proposed method also work for other networks without dimensionality reduction in spatial domain? Thanks to the U-Net structure, I can suspect that image enhancement could be done to a certain level and it seems that another loss L helps to further improve. Ablation study should be provided to see which loss was more important for better performance (L_r only, L only, and then L+L_r together). In addition, note that L_r could be quite good for removing perturbations thanks to the structure it has (see [Ulyanov2018] Ulyanov et al., Deep Image Prior, CVPR 2018). Thus, I suspect that DIP could be the most important factor for the image enhancement training rather than the proposed high-level computer vision task losses and this manuscript should provide enough evidence to lift this concern.\n\n\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "The authors propose an indirect supervised approach to making deep neural network (DNN) models more robust against noise and adversarial attacks, with examples on classification and segmentation tasks but the novelty is limited for this work.",
            "review": "The authors propose an indirect supervised approach to making deep neural network (DNN) models more robust against noise and adversarial attacks, with examples on classification and segmentation tasks. The general idea is to use the available gold standard, unperturbed images \\mathcal{Y}_0 to pre-train an autoencoder f_\\theta, then use \\mathcal{Y}_0 and corresponding class labels or segmentation masks \\mathcal{Z}_0 to pre-train a classifying or segmenting CNN g_\\phi, respectively, on the task g_\\phi{(y}_i)=z_i. Finally, weights on g_\\phi are frozen and training is undertaken on the task g_\\phi\\left(f_\\theta\\left(x_i\\right)\\right)=z_i, where x_i is a perturbed image and only \\theta is updated.\n\nThe improvement margin over the baseline, state-of-the-art methods is massive, e.g. 2 to 3-fold for the MNIST experiments, which makes me think that they are not well-posed for the task and are therefore inappropriate baselines. Is DC-GAN the same model used in (Chen et al. 2018)? If not, a comparison with the very same model from (Chen et al. 2018) is required. Also, model training with data augmentation (injecting noise) might be useful for additional comparison. Cursory google search for similar classifier(AE(.)) frameworks reveals several similar from last three years, so the novelty is limited for this work. \n\nThere exist inconsistent notations. For instance, Figure 2 is confusing because, as illustrated, the reconstruction loss L_r is computed between perturbed images X and clean images Y, rather than between perturbed images X and reconstructed images \\bar{X}, as is described in the text. That is, the model figure does not match the description in the text. If the authors mean that here Y means reconstructed images, rather than gold standard, clean images, they should make this clear and use unambiguous notation.\n\nThe almost full-page replication of the \\epsilon-expansion proof from (Shafahi et al. 2018) does not serve as a particularly compelling motivation to this work.\n\nThe authors admit that the direct supervision approach is overfitted during finetuning, which explains its poor performance. Why not try retraining and stopping short of overfitting, rather than using a model that you know is poorly trained for comparison against the proposed? \n\nMinor comments:\n\tThe y-axis label in Figure 3a is missing.\n\tA few cases of misused capitalization, missing articles, and other typographical errors.\n\tShould probably cite and compare against https://arxiv.org/pdf/1812.03087.pdf and https://arxiv.org/abs/1801.00693, two other works that use AE-based denoising to improve downstream models.\n",
            "rating": "2: Strong rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}