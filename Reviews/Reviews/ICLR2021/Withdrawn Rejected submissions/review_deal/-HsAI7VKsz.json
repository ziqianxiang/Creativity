{
    "Decision": "",
    "Reviews": [
        {
            "title": "-",
            "review": "This paper proposes an approach for aggregating information across mask predictions to improve instance segmentation performance. It builds off SOLO (Wang et al.) which produces a set of instance masks where each mask corresponds to a particular location in the image. The authors of this work suggest that the mask of a particular object can be improved by leveraging the predictions made at adjacent locations. They propose aggregating masks roughly as follows:\n- concatenate a mask with the masks produced at neighboring locations\n- concatenate some additional learned features for context\n- process this with a few convolutional layers whose weights have been dynamically generated by another branch of the network\n- the output is a new refined mask\n\nStrengths:\n\n- I like the initial demonstration in 3.2 that shows there is information that can be taken advantage of in adjacent masks even without training to do so, this helps motivate the learned aggregation\n- the ablations in Table 6 are thorough, and cover the main design choices raised in the paper\n- the experiments back up this consistently does yield a boost to performance for both SOLO and SOLOv2 on different sized backbones\n\nWeaknesses:\n\n- I think the opportunity to have a lower resolution (G') for the mask representations is interesting but I'm not sure that the experiments provide a clear sense of the trade-offs and if it's worth it to use the '-mask' setting. I think it might be helpful to have a sense of how much performance improves/suffers due to changing G' naively and then see that this trade-off is better when taking advantage of the unique dynamically generated weights at resolution G.\n\n- SOLOv2 seems to benefit a lot from using a ResNet101 backbone with deformable convs, achieving 41.7 on COCO test-dev, while this is an orthogonal detail, were any experiments performed with the DCN backbone + AggMask?\n\nMinor comments:\n\n- a middle ground between static weights and dynamically generated weights might be to learn static weights that are not tied across position, was this tested at all?\n\n- Figure 3 could be a little bit clearer\n\nOverall:\n\nI think this paper does a reasonable job presenting and justifying its ideas which lead to a moderate, consistent boost on a very difficult vision problem. The clarity of presentation/writing could be improved, but I don't have any major issues.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Limited technical novelty compared with SOLO",
            "review": "This paper proposed a one-stage instance segmentation method, called AggMask. It aggregate neighbor representations to obtain the final prediction, by using dynamic convolution filters.\n\nStrengths:\n\n+Compared to SOLO, the new part is the learned aggregation of neighbouring masks.\n\n+The method achieves state-of-the-art results on the COCO dataset and yields consistent improvements over the compared baselines SOLO and SOLOv2.\n\nWeaknesses:\n\n-Very limited novelty. The main body of proposed network is based on SOLO (SOLOv2), the only new part is the aggregation of neighbouring masks. In SOLO, the instance mask is chosen only by category branch. While in the proposed AGGMask, besides the chosen mask, its neighbouring masks are also considered to form final mask. Although interesting, the new added part is very limited.\n\n-The AGGMask seems a simple combination of SOLO and YOLACT. The architecture is SOLO, and borrow the \"Mask Coefficients\" (aggregation weights in AGGMask) from YOLACT.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "The paper addresses a single-stage instance segmentation problem. The main contribution of the paper is the dynamic mask aggregation scheme, which is used combine neighboring mask predictions. The authors also propose a mask interpolation mechanism that improves the efficiency of their method, and allows higher resolution predictions.",
            "review": "Strengths:\n- The paper is easy to read and understand\n- It clearly identifies the problem of a few previously published models\n- The authors demonstrate consistent improvements of their proposed approach\n\nWeaknesses:\n- The major weakness of the paper is its lack of a technical contribution. The proposed method seems like a combination of ideas from several previously published papers (SOLO, SOLO_v2, YOLOACT, and CondInst). The authors acknowledge similarities with this prior work, and present some arguments why their work is different (and thus, novel). However, in my opinion, these arguments are weak, and doesn't change the fact that the work is technically incremental. I view this paper more as an engineering effort, as opposed to a paper that presents some novel and insightful technical ideas.\n\nConclusion:\n- Despite a lack of a strong technical contribution, I think the paper is well written, and it demonstrates consistently improved results over several strong baselines. Thus, I'd be willing to vote for accepting the paper as a poster.\n\nRebuttal Requests:\n- The authors should add missing baselines in their comparisons (i.e. CondInst).\n- Please fix typos and other grammar related issues.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Okay paper with limited novelty",
            "review": "Strength\n- This paper is overall well written and easy to follow.\n- The experiments support the contributions of the paper, showing improvements (2.0 AP) over existing methods, i.e. SOLO and SOLOv2.\n- It shows visualizations and analysis of why the proposed aggregation module works, as well as reasons for each individual choice in the module design.\n- The proposed mask interpolation schema can reduce computation overhead in instance segmentation.\n\nWeakness\n - This paper proposes a dynamic aggregation module that aggregates contextual information from the neighborhood of each grid for segmentation mask prediction. The Relation with Existing Works paragraph in Section 4 advocates the proposed module can potentially benefit many one-stage instance segmentation methods such as SOLO, CondIns, YOLACT. However, in the experiment section, it only shows the proposed module can improve SOLO and SOLOv2. It is not clear whether the proposed module can be generalized and benefitting other one-stage instance segmentation frameworks, or just works for the SOLO framework.\n - The main contribution and intuition of this paper is to utilize the neighborhood contextual information to facilitate instance segmentation mask prediction. However, in the Individual Design Choices paragraph in Section 5.2, the model trained without aggregating neighborhood information (i.e. |N| = 0 with only a dynamic transformation being learned) has already brought an improvement of 1.4 AP, which is more than the contribution of neighborhood aggregation. Thus, it is not clear whether the main improvement is introduced by more layers or by the proposed aggregation module.\n\nNovelty\n\nThe novelty of this work is limited because:\n- The neighborhood aggregation idea has been used in prior works such as bounding box voting while the dynamic parameter prediction has been widely used in hyper-parameter prediction networks. \n- The proposed aggregation module is an add-on module on top of existing instance segmentation networks, the experiments also only demonstrate its effectiveness for the SOLO framework, thus it is unclear if this module can be generalized to other segmentation frameworks.\n\nPresentation\n\nOverall the paper is well written and easy to follow. There're few confusions listed below:\n- In the 'Network Architecture paragraph of Section 4. The abbreviation FPN (feature pyramid networks) is mentioned without citing the following paper, which is confusing for readers without background knowledge.\nLin, T., Dolla ÃÅr, P., Girshick, R.B., He, K., Hariharan, B., Belongie, S.J.: Feature pyramid networks for object detection. CVPR, 2017\n- The caption for Figure 5 is too close to the image.\n\nContribution\n\nThe main contribution of this paper is to propose an aggregation module to utilize the contextual information that has been overlooked by the widely used NMS operation. Though it outperforms existing instance segmentation methods, it is not clear whether the major improvements come from more layers or the proposed aggregation. Also, further experiments are needed to show that the proposed module can generalize to and benefit other instance segmentation frameworks. Overall, the contributions are not significant enough for acceptance in ICLR.\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}