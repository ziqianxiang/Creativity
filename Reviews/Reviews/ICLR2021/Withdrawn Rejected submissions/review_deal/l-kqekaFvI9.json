{
    "Decision": "",
    "Reviews": [
        {
            "title": "Intuitive extension with the help of graph network",
            "review": "# Summary\n\nIn this paper, the authors propose a graph network module to capture the sample-level and class-level structure for unsupervised domain adaptation. Compared to the existing UDA methods, which focus on adversarial domain-invariant feature learning, the proposed system augments the representation learning part with the recent practice of graph network. The main motivation is that both source and target domains share the same label space so that such structured knowledge could be crucial to bridge the gap between source and target domains. The extensive empirical studies on several domain adaptation benchmarks demonstrate the effectiveness of the proposed method.\n\nThe overall writing looks good to me. The storyline is consistent and well-motivated. The authors provide enough detail to shed light on the design choices for the state-of-the-art UDA approach. The figures and tables are also quite informative. For example, I particularly love the figure 1 because it helps the readers catch up with the overall architecture of the proposed system.\n\n# Questions\n\n1. Even though the source and target domains share the same label space, the actual semantic prior could be different. For example, let's think of the real-world long-tailed distributed data. Both source (evenly sampled) and target (long-tail) could have the same label space, but the label priors are quite different. It could be much more helpful if the authors could also discuss this situation.\n\n2. The proposed TFLG and TFLGM approaches utilize the pseudo label. I noticed that all these domain adaptation experiments have a strong baseline to start with. For example, most of the classification accuracies on office-31 are above 60%. I wonder if the proposed module could still be helpful when the initial guess on target data is too bad to be trusted with.\n\n3. Considering the potential of the real-world application, I am suggesting that the authors could also include the additional computational cost of the proposed module. The extra graph network looks expensive to me, especially the memory bank version. It could be helpful to also discuss this perspective as well.\n\n---- Post-rebuttal comments----\n\nI agree with the other reviewers' concerns so that I turn down my rating.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Marginal novelty with UDA settings of less interest",
            "review": "The authors proposed a transferable graph-based feature learning scheme, which can be applied to address the task of unsupervised domain adaptation. With both sample and class-level structural information exploited, improved performances were reported. Generally, the paper is clearly written and easy to follow. My review comments are discussed below.\n\nI found the paper to be technically sound but with marginal novelty. Based on DANN-like architecture (i.e., use of adversarial learning for domain adaptation), the authors proposed additional GCN layers to process the features, while additionally adaptation performed by regularization on local structure of the same label (i.e., T*Z_s*W_tra).  Adding/observing such local and class-level structural consistency has been observed in existing vision and learning models, and this is the reason why I feel the novelty would be marginal.\n\nAfter such an additional GCN-based feature extraction stage, the derived feature is concatenated with the original ResNet features (w/o adaptation) for final domain adaptation. On the datasets like Office-31/home, one would expect ResNet-like deep features are robust enough to describe such cross-domain data. Thus, adding extra GCN-based features (which require additional parameters for feature learning) for producing slightly improved results would not be very surprising. I'm not saying that the experiment results always need to show a clear margin when comparing to others, but I feel that such improvements were simply due to extra efforts on feature learning and thus can be expected.\n\nLastly, UDA settings considered in this paper have been well studied over the past decade. Recently, researchers shift their interests to more advanced/challenging settings like partial DA [A], universal DA [B], etc. This is also the reason why I feel that this paper might not be of sufficient interest to the community.\n\n[A] Cao et al., Partial domain adaptaion, ECCV 2018\n[B] You et al., Universal domain adaptation, CVPR 2019",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "An intuitive idea but lacking originality and experimental comparisons",
            "review": "This paper introduces an approach to account for the structure of the data for unsupervised domain adaptation. In essence, structure-aware features are extracted via a graph convolutional network acting on a graph whose node represent the different samples in a mini-batch. The structure-aware features extracted from a source mini-batch are then combined with those from a target mini-batch according to the class (pseudo-)labels of the samples.\n\nStrengths:\n- Taking the structure of the data into account when performing domain adaptation seems intuitive, and so does using a GCN to encode this structure.\n- The paper is reasonably clearly written, and the methodology should be reproducible with some effort\n- The experiments evaluate different aspects of the proposed method\n\n\nWeaknesses:\n\nOriginality:\n- While I find the idea of modeling the data structure during the domain adaptation process attractive, this paper is not the first one to propose a solution that does so. In particular, as very briefly discussed by the authors in the related work section, Ma et al., 2019 also introduced a solution to doing so with GCN acting on the source and target mini-batches. I acknowledge that the specifics of the two solutions differ, but this seriously limits the originality of this submission.\n\nRelated work:\n- As stated above, the discussion of Ma et al., 2019 is very brief. Considering the similarities between both methods, I suggest the author to provide a much more detailed explanation of this work and of the differences with the proposed method.\n- To a lesser degree Ding et al., 2018 should also be discussed in more detail, as it also relies on the notion of graph structure of the data, albeit for label propagation.\n\nMethodology:\n- In the introduction (top of page 2), the authors mention that a domain discriminator might struggle when the discrepancy between the source and target domains is large. While I agree with this, I do not see how the proposed method tackles this issue.\n- I do not understand the intuition behind the formulation in Eq. 8. This essentially adds features extracted from the source samples to those of the target samples. The value of these features will depend on what samples are seen in the mini-batch. I would highly appreciate if the authors could justify this design choice.\n\nExperiments:\n- A comparison to the most important baseline (Ma et al., 2019) is missing. This is the closest work to the proposed method, which essentially only differs from it in the way it uses the GCN features. For this paper to be valuable, it needs to show that the proposed method is a better way to encode the data structure, and ideally to provide an explanation why. Note that the numbers reported in (Ma et al, 2019), while on the same dataset, were obtained with a different backbone architecture (AlexNet vs ResNet-50). Therefore, one cannot directly compare these numbers.\n- The results on ImageCLEF in the appendix are less convincing than on the other datasets. Do the authors have an explanation why?\n\nMinor comments/questions:\n- The minimization problems in Eq 3 should also depend on the feature extractor G.\n- At the end of the intro, extensive experiments are not a contribution per se.\n- Is TFLG(w/o cg) equivalent to setting \\gamma to 0, or does it represent something else?\n- Considering that the results of t-SNE depend on initialization, I am not confident that one can draw conclusions from Figure 5 in the appendix, where the t-SNE results for CDAN and CDAN+TFLG are quite similar.\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "A novel unsupervised domain adaptation method",
            "review": "This paper tackles the problem of unsupervised domain adaptation (UDA). They present TFLG, a novel unsupervised domain adaptation method by extending the domain adversarial networks with a mini batch-wise feature GCN, and use it exploit the sample-level and class-level structure information. To transfer the relevant information from the source domain to target domain, TFLG uses the GCN features computed on the target domain, and the class-label relationship between the source domain and target domain to compute the features. The authors also propose memory-bank augmented TFLG to handle larger dataset where the class-label relationship becomes too sparse. \n\nStrengths\n\n+ The paper is well written and well motivated.\n+ Proposed method is a flexible module and can be plugged into existing UDA methods.\n\nWeaknesses\n\n- In Table 3, it would have been nice to know the performance of CDAN+TFLG with only cross-domain graph convolution\n- Typo in Section 3.3: “In equation 8 ... across domains, b_nt” should have been “b_ns”. \n- In both Table1, table2, and section 4.2, it was not clear to me what “A->D” or “W->A” etc. stands for. It would have been nice to give a short description if they are dataset specific.\n- My main concern is in the experiments section, according to table 2 the improvements over CDANE is not significant in larger datasets such as Office-Home, and this makes me wonder how it would perform on larger datasets such as LVIS which is closer to practical settings.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}