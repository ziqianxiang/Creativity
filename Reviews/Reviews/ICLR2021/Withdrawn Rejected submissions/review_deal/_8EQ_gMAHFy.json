{
    "Decision": "",
    "Reviews": [
        {
            "title": "Review of VortexNet: Learning Complex Dynamic Systems with Physics-Embedded Networks ",
            "review": "\nThis work tackles the prediction of fluid flow taking inspiration from the Vortex method in fluid dynamics. In this method, the information of the velocity field is summarized into a discrete, finite number of particles (vortices), whose position and strength govern the field. The evolution of the velocity field can then be recovered considering the evolution of the vortices. In this work, the computations for each step of the Vortex method (discretization, dynamics, and reconstruction) are done using neural networks.\n\nThis idea in theory is appealing and simple, however its practical realization seems complex: up to my understanding, as there is a neural network for each step, an end to end training is impossible, as the latent code would no longer necessarily correspond to the position and strength of valid vortices. This is why they use the supervision on the position of the vortices, which could not be obtained for real fluid problems.\n\nMoreover, the writing of the paper perhaps  be improved: there is no mathematical framework summarizing the method, making the narrative vague and often unclear. For example, the precise loss functions for the different training steps are not included. \n\nAdditional references on introductory related material on the vertex method should also be added (or a more detailed and less vague introduction in the appendix).\n\nThis paper makes somewhat overzealous claims: ‘Our method opens up a brand new horizon for embedding knowledge prior via constructing physically-valid latent spaces’. Is this referring to adopting the Lagrangian point of view for physical systems? This is by no means novel. If not, please elaborate on this aspect.\n\nA discussion about the expressive power of the method would have been appreciated: what flows could this method represent, and how many vortices are needed in practice for a given fluid?\n\nThe experiment section is clearly lacking. The baselines are poor, the experimental protocol details, quantitative results, and discussion about generalization issues are missing (generation of train/test data). If DeepHPM does not converge why is this method included as a baseline? In this case, why not compare with another approach, for example https://arxiv.org/pdf/1902.11136.pdf ?\n\nIn many real world settings, you do not usually have access to the velocity or vorticity field, only to tracer data. Your method does not seem to as you need the supervision on these fields by construction. Can you comment on this?",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting idea, but a bit weak on the experimental side",
            "review": "The paper proposes to utilize neural networks in the vortex method of fluid simulation. To do so, ResNet-based encoder and MLP decoder networks are trained to map between the vorticity field and a low-res probability map of vortex locations, from which discrete vortices are extracted. The vortex dynamics is modeled with a graph neural network, and the time evolution is performed with a standard Runge-Kutta scheme. Curriculum learning is used to train the network, which the authors explain was necessary to prevent the optimization from getting stuck in local minima. The stability of the method is demonstrated on the leapfrogging rings test case, and further examples are shown for a complex flow, and forced Euler equations. VertexNet is then briefly compared to a non-ML vortex method, a U-net image-to-image approach, and DeepHPM.\n\nThe idea to utilize NNs in the context of the vortex method appears to be novel, and the results are promising. The paper is also quite easy to read, and should be understandable to people without a CFD background. However, I found the experimental results too succinct and lacking in detail. For instance, many details of the training procedure are entirely missing (optimizer & its hyperparameters, ground truth dataset sizes, how the simple/complex datasets were generated specifically). There is no data on the computational cost, despite the claim that it is low for turbulent flows. Not much information is provided about the baseline methods (e.g. the vortex method implementation used), and no baselines involving learned systems with evolution in a low dimensional latent space are compared against.\n\nI'm recommending the rejection of the paper in the current form. I believe this line of work is quite promising, so I'd be happy to reconsider this evaluation if the details of the experimental results could be improved and other comments below addressed.\n\nQuestions/comments:\n- Vortex dynamics can be quite different between 2d and 3d, so any claims about turbulence should really be demonstrated on 3d problems. Even for complex 2d flows, one would want to see a quantification of the results instead of just the snapshots shown in Fig. 6.\n- The discretization of a continuous vorticity field into a set of vortex elements is considered to be one of the sources of inaccuracies of the vortex method. How does the choice of the spatial resolution of the probability map, as well as the vortex probability threshold, impact the quality of the results obtained with VortexNet?\n- In the vortex method, the vortices can split and merge. Can the same happen in VortexNet?\n- The input to the network is a 200x200 vorticity field, but in Fig. 7 the simulation domain is not a square. Is the vorticity discretized onto a grid with cells with an aspect ratio != 1?\n- It would seem fair to compare the stability/performance of the method with one also using evolution in latent space (e.g. https://arxiv.org/pdf/1802.10123.pdf,  https://arxiv.org/pdf/2003.08723.pdf). This way, the impact of one of the principal innovations of the present work (the specific choice of the latent space and its evolution with a standard numerical scheme) could be elucidated.\n- In the Unet comparison, how are the test trials chosen and over how much time is the network asked to evolve the initial state of the simulation?\n- Please provide the details of the training procedure (ground truth set size; optimizer settings; how the initial conditions for these simulations were chosen?).\n- Fig. 3 suggests that in stage 3 all three networks are trained together, but it wasn't clear from the text whether that indeed happens. Please clarify if all network weights are adjusted at that stage, or if some of them are held fixed. It would also be interesting to quantify how much this stage 3 impact the quality of the results.\n- The text states that the dynamics and reconstruction nets are assumed to be generalizable. Please comment on why this is so. More generally, how does VortexNet generalize e.g. across Reynolds numbers or different boundary conditions?\n- Please provide the details of the vortex method used (e.g. how were vortices defined, and evolved in time).\n- Please comment on the computational cost of the method (including the training phase and ground truth generation), as compared to the baseline (non-ML vortex method) as well as an Eulerian DNS.\n\nSuggestions:\n- The paper claims/suggests generality (\"a brand new horizon for embedding knowledge prior via constructing physically-valid latent spaces, which can be applied to further research areas beyond physical simulation\") that is not supported by the text. The idea to perform dynamical evolution in a lower dimensional latent space is not new, and the construction of the latent space in this case is specific to the Navier-Stokes equations. It is unclear how a similar scheme could be used for other PDEs.\n- It is a bit unusual to see related work discussed so late in the paper (sec. 5). Please consider moving it after introduction.\n- End-to-end training is claimed infeasible. Please elaborate on that -- is it fundamental, or because the computational cost would be too great, or the optimization problem too complex to handle with existing optimizers?\n- The paper would be easier to read if some (high-level) details from the A2 sections were included in the main text.\n\nTypos:\nFig 9. plot titles: \"aggrgate\"\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting premise, but problematic execution",
            "review": "### Summary\nThe paper introduces a method for predicting fluid dynamics using a Lagrangian vortex particle representation. Their method encodes a vorticity field into a discrete set of particles, computes their dynamics using InteractionNets, and decodes back to a vorticity fields. The paper claims superior results and versatility compared to other methods.\n\n### Background on vortex methods:\nThe papers' introduction and appendix are a bit hard to follow, and paint a distorted picture of (classical) vortex methods. To have the basics discussion, I'll summarize a few important points here. A comprehensive overview of this topic can be found e.g. in Cottet et al.'s \"Vortex Methods\": https://www.cse-lab.ethz.ch/wp-content/papercite-data/pdf/cottet2000b.pdf\n1. The Navier-Stokes equations are often solved in their more well-known velocity form (eq.2). Vortex methods solve it their vorticity form (eq.3). Both are equivalent, but there are practical pros and cons for each formulation.\n2. Vortex methods aren't by definition Lagrangian. E.g. Vortex-in-cell (VIC) methods which solve (eq.2) on a grid are quite popular in some subfields of CFD. It's just that for some setups, especially simple flows in 2D, the vorticity field is much sparser than the velocity field, and so it might make sense to approximate it by a set of Lagrangian elements. However, for more complex settings (e.g. turbulent flow, flow around complex obstacles) the vorticity fields isn't necessary any simpler or sparser than the velocity field.\n3. These Lagrangian elements can be particles with a (typically polynomial) kernel. There is no \"best\" kernel-- whatever allows to best sample the vorticity field with a small number of particles is best. Often, that's not even particles: vortex filaments (lines) and vortex sheets (surfaces) can be preferred, depending on the flow studied. \n4. What makes Lagrangian vortex methods tricky is that the best representation will change over time. While the initial state may be well-described by a few particles or filaments, viscosity or turbulent breakdown can quickly deform and scatter the vorticity field, and e.g. a single symmetric kernel may suddenly be a bad approximation. Thus, elements need to be resampled (split/merged); in complex flows this often leads to significant implementation complexity and can eat up the benefits of the sparse representation. I assume this is what the paper means by \"human heuristics\" and \"lack of physical integrity\" in the appendix.\n\n### Strong/Weak points, recommendation\nWhat I like best about the paper is that it gets us thinking about representations. Particularly in physics predictions, most methods chose 2D grids as representation, simply due of the popularity of CNN-style architectures, but they may be far from the best representations for the problem studied. And particularly on the topic of vortex methods, there's a nice opportunity to capitalize on their advantages, while overcoming some limitations of classical vortex methods ((4) in background) by e.g. learning non-linear latent kernels.\n\nThe main issue with this paper is that it does not back up its claims. It states in the abstract that it *\"... provides superior results for being more versatile, yielding more physical-correctness with less data sample, and faster to compute at high precision\"* and in the introduction *\"We show the superiority of our vortex-based approach to the previous approaches with its ability to generalize to different initial conditions, adapt to arbitrary precision, learn with small data sizes, and to simulate complex, turbulent flows.\"*. But there is no discussion or numbers on timings and data sparsity, and no generalization experiments. It's unclear what is meant by physical-correctness. There are two baseline comparison w/r to accuracy, but they are not well-described and the numbers look suspicious (see details below). \n\nTherefore, I recommend rejecting this paper. However, I do encourage the authors to keep pushing this direction, as the general premise of the paper is a good one, and something ML could use more progress in. I'd reconsider the model architecture, and how learning can be used effectively for this problem.\n\n### Detailed comments\n- Exposition: The paper is hard to read and often confusing (e.g. introduction), and lacks detail for its model architecture (e.g. Dynamics module only mentions that it is \"similar to InteractionNets\"), and results (neither setup, nor datasets or baseline implementation are explained in sufficient detail). It's also not explained how the model rollout is supposed to work-- is the rollout happening on the particle representation, or is it decoding & re-encoding from grids at each step? In general, should this paper get accepted I strongly recommend polishing the writing and figures, to make it easier to read.\n- The proposed model architecture doesn't really make sense to me. First, it seems like there can at maximum be one vortex particle per 25x25 subgrid cell. I'm not sure why that would be a reasonable assumption. Second, the reconstruction module decodes to a vorticity field, which is then turns into a velocity field using a classical method. Going from vorticity to velocity fields is the most expensive operation in vortex methods, to be more efficient this is the #1 thing that should be learned. Third, the encoder is pretrained using ground-truth vortex particle data, and the particles are parametrized not by a latent vector, but by position and vorticity magnitude. This means the model will just inherent the traits of classical vortex methods, and also their issues around vortex stretching, viscosity, etc. that the authors raise, and cannot e.g. learn a better parametrized kernel. \n- Results: The results text and figures don't tell very much. Ground-truth comparisons are only shown for the simplest domains. There really should be videos or at least side-by-side images with ground-truth/baseline comparisons for all experiments. As far as I can tell, all examples were, while created with an Eulerian solver, specifically chosen to be easily representable by a handful of vortex particle.\n- U-Nets: We don't really get to see the actual predictions of Unet/VortexNet/GT, but the results look a bit suspicious. Generally UNets should be quite good at this kind of task; maybe not as good as something more structured, but I certainly wouldn't expect that big of a performance gap. This looks like an undertuned baseline to me.\n- Classical vortex methods: This is not a good baseline. [Selle et al.] is a specialized computer graphics method to augment an underlying fluid simulation with artificial turbulence for artistic control in VFX; it is *not* intended to be general solution to Navier-Stokes, and not something anyone would use outside the context of VFX. See the Cottet et al. reference above for a review of more relevant methods.\n\n### Questions\n- How is the number of vortex particles determined? Is it fixed, or does the model choose it?\n- How does the model rollout work?\n- In the 'separable' dataset, you provide ground-truth vortex positions and magnitudes. What's the ground-truth vortex particle model (kernel etc.)?\n- What exactly is predicted for each particle? The text only mentions positions, but from the figures and context I assume vorticity magnitude is also predicted. \n- What do you see as the advantage of your method over classical solvers? Is it actually faster than a velocity-Eulerian or VIC solver?\n- For training the dynamics module, both input and target is encoded into particles. How do you prevent them being in a different ordering, i.e. particles swapping slots, or them being clustered differently?",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Techniques reasonable, experiments needs some clarification",
            "review": "### Summary of my understanding\n\nThe authors propose a neural network architecture and its learning strategy for (incompressible) fluid flow prediction. The proposed architecture is based on the knowledge of physics that fluid flow can be concisely described in the Lagrangian perspective with vortices as particles (the vortex method). The proposed architecture comprises different components to find vortices from grid-based observations, to predict the motion of vortices, and to reconstruct the grid-based observations. They propose a kind of curriculum learning scheme in which they pretrain each of the components in an easier setting.\n\n### Evaluation\n\nThe paper is basically easy to follow. The motivation and the intuition behind the proposed method are clearly stated in the introduction. The proposed method seems technically reasonable and novel (to the best of my knowledge) in the sense that they claim in the paper (i.e., combining the Eulerian and the Lagrangian perspectives in fluid flow prediction with neural nets). The related work is concisely reviewed. The experiments look valid to some extent, but the paper lacks some important information to assess their adequacy fully. Hence, my main concern, which makes my score below acceptance threshold now, lies in the experimental part. The description is unclear in some points in the current manuscript, which I detail below.\n\n### Questions\n\n[Q1]\nOverall in the experiments, how the datasets were created is not clear. The core data generation process with DNS is presented in Section 3.1, but a data splitting scheme (into training, validation, and test sets) should also be clarified in the text. It is important in assessing the adequacy of the evaluation of generalization capability.\n\n[Q2]\nThe authors mention the two types of datasets (*separable* and *complex*) in Section 2.3, but how a *separable* dataset is to be created is not clear. True vortex position is necessary for *separable* datasets, but how do you obtain such true position of vortices?\n\n[Q3]\nIn the example of leapfrogging vortex rings (in Section 4.1); Is it correct that Figures 7(b)-(d) are prediction results only with the initial condition at $t=0$ given to the proposed method?\n\n[Q4]\nThe last half of Section 4.1 is hard to understand. What \"Lagrangian scalar fields\" refer to here? What is \"$x$\" in the statement \"initial condition $\\phi=x$\"? Is it correct that Figure 6 is showing the output of the reconstruction net of the proposed method with different numbers of vortices?\n\n### Comments and minor points\n\nIn Section 4.4, it is more helpful if some empirical evidence of the non-converging behavior of DeepHPM (e.g., learning curves) is available.\n\nI think it is really helpful and makes the paper quite complete if the authors can summarize the pros and cons of the vortex method in general, while they just refer to the literature [2].\n\nThe sentences in the third paragraph of Section 2.1 (The design of VortexNet is upon ...) include some typos?\n\nThe letters in Figure 3 are too small.\n\nIn Figure 8, what the blue, red, and black circles denote should be clarified.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}