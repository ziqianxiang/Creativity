{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The reviewers agree that the paper is addressing an interesting problem (cold-start for representation learning on dynamic graphs). However, the proposed methods can be improved by proposing more novel ideas. At the moment, the proposed methods is a combination of GCN model for node classification and GAE model for link prediction. In this case, some analysis or theoretical justification may make the paper more interesting. Furthermore, the reviewers think the experiments can be improved. For instance, results on more datasets, more comparison methods and a different setup will strengthen the paper. "
    },
    "Reviews": [
        {
            "title": "Lack of novelty, experiments should be improved.",
            "review": "Clarity : Eqn(5) and (6) introduce symbols $\\theta_1$ and $\\theta_2$ whose meaning is unclear. Eqn(6) requires more clarity as it is important to understand how intermediate embeddings for cold nodes are being generated. \nOverall the problem motivation and related work section is well described\n\nNovelty:  The proposed model is created by clubbing together GCN model for node classification and GAE model  for link prediction. The loss function is a weighted combination of the two. Lacks sufficient novelty\nImpact: The paper clubs together two earlier well known models and makes no additional theoretical contributions. \n\nCorrectness: The link recommendation test sets have the same no. of positive and negative ratio. This scenario is highly unlikely in a real-world setting. A more skewed dataset would throw off the performance metrics significantly. \nAUC scores are reported. AP/RR/Accuracy values should be explored as well. While I agree AUC is well prevalent in community, Precision captures the sensitivity in ranking much better in link prediction.\n\nMaybe I missed the code, can the reviewer point out to it?\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Using link-prediction/retrieval to generate hard links in cold-start node classification is effective.",
            "review": "##########################################################################\nSummary:\n \nThe paper proposes a new task in Graph Learning. Basically, the idea is the following: suppose we have a node classification model trained on a Graph G, suppose we have a new node (not present in G) and we want to classify it. Given that the new node has no connections with G’s other nodes we cannot leverage any structural information to run the classifier. This is an issue that authors present it as cold-start in semi-supervised graph learning. The solution, even if simple, is very effective and for this reason even more interesting. Basically, they start with a retrieval step (they call it link prediction) that is trained using a link reconstruction loss and it’s based on dot-product to make the link prediction phase scalable. After those links are reconstructed they run a node classification step (based on GCN, GraphSAGE, or GAT) on G plus the new node and the predicted links.  The results obtained in the experiments are really encouraging with improvements ranging from 15 to 25% over a baseline that does not consider the link prediction phase.\n##########################################################################\nReasons for score: \n \nOverall, I vote for accepting. I consider this as a non-trivial step forward towards using Graph Learning on recommendation problems and node classification problems. There are many applications of Graph Learning where the technique presented in this paper can be of help. Consider, for instance, all the words relying on GNNs to do fake news detection based on a semi-supervised technique. All of those methods fail in the case a new document (node) has no explicit connections to the graph. This method would solve that issue. \n \n##########################################################################Pros: \n \n1. The paper tackles a problem that is, in my opinion, very important and, so far, overlooked: cold-start node prediction using graph learning.\n2. The technique presented in the paper is simple, which I consider a plus. It works and it’s simple.\n3. The experiments show a great improvement over the baseline\n \n##########################################################################\nCons: \n \n1. One big limitation of this work, that is in my opinion under explored is that it is based on the assumption that links depend on the content/features of the nodes. In some cases this assumption might not hold true. I would like authors to discuss on this point.\n2. I am not sure how the link prediction phase could be made scalable. As it is defined now it is an O(n^2) step. Or better, I have some ideas but I’d like authors to discuss this.\n3. Why you pick a threshold of .5 in equation (8) Shouldn’t this be an hyperparam?\n \n##########################################################################\nQuestions during rebuttal period: \n \nPlease address and clarify the cons above \n \n#########################################################################\nSome minor issues \n(1) There is an inconsistency in the notation for M in equation (4) and M in equation (5). In equation (4) M takes 3 parameters, while in (5) it takes 2. Please clarify.\n(2) Why you speak about cold nodes X_c instead of  cold node? Up until now it looked like you only used one node at a time. Please clarify.\n(3) What is q() in equations (5) and (6)?\n(4) In Figure 3, what is the black line under the blue curve? It’s not written anywhere.\n",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Recommendation for Rejection (title before rebuttal phase)",
            "review": "Summary\n========\nThis paper is about the cold-start problem for representation learning on dynamics graphs. More specifically, the proposed method (ColdExpand) uses convolutional networks and multi-task learning (node classification loss and link prediction loss) to learn embeddings for new unseen nodes in the graph, i.e., nodes that we only know their features and not their connectivity to the existing graph. Such a problem is useful for applications of the link prediction problem and more specifically, recommendation tasks or graph completion tasks. The authors test their technique using three benchmark datasets (Cora, CiteSeer and PubMed) and by using building blocks of existing works they create some baselines to compare. They claim to be the first study for semi-supervised learning to unseen nodes. However, there are a couple of works in this field already, as for example the GraphSAGE model that they cite in this paper (see below for more). \n\nReasons for score\n================\nOverall, the paper is about an interesting problem (cold-start for representation learning on dynamic graphs). However, the proposed methods has limited novelty by using known building blocks from the literature. Also, the experimental setup and the results are not very convincing. Results on more datasets, more comparison methods and a different setup will strengthen the paper.\n\n\nStrengths\n========\n- The problem of representation learning in dynamic graphs for unseen nodes is interesting and has attracted the attention of researchers in the field in the last years. In this paper, the authors propose a semi-supervised learning for the link prediction for unseen nodes.\n- The proposed method that uses a multi-task learning strategy by combining a loss for link reconstruction and a loss for node classification is reasonable, has been well motivated in the paper, despite the limited novelty.\n- Overall the paper is well-written and has a nice flow. \n\n\nWeaknesses\n===========\n- The authors claim that this is the first work on semi-supervised learning for unseen nodes. However, there are a couple of methods already in this field. Other methods include: GraphSAGE (already in the references of the paper), PinSAGE [1], HAN [2] and DynRep [3]. The authors should consider to add these methods in the comparison, and also in related work subsection 2.3.\n- Figure 1 is not useful and takes a lot of space, the authors could use the space to expand their experiments.\n- In subsection 4.2 there are some parameters that are never described, as for example \\Theta.  In equation 4, M(,,) takes 3 arguments, but later it is used with only two. In general there are some inconsistencies in the notation and the equations in terms of the definition/description of some of the parameters. It needs careful check.\n- The experimentation is limited. The authors use three datasets and they apply some preprocessing in order to use some nodes/edges as unseen. It would be nice if the authors can add these numbers in Table 1. \n- It would be interesting to see results for the GCN, GraphSAGE and GAT in the link prediction task. An aggregation of the node embeddings from the nodes that create an edge can be used to compute an edge embedding (as it is already done in the literature).\n- It could be interesting to add an experiment with a more realistic imbalance in the dataset (more negative edges, and less positive ones).\n- In Figure 3, it is not obvious what the light blue and dark blue lines represent. I would suggest to add the x-axis, y-axis and labels in the figure and remove them from the caption if there is no space.\n- Overall, more datasets (e.g., Reddit, PPI) and more comparison methods (e.g., GraphSAGE (for link prediction), HAN, DynRep) will make the results more convincing and insightful.\n- There is no comment on the scalability/runtime of the proposed method.\n- The results in some cases are very close, it would be better if the authors could test for statistical significance and report the scores.\n\n\n[1] Ying, R., He, R., Chen, K., Eksombatchai, P., Hamilton, W.L. and Leskovec, J., 2018, July. Graph convolutional neural networks for web-scale recommender systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 974-983).\n\n[2] Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019. Heterogeneous Graph Attention Network. In <i>The World Wide Web Conference</i> (<i>WWW '19</i>). Association for Computing Machinery, New York, NY, USA, 2022–2032. DOI:https://doi.org/10.1145/3308558.3313562 \n\n[3] Trivedi, Rakshit, Farajtabar, Mehrdad, Biswal, Prasenjeet, and Zha, Hongyuan.. \"DyRep: Learning Representations over Dynamic Graphs\". International Conference on Learning Representations (). Country unknown/Code not available. https://par.nsf.gov/biblio/10099025.\n\n\nQuestions during rebuttal\n=====================\n- Please address and clarify the suggestions mentioned in the weaknesses above.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "ColdExpand",
            "review": "Summary:\n\n \nThis paper presents a model called ColdExpand that addresses learning tasks related to attributed graphs. Authors argue that this model is the first model able to deal with the cold-start problem, i.e. new nodes with no structure information, which explains its name. However I think they totally miss part of the recent literature on inductive approaches. ColdExpand addresses the new node issue by using an architecture that combines a deep auto-encoder and a GNN classifier. Experiments show that ColdExpand is better for both link prediction and node classification, but (again) it is not compared to more appropriate baselines.\n\n\n##########################################################################\n\nReasons for score: \n\nI vote for rejection because of two reasons. First, I think the cold-start problem presented in this paper can be solved by using inductive approaches that has already been developed. I guess that \"inductive\" can be understood in different ways, but previous works are able to deal with new nodes that are described by attributes only (see, for instance, G2G [1] and IDNE [2]).\nSecond, the model looks really incremental with a simple concatenation of AE and GNN. The semi-supervised task is not clearly described (it looks as if the whole dataset is labelled). As a minor remark, I find that evaluating the model on a unique data type (here, scientific networks) shed a bad light on the ability to generalize on diverse datasets.\n\n[1] Aleksandar Bojchevski, Stephan Günnemann (2018), Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking, ICLR 2018\n\n[2] R. Brochier, A. Guille and J. Velcin (2020), Inductive Document Network Embedding with Topic-Word Attention, ECIR 2020\n \n##########################################################################Pros: \n\n \n1. The model addresses the more realistic task of inductive prediction, in contrast to transductive approaches.\n2. The paper is reasonnably written.\n \n##########################################################################\n\nCons: \n\n \n1. Litterature on inductive approaches is missing (see above).\n2. Model looks really incremental \n3. It is not compared to inductive models \n\n \n##########################################################################\n\nQuestions during rebuttal period: \n \nPlease clarify the novelty of the cold-start problem addressed in this paper and the usual inductive task as addressed in [1] and [2]. Besides I would like to know why it is a semi-supervised setting.\n\n \n#########################################################################\n\nI guess A should be mentioned in Eq. (5).\n\nThe authors should check the references (e.g., Velickovic et al. has been published at ICLR 2018).\n\nSome typos: \n\n\"in a log of variant matrix\"\n\"different hyperparameter\"\n\n######\n\nUpdate: after reading the other reviews and author response, I decided to increase my grade to 6.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}