{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper presents an efficient secure aggregation algorithm in federated learning scenarios, which employs sparse random secure-sharing clients. Four experienced reviewers left valuable comments on this paper, and three of them are unfortunately negative to this work (4, 4, 3) while one reviewer is slightly on the positive side. \n\nThe reviewers are generally positive about the main idea and the direction for this work, but they are not convinced of its mathematical soundness and practical benefits; the theoretical analysis and mathematical proof has been conducted only for simplified models while their practical advantage is not clear enough. Also, even the most positive reviewer (R3) is concerned about the novelty of the proposed approach.\nAlthough the concerns raised in the original reviews have been partially clarified during the discussion phase, there still remain several critical limitations, which makes this paper require (probably) multiple rounds of revision before publication and this AC has a reservation for accepting this paper."
    },
    "Reviews": [
        {
            "title": "A nice idea with insufficient analysis",
            "review": "This paper proposes an efficiency improvement on the \"secure aggregation\" (called SA in this paper) protocol of Bonawitz et al. \n\nFor context: the SA protocol allows a group of clients holding secret values to compute the sum of their values with the help of a reliable server. The computation is \"private\" in the following sense: any adversary that controls the server and at most $t$ out of the $n$ clients learns nothing except the sum of the honest parties' inputs. \n\nMore formally: SA is a multiparty computation protocol for the \"summation\" ideal functionality, that is secure against a *semi-honest* honest adversary. It has the desirable feature of being resilient to failures on the part of many clients (as long as the server remains online). \n\nThe big downsides are that (a) the protocol does not handle malicious behavior on the part of the server and clients and (b) the communication scales poorly with the number $n$ of clients (each client's communication is $\\Theta(n)$, and the server's total communication is $\\Theta(n^2)$).\n\nThis paper aims to alleviate problem (b) by giving a version that uses a reduced communication graph. The paper argues that if the graph has appropriate properties then the resulting protocol is secure (though that argument is problematic, see below). The paper shows that a random Erdos-Renyi graph with density about $1/\\sqrt{n}$ satisfies the properties, leading to a protocol with communication $\\tilde O(\\sqrt{n})$ per client. \n\nI like the approach and idea of the paper, but I don't think the execution is quite there yet—I don't feel the paper, as written, is acceptable for ICLR.  The paper's value hinges on three claims: correctness (the protocol should complete even when some players drop out), low communication, and security. I did not check the arguments for any of these in detail, but correctness and communication look fine. The main issue is the security argument, which is not properly developed (and not obviously correct). The security model is not clearly articulated, the claims don't clearly describe assumptions on the number of corrupted parties, and so forth. For example, the paper makes claims such as that the protocol prevents membership inference. That can't be true because many (most?) membership attacks use only the final trained model (or even just its outputs)—hiding the intermediate gradients doesn't help. \n\nThis paper is about multiparty computation (to be clear, secure summation is a special case of MPC where the ideal functionality is a sum). It should use the language developed over the past thirty+ years in the crypto and security communities to formulate and prove its claims of security. This would allow for clear and refutable claims, and a clear discussion of the new protocols limitations.  In particular, the restriction to semi-honest parties is a huge one, albeit shared with the SA protocol of Bonawitz et al. \n\n\n\n* Modeling the exact security properties of protocols with parties that drop out is a bit subtle. See, for example, this paper for discussion: https://eprint.iacr.org/2018/997\n\n* The idea of replacing the complete graph with a low-degree expander to save communication has been used elsewhere. Some relevant citations are below (though there are others, too):\n\n** Fitzi, M., Franklin, M., Garay, J., Vardhan, H.: Towards optimal and efficientperfectly secure message transmission. In: Vadhan, S.P. (ed.) TCC 2007. LNCS,vol. 4392, pp. 311–322. Springer, Heidelberg (2007)\n\n** Harnik, D., Ishai, Y., Kushilevitz, E.: How many oblivious transfers are neededfor secure multiparty computation? In: Menezes, A. (ed.) CRYPTO 2007. LNCS,vol. 4622, pp. 284–302. Springer, Heidelberg (2007)\n\n* Finally: This type of paper might be a better fit for a security or crypto venue, where its contributions can be better evalauted and appreciated. It is up to the authors where to submit, of course, and I don't generally take conference scope too strictly, but the paper isn't really about learning representations, and isn't clearly a good fit for the ICLR audience.\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Official Blind Review #4",
            "review": "This paper considers the problem of secure aggregation for federated learning, where the goal is to design a protocol that allows the server to aggregate models from clients without learning anything about any individual model. The paper builds up on the secure aggregation scheme of (Bonawitz et al., 2017), and proposes a scheme that requires smaller communication and computation costs. The main idea is to use a sparse random graph as a communication graph as opposed to the complete graph used by (Bonawitz et al., 2017).\n\nStrong points:\n\n1. Reducing communication and computation costs in secure aggregation is indeed an important practical challenge. The idea of using a sparse communication graph is interesting.\n\n2. The paper gives experimental results on CIFAR-10 and compares with (Bonawitz et al., 2017). On the other hand, (Bonawitz et al., 2017) only present results on synthetic vectors and do not consider any machine learning task in their experiments.\n\nMajor concerns:\n\n1. My main concern is that the paper lacks the mathematical rigor required in a theoretical security/privacy paper.\n\n(a) In Definition 2, the eavesdropper model (or threat model) has not been properly defined. In particular, what messages of the protocol the eavesdropper can observe is not explicitly defined. Further, it is not mathematically rigorous to simply say that “an eavesdropper cannot obtain any information on the partial sum”. This needs to be quantified, e.g., by using an information-theoretic or computational expression. \n\n(b) The proof of Theorem 2 in supplementary material simply shows that the eavesdropper cannot compute the sum of local models $\\sum_{i\\in\\mathcal{T}} \\theta_i$ from the sum of the masked models $\\sum_{i\\in\\mathcal{T}} \\tilde{\\theta}_i$. How does this guarantee that the eavesdropper cannot obtain ‘any information’ about the sum of local models? The proof is not rigorous (partially due to the ill-defined privacy requirement).\n\n(c) Sufficient details are not provided in experiments. Specifically, what encryption scheme is used, what PRG is used?\n\n2. From the proof of Theorem 2, it is assumed that the eavesdropper has access to masked local models of a subset $\\mathcal{T} \\subset V_3$ of nodes. This is a much weaker adversary model than (Bonawitz et al., 2017). It does not seem fair to compare costs of protocols that give security guarantees for different threat models. At the very least, it should be explicitly mentioned upfront that  the proposed protocol is secure against a weaker threat model than (Bonawitz et al., 2017).\n\n3. Similarly, the attack considered in experiments (Sec. 5.3) is fairly simple. Secure aggregation schemes in (Bonawitz et al., 2017) and (So et al., 2020) provide security against much stronger attacks — privacy is guaranteed even if a subset of devices collude with each other, or the server colludes with a subset of devices.\n\n4. The following recent paper uses a very similar idea to reduce communication and computation costs of secure aggregation. (This paper gives precise privacy definitions and rigorous mathematical proofs for security.) \n\nJames Bell, K. A. Bonawitz, Adrià Gascón, Tancrède Lepoint, Mariana Raykova, “Secure Single-Server Aggregation with (Poly)Logarithmic Overhead”, Jun 2020. (https://eprint.iacr.org/2020/704)\n\nEven if one considers CCESA as a parallel and independent work, it will be helpful to acknowledge the above paper. \n\nOverall, the paper proposes an interesting idea of using sparse communication graphs for secure aggregation to reduce communication and computation costs. However, the paper seems to lack the mathematical rigor and details.\n\n----------- Post-Rebuttal Comments -----------------\nThanks to the authors for the response and for updating the draft. Some of my queries were clarified. However, I still think the paper lacks the mathematical rigor required for a theoretical security/privacy paper. For instance, in the updated proof of Theorem 2, the authors consider the output of a pseudo-random generator (PRG) as uniformly random and claim information-theoretic (perfect) security. However, PRG output is not uniformly random, and one needs to consider computational security, which is standard in cryptography/security literature. Moreover, the comparison with (Bonawitz et al., 2017) and (Bell et al., 2020) seems a bit unfair since the threat model in the paper is weaker. As an example, for the same threat model in the paper, it is not clear if (Bell et al., 2020) would need the strong assumption on dropouts. For these reasons, I retain my original score. ",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "I would recommend weak accept. The paper studies an important topic in private federated learning, i.e., improving the communication/computational efficiency. The main concern that limits my score is its novelty/contribution (See reviews). ",
            "review": "Summary: \n\nThe paper proposes a secure aggregation framework for federated learning that is communication-computation efficient. Specifically, instead of sharing its public keys and secret shares to all the other clients as done in the existing scheme, each client only shares to a subset of selected clients, which reduces the communication and computational costs. The sufficient condition on the graph topology of the selected pairs (assignment graph) is identified under which the private and reliable learning is guaranteed. Experiments on real-world datasets validate the theory. \n\n\nStrength:\n\nThe paper provides the rigorous theoretical guarantee for the algorithm, including the followings,\n1. Sufficient conditions on the assignment graph are identified under which the federated learning is reliable and private; \n2. For Erdos-Renyi random graph where two nodes are connected with probability $p$, the lower bound of $p$ is given such that the algorithm is asymptotically almost surely reliable and private. The upper bound of error probability is also given for a finite number of nodes such that the algorithm is reliable and private.  \n\n\nWeakness/Comments: \n\n1. My biggest concern is the novelty of the paper, which seems to be not significant. Specifically, the proposed algorithm's main contribution is generalizing the existing secure aggregation framework (Bonawitz et al., 2017) from the complete assignment graph to an arbitrary graph. The only modification is on the assignment graph, while the framework itself is still the same as (Bonawitz et al., 2017). Moreover, the idea of limiting communications over a li\ndistributed learning over the Erdos-Renyi random graph has been studied and analyzed extensively in the literature.\n\n2. In experiments (Fig 4), when p >0.795, the proposed algorithm can achieve the same test accuracy as SA. It seems communication/computational efficiency can be attained \"for free. \" However, intuitively, if the fewer nodes are aggregated each round in update, the convergence rate ought to decrease. Is the same test accuracy because of the generalization property? How does the training accuracy of two algorithms compared to each other? \n\n3. Related work: secure multiparty computation (MPC) has been studied extensively in distributed learning, with or without a central server. Federated learning essentially is a special type of distributed learning. I suggest authors can include more related work about MPC in distributed learning. For example, \n(1) K. Tjell and R. Wisniewski, \"Privacy Preservation in Distributed Optimization via Dual Decomposition and ADMM,\" 2019 IEEE 58th Conference on Decision and Control (CDC), Nice, France, 2019\n(2) C. Zhang, M. Ahmad and Y. Wang, \"ADMM Based Privacy-Preserving Decentralized Optimization,\" in IEEE Transactions on Information Forensics and Security, vol. 14, no. 3, pp. 565-580, March 2019\n(3) Shen, S., Zhu, T., Wu, D., Wang, W. and Zhou, W., \"From distributed machine learning to federated learning: In the view of data privacy and security. Concurrency and Computation: Practice and Experience\", 2020.\n\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An Ok paper. Unrealistic assumptions.",
            "review": "This paper proposes a secure (or private) algorithm that is communication and computationally efficient for the purpose of federated learning. The main idea is to allow each client to share its public keys and shares them secretly with a subset of its clients. This is a very natural idea. The main theoretical contribution is potentially useful. However, it is based on a very unrealistic model of a graph -- namely the Erdos-Renyi (ER) graph. It is widely acknowledged that in the real world, ER graphs are not realistic and indeed, are too simple to model real world networks. Consequently, the analysis leading to Theorems 3 and 4 are overly simplified and the insights on p^* may not carry over to real-world settings. \n\nThe analytical results illustrated in Fig 3 are also misleading. The authors mention that the privacy error probability is approx 10^{-40}, but this number depends on what p you choose (that is above p^*). If p is only slightly above p^*, this small error probability is unlikely to materialize. Thus, the discussion here is weak. \n\nThere is no impossibility result or any discussion on whether the results in Theorems 3 to 6 are tight in any way. If they were, the illustrations would be more informative. \n\nIn the real-world experiments on CIFAR-10, it is mentioned that p = p^* = 0.795 is the provably minimum connection probably. Isn't this number way too large? Essentially your whole graph is connected and the structure, if any, can't be reasonably exploited. This leads me to think that there is a great deal of looseness in the analyses. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}