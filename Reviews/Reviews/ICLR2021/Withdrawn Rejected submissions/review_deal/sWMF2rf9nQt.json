{
    "Decision": "",
    "Reviews": [
        {
            "title": "Review for Misclassification Detection via Class Augmentation",
            "review": "This paper focuses on addressing the challenge of misclassification detection in DNNs. To this end, the authors propose a method of class augmentation (classAug) which is an extension of Mixup. They increased the number of classes during training by assigning new classes to the samples generated using between-class interpolation. \n \nAlthough the proposed classAug is new, the following concerns still need to be clarified.\n\nAs the authors mentioned in their contributions, the proposed method is simple. The key change of the proposed model lies in Fig.2 (c). This is a minor change, and at the same time a little straightforward making the proposed method not principled.\n \nAs the fig. 5(a) shown, all samples presented are blurred, the reason why chose to use the proposed method BCI instead of adding some samples by imposing noise is not explained.\n \nAs the results on misclassification detection shown by Table 1, classAug performs better than the others, but classAug needs to generate many samples during training, so its performance compared with other methods that need to generate adversarial samples is not clear.\n \nIt will be better to add more experiments to make comparisons with other methods that need adversarial samples.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The proposed method is simple and effective, but the reasons for the performance improvement should be explained more clearly.",
            "review": "The authors tackled the problem of misclassification detection in deep neural networks and proposed class augmentation,  which increases the number of classes by assuming that the new example generated by between-class interpolation belongs to the new class during training. The authors proposed BCI-1 and BCI-2 as methods of interpolation between classes. From experiments, the authors confirmed that the proposed method achieves higher performance than existing methods. The proposed method also improves the performance of original classification tasks and few-shot learning.\n\nPros: \n- The paper as a whole is well organized and easy to follow.\n- The proposed method is simple and easy to understand and implement. Furthermore, it achieves higher performance on various metrics than conventional methods.\n\nCons:\n- My main concern is the lack of explanation of why the proposed method achieves high performance. The authors argue that the extended class lies in the confusing region of the two classes, thus reducing the confidence of misclassified samples. However, from the model's standpoint, a sample misclassified with high confidence is likely to be indistinguishable from a sample correctly classified with high confidence, even if confusing new classes are added. Therefore, if the confidence of misclassified samples is reduced, the confidence of correctly classified samples may be reduced as well. The authors should clearly explain why the confidence of correctly classified samples does not decrease so much.\n- Also, the above claim does not explain why adding real novel classes improves performance because they are not always in the confusing region of the original classes. The authors also state in section 2.1 \"can we use some algorithms for synthesizing classes, and will it also be effective like adding real classes?\", i.e., the synthesized classes are approximations of the true classes. However, this is at odds with the above claim that it is important to introduce confusing classes. The authors should clarify whether \"adding more classes\" is good or \"adding confusing classes\" is good, and explain why.\n- The results of BCI-2 are not listed in Table 1 and the results of Table 2 show worse results than those of BCI-1. In addition, there is little discussion on why BCI-2 performs worse than BCI-1. If BCI-2 is introduced as a proposed method, the authors should explain the advantages of the method and the reasons for its poor performance cleary.\n- I don't know how the \\lambda is sampled in BCI-1. For example, Mixup samples \\lambda from the beta distribution. Here, is the \\lambda sampled from the continuous uniform distribution of [0.4, 0.6]?  And why not the beta distribution? (Increasing the beta distribution parameter \\alpha narrows the support of the distribution). Furthermore, since the range  [0.4, 0.6] is hyperparameter, the effect of this on performance should be checked.\n- There are some grammatical errors in the paper. For example:\n  - in in -> in\n  - As show in Figure 3 -> As shown in Figure 3\n  - Minte-Carlo -> Monte-Carlo\n  - the more the better? -> the more, the better?\n  - While our method, classAug, is a new and different way to use auxiliary data. -> The sentence is cut off in the middle.\n  - we can observe that -> We can observe that\n\n- Minor comment:\n  - The image of a bird in Fig. 1(b) is the same as the image in the training data in Fig. 1(a), but it should be the test image in Fig.1(a) because it represents the testing.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A simple yet effective method for improving misclassification detection",
            "review": "Summary:  \nThis paper proposes to address the problem of misclassification detection by introducing class augmentation. New intermediate classes which fall in between existing classes are created for the purposes of training, but ignored during inference. This simple strategy is shown to consistently improve misclassification detection performance, and is also shown to be useful for other tasks such as out-of-distribution detection and few-shot learning.\n\nStrengths:  \n-Paper is well written and easy to follow, with many clean and informative figures.  \n-Proposed method is easy to understand and fairly simple to implement.  \n-Experiments demonstrate good performance on a variety of tasks (misclassification detection, OOD detection, and few-shot learning), on several datasets, with multiple architectures. It also improves classification accuracy, which is a bonus.  \n-Experiments and discussion address many followup questions that might arise from the initial introduction of class augmentation.  \n\nWeaknesses:  \n-Number of auxiliary classes grows quadratically with the number of base classes. For datasets with large numbers of classes, applying class augmentation may not be feasible (although it stands to reason that if a dataset already has many classes it may not require class augmentation in the first place).  \n\nRecommendation and Justification:  \nI really like this paper, and as such I would recommend for its acceptance. The method is simple, intuitive, and effective, the experiments are thorough, and the paper itself is very well written.   \n\nClarifying Questions:  \n-As previously mentioned, one limitation of this technique appears to be that it scales poorly with the number of classes. Could the authors comment on how they expect classAug to behave when the number of base classes is already quite large, such as if training on ImageNet-1k, or even ImageNet-22k?  \n-Calibration was not the focus of the paper, but I am curious if the authors have any indication as to how classAug affects confidence calibration?  \n-In Section 3.2, Computational cost, it is indicated that training with classAug converges twice as fast as the baseline. Which dataset is this for? This is an interesting result, so it would be nice if there were a few more details included about this, even if in the appendix.  \n\nAdditional Feedback:  \n-Which dataset is shown in Figure 6? As far as I could tell this information is not indicated in the paper, but it would be good to do so.  \n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "MISCLASSIFICATION DETECTION VIA CLASS AUGMENTATION",
            "review": "Summary: The paper proposes Class Augmentation, a regularization procedure for training deep neural networks. Class Augmentation works by adding pseudo random classes to the model during training. These random class are assigned to new samples generated by interpolating two data examples.\n\nPros:\nThe method is simple and easy to understand.\n\nThe experiments show better performance over competing baselines.\n\nCons:\nThe paper lacks clarity in some sections. The motivation and methodology section can be better written.\n\nMore ablation tests will be needed to demonstrate the effectiveness of the proposed method.\n\nComments:\n- I find the proposed method counter intuitive. Interpolating two data samples means combining features of examples from two different classes and assigning them a random label. I think this could be confusing for neural network especially if the interpolated features are crucial for the model understanding of the class. I think applying ClassAug on a model will effectively cause it to assign lower softmax scores to the data examples for which random interpolations were generated from. This can be problematic if the data is separable.\n\n- Going on the previous point, i will like to see how ClassAug performs on non-image datasets such as text data and also synthentic separable data. I think its useful to compare it's performance in this scenario to other data augmentation methods.\n\n- The authors should provide explanations and ablation tests on how to choose M for the for the augmentation tasks.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}