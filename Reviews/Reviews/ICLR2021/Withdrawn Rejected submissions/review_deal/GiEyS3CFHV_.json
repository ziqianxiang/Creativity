{
    "Decision": "",
    "Reviews": [
        {
            "title": "The paper is not clearly written and hard to follow",
            "review": "In this paper, the authors study non-asymptotic PAC-Bayes generalization bounds for unbounded risk functionals. The main contribution is the construction of estimation error bounds which are faster than the traditional Chernoff type inequality. This bound is used to construct prior distributions to derive strong PAC-Bayes bounds.\n\nThe paper considers an interesting problem. The paper exploited several advanced mathematical techniques to get their results.\n\nThe paper is not well organized. For example, the first section has 5 pages. This is too long since the main text has only 8 pages. As a comparison, Section 3 is too short and only has half a page. The applications in Section 3 are not clearly presented.\n\nThe paper is a bit hard to follow. The paper introduce a lot of advanced mathematical concepts and notations. I am not sure whether all these concepts and notations are necessary. Some concepts are not clearly defined. For example, it is not clear to me the meaning of push-forward measure. What is the meaning of Gamma subordinator?\n\nThe presentation of the main result (Theorem 2) is a bit complicated. The upper bounds involve $\\Lambda^*_{v_n}(\\epsilon)$, which is defined via a sup and is not intuitive to understand. Furthermore, the authors claim that their bound is much shaper than a traditional Chernoff type inequality. I would suggest the authors to explain it clearly.\nFurthermore, the authors do not provide the detailed deduction process in deriving Theorem 2. Therefore, it is not quite clear to me how the authors get this result.\n\nIn eq (5), the authors use the inequality \\log\\delta(f,\\epsilon)<0, which is equivalent to \\delta(f,\\epsilon)\\in(0,1). It is not clear to me whether there is an advantage of using log?\n\nThe authors give a definition of generalization error in page 1. However, I am not sure whether this definition is correct. It seems that the authors define the generalization error as the training error of \\hat{f} minus the testing error of the best model. Traditionally, the generalization error should be the testing error of \\hat{f} minus the testing error of the best model.\n\nThere are several typos. The authors should check the paper carefully.\n- \"Following the steps used the derive\"\n- \"effects the performance\"\n- \"representation can not\"\n- \"an assumptions\"\n- \"it's cumulant generating function\"",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Nicely motivated paper on PAC-Bayes Bounds on Generalisation Error, but overall presentation and proofs fall short of standard expectations",
            "review": "The paper is interested in obtaining PAC-Bayes bounds on generalization errors for unbounded risk functionals. This is done by using the theory of Lévy processes. \nThe paper is overall nicely motivated, and I think it is original. However presentation and clarity fall short of the conference standards, and there are major issues, some of which are critical:\n- I haven't found any Appendix, though it is alluded to in p7: \n > \"The strategy (see Appendix for details), following Bahadur-Rao asymptotics...\"\n- This means that there are no further details for a proof to Theorem 2, although it does not directly follow the arguments preceding it.\n- The generalization bounds given in the Application section in p8 are not in the same format as that of Theorem 2 (presence/absence of absolute value inside probability). This means that these applications do not directly follow from the main theorem. Please explain in more detail how they are derived.\n- In the two proposed applications in p8, the strategy consists in two steps, first estimating \"the push-forward measure well\", and then applying the main result (or a slightly different version of it, see the previous point). The first estimation step is not discussed at all, and above all, no estimation error on the push-forward measure parameters (theta and c, or alpha and c) is taken into account in the PAC-Bayes bounds. I am not expert in this field, but this seems to be a critical downside of the approach.\n- There are some unclear statements, eg: \n\t- p5: \"For example, if Z_i is assumed to be bounded in a compact interval on the real line, then clearly the behavior of its sum would be bounded by the maximum entropy distribution on it i.e. the uniform distribution.\" I do not understand what it means that the behavior of a sum is bounded by a distribution. Please clarify.\n\t- bottom of p6: \"Hence even if the cumulant generating function of the original measure does not exist, if the push-forward measure satisfies (14), then it’s cumulant generating function exists.\" Please clarify.\n- There are some peremptory statements, eg p1: \"Constructing probabilistic bounds on the generalization error, is the main aim of statistical learning theory.\" This is an overly narrow view of statistical learning theory.\n- The bibliography could be tidied:\n\t- I think that the published reference for \"B J K Kleijn and Y Y Zhao. Criteria for posterior consistency, 2013\" is an EJS paper from 2019 (Criteria for posterior consistency and convergence at a rate, https://projecteuclid.org/euclid.ejs/1574240425).\n\t- Benjamin Guedj's 2019 reference \"A primer on PAC-Bayesian learning\" is erroneously cited twice (with John Shawe-Taylor as co-author).\n\t- Missing capitals to gaussian, dirichlet, markov, as well as to journal names; some first names are abbreviated, some not.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Appealing analysis that needs to be more conscientious explained.",
            "review": "The paper pursues the goal of stating PAC-Bayes generalization bounds for unbounded losses. Although the result seems appealing, I must say that the contribution of the paper appears to me very technical. Few mathematical derivations are provided (Section 2.2 even refers to a non-existing appendix). I feel that more details are needed to assess the importance of the result. The application to specific settings is short. Comparison with results from the literature and numerical evaluation of the bounds would be appreciated.\n\nIt also appears that more conscientious comparison with previous results is needed as, in order to differentiate their approach from existing ones, the authors make the following inexact claim.\n*'Ignoring the consistency criterion i.e. for $\\lambda = 0$ [in Equation (9)], we end up with the standard data-independent PAC-Bayesian approach, which has had great success especially in the case of classification and regression problems with bounded risk functionals [Catoni (2007); Germain et al. (2009; 2015); Guedj (2019)]. However in the under-sampled regime, when the number of samples are smaller than the number of parameters, for example in Deep neural networks, such optimality results do not hold…\"*\n\nThe above claim is inexact, because:\n- A common strategy to obtain PAC-Bayes bound is to use a Gaussian Prior over parameters, either with zero mean or randomly picked, rather than a uniform prior like the one obtained with $\\lambda = 0$ in Equation (9) (e.g., Langford and Caruana 2001, Langford and Shawe-Taylor 2002, Germain et al. 2009, Parrado-Hernandez et al. 2012, Dziugate dan Roy 2017a). These are also data-independent priors.\n- Dziugate dan Roy (2017a) applied this approach to deep neural networks with great success. \n\nAnother comment:\n- End of page 2: The PAC (without Bayes) setting goes back to Vaillant (1987) rather than Catoni (2007)\n\nReferences\nLangford and Caruana. (Not) Bounding the True Error. NIPS 2001\nLangford and Shawe-Taylor. PAC-Bayes & Margin. NIPS 2002.\nValiant. A theory of the learnable. Communications of the ACM, 1984.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Proofs missing; asymptotic results without convincing learning-theoretic implications",
            "review": "This paper considers the general frameworks for PAC-Bayes generalization error bounds. The study focuses on the push-forward measure of the empirical measure under the risk functional $R(f)$, i.e., the empirical measure of the risk for a given function $f$, conditionally on the data. For a fixed function $f$, an asymptotic large-deviation result is established for the upper tail of the generalization error, which depends on the cumulant generating function of such push-forward measure.\n\nThe general strategy for PAC-Bayes theory is well-established in literature. There are some important questions left open, such as relaxing the boundedness or sub-Gaussian assumptions. It could also be potentially interesting to borrow more tools from large deviation theory to sharpen the bounds. The contribution in this paper, however, seems not to be convincing enough. The main results in Theorem 2 are asymptotic, with the $O(n^{-3/2})$ term hiding dependency on many parameters (which is particularly ironic with the word ``non-asymptotic'' in the title). The implications to PAC-Bayes bounds are not discussed sufficiently. In practice, the empirical measures for the the risk functionals are typically very complicated object. How can it be possible to compute the cumulant generating functions? Are there practical bounds for it that leads to non-trivial consequences to learning theory? The two examples of Gamma subordinators and stable subordinators are very artificial - there are no known learning models whose empircal push-forward measures are actually given by these formulae.\n\nThe technical quality, in addition to above comments, is also questionable. First of all, the theorems are presented without a proof, and the authors did not upload any supplementary material. The authors refer the details for proof strategy to the appendix, which does not exists. The statement of Theorem 2 is also unclear. If the probability on the left-hand-side is taken with respect to the i.i.d. randomly drawn data points, how can the righ-hand-side involve random quantities such as cumulant generating functions of the empirical measure? These need to be clarified before we're able to judge the technical novelty of the results.\n\nDetailed questions:\n1. On page 6. How can the push-forward measure for a probability measure be not finite? I understand that it may be heavy-tailed and may not event have finite first moment. But the definition of push-forward measure guarantees that it is a probability measure, which is finite.\n\n2. Levy-Khintchine formula gives an expression for the Laplace transform of a sub-ordinator under integrability assumptions. However, this requires the factor in the exponent to be negative, and does not guarantee the existence of moment generating function. Therefore, the claim on page 7 that the existence of needed quantites is justified by Theorem 1 is incorrect.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "A hard paper to follow",
            "review": "TL;DR:  The paper's structure and  a certain lack of purpose in some of its sections made it hard for me to follow what problem was actually solved, how that problem related to the literature, and why it was relevant.  \n\nI struggled following this paper’s contributions and structure throughout. In fact, I found it frustrating to read the paper as I really wanted to follow the arguments, but found myself largely unable to. While this may in part be due to my lack of knowledge of the area, I don’t think the paper is clearly communicating its findings. I have reason to believe this assessment is not completely inaccurate: While I myself do not publish within statistical learning theory, I regularly read papers in the field and can usually follow the main arguments & contributions. I cannot really claim the same for the current paper. \t\n\nFirst, the paper spends an inordinate amount of time (5 pages) recapitulating the prior literature and techniques typically employed within statistical learning theory. With several of the sections, I could not follow how they integrated with the remainder of the paper. The purposes/functions/uses of sections 1.3.1 and 1.3.2 were especially nebulous to me. Why do we spend time going over the Chernoff-bound and sub-gamma random variables all of the sudden? How does this relate to the paper’s contribution? Which drawback of the Chernoff-bound do we fix? I could not really locate the answers to these questions in the paper.\n\nWithin this lengthy introduction, the paper also derives a (new?) ‘consistency prior’.  This claimed contribution was confusing/unconvincing to me on several levels: First of, is this a contribution of the current paper or a well-known fact in the literature? Much of section one repeats well-known facts, but the ‘consistency prior’ is never attributed to any outside source. So I am guessing it is a contribution of the current paper. The next problem is that the prior depends on $\\delta_n$, which is first defined above eq. (3) to *directly* depend on the empirical measure. Obviously, this wouldn’t make it a prior. For reasons that are never explained however, the delta_n term suddenly loses its dependence on the empirical measure right after eq. (3). Why? Why introduce it as depending on the empirical measure at all then? The ‘consistency prior’ also felt unconvincing because the derivation in section 1.2 is essentially a standard PAC-Bayes bound with a modified loss  $L = R + log(\\delta_n)$. Of course, the exponential additivity of the Gibbs posterior allows you to rewrite this additivity into a multiplication where the second term defines a new distribution, but why would you do this exactly? What does it buy you? I understand that $\\log(\\delta_n) < 0$ for big enough $n$, but it was again not clear to me\t why one should care/what the relevant differences are to previous approaches. \t\nOverall, the entire first section lacked ‘narrative tissue’ — what’s the story of the paper? Why do we look at one thing right now? Where is this going? I could not follow the narrative flow in spite of trying quite hard. \n\nAnd then—suddenly—section 2 happens. Without first defining the notation for it (in particular, # and $\\mathcal{R}$ are never defined), the reader is flung into an argument about Radon measures and push-forwards. Again: Why are we looking at this all of the sudden? Why is this interesting? Only after the reader is left puzzling for a paragraph do we receive the answers: “we characterize the condition under which the required moment generating function exists for non-negative risk functionals. Such a characterization allows us to expand the domain of applicability to general unbounded risk functionals even when the data generating process has polynomially decreasing tails. In order to that, we need to construct a stochastic”. This sounds fantastic! Why not lead with this? Why did I have to wait until p.6 to find out what the paper actually does? And couldn’t we have spent the previous pages laying the ground work for this (e.g., by giving some intuitions as to why this should be expected to work)?\n\nBeyond that, the results of section 2 had two other problems: Firstly,  the technique for deriving the second result is deferred to the appendix, but the paper doesn’t have one. Secondly, it is actually unclear what  kind of risk functionals the results can be applied to. While the paper states that “$\\zeta(t)$ is a subordinator if and only if $\\lambda_n$, the push-forward measure defined on R, is a Levy measure. Many of the well studied measures belong to the family of Levy measures, including Compound Poisson Processes, Gaussian Processes, Gamma Processes, Stable Processes, etc.”, it is completely unclear to me what kind of risk functionals would make lambda_n into such a Nicely-behaved measure. What about the square loss? The absolute loss? The logistic loss? … — The results are not useful if we cannot show them to hold for certain risk functionals that we (1) want to use in practice but (2) that previous results did not allow us to make any statements about.  \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}