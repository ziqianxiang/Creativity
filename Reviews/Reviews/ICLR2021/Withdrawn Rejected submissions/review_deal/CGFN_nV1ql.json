{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper investigates a non-attentive architecture of Tacotron 2 for TTS where the attention mechanism is replaced by a duration predictor.  The authors show that this change can significantly improve the robustness. In addition, the authors propose two evaluation metrics for TTS robustness, namely, unaligned duration ratio (UDR) and word deletion rate (WDR), which appear to be novel to the TTS community. The proposed non-attentive architecture yields good MOS scores in the experiments.  \n\nOverall, the paper is well written but the reviewers commented on the technical novelty of the work as it is essentially an improvement within the Tacotron 2 framework. There is also a lack of comparative study with other existing frameworks with similar techniques.  Although the authors put together a detailed rebuttal to address the comments, in the end the above two major concerns remain. "
    },
    "Reviews": [
        {
            "title": "Review",
            "review": "This paper presents an approach based on the Tacotron model for speech synthesis, where the attention mechanism is replaced by a duration predictor. It also presents a short study on semi-supervised and unsupervised training. The paper also introduces two metrics to evaluate the robustness of the model. The experiments shows that the proposed model is on par with the Tacotron baselines in terms on MOS score and better in terms of the new metrics.\n\nPros:\n- The presented approach improves upon the Tacotron model.\n- The semi- and unsupervised learning capability of the system is significant.\n- The new metrics are very welcome, as the evaluation tools for TTS are limited. \n- The paper is clearly written.\n\nCons:\n- The novelty is limited as it is mainly an incremental improvement to an established approach. \n- The references are limited.\n\nDetailed comments:\n-  In terms of clarity, it's hard to say which part of the proposed approach is novel and which parts are from the original Tacotron. The authors should provide a brief description of the attentive Tacotron and clearly explain which parts they modified.\n- A Related Work section is missing. Some related works are presented in the introduction, but I think the paper could benefit to have a separate section for that. It could also be a good spot to present the Tacotron approach.\n\nOverall, the paper's novelty is limited, mainly due to it's incremental nature, but the unsupervised training capabilities and the new metrics are  significant, so I put it just above the acceptance threshold. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Similar ideas have been investigated.",
            "review": "Summary:\nIn this paper, the authors introduce a text-to-speech model based on Tacotron 2, called Non-Attentive Tacotron. Instead of an attention mechanism, a duration predictor is utilized to improve robustness, which is evaluated by two metrics, unaligned duration ratio (UDR) and word deletion rate(WDR). The authors propose semi-supervised and unsupervised duration modeling with a fine-grained variational auto-encoder (FVAE).\n\nReasons for score:\n\nThe paper is well-written. The experiment results of improvement in robustness are convincing. And the duration modeling in an unsupervised manner is appealing. However, using similar ideas to improve the robustness of end-to-end TTS has been investigated.\n\n\nPros:\n\n-- With the use of Gaussian upsampling instead of location-sensitive attention (LSA), the results in Table 2 demonstrate the improvement of robustness compared to Tacotron 2.\n\n-- Two metrics, UDR and WDR, focusing on TTS over-generation and under-generation, respectively, are introduced for robustness evaluation, which seems convincing and suitable for large-scale evaluation.\n\n-- A method of unsupervised duration modeling is proposed. As shown in Table 4, with FVAE, the TTS system can achieve high MOS in an unsupervised manner when the target durations are not available.\n\n\nCons:\n\n-- This paper mainly focuses on improving Tacotron 2 with regard to robustness. However, the similar weakness in Tacotron 2 has been investigated in DurIAN and FastSpeech, as mentioned in section 1. There should be more experiments on the comparison between Non-Attentive Tacotron and similar work, such as DurIAN, non-autoregressive FastSpeech, etc.\n\n-- The introduced Gaussian upsampling and FVAE improve the robustness compared to Tacotron2, but similar ideas have been investigated before, as mentioned in the paper. In Donahue et al. (2020), a similar concept to Gaussian upsampling has been introduced. The authors should have the experiments verifying the benefit of a learned range parameter sigma. Besides, a similar duration modeling method that utilizes attention between target spectrogram and phone embedding also appears in Sun et al. (2020).\n\n\nQuestions:\n\n-- The ratio of labeled duration data and unlabeled data in the semi-supervised experiment is unclear. The amount of training data and the ratio of the unlabeled duration should be compared in Table 4.\n\n-- In Sun et al. (2020), besides the duration, pitch and energy are also predicted by the VAE. Can the similar method be applied to Non-Attentive Tacotron with the VAE? \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Explicit duration information in TTS models leads to better robustness in terms of alignment",
            "review": "Summary:\nIn this paper the authors tackle the problem of alignment between input tokens and output acoustic features. The key contribution of this paper is replacing the attention mechanism of the Tacotron 2 with an explicit representation of token durations. The attention mechanism is vulnerable to issues such as pauses, repetitions, and skips, and hence using durations directly takes care of such issues. The challenge lies in obtaining the durations. The authors propose different methods toward that end. \n\nFirst, they introduce a duration predictor in the Tacotron 2 model architecture which utilizes the encoder features to predict the durations. This duration predictor may be supervised if target durations are available. The authors train HMM-based aligners to obtain target durations for this method. They also introduce a fine-grained variational autoencoder (FVAE) which is a conditional VAE that model the alignment between phonemes and acoustic features to extract token-level features which are in turn used by the duration predictor to predict the durations. The FVAE may be semi-supervised or unsupervised.\n\nThe proposed non-attentive Tacotron model achieves similar naturalness scores to Tacotron 2 which is very close to ground truth naturalness. Additionally, the authors evaluate the proposed model for robustness. They propose two metrics which measure the severity of alignment issues in synthesized speech. The proposed model outperforms the attention-based Tacotron 2 for multiple datasets. The authors also demonstrate the ability to control the pace of utterances by modulating predicted durations. Finally, the authors demonstrate the ability of the semi-supervised and unsupervised models to achieve similar results to the supervised model by utilizing the FVAE duration model.\n\nPros:\n1. The use of speech recognition-based metrics for measuring robustness is very interesting. More widespread adaptation of robustness as a criteria in addition to MOS scores is required. These objective metrics which can be computed for large datasets can be very helpful.\n2. The duration modeller working in the supervised, semi-supervised, and unsupervised setting is another good feature of this model. \n\nCons:\n1. The connection between the duration model and the full model is not very clear in the text. Why does the duration model have a section separate from the Model section, instead of a subsection? A suggestion would be to at least mention early in section 2 that ground truth target durations are not required since there is a semi-supervised duration modeller. There is a delay of 4-5 pages before it is clear that phoneme durations are not a requirement to use the non-attentive tacotron.\n2. In section 5.4, the experiment setup is not very clear. Do you mean that out of the 66 speakers in the full dataset, 10 speakers' durations are removed (for the semi-supervised experiment)?",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Nice MOS results but lacks novelty.",
            "review": "This paper proposes a new text-to-speech synthesis (TTS) framework that does not require attention mechanism at inference time. The authors suggest to use Duration Predictor to estimate the duration of each phoneme in a phoneme sequence.\nThe estimated duration of phonemes are upsampled by the proposed approach GaussianUpsampling, which shows significantly better listening test results than Vanilla repetition upsampling method. The authors also combine prior work, FVAE, to enable semi-supervised or unsupervised training (no duration labels). The authors show that naively predicting the duration in the unsupervised setting does not work very well, whereas combining FVAE makes it work significantly better.\nFinally, the authors suggest two evaluations metrics, 1. Unaligned Duration Ratio (UDR) and 2. ASR word deletion rate (WDR), to test the robustness of TTS systems. The first metric was used to test the problem of over-generation, and the second metric was used to test a word skipping problem. The authors show that the proposed Non-attentive Tacotron model shows superior performance on both metrics compared to the attention-based Tacotron2. Lastly, the authors also show that both semi-supervised and unsupervised approach perform well as much as the supervised one in terms of MOS.\n\nStrength: \nThe authors improve Tacotron2 to solve the problem of attention-based model such as over-generation and word skipping problem.  The experiments are well defined to show the robustness of Non-attentive model. It shows the robustness of Non-attentive TTS model by showing UDR and WDR. The MOS score is almost close to that of human voice, which is impressive. \n\nWeakness:\n\n---Lack of novelty---\nWhile the results are impressive (e.g., MOS score) I feel like the proposed approaches lack novelty.\nFor example, \n1)Duration prediction has been there for a while since Fastspeech1.\n2)GaussianSampling is similar to EATS (https://arxiv.org/abs/2006.03575).\n3)FVAE is also not proposed by the authors\n\n---Lack of some experiments---\nI assume the biggest advantage of Non-attentive Tacotron is the robustness in generation quality. If so, does the unsupervised Non-attentive Tacotron still has the advantages of less over-generation and word skipping problems? It’d have been nicer if the authors had shown UDR and WDR results in the unsupervised setting too.\n\n---Writings---\nAlthough using FVAE makes the unsupervised experiments successful, the insights on using FVAE to tackle this problem is not clearly stated. The authors must state why is combining FVAE approach expected to predict duration better than the naïve w/o FVAE version.  Also, I ask the authors to keep readers in mind little more when writing the paper. The authors should make the writings clearer when explaining the existing methods. For example, in Section3, the depth of explanations on FVAE is too short. Please elaborate more on how it can be formulated as conditional VAE framework.\n\nRating:\nI consider it “not bad” paper, but I think the impact of this paper is not strong enough to pass the bar of ICLR because of the lack of novelty (as written in Weakness part). Therefore, I recommend rejection. However, I’d be happy to listen to the authors’ opinion regarding this issue.\n\nQuestions:\n\n--- Questions on Vanilla upsampling ---\nIt has been shown by Fastspeech1 that the Vanilla upsampling  gives similar score to Tacotron2 model (3.84 vs 3.86). In this paper, however, it seems like the Vanilla upsampling is not working very well compare to Tacotron2 (4.13 vs 4.37). I’d like to ask the authors what the source of this difference could be.\n\n--- Questions on training WaveRNN ---\nThe authors have written that WaveRNN model was trained on *predicted features*. In this case, I assume the ground truth waveform and the predicted features are *unaligned* because Tacotron2 autoregressively decodes features, which must be different to the ground truth mel-spectrogram. How could WaveRNN be trained well enough in this setting? Were the *predicted features* predicted using Teacher-forcing?\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}