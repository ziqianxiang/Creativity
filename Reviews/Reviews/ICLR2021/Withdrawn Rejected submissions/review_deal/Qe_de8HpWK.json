{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper proposes a new quantum machine learning framework which is evaluated on the MNIST dataset. While the paper was relatively well written, reviewers noted that most of the ideas are already well established and used in quantum machine learning community. Thus it was not clear what novelty is provided relative to related work."
    },
    "Reviews": [
        {
            "title": "This is one of the early papers on the concept of using quantum qubits for neural network computations.  The authors propose a robust method to map data into entangled qubits; this method is efficient in the qubit space, which is an important consideration in quantum systems.  However, the actual optimization problem is not solved by the quantum computer, only the forward pass.  I see this as a start in a potentially new and important field.",
            "review": "The authors identify that “classical” learning is running into limitations due to power and scale of computing systems. The authors suggest “quantum” learning might supplant classical learning and solve these fundamental challenges.  And, the authors suggest a method that is efficient in the number of QuBits, which can be quite precious.  \nThe authors believe this work is well motivated by the fact that little work has been done in finding ways to combine the virtues of quantum methods with the power of deep neural networks.\nThe authors propose an encoding scheme to map data efficiently to a qubit, to exploit multiple qubit samples. The ability to entangle multiple qubits to represent points on the Bloch Sphere is a key concept for efficiently using the qubit space.  I believe the biggest contribution this paper makes is this efficient mapping of data to qubit space.\n\nOverall, this paper demonstrates that some ASPECTS of neural computing can be mapped to a quantum, qubit system.  This is a timely topic as the scale and energy usage of classical computers for deep learning training is becoming untenable, and many are thinking about ways to make this problem tractable.  The most novel concept in the paper is the symmetry described between the nature of how entangled qubits can encode information, and how a neural network progressively makes data more separatable.  The actual learning process appears to be done on a classical computer (backprop and update) and then mapped back into the quantum system.  To me, a much more interesting result would be exploiting the quantum nature of the computer to solve this non-convex optimization problem of reducing the loss via layers of features. The generative aspect described is a nice side-effect (as the authors indicate) but isn’t really a novel concept.  \nThe results of the paper really are proof that the basic functionality is there, but not really a proof of concept in a general way.  The dimensionality of a small neural network for MNIST had to be reduced to be able to be realized on an actual quantum system; this weakens the claims of these results as it may be untenable as complexity is scaled-up.  Nevertheless, I believe this result does demonstrate an existence proof, and the community will benefit.\n\nIn general, the language should be cleaned up.  There are just a few sentences with a slightly odd structure.\n\nSection 3: I can see how the data is encoded to make it linearly separable.  But how does this relate to backprop? I can see that backdrop isn't really handled by the quantum system, so the separable mapping of the data is really just a general data concept.\n\nSection 3.1: It looks like the actual backprop is done on a classical computer.  A much more interesting result would be to do the actual gradient descent in the quantum domain.\n\nSection 3.2: Is the data encoding done on a classical computer?\n\nSection 3.5: Looks like the generative concept is really just exploiting the stochastic nature of qubits as a random generator.  I think this points to a strong parallel between neural networks and quantum systems but isn’t really a new concept.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "GenQu: A Hybrid Framework for Learning Classical Data in Quantum States",
            "review": "The paper claims to introduce a new quantum machine learning framework called GenQu. However, the description of the framework very vague (using classical computers to optimize the parameters of a fixed quantum circuit), and hardly novel. In fact, the same basic ideas are so well-known in the community that they are described in detail as usage examples for popular quantum computing platforms such as Qiskit and IBM Q.\nThe only remotely nontrivial part of the paper is contained in Section 4.2 about Quantum Deep Learning, where the authors consider the MNIST data set. Upon closer inspection it turns out that they use PCA to reduce the dataset to 4 dimensions, which is in turn used to train a \"quantum neural network\" to perform binary classification (i.e. to discriminate between '0'-instances and '5'-instances). The authors claim that such a quantum classifier provides an advantage versus a convolutional neural network in terms of\n 1. the number of training epochs (while ignoring the time needed to perform PCA), and\n 2. the number of parameters (while ignoring the parameters needed to describe the principal components).\nAdditionally, no confidence intervals are visible on Fig. 7, which suggests that the data might have been obtained from a single experimental run. Finally, there are several instances of sloppy writing, such as the inconsistent usage of math mode for variables, the statement P(|\\phi>) = |0>, the typo \"iWs\" instead of is, etc.",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review of \"GenQu: A Hybrid Framework for Learning Classical Data in Quantum States\"",
            "review": "I agree that promoting experiments for real quantum hardware is important. But I don't think the team has yet to create a working platform that could be accepted to ICLR. If the open-sourced platform is the main contribution (rather than a new understanding of how quantum computers could be useful for machine learning problems), then the authors should submit the manuscript after having the open-sourced software available. Furthermore, a lot of the wording should be changed (the current version sounds like they are proposing a new quantum machine learning framework, while they are creating an open-sourced platform).\n\n##########################################################################\n\nSummary:\n\nThe authors propose a framework, GenQu, for learning classical data using quantum computation. The classical computer would encode the classical data into quantum circuits. The quantum computer would then run the quantum circuit, measure the resulting quantum state, and feed the measurement data back to the classical machine. This process would repeat until the classical computer output the final result.\n\n##########################################################################\n\nReasons for score: \n\nThis framework is not new and has been widely adopted in the quantum machine learning community. It is unclear to me what is being proposed by this work. The framework is known as a variational quantum-classical algorithm and there is extensive literature for different applications in quantum computing, such as quantum chemistry, simulating quantum field theory, optimization, and machine learning. For example see references [1, 2] for existing proposals for machine learning applications. Due to the lack of meaningful contributions, I would not recommend acceptance.\n\n##########################################################################Pros: \n\nCons: \n\n1. The framework is not new. It is not scientifically correct to claim the proposal of a new framework \"GenQu\" when this has already been widely adopted in the quantum machine learning community.\n\n2.  The authors did not provide any new theoretical insights into how quantum computation can learn classical data better.\n\n3. The numerical experiments were not strong enough to justify any form of advantage using the quantum computer. Furthermore, these numerical experiments have already been presented in the literature. For example, a tutorial in Tensorflow Quantum [3] has also included such an experiment.\n\n#########################################################################\n\n\n[1] Havlíček, Vojtěch, et al. \"Supervised learning with quantum-enhanced feature spaces.\" Nature 567.7747 (2019): 209-212.\n\n[2] Farhi, Edward, and Hartmut Neven. \"Classification with quantum neural networks on near term processors.\" arXiv preprint arXiv:1802.06002 (2018).\n\n[3] Peruzzo, Alberto, et al. \"A variational eigenvalue solver on a photonic quantum processor.\" Nature communications 5 (2014): 4213.\n\n[4] https://www.tensorflow.org/quantum/tutorials/mnist",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper is well written, very easy to follow.  But the lacking part is its limited technical contributions.",
            "review": "This paper presents GenQu, a hybrid and general-purpose quantum framework for learning classical data through quantum states. By encoding two dimensions of data per one qubit. they demonstrate the effectiveness of their framework via two classical classification tasks, where 1 and 2 qubits are used, respectively. This paper is more like an entry-level tutorial, rather than a technical paper.  More technical contributions are needed towards a paper.\n\n\n1. One of the key contributions claimed by the author is that \"they show the power of encoding two dimensions in one qubit ...This thereby reduces the quantum state dimensionality by 2^(n/2).\" I am super surprised by this claim. What is your baseline? One qubit per one dimension of classical information? Could you refer to the paper from which you get this baseline? There are just too many papers[1] about how to encode classical data into quantum states.  The coding scheme proposed in the paper is not novel and not even state-of-the-art.  \n\n2. What is the key difference between your framework and TensorFlow Quantum[2]? For me, TensorFlow Quantum is a much stronger framework. For example, the SINGLE QUBIT KERNELIZED CLASSIFICATION case study in section 3.3 is just an illustrative example in [2].\n\n[1] Biamonte, Jacob, et al. \"Quantum machine learning.\" Nature 549.7671 (2017): 195-202.\n\n[2] Broughton, Michael, et al. \"Tensorflow quantum: A software framework for quantum machine learning.\" arXiv preprint arXiv:2003.02989 (2020).\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}