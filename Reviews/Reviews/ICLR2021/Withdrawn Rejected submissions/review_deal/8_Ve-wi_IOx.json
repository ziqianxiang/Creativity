{
    "Decision": "",
    "Reviews": [
        {
            "title": "Interesting representation time series analysis but missing important details",
            "review": "This work describes a new time–frequency representation for time series based on the Wigner–Ville transform, whose inner product is computed with a sequence of kernels. The resulting transform is called a K-transform. The kernels are mostly given as Gaussians parametrized by their center frequencies and covariance matrices. The authors provide some theoretical results regarding the robustness of the transform with respect to the parameters, but also to changes in the signal. Finally, an algorithm is presented based on short-time Fourier transforms for fast calculation of the representation. The authors apply this representation to various audio classification tasks and achieve good performance.\n\nThe idea of employing a Wigner–Ville representation is interesting and a potentially quite powerful one. For one, as the authors discuss, by appropriate choice of kernels, many popular time–frequency representations are obtained: spectrograms, constant-Q or wavelet transforms, chirplet transforms, mel-frequency filter banks, and so on. That being said, there are also significant weaknesses in the work. For one, many of the definitions and statements of the theorems are vague and confusing. Due to the mathematical nature of the work, this lack of precision is problematic, especially in evaluating the usefulness of the theoretical claims. Another serious issue is that of the fast implementation (given in Section 4.2), which essentially states that the K-transform can be calculated from a short-time Fourier transform. If that is the case, it is not clear what the benefit is of basing the representation on the Wigner–Ville transform over instead of a short-time Fourier transform in the first place. Furthermore, it appears that the benefits of super-resolution are lost, since minimum time and frequency resolutions will be imposed in the proposed implementation. Overall, the paper is poorly organized and the writing is hard to follow (with frequency spelling and grammatical errors). Because of these weaknesses, I recommend that the paper not be accepted for publication in the proceedings.\n\nAs stated above, there is a lack of precision in many definitions and statements. To start, with the definition of the K-transform states that is is obtained by taking the inner product of the Wigner–Ville transform with a kernel Φ[t, f], but it is never stated what this kernel is. Likely, we have that Φ[t, f] is in L²(R²) for any t ϵ R and any f ϵ R₊, but that is never explicitly stated. In addition, Theorem 1 states that “the representation K_x,Φ moves continuously with Φ”. What does this mean? What metric do we impose on K_x,Φ and Φ? Proposition 2 had formulas like Φ[t – τ, f] = Φ[t, f](. – τ, .), which are difficult to understand. Notation also changes throughout the paper. In eq. (6) σ_t and σ_f denote the variances of the kernels Φ[t, f], then in Sections 4.1 and 4.2, we have another parameter 1/σ_f, which is potentially equal to σ_1/f. We also have σ_t', σ_f' in Section 4.1, which is likely not related to σ_t', σ_f' in Section 5. In Figure 2, the caption speaks of filters Ψ[., f] – presumably these are supposed to be Φ[., f]?\n\nFurthermore, the fast implementation outlines in Section 4 casts some doubts on the need for a Wigner–Ville transform in the first place. If the K-transform can be calculated by appropriate convolution with a short–time Fourier transform, why do we need the Wigner–Ville transform? In this case, the main advantage of the proposed transform is the parametrization of the Gaussian kernels, which is not unimportant, but that is a very different way to define the representation. The question here is, therefore, why not define the K-transform as a function of the short–time Fourier transform?\n\nFinally, the organization of the paper and the results leave much room for improvement. Beyond the lack of precise definitions of many terms, figures (notably Figure 2) are not properly explained: we see axes labeled “time” and “frequency”, but that is about all. Theorem 2 defines the K-transform as a convolution but where we only extract a single value, which is equivalent to an inner product – why? Several words are misspelled (“time-serie”, “nd”, “architecutre”) or used incorrectly (“a representation that is highly dimensional”, “kernel employed onto the WV”, “what information is encoder”, “the representation … allow to continuously interpolate”, “gaussian”). Having such a large number of mistakes in the paper not only makes it hard to read, but shows a lack of care on the part of the authors when preparing and submitting their paper.\n\nThere are also some concerns about how the literature is cited. The authors refer to scattering transforms and joint scattering transforms applied to time series in the paper, but do not cite the main works related to these, which are Andén and Mallat, 2014 and Andén, Lostanlen, and Mallat, 2019. They also report the state of the art for the BirdVox dataset (specifically the BirdVox-70k dataset) as 90.48% (which they claim to beat with a performance of 94.2%), but the actual state of the art in the paper they cite stands at 94.85%.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "INTERPRETABLE SUPER-RESOLUTION VIA A LEARNED TIME-SERIES REPRESENTATION",
            "review": "This paper develops a novel interpretable and learnable Wigner-Ville Distribution (WVD) that produces a super-resolved quadratic signal representation for time-series analysis. It interpolates between known Time-Frequency Representations (TFRs) in that it can reach super-resolution with increased time and frequency resolution beyond what the Heisenberg uncertainty principle prescribes and thus beyond commonly employed TFRs. Besides, it is interpretable thanks to an explicit low-dimensional and physical parametrization of the WVD.\n\n\nPlease show some examples of Time-Frequency Representations (TFRs), and the effects before and after super-resolution. It's better to show some results on a specific application so that the authors easy to understand the paper. \n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Tries to fit in too much and in so doing leaves out important details",
            "review": "This paper describes a Wigner-Ville Distribution of a signal based on a time- and frequency-varying Gaussian window, where the parameters of that Gaussian can be fit to an observation. This representation is related to several well known time-frequency transforms, and an algorithm for calculating in the representation using short-time Fourier transforms is described. The representation is used as input to several different audio classifiers on several different audio classification tasks and generally performs better than morlet, sincnet, and learnable morlet features.\n\nThis paper covers a lot of ground and by doing so, leaves much important detail to the various appendices or omits it entirely. For example, it is not clear how many bases are used in the various representations and whether they are comparable across the baseline algorithms. It is not clear how many STFTs are required to compute them. An important equation (8) which is mentioned in the main body of the paper is only included in the appendix.\n\nin terms of experimental evaluation, several especially important details are missing. While it is reported that the same data split is used for each algorithm on experiment repetitions, this split is not described. Presumably it is different for each repetition, so much differ from the prescribed splits in the datasets (when provided). The datasets seem large enough to utilize a single split and use the validation set to decide on the hyperparameters (learning rate and network architecture). This would also demonstrate the ability of the model to generalize to new data. In order to understand what the representation brings beyond the STFTs that it is calculated from, a baseline should be run using all of the source STFTs as input. While state of the art references are mentioned in the text, they utilize different models and different data splits, so are not directly comparable.\n\nAdditionally, there are a lot of typos in the writing, which should be corrected:\n- The use of \\cite{ or \\citet{ where \\citep{ is necessary in many places throughout the paper\n- the use of \"time-serie\" in many places should be replaced with \"time-series\"\n- the subject of a number of verbs is missing, frequently in the construction \"let consider here\" which should be \"let us consider here\" or something similar\n- on page 4 \"we also explicit\" should be \"we also make explicit\"\n- on page 4, \"what information is encoder\" should use \"encoded\"\n-  on page 6, \"while having poor resolution\" should presumably be poor frequency resolution\n- the description of high and low frequencies seems to be reversed, possibly because the spectrograms are drawn upside-down (with low frequencies on top and high frequencies on the bottom).\n- Figure 2 should include explicit tick marks on the axes in meaningful units of frequency and time as should the figures in the appendix (3, 4, 5), which should also have their axes labeled.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "A good theoretical paper that proposes novel learnable time-frequency representations",
            "review": "The authors generalize the \"Cohen class\" of time-frequency representations (TFRs) for time-series data. A Cohen class representation for a signal is produced by low-pass filtering the Wigner-Ville transform. The low-pass filter is the same for all time and frequency. The generalization presented in this paper by the way of learning parameters of Gaussian kernels which are time and frequency-dependent. These kernels are applied to the Wigner-Ville transform of the signal.\n\nPros:\n1. As the learnable parameters are parameters of 2D Gaussian kernels, they are easily interpretable. \n2. The authors prove that the kernel functions are continuous with respect to the Gaussian parameters which make them amenable to be applied alongside gradient-based algorithms. I have gone through the proofs, although not in detail. They appear to be technically sound.\n3. The authors show clearly how the Cohen class can be derived from the general form by allowing time and frequency equivariance.\n4. The experiments on audio classification show that the learned transforms presented in this paper outperform other learned TFRs commonly used in literature. Also, the visualizations of the learned kernels provide an intuitive understanding of how the optimal kernels correspond to the dataset at hand.\n\nCons:\n1. I am not sure about the title of the paper. At first glance, it appears that the paper is proposing a novel super-resolution algorithm for time-series (i.e. upsampling time-series), although that is not what the paper is about. Perhaps the authors can better explain this as I am new to this use of the terminology.\n2. The authors say that the network layers used in the experiments are scattering layers. Does this mean that there are no learnable parameters in these networks? If so, it would be of value if the authors can present results when trainable networks are employed, ideally with the same architectures as in Becker et al. (2018), Lostanlen et al. (2018) and Andrade et al. (2018).\n3. From the standard deviations presented in Table 2, it can be seen that the proposed method is not stable with higher learning rates. This appears to be a limitation of the method. The authors should comment on point and whether a stable learning rate can be found automatically. \n4. The writing of the paper can be improved in general, and in particular Section 4. It is not clear what the computational complexity is for the datasets used in the experiments. I guess it comes down what the values for sigma_f are in practice?\n5. It would be valuable to show the empirical results with time and frequency-equivariant learned Gaussian kernel, in order to demonstrate the importance of generalization to time and frequency-dependent kernels. I did see in the supplement that the authors use time translation equivariant kernels for the experiments. Perhaps this should be moved to the main paper as this is an important detail.\n\nUPDATE AFTER AUTHOR RESPONSE:\n\nI appreciate the authors responding to all my comments and questions. I believe the paper can be still made better with these changes. I am sticking to my earlier rating. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}