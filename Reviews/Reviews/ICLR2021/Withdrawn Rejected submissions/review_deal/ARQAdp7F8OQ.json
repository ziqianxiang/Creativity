{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper conducts a comparison between a small set of models (4 in total) for unsupervised learning. Specifically, the authors focus on comparing Bayesian Confidence Propagating Neural Networks (BCPNN), Restricted Boltzmann Machines (RBM), a recent model by Krotov & Hopfield (2019) (KH), and auto-encoders (AE). The authors compare trained weight distributions, receptive field structures, and linear classification on MNIST using the learned representations. The first two comparisons are essentially qualitative comparisons, while on classification accuracy, the authors report similar accuracy levels across the models.\n\nThis paper received mixed reviews. Reviewers 4 and 5 felt it did not contribute enough for acceptance, while Reviewers 2 & 3 were more positive. However, as noted by a few of the reviewers, this paper does not appear to achieve much, and provides very limited analysis and experiments on the models. It isn't introducing any new models, nor does it make any clear distinctions between the models examined that would help the field to decide which directions to pursue.  The experiments add little insight into the differences between the models that could be used to inform new work. Thus, the contribution provided here is very limited. \n\nMoreover, the motivations in this paper are confused. In general, it is important for researchers at the intersection of neuroscience and machine learning to decide what their goal is when building and or comparing models. Specifically, is the goal: (1) finding a model that may potentially explain how the brain works, or (2) finding better machine learning tools?\n\nIf the goal is (1), the performance on benchmarks is less important. However, clear links to experimental data, such that experimental predictions may be possible, are very important. That's not to say that a model must be perfectly biologically realistic to be worthwhile, but it must have sufficient grounding in biology to be informative for neuroscience. However, in this manuscript, as was noted by Reviewer 4, the links to biology are tenuous. The principal claim for biological relevance for all the models considered seems to be that the update rules are local. But, this is a loose connection at best. There are many more models of unsupervised learning with far more physiological relevance that are not considered here (see e.g. Olshausen & Field, 1996, Nature; Zylberberg et al. 2011, PLoS Computational Biology; George et al., 2020, bioRxiv: https://doi.org/10.1101/2020.09.09.290601). It is true that some of these models use non-local information, but given the emerging evidence that locality is not actually even a strict property in real synaptic plasticity (see e.g. Gerstner et al., 2018, Frontiers in Neural Circuits; Williams & Holtmaat, 2018, Neuron; Banerjee et al., 2020, Nature), an obsession with rules that only use pre- and post-synaptic activity is not even clearly a desiderata for neuroscience.\n\nIf the goal is (2), then performance on benchmarks, and some comparison to the SotA, is absolutely critical. Yet, this paper does none of this. Indeed, the performance achieved with the four models considered here is, as noted by Reviewer 4, very poor. In contrast, there have been numerous advances in unsupervised (or \"self-supervised\") learning in ML in recent years (e.g. Contrastive Predictive Coding, SimCLR, Bootstrap Your Own Latent, etc.), all of which achieve far better results than the four models considered here. Thus, the models being compared here cannot inform machine learning, as they do not appear to provide any technical advances. Of course, some models may combine goals (1) & (2), e.g. seeking increased physiological relevance while also achieving decent benchmark performance (see e.g. Sacramento et al., 2018, NeurIPS), but that is not really the situation faced here, as the models considered have little biological plausibility (as noted above) and achieve poor performance at the same time.\n\nAltogether, given these considerations, although this paper received mixed reviews, it is clearly not appropriate for acceptance at ICLR in the Area Chair's opinion."
    },
    "Reviews": [
        {
            "title": "Lacking in clarity",
            "review": "Summary:\nThis paper proposes a set of biologically plausible update rules that can be used to compute latent representations. The paper presents a number of heuristics to set hyper-parameters and train the proposed model. The model is compared to RBMs, auto-encoders and another recently proposed biologically-plausible model.\n\nPros:\n- The method explores a new kind of model motivated by having biologically plausible update rules.\n- The experimental results include an interesting comparison of the learned features.\n\nCons:\n- The paper places emphasis on interpreting the update rules as Bayesian confidence propagation. Yet, the underlying probabilistic graphical model is not clearly described. It would be useful to have a figure in the paper that describes the model, including whether the model is directed or undirected, which variables are observed or unobserved, if the model is directed what is the generative model, etc.\n- Two assumptions are mentioned about the graphical model : \\\\( P(X_1,..,X_N) = \\prod_i P(X_i) \\\\), and \\\\( P(X_1,..,X_N|Y_j) = \\prod_i P(X_i|Y_j) \\\\). Unless I misunderstood, the first assumption is saying that each dimension in the input data \\\\(X\\\\) is independent of the others. This is a very strong assumption and makes the model weak. The paper does not include an explanation about why these assumptions make sense, or how they influence the model's inductive bias relative to other probabilistic models.\n- The derivation of the update rules is also unclear. The approximation that the indicator function \\\\(I(x_i=x^D_i)\\\\) can be replaced by its expected value \\\\(P(x^D_i)\\\\) is hard to understand. In particular, I could not understand how to parse Eq (4) which has a sum over \\\\(x_i\\\\). Is this still dependent on the input, given that the indicator function has been replaced by its expectation ? It would be good to have a more clear derivation of the update rules starting from the probabilisitic model.\n- The paper makes some very general assertions that do not add to the point being made. For example, \"One disadvantage of probabilistic models is that the known methods do not scale well in practice.\" Models such as VAEs are probabilistic models which scale quite well to high-dimensional inputs and large amounts of data.\n- In the introduced model, each HC seems to have a similar representational capacity as a softmax hidden unit. Therefore, instead of comparing to RBMs and AEs with sigmoid units, comparisons to RBMs and AEs with softmax hidden units will be more relevant.\n \nOverall, the paper can be improved along two directions : making the probabilistic interpretation more clear (specifying the graphical model clearly, deriving update rules), and doing experiments with softmax hidden units (so that the only thing changing is the update rules, and not the model architecture).\n\n---------------\nPost-rebuttal\n\n- Figure 1 is helpful in understanding the model. Thank you for adding that.\n- The additional experiments are also appreciated. This seems to indicate that it's not just the architecture but the learning rules that make the BCPNN model work well.\n- It would also be helpful to visualize the features learned by softmax units in RBMs and AEs and see if this results in a similar pattern of HCs encoding broad regions and MCs encoding variations within those regions.\n- It seems that the RBMs and AEs were not trained using any sparsity penalty. For example, Page 11 of https://www.cs.toronto.edu/~hinton/absps/guideTR.pdf and https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf. Having a target sparsity can have a significant impact on the learned features. Higher sparsity makes the features look more like stroke like and localized, and less spread out all over the visual field (as they do in Fig 4, C and D).  \n- Based on the additional experiments, I will be increasing my score to 5. However, given that the main contribution of the paper is a comparative study, the paper can add value by doing a more thorough comparison against variants of AEs and RBMs that have otherwise similar properties (such as keeping the HC-MC (softmax) architecture and sparsity levels the same).",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An incremental contribution lacking convincing experiments",
            "review": "Summary:\nThe Bayesian Confidence Propagating Neural Network has recently been extended to the case of unsupervised learning (Ravichandran et al., IJCNN, 2020). This paper compares this extension to restricted Boltzmann machines, autoencoders, and a biologically plausible model proposed by (Krotov & Hopfield, PNAS, 2019) on the MNIST dataset. For evaluation the authors consider the learned receptive fields and the classification performance of a linear classifier. The paper is very similar to (Ravichandran et al., IJCNN, 2020) but with an extended experimental section.\n\n\nPositives:\n\n+ Biologically plausible methods for unsupervised learning are an interesting area of research.\n\n+ There has been relatively little research on structural plasticity.\n\n\nConcerns:\n\n- The paper does not introduce anything new but merely compares existing methods.\n\n- The comparison is not an extensive study, but limited to one dataset, MNIST, and few alternative proposals, of which only the KH model is deemed 'brain-like'.\n\n- There seems to be something off with the experimental results. Krotov & Hopfield report a better test accuracy of 98.54% in their original paper in spite of using less hidden units.\n\n- BCPNN's performance is mediocre. It is even outperformed by random shallow networks with fixed, localized, random & random Gabor filters in the hidden layer (Illing et al, Neural Networks, 2019)\n\n- Lacking performance could be excused by greater biological plausibility as a neuroscientific contribution, which is however not the case here. As the authors themselves state, their model is 'abstract' (page 4) and not a neural implementation but merely 'uses implicit competition via a local softmax operation, the neural implementation of which would be lateral inhibition'.\n\n\nMinor comments:\n\n$\\pi(x_i)$ in Eq (6) is never introduced.\n\nThe line above Eq (11) should probably refer to (11) not (6).\n\nThere's a typo in the sentence after Eq (11).\n\nThe hybrid representation might be interesting. Is it any more biological than the well-known distributed and local representations?\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper systematically investigates Bayesian Confidence Propagating Neural Networks (BCPNN) on learning unsupervised representations on MNIST dataset. It presents a comprehensive comparison of four different commonly used unsupervised methods. ",
            "review": "Systematic investigation of biologically inspired algorithms and architectures is a very important research topic. \n\nThe paper investigates Bayesian Confidence Propagating Neural Networks (BCPNN) on learning unsupervised representations on MNIST dataset. It presents a comprehensive comparison of four different commonly used unsupervised methods. \n\nThe strong merit of BCPNN approach is the nice receptive fields of the hypercolumns (HC) and minicolumns (MC) learned by the proposed algorithm. As the authors point out, the advantage of the proposed algorithm is that it is able to produce sparse and highly localized (in the image plane) receptive fields for the MCs. Also, those filters look much cleaner than the counterparts of the classical algorithms considered in figure 3.  Additionally, the authors demonstrate that their representations stand in line with previously published proposals in terms of the classification accuracy. \n\nThe main weakness of this work is that the proposed method has only been investigated on MNIST and in one-layer architectures. At the same time, given the novelty of the approach, I think it deserves attention even in this simplest setting considered in this manuscript. \n\nSmall comments: \n1. Section4 (3rd line) should be “learned” \n2. There are some misprints around equation 11, such as the use of p(y) vs. P(y) is inconsistent. Also, it seem that the word “large” is missing following the formula in the line after equation 11. \n3. I also find panel B in figure 2 confusing. The way it is presented makes it look like the authors have combined the outputs of four networks to feed into the classifier, while in reality those four networks were evaluated one by one. \n4. It would be better to designate a new variable for the left hand side of equation 12, since I_ij is already taken. \n\nPost Rebuttal: \n\nThank you for the response. I have read the discussion with other reviewers. A small comment: while I agree that it is reasonable to keep the classifier the same for all the models (softmax with cross entropy) for a fair comparison, I disagree that the activation function for the first layer should be kept as ReLU in the KH model. In fact KH explain that this is a suboptimal choice in Fig. 4 of their original paper. Using powers of ReLUs should increase the KH accuracy. Overall, I think that this is a nice paper, and I am inclined to keep my initial score. \n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This is a comparative study of four unsupervised learning approaches. The authors specifically focused on the brain-like BCPNN model. Overall, the methods were clear and fair. However, it is difficult to draw reliable conclusions based on current comparison results.",
            "review": "This paper evaluated four unsupervised learning approaches (BCPNN, KH, RBM, AE) by training a supervised classification layer on top of the hidden representation. Specifically, the authors qualitatively compared the receptive fields and quantitatively compared the classification performance across four models. The authors emphasized the advantages of BCPNN since it applies biologically plausible local learning rules and requires fewer epochs for convergence.\n\nOverall, the comparison was fair and solid. The description of the BCPNN model in section 3 was clear and comprehensive. But the authors did not provide sufficient details of key mechanisms in the other three models (especially the KH model, which also used brain-like learning rules). The detailed introduction of the other three models should be an important component since this is a comparative study. The results were clearly stated, but the insignificant difference in the classification accuracy comparison (Table 2) can hardly lead to a reliable conclusion about which unsupervised method is better. And it would be better if the authors could provide more interpretations about the \"hybrid\" receptive fields of HCs and MCs in BCPNN (Fig. 3A).\n\n##### Specific comments and questions:\n1. In the original KH model (Krovtov & Hopfield, 2019), they also tested the classification accuracy on the MNIST dataset, and the result reached an error rate of 1.46% with 2000 hidden states. This is better than the reproduced result shown here (97.39% accuracy) with 3000 hidden states. Is this accuracy drop caused by a different setting of hyperparameters? Then is it fair to say that \"BCPNN outperforms KH\"?\n2. Could you provide more explanation on Eq. 11? Why this dynamic update of $k_{\\beta}$ could be used as a desired bias regulation?\n3. When the number of total hidden units is fixed, what would be the effect of changing the ratio $\\frac{N_{MC}}{N_{HC}}$ in BCPNN?\n4. The \"hybrid\" structure of BCPNN provides interesting receptive field results in Fig. 3A. Is this structure generalizable to a model with multiple hidden layers?\n\n##### Minor:\nPage 4. in 3.1 Bias regulation. Typo: Eq. 6 should be Eq. 11. And \"the value of gain $k_{\\beta}$ at around 1 when $P(y_j) - \\frac{p_{MaxEnt}}{4}$,\" missing $\\gg 0$ here?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}