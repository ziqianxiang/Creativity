{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper introduces a model-agnostic heuristic for batch active learning.  There was an agreement among the reviewers that it's a good approach to try and report about, but the paper was ultimately rejected after calibration.\n\nThere were two concerns raised in the reviews, and the authors are encouraged to address them in a revision:\n\n1) Several reviewers commented on issues with readability, affecting the paper's reproducibility (see reviews for details).  The reviewers would have also liked to see more evidence of empirical robustness to various choices made.\n\n2) For the paper to be compelling, it should either compare with gradient-based approaches like BADGE (Ash et al. 2019) or include experiments with a representation where BADGE can't be applied (to support the model-agnostic distinction the authors are making).  The core motivation is the same, with both approaches trying to explicitly incorporate predictive uncertainty and sample diversity, and it would be interesting to see a comparison."
    },
    "Reviews": [
        {
            "title": "Interesting idea for active learning: Well motivated and tested. ",
            "review": "**Summary:** This paper proposes a way to do batch mode model agnostic active learning. In this task, the agent has to query a batch of data points from a set of unlabeled examples for which it will get labels. The paper puts an additional requirement that the algorithm is model-agnostic. The key idea here is to sample a batch of points that provide the most \"information\" about the remaining unlabeled examples.  Authors argue that this will result in higher performance on the unlabeled examples. The proposed approach called ICAL (Information Condensing Active Learning) uses Hilbert-Schmidt Independence Criterion (HSIC) to measure dependence between a chosen batch and the unlabeled examples. The goal is to pick a batch with a maximum value of HSIC which should intuitively give us a batch which is representative of the unlabeled set. HSIC can be easily estimated unlike other dependence measures such as mutual information. Given a batch size $|B|$, a dataset of unlabeled examples $D_u$  and $m$ samples to estimate HSIC, the ICAL algorithm computes a batch for label acquisition in $O(|D_U|m^2|B|)$ steps, where a greedy strategy is used to search over batch.  Results are presented over MNIST, variants of MNIST and CIFA and show improvements over five previous active learning approaches and a random acquisition baseline. \n\n**Strength:**\n1. ICAL makes a useful contribution to the active learning literature which has wide range use. Particularly, experiments are presented on realistic domains, with neural networks, and show gains over a few different baselines.\n2. ICAL is model-agnostic which means it can be applied to decision trees, neural networks, complex ensembles, etc. \n3. Experiments show that ICAL acquires a more diverse batch for acquisition.\n\n**Weakness:**\n1. For HSIC, one has to decide the kernel which may be difficult for some domains.\n2. No comparison with BADGE (Ash et al. 2019) is provided. \n3. Time complexity of $O(|D_U|m^2|B|)$ seems expensive particularly if $m > 1000$. What is the value of $m$ that one should expect in practice?\n\n**Questions:**\n1. For Repeated MNIST task, how do the different baselines compare in terms of the number of times they pick a datapoint and its replica for label acquisition?\n2. Is the set $X$ and $Y$ assumed to be countable in Section 3 since summations are used everywhere. \n\n**Writing:**\nThere are issues with writing in several places. Some are enumerated below:\n1. Grammar error on the second line of the third paragraph of intro in \"directly focus on 'minimize' the error rate\". It should be minimizing.\n2. Unexpected full stop after \"model's parameters\" in the third paragraph of the intro. \n3. No $d \\theta$ in Section 3 when taking integral in the first paragraph.\n4. What is $B_{D_u}$ in the definition of $B^\\star$ in the third paragraph of Section 3. Also, how is the training set used in this definition?",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A novel batch acquisition function with promising results---reservations arise about its exposition in the paper, however",
            "review": "The paper introduces a new acquisition function for (batch) active learning that uses a variant of the Hilbert Schmidt Independence Criterion to acquire diverse batches that are informative for the remainder of the unlabeled set. The new acquisition function leads to better calibration, as evidenced by achieving lower NLL (for similar accuracy), as well as better accuracy on EMNIST and FashionMNIST than current baselines.\n\nOverall, I’m scoring the paper with a weak reject. While the paper provides good results on EMNIST and FashionMNIST, it does not seem to scale to CIFAR-10 that well. More importantly, the reviewer had trouble understanding the description of the approach in the paper. The novel idea of using HSIC instead of estimating mutual information terms, which scale badly in batch size, is very interesting and needs to be explored. Sadly, for this reviewer at least, the exposition in the paper is very confusing and hard to follow to the point that this reviewer cannot recommend acceptance in its current form.\n\n### Strengths\n\nThe motivation of the paper is strong: it points out that current methods neglect to look at the effect of sample selection on the unlabelled set and focus instead on informativeness for the current model. This prevents current acquisition functions from taking the distribution of the unlabelled set into account. Section 4 provides two convincing examples for this. The simpler one being a strong class imbalance.\n\nThe paper proposes to estimate a d-variable Hilbert Schmidt Independence Criterion (dHSIC from Pfister 2018) instead of a mutual information term that includes a d-variable joint distribution (like in BatchBALD by Kirsch 2019). Computation of joint entropies does not scale well, and thus using dHSIC seems like a good alternative to capture dependencies and which also scales better.\n\nThe paper provides strong empirical evidence that its approach works much better on EMNIST and FashionMNIST. It provides performance comparable or slightly better to BatchBALD on MNIST and RepeatedMNIST, and it also shows that overall, it seems to pick from different classes more uniformly.\n\n### Concerns\n\n1. This reviewer has had difficulties understanding the method described in the paper as well as its practical implementation. HSIC and dHSIC are not properly introduced in the main paper, whereas mutual information, which is not used, is defined. dHSIC is not even explicitly defined in the appendix. Moreover, the step from having a (MC-Dropout-based) BNN with sampled output probabilities for each pool sample to computing kernels for different variables is not clear. Is consistent MC dropout used? How are the kernels computed?\n2. The paper mentions that the pool set is subsampled for computing the pool kernel matrix (acc to Proposition 1) and this noise helps to acquire diverse batches. From the reviewer’s experience, methods that benefit from noise usually perform worse for imbalanced datasets. Could an ablation be run to show the trade-off? Especially given the examples in the motivation in Section 4, another experiment with imbalanced classes would be helpful to show that the proposed approach helps with the issues detailed in its motivation.\n3. This reviewer is also confused about the runtime complexity of the proposed algorithm. In the appendix, $dHSIC(x_1, \\ldots, x_d)$ has runtime complexity $O(n^2 d)$, where $n$ is the number of samples (the reviewer is guessing this) and $d$ is the number of variables. The number of classes seems to be missing. It has to be linear in the classes and number of MC samples at least as the model outputs need to be used at some point. BatchBALD’s runtime complexity is also stated incorrectly, see Kirsch 2019. \n4. In general, the paper is not clearly written, with a notation that changes between the main paper and appendix and variables whose meaning is not explained in the text: for example, the proof of Proposition 2, or the definition of HSIC in the appendix, which does not explain from which distributions the variables are sampled specifically.\n\nThis reviewer was not well-acquainted with kernel methods and RHKS.\n\n---\nUPDATE: After reading the replies, I have updated my score from 5 to 6.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Another acquisition function that seems to do a little better on several datasets for CNNs ",
            "review": "This paper introduces a model agnostic active learning technique that maximizes the dependency between a batch and the rest of the unlabeled pool. The dependence is measured via the Hilbert Schmidt Independence Criterion and this paper introduces some approximations/optimizations to speed up the method.\n\nIn terms of novelty, this paper introduces another acquisition function, which to the best of my knowledge is technically novel. However, the reasoning or intuition for the algorithm does not seem very novel. For instance, expected error reduction (EER) is motivated by a similar intuition.\n\nThe significance of this paper rests on its empirical evaluation as there isn't any justification for the heuristic algorithm beyond a conceptual motivation (which isn't unusual). The empirical results are relatively strong, comparing to a variety of recent algorithms an outperforming the others by a small margin (and a larger margin on a couple of datasets).\n\nIt would have been nice to see the model agnosticity used by running experiments with different models beyond CNNs. In fact, if some other methods (which apply to CNNs) are discounted because they are not model agnostic, the experiments should really include these other methods or include more than just CNNs. It would also have been nice to see the learning curves in the higher accuracy range, which may be more practical: for instance, in addition to the current plots, also having plots with larger batches that go up to budgets of 1000 or more.\n\nAFTER READING AUTHOR RESPONSE-----------------------------------------------------------------------------------------\n\nThanks for the response.\n\nIdeally, you would be able to show results for ensembles of decision trees or some model that is very different from neural networks.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An interesting, principled new active learning method",
            "review": "The authors propose a novel acquisition function for active learning based on the (sample) Hilbert Schmidt Independence Criterion (HSIC) statistic. The authors use several standard approximations (using MC dropout to sample from the posterior, building the pool batches greedily, subsampling other unlabelled points when estimating the value of a candidate batch) as well as useful properties of the HSIC statistic, to make the proposed method computationally tractable. \n\nPros:\n\nThe proposed method is fairly straightforward and uses relatively well studied tools. \n\nSection 4 provides a valuable analysis of existing active learning methods which is of independent interest, and shows how the new method is not as susceptible to the flaws of other methods. This insight can be quite valuable to further develop new active learning algorithms.\n\nFigure 3 suggests a reason for why the proposed method outperforms existing ones on some data sets (although it would be interesting to get statistics which back up the claim that individual batches are more balanced as well as the overall sampling process).\n\nExperiments compare the new method to a reasonable set of SOTA active learning methods. \n\nCons:\n\nThe new method is competitive on all experiments, but can only be claimed to outperform existing methods on EMNIST and fashion-MNIST. \n\nWould be interesting to see things like robustness to some of the approximation choices (number of MC dropout resamples for example). \n\nThe ideas and observations here are a contribution to the active learning community, and experiments still show this method to be competitive with existing methods. Therefore I currently lean towards accepting. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}