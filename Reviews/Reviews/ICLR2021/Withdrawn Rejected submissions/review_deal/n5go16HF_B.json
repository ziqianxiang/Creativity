{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper proposes a new generation technique for multi-category marked temporal point processes.  The paper was reviewed by three expert reviewers who expressed concerns for limited novel contributions, theoretical justification, and empirical evidence. The authors are encouraged to continue research, taking into consideration the detailed comments provided by the reviewers."
    },
    "Reviews": [
        {
            "title": "Justifications and experiments can be improved",
            "review": "Summary:\nThe authors propose a method for multi-category marked temporal point processes (MTPPs) generation with sparse, incomplete, and small training dataset. They apply Adversarial Autoencoder (AAE) and feature mapping techniques, which include a transformation between the categories and timestamps of marked points and the percentile distribution of the category.  The paper shows effectiveness and robustness of the proposed method by comparing with Markov chain approach on three datasets: Radicalization Dataset, Mimic III Dataset and Stack Overflow Dataset.\n\nStrength:\n1.\tThe paper is clear in general. Firstly, they define MTPP and multi-category MTPP. Then, the multi-category MTPP generation with sparse, incomplete, small training data problem is addressed.  The authors argue that it is a popular real-world problem where we only can access small and incomplete data.\n2.\tThe description of the overall method is reasonable. But more details can improve understanding.\n\nWeakness:\n1.\tThe authors should provide justification of choosing to use AAE in the work. In particular, why is AAE an attractive approach for MTPP? \n2.\t The authors mention: \"The typical MTTP baselines like Reinforcement Learning, RNNs, Wasserstein GANs require a significant amount of data to train a network. Therefore, such techniques are not applicable to our proposed approach. As the baseline, we compare the proposed data generation technique with a Markov chain approach which was applied to the same dataset in (Klausen et al., 2018b).\" The authors could try to apply Reinforcement Learning, RNNs, Wasserstein GANs with data filled by simple methods, to empirically validate that these methods are not suitable for incomplete, small data.\n3.\tIn feature mapping method, the authors could provide justification for converting marked point times t_ij to days a_i. Besides, the method to convert t_ij to a_i and examples are not provided. If this is a common preprocessing method in MTPP, the authors should cite the relevant work. Overall, Step 1 of Algorithm 1 is not clear. \n4.\tAt the data approximation technique (step 3 of the Algorithm 1), the author randomly chooses a probability for the appearance of an unobservable data point but there is a lack of explanations. Can the authors explain the reason of selecting from [0, Pcj(0)]?\n5.\tThe authors should provide more details of incomplete and small dataset, and compare with their method when training with full data. This is to understand that if generated data is still good when training with small dataset\n\n\n=============== \nafter rebuttal: I thank authors for the responses. After reviewing the authors' response and other reviewers' comments, I keep my original rating. \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper presents a deep method for a practical data augment for event sequences via adversarial autoencoder (AAE). The method is straightforward, which makes the contribution of the paper marginal. The paper also has some theoretical concerns.",
            "review": "The paper is concentrated at dealing with the data missing problem of MTPP and applies an AAE for the “incomplete multi-categorical MTPPs”.  First, the problem description appears questionable. Point processes are a class of stochastic processes for modelling discrete event sequences in a continuous time domain. They are statistical models and have a well-defined mathematical meaning. The expression of “incomplete point process” is quite confusing. One possible reason is that the authors fail to distinguish between the model and the data. One can say “incomplete data” or “incomplete observations of a model”, but “incomplete model” is not acceptable unless properly defined. Therefore, the proposed method seems not specifically for point processes but for the sequential data. \n\nThe authors seem to misunderstand the difference between empirical distribution and probabilistic distribution. The probabilities, e.g., $p_d(\\mathcal{H})$, are actually empirical distributions of the time. Here the authors see the arrival time of the events as a random variable, and $t_{ij}$’s are independent samples of the random variable, which is unrelated to point processes. The percentiles used in the algorithm are essentially the cumulative empirical distributions of the arrival time. If point processes need to be considered here, the authors should define their probabilistic structures as they are probabilistic models, where the intensity function is often inevitable unless otherwise defined. I believe the confusing mathematical formulation should be considered as a fatal flaw.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "review for #895",
            "review": "This work studies the generation technique for multi-category MTPP using adversarial autoencoders for sparse and incomplete datasets. To address the sparsity and incompleteness, some pre-processing and post-processing methods are utilized to adapt the data to AAE.\n\nStrengths: The model setup is reasonable, and the idea is straightforward to understand. \n\nI recommend rejection of the paper for the reasons below.\n\nWeakness: The major concern is the contribution of the work is very limited. The generation framework is a combination of adversarial auto-encoder and feature mapping encoder (decoder), where the AAE part is completely same as the original work in [Makhzani et al., 2015]. In my eyes, the only contribution is the addition of the feature encoder and decoder. Although the author named it like that, the so-called encoder and decoder are in fact some heuristic pre-processing and post-processing (shift and normalization) of the raw data. \n\nSome specific concerns: the notation in Eq.(2) is confused. If c_j is defined as the category, then c_j should \\in [1,m] not j. I understand what the author means by the current notation. It is better to define e_i=(t_i,c_i) where i \\in [1,n] and c_i \\in [1,m]. \nIn algorithm 1, the steps 1-3 are some heuristic pre-processing of the raw data. Why do that? Why change the timestamps to days and scale it to a probability value? Any intuition behind this operation? My understanding is the raw data is shifted, scaled and normalized to [0,1]. Add some theoretical analysis why performing that pre-processing will help AAE handle the sparse and incomplete data. \nIn experiments, there is only one baseline model to compare with. Add more DNN-based generative baseline models will make the experiment more convincing. \nIn experiments, although the author claimed 3 real datasets, I did not see any experimental results of the 3rd (stackoverflow) dataset. \n\nTypo: above Eq.(5), significance-->significant",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}