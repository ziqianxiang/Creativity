{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "\nThis paper analyzes several neighbor embedding methods-- t-SNE, UMAP, and ForceAtlas2-- by considering their objectives as consisting of attractive and repulsive terms. The main hypothesis is that stronger repulsive terms contribute towards learning discrete structures, while stronger attractive terms contribute towards learning continuous/manifold structures. The paper empirically explored the space parameterized by the relative weighting of the attractive and repulsive terms for the t-SNE and UMAP algorithms, using several data sets, and qualitatively confirmed their conclusions about the impact of the attractive and repulsion terms as the relative weights vary. \n\nThe experimental validation of the paper's main hypothesis is thorough and the use of diverse data sets and neighbor embedding methods is appreciated-- as the authors point out, several reviewers missed this contribution. However, several reviewers point out that the insight presented in the paper is already largely present in the literature, and that beyond its analysis the paper does not present new algorithms based on this insight. The authors rebut this claim by arguing that the novelty of the paper lies in it: (1) showing the contrary to the established opinion, UMAP works despite, instead of because, it uses cross-entropy loss, and (2) the paper offers for the first time a theoretical understanding of why ForceAtlas2 highlights continuous developmental trajectories, and (3) prior work has not made the connection between UMAP, ForceAtlas2, and t-SNE or suggested using exaggeration throughout the optimization process for t-SNE rather than simply as a warm-up. The paper does indeed present intuitions for (1)-(3) based on the attraction-repulsion ideas, and makes the connection between these neighbor embedding algorithms by viewing them as variations on the theme of attraction-repulsion, but these intuitions are not significant steps forward with respect to what is already known about how neighbor embeddings balance attraction and repulsion. The mathematical analyses consist of stating the gradient for the algorithms and explaining how weighing the attraction and repulsion terms differently lead to different qualitative observations. The use of exaggeration throughout the optimization process is straightforward, and no strong mathematical characterization of the properties of the resulting algorithm is given.\n\nIt is recommended that this paper be rejected, as it consists of a thorough empirical validation of an understanding of the trade-off between attractive and repulsive forces in neighbor embedding methods that was already present in the literature, along with some straightforward arguments connecting several popular neighbor embedding methods, but does not introduce any significantly new actionable insights or novel algorithms.\n"
    },
    "Reviews": [
        {
            "title": "The paper does not offer a significant contribution",
            "review": "Summary: the authors study a number of neighbor embedding methods in terms of attraction-repulsion forces. The authors show that t-SNE, UMAP, FA2, and LE can be (approximately) unified as a common approach that use different levels of tradeoff between these two terms. They also discuss the increased attraction in UMAP as a result of negative sampling.\n\n\nReview: a main portion of the technical contribution of the paper is simply writing down the gradients of the commonly used DR methods and providing an intuitive comparison of gradient terms. However, there is not much rigorous mathematical result to support the claim. I am aware of the complexity of such a strong theoretical result (e.g. the work of (Arora et al. 2018)). However, the current version of the paper does not offer any concrete result and remains on an intuition level observation. The experiments partially support the claims, but similar observations have been made before in related work. For instance, (Amid and Warmuth 2019) qualitatively sort DR methods by means of their \"global score\" (which is a notion of how well a method preserves cluster information).\n\nA minor note on the experiments: in order to eliminate the bias in initializing some methods with PCA, I encourage the authors to also consider random (shared) initialization for all methods (Kobak and Linderman 2019). Also, since the paper is mainly experimental, (larger scale) experiments on a more diverse set of datasets would improve the paper. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Study of role of repulsion/attraction trade-off in manifold leaning.",
            "review": "The paper studies an early-exagerration constant \\rho that trades-off the attraction vs repulsion parts of the manifold learning algorithms at the early steps of optimization.\n\nThe paper provides a comparative analysis of objective functions for several manifold learning algorithm through the lights of effect of \\rho. It shows that the embedding of UMAP and ForceAtlas2 could be roughly recovered using t-SNE with a special choice of \\rho. The paper also proposes an explanation why UMAP works better when initialized from LE and why t-SNE gets better results from early exaggeration. All the analysis is done on a single MNIST dataset .\n\nThe paper seem very incremental in nature, since Elastic Embedding (Carreira-Perpi√±an, 2010) already studied the effect of \\rho in a very similar manner to the findings proposed in the paper. The paper, however, only briefly covers that paper, mentioning the algorithm only in he Discussion section.\n\nThe authors added the analysis between t-SNE and most recent UMAP and ForceAtlas2 algorithms, but most of the novelty about the effect of \\rho and the connections to LE and early exaggeration are quite apparent. Most importantly, the paper doesn't propose any new algorithm or any improvements beyond insights. Even those are defined very vaguely. For example, it is not clear to me, ho the authors define \"high-repulsion embeddings\" and how much lower the repulsion strength should be.\n\nFinally, the result on a single MNIST dataset are not very general nor conclusive. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interpretation is nice, but what kind of practical benefits can we get?",
            "review": "Summary:\nIn this paper, a unified view of embedding methods for visualization is presented. The main message is that, Laplacian eigenmaps and t-SNE are governed by a single formula, and the difference of them can be seen as a difference of a hyperparameter value. We can also approximately recover two different embedding methods --- UMAP and ForceAtlas2. Using a few benchmark data sets, the relationships of these methods are visualized.\n\n\nDetailed comments:\nFirst of all, I have almost no experience to study visualization methods, and my assessments, especially towards non-technical parts, could be biased. \n\nThe main result --- a general equation that covers several embedding methods --- is technically interesting. However, it would be not clarified what kind of benefits we can get from the finding. A possible direction is to tune $\\rho$ so that we can get the most effective visualization. Is it possible to do something like this?\n\nAnother concern is that it is not easy to judge the visualization results (e.g. Fig 2) because they are qualitative and subjective. To prove the significance of this study, more quantitative results that everyone can understand would be necessary.\n\n\nMinor comments:\n- $\\sim$ in Eq. (3) seems to mean the equality up to constant but such usage would be not common. It would be better to add an explanation. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "A unified perspective based on the attraction-replusion spectrum is proposed to empirically study various neighbor embedding methods. ",
            "review": "Authors of this paper conducted study on existing neighbor embedding methods from the perspective of the attraction-replusion spectrum. \n\nPros:\n1)\tExtensive experiments demonstrate the phenomena that neighbor embedding methods can achieve the continuous manifold structures or discrete clustering structures by varying the balance parameter.\n2)\tDetailed implementations of existing methods are taken into account for the analysis, so it is a good guideline for users of these methods on real applications.\n\nCons:\n1)\tThe novelty of this paper seems limited. The attraction-replusion property is not new to the existing neighbor embedding methods. \n2)\tAuthors conducted various experiments to show the property, but the conclusion is only empirical.\n3)\tAuthors may need to demonstrate how these observations can make improvement over the existing methods or motivate new models.\n4)\tTo better demonstrate the continuous manifold or discrete clustering structures, authors can take various real data with clear underlying manifold structures that have been studied in the literature. Simulation data is good, but it is less real since the noise may significantly affect the experimental results.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}