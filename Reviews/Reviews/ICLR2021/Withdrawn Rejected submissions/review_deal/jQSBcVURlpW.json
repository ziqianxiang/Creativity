{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper was reviewed by 4 experts in the field. The reviewers raised their concerns on lack of novelty, unconvincing experiment, and the presentation of this paper, While the paper clearly has merit, the decision is not to recommend acceptance. The authors are encouraged to consider the reviewers' comments when revising the paper for submission elsewhere."
    },
    "Reviews": [
        {
            "title": "initial review",
            "review": "Initial review (2020.11.01)\n\nReview: \nThis paper addresses a specialized solution to combine neural networks and linear models for Raven progressive matrices (RPM). The solver is composed of convolutional neural networks (CNN) as an image perception module and a reasoning module with linearly parameterized operators to represent successive operations in the RPM. The operators are trained with regularized linear regressors, which are lightweight capable to adapt on-the-fly for each instance. The overall architecture enables end-to-end training and can be used for generation. For performance evaluation on two kinds of automatically generated problem sets, the authors test the proposed method with respect to 3 extrapolatory settings such as systematicity, productivity, and localism, which seems to be newly defined tasks for RPM. Their method outperforms pure neural state-of-the-art methods with a large margin over all of settings. \nThe proposed methods solve RPMs well with available components such as CNNs and linear models, which are able to be tuned on-the-fly. Also, this paper provides systematic results to easily comprehend the role of modules with new settings (systematicity, productivity, and localism) for RPMs. On the other hands, my major concerns are two-fold: (1) one of important research questions introduced in this work, “what constitutes such an algebraic inductive bias?” seems not so clearly answered in this paper. (2) the comparative result in the paper just considers only pure connectionist methods without considering other (semi-)symbolic approaches. Since this work utilizes additional problem information (e.g., specified features) for modeling than compared neural methods, I think it would be better to justify the position of this work by comparing various approaches including search-based solver, symbolic, and the neural methods to figure out the superiority of this approach.\nAs a result, I vote for marginally below acceptance threshold.\n\nPros:\n-\tThe authors provide a specialized solution for RPM well with CNNs and linear models.\n-\tThey introduce new 3 settings of RPMs and report systematic experimental results.\n\nConcerns:\n-\tIn the comparative study, the authors report only the systematicity, the productivity, and the localism, not the \"accuracy\" used in the cited related works. Due to the lack of the information, the readers can not directly compare them with respect to the previous viewpoint.\n-\tIf the result of other various approaches for RPM not only pure connectionist methods but also search-based solver, symbolic, and neuro-symbolic approaches, it would be easier to find the niche of this work and its superiority.\n-\tAs I mentioned above, the research questions, “what constitutes such an algebraic inductive bias?” seems not so clearly answered in this paper. Could you discuss this issue with the result in the paper?\n\nMinors:\n-\tIt would be better understandable to show examples for 3 settings of systematicity, productivity and localism on RPMs.\n-\tfare -> far?\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Paper 950 Review",
            "review": "This paper proposed ALANS, a semi neuro-symbolic learner specifically designed for improved systematic generalization on RAVEN dataset.\n\nPros:\n1. The proposed model integrates learnable symbolic operators that are similar to the ones used in Neural Theorem Proving. The operators are shown to have improved systematic generalization performance.\n2. Introduced a new generalization testing dataset based on RAVEN dataset.\n\nCons:\n1. The proposed model relies on strong assumptions specific to RPM, and even RAVEN dataset. For example, In Equation 3, the authors assume the knowledge that relations can only exist in rows of the RAVEN dataset. However for PGM dataset (another well-known RPM dataset), the relations can exist either in rows or columns, or both. I hypothesize that training operators when there is no guaranteed existence of relations will lead to noisy gradients. I have doubts that the proposed method can be readily adapted to PGM, not to mention other types of reasoning tasks.\n2. While the proposed model is shown to perform well on the dataset generated based on RAVEN, I think the authors should show results on PGM dataset as well, considering that PGM already have a few data splits to test systematic generalization.\n\nClarity:\nIn general the paper is written in a clear and understandable manner. The only part that confuses me is about the perception CNN module. It is not clear to me how the model learns to disentangle object attributes such as color and position? Is there any auxiliary labels to help induce such disentanglement, or does the model learn to disentangle the attributes because of the way authors marginalize the object attributes in a diagram? The authors only show the marginalization for the attribute 'number'. I suggest the authors to include the marginalization for all other attributes in the Appendix for better understandability. \n\nSummary:\nOverall I think this paper propose an interesting approach that improves systematic generalization on RAVEN datasets. But I have doubts on its adaptabilities to PGM dataset and other types of reasoning tasks. And there is also some lacking details that hinders understanding of the paper. I will raise my score if the authors can (1) show improved performance on generalization data splits on PGM dataset, and (2) clarify about how the model learns to disentanglement the object attributes.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning",
            "review": "The author(s) propose an architecture ALANS^2, primarily focused on the task\nof Raven's Progressive Matrices (RPM, popularly known as IQ tests).\nTo solve it, they join an image classifier on the individual fields\nof the 3x3 picture matrix with a \"reasoning backend\". In the backend,\nthey model the high level rules of the task by matrix multiplication.\nGiven a problem instance, they find a such an operator (matrix) that fits\nthe first two rows of the instance the best, and use this operator\nto determine what picture belongs to the missing field.\n\nFor training, they use not only the knowledge of the correct answer but also\nthe correct operator which should be found (the \"rule\" which should be discovered).\nExperimental results show that they exceed by a margin\nthe previous models used for this task.\n\nThe task is interesting, in fact some research has been done on trying to\nlearn intelligence tests in various ways and a number of the relevant ones\nare properly cited in the paper.\n\nThe results presented show an improvement with respect to previous\nresults that I find enough to deserve publication.\n\nThe article is well written apart from the typo mentioned below.\n\nTypo:\nPg3, part \"Abstract Visual Reasoning\" last sentence: fronend -> frontend\n",
            "rating": "7: Good paper, accept",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "Good but could benefit further clarification and discussion on the applications of this work",
            "review": "**Summary**.\nThis work proposes a new learner bridging the gap between connectionists and classicists in the task of Raven’s Progressive Matrices (RPM). It relies on a CNN to extract visual features and then uses an algebraic abstract reasoning module to infer the operators of an RPM instance, which allows applying the inferred operator on the RPM instance to predict potential solutions according to various attributes. The most likely solution according to the ensemble of the attributes is then selected as an answer.\n\n**Pros**.\n- This work is significant as neural models still struggle in systematically generalizing in reasoning tasks.\n- The general idea of the paper is easy to follow but that does not mean the proposed method is trivial, far from it.\n- Experiments are clearly described and the authors give particular attention to split their dataset to systematically test for generalization.\n\n**Cons**.\n- Additional clarifications and motivations could benefit the paper (see **Questions & Suggestions** below).\n- While yielding impressive results and targeting a fundamental issue of neural models, it is not clear how the proposed technique could be applied to other domains. As of now the paper focus only on the RPM task. It would be beneficial to open up the discussion to potential applications. It would be nice to know what the authors think are the potential applications of their learner. How would it be applied to other reasoning tasks?\n\n**Questions & Suggestions**.\n- The CNN is used to predict the presence of an object, its type, its size, and its color while a belief inference engine is used to predict the position and number of objects. It is not clear why the CNN was not also used to predict the position and number of objects, thus questioning the motivation behind the belief inference engine.\nWould training a CNN to predict the position and number of objects also help?\n- It is not clear how the CNN predicts the presence of an object, its type, size, and color given that it is not trained to do that. Do you produce 4 feature vectors, apply a softmax to each, and arbitrarily decide which feature vector will predict each object attribute? If so the results in Table2 are very impressive and hard to believe. How do you decide which feature vector will predict each object attribute?\n- Suggestion: as an ablation study, it would be nice to also compare the performance of ALANSS with randomly initialized and fixed CNNs. This would give an estimate on the advantage of using CNNs as neural modules. One could hypothesize that the robustness of the method comes mostly from the symbolic abstraction rather than the neural representation.\n- Neural Theorem Proving also tries to bridge the gap between connectionists and classicist approaches. Can it be related to this work? It would be nice to discuss this in the Related Work section.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}