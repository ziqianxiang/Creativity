{
    "Decision": "",
    "Reviews": [
        {
            "title": "Simple idea and works well. ",
            "review": "This paper develops AdpCLR: Adaptive Contrastive Learning Representations, which is an extension of contrastive-based self-supervised learning. They are the first to involve the hard-positive pairs mining, while the previous works mainly focus on negative mining.\n\nPros:\n1. Positive pairs and negative pairs are usually not specifically defined in contrastive learning domain, but due to the success of supervised contrastive learning, which proves that the definition of positives in SimCLR (images augmented from the same images are positives) is not the best. This paper re-define positives (images belongs to top-$K$ closest embedding set), and their method AdpCLR can mine these hard positives automatically. The provided f1 scores show that their approach can really mine these pairs.\n2. This paper gives the upper bound and convergence rate of generalization error. The experimental results are in line with the theoretically analyze.\n3. This paper mainly conduct experiments on ImageNet. The experimental results show they outperform all the existing contrastive-based self-supervised learning. \n\n\nCons:\n1. The paper is not well written, there are some typos and some information is clearly delivered. I suggest the authors shall carefully proof-read the paper in the new version.\n2. I wonder why only K=1 and K=5 are given for their experimental results, how the performance on other settings of K?\n3. Under the definition of positives in this paper, I wonder can this idea be applied in other self-supervised learning methods, such as MOCO, BYOL, to get better results?\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Reproducibility and writing is concern",
            "review": "The paper proposes a self-supervised learning model where, in each batch set of positive pair are used to increase the positive support set. These positive pairs are selected as top-K most similar pair after encoding the samples. The paper also provides the generalization error and convergence rate. The paper shows the improved result on the ImageNet dataset on the ResNet-50 (1x,2x,4x) architecture. Also, compared to the base model simCLR the proposed model shows the slow convergence rate.\n\nPositive:\n1: Instead of using a single positive pair, K positive pair provides richer information; therefore, the performance gain is expected. At the same time, we have to ensure that the positive pair are true positive pair; otherwise, performance may drop quickly. \n\n2: Paper shows the consistently improved result on the ImageNet dataset for the ResNet-50 (1x,2x,4x) architecture compared to the baseline simCLR.\n\n3: Ablation over the different setup like K value, batch size and epoch are properly provided.\n\nPossible weakness:\n1: AdpCLR_pre looks intuitive since it uses a pre-trained self-supervised model (simCLR); therefore, we can get a high-quality similarity measure in the pair of image embedding. While in the AdpCLR_full author mentioned that no pre-trained model is used then only we can ensure that P_same is the correct pair and rest of the top-K pair we can not guarantee anything.  Because the similarity measure on any other embedding vector will not be of high quality and incorrect pair will degrade the result more compared to the correct one. How will you get the correct top-K positive pair in the AdpCLR_full setup? Maybe I am missing something, or the proper explanation is not provided. In the Algorithm, if pretrain=False the encoder F will be random and it will provide poor embedding, hence we expect poor similarity measure.\nPlease explain the process of embedding in the case of AdpCLR_full if no pre-trained is used.\n\n2: I believe the convergence and generalization should be a function of the number of incorrect positive pair. In the generalization error, we can see that it is a function of K, but at the same time, the error will depend on the expected error in the positive pair. It is counter-intuitive AdpCLR_full convergence does not have any dependency on the correct positive pair or the positive pair. If we have few/may incorrect positive pair the learning will be too difficult, and convergence will slow down, or it will oscillate and will not converge at all. Please provide a detail explanation.\n\n3: The experimental settings are not mentioned properly; result reproducibility is critical using the provided information. The author does not provide the code. \n\n\n4: can you provide the result for the AdpCLR_full approach for the ResNet-50 (1x,2x,4x) architecture like the result provided for AdpCLR_pre in the table-1.\n\n5: How the pseudo label is defined?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "1`487 Review",
            "review": "This paper proposes a new contrastive method, which fills the gap between self-supervised contrastive learning and supervised contrastive learning. Pseudo-labeling point view is used to construct positive and negative labels for sample pairs.\n\nStrengths：\n1. This paper learn the self-supervised model from the perspective of positive and negative pair samples, which may be an interesting and useful point. The idea of mining positive pairs is interesting, especially in self-supervised domain.\n2. Existing self-supervised contrastive-based method mainly focus on negative pairs mining. It is interesting to explore hard positive pairs in this domain. The experiment results also demonstrate the power of positives.\n3. This paper provides a theoretical guarantee for the upper bound generalization error and the convergence rate of the proposed model; And the experimental results on ImageNet are consistent with their theoretical analysis.\n\nWeaknesses and suggestions to this paper.\n1. The setting of symbols and the expression of formulas are sometimes not clear and rigorous enough in Sec 3.2. For example, what is the difference between $z_i^1$, $z_i^2$ and $z_i$; the similarity matrix $S$ is also not well defined. And does typos exist in Eq.3? \n2. The x-axis coordinates in Fig.2 looks disproportionate. Is this setting intentional? It's better to explain why for this setting.\n3. While pre-trained AdpCLR can outperform the accuracy of SimCLR 3.0%, I'd still like to see if the fully-trained AdpCLR perform under different backbones (resnet-50(1x, 2x)). It is better to add some results of AdapCLR$^{full}$ in Table 1.\n4. Authors theoretically analyzed the effect of different K and batch size. By set K=1 and K=5, which both outperform the accuracy of SimCLR. But why did only try K=1 and K=5, but not more K values?\n5. Table 3 shown in plot might be better than in table.\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "comments on #1487",
            "review": "This paper proposes a new contrastive method that adaptively mines hard positive pairs during the training process. Two variants of it include pretraining based version (AdpCLR^pre) and fully trained version (AdpCLR^full), which also gives theoretical analysis on convergence rate and generalization and is consistent with experiment results. AdpCLR^pre outperforms state-of-the-art contrastive-based models by 3.0% with extra 100 epochs while AdpCLR^full is over by 2.5% with additional 600 epochs. \n\npros:\n1. The main contribution of this paper is to propose an adaptive way to find out positive pairs sampled from two different categories with data augmentation, which expands the distribution of positive pairs. It can increase the generalization ability of the framework. \n2. The proposed approach AdpCLR is the balance of supervised contrastive method and SimCLR, so it should be slightly more accurate than SimCLR and less accurate than supervised contrastive method. The experiment results demonstrate this.\n3. Since it’s novel to my best knowledge of mining positive pairs. I think it’s interesting to explore these positives and it’s a valuable addition to the field.\n\ncons:\n1.\tExperiment configurations: \nOn Overall comparison with state-of-the-art of Section 4.2, it could be more clear to present the number of training epochs and the choice of K(the number of top-K nearest neighbors for one image) for AdpCLR$^{pre}$. And it's better to point out the best K and batch size pair in the paper.\n2.\tHyper-parameter transferability:\nThis paper shows that the choice of K is closely related with the batch size and has great effect on the final performance. One of my concerns is that for different datasets and backbones, are the optimal K values and batch sizes given in the paper still the best?\n3.\tTheoretical analysis on hard positive pairs: \nAlthough Table 4 presents F1-score with different K and batch size, showing that the error rate of pseudo labels decreases gradually, it remains to see if the dot product of two feature vectors is the best way to measure the similarity of two images. The distribution of feature vectors corresponds to that of dataset. It is interesting to see which way to measure the similarity of two images with which portion of feature vectors could have better performance.\n4.\tSome typos:\n(1)\tOn the title of Table 4, the value of batch size is missing.\n(2)\tOn the third last line of the second last paragraph of page 7, it should be ‘After 1000 epochs of boosting training’.\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}