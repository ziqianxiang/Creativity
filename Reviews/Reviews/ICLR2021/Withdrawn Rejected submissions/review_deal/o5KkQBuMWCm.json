{
    "Decision": "",
    "Reviews": [
        {
            "title": "Clever idea incorporating training dynamics into hyperparameter optimization",
            "review": "I must admit that I'm not an expert in Bayesian optimization, so I'm not keen on the literature, and thus my evaluation of the novelty may be wrong.\n\nSummary\n\nThis paper proposes a novel Bayesian method for hyperparameter optimization. The main idea is to introduce additional states describing the training dynamics represented by the leading eigenvalues and training losses, and augment the kernel with them to incorporate those training dynamics during acquisition. An important advantage of this approach is that since the acquisition procedure takes the nonstationarity of the target function via the additional state, the algorithm need not wait for the completion of the training step, and as a result, the whole optimization procedure is just a one-shot training where the target hyperparameters are optimized on the fly during the one-shot training.\n\nPros\n- I think the idea of incorporating training dynamics is interesting.\n- On the fly hyperparameter optimization is appealing.\n- The experimental results look promising.\n\nConcerns\n- As far as I know, the training dynamics of deep neural nets at the initial phase and after convergence are quite different. It seems like the algorithm builds a kernel computing that similarity of training dynamics on the fly. Is it safe to say that the training dynamics kernel learned at the initial training phase seamlessly generalizes to the later stages of the training?  At least empirically the algorithm seems to work, but I guess it would be good to have some intuitive justification for that.\n- How sensitive the algorithm is to the quality of the eigenvalue approximation? Empirical study w.r.t. varying size of D_e and the iteration number M would be helpful.\n- Are the training losses L crucial for the performance? What if the state theta just be the top eigenvalues? Would be good to have an ablation study.\n- I think the algorithm is not as general as the original BO framework. For instance, can the proposed algorithm be applied for the optimization of the number of hidden units?\n- The paper is not written clearly. Many components of the algorithm is vaguely described. For instance, how the top eigenvalues are actually computed? The paper lists several techniques to approximate the Hessian but it still remains unclear. \n\nMinor points\n- MT and FABOLAS on page 6 are used before being defined.\n- Figure 1 and 2 only display MT and Gsdyn, why no FABOLAS here?\n- Why Gsdyn takes 28.8h compared to MT  taking 3.4h on CIFAR10? Is the additional computation is due to the eigenvalue computation?\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "see review",
            "review": "This paper proposes a Bayesian algorithm for dynamically optimize hyperparameters and train Deep neural networks (DNNs). This is done by using local curvature information within a Bayesian optimization (BO) framework. Based on the empirical insights provided by [1], the paper proposes to model the Stochastic Gradient Descent (SGD) training dynamics between hyperparameters, training loss, dominant eigenvalue and validation accuracy using a non-stationary GP as the surrogate model within a BO framework. The advantage of this, as the paper mentions, is that the underlying DNN is trained only once, that is, the hyperparameters are tuned within the training procedure of the DNN guided by the non-stationary GP. The hyperparameters are sampled using Expectation Improvement (EI) as the acquisition function. The paper validates the proposed algorithm by comparing with vanilla BO, FABOLAS and manual tuning by training a Restnet50 on the datasets CIFAR-10 and CIFAR-100.\n\nThe paper is well written and easy to follow. While the purpose of the paper is not to propose a practical algorithm, the experiments show promising results. Thus, the significance of the paper lies on the practicality of computing the top eigenvalue at each iteration. Nevertheless, I think it opens the door for further research on Bayesian algorithms for dynamical hyperparameter tuning.\n\nQuestions: \n - Does the separable non-stationary kernel captures the insights provided by [1]?\n - Can the batch-size be included as a hyperparameter to tune?\n\n[1] Stanislaw Jastrzebski, Zachary Kenton, Nicolas Ballas, Asja Fischer, Yoshua Bengio, and Amos\nStorkey. On the relation between the sharpest directions of dnn loss and the sgd step length. In\nICLR 2019 : 7th International Conference on Learning Representations, 2019.\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The idea of incorporating the training dynamics to the Bayesian optimization tuning process is novel, however, I have several concerns on the proposed method and the experiments.",
            "review": "This paper proposes a novel online Bayesian optimization algorithm (GSdyn), that is, optimizing hyperparameters dynamically under the Bayesian framework over the training process. The main idea is to introduce to additional inputs (training loss and the dominant eigenvalue of the Hessian matrix of the neural network training process) into the BO process in order to improve the hyperparameter tuning process. The paper argues that by incorporating the training dynamics into the BO process, the optimal hyperparameter set found can lead to better generalization.\n\nStrengths:\n+ Overall, the paper is well-written, although some technical details are not too clear (see the Weaknesses)\n+ The idea of incorporating the training dynamics to the Bayesian optimization tuning process to construct online BO is novel.\n+ The experiments are conducted on two complex datasets CIFAR-10, CIFAR-100.\n\nWeaknesses:\n- No deep analysis is conducted to understand why the proposed method can lead to better generalization. \n- I feel unclear with several technical details: \n      1) What is the x-axis in Figures 1 & 2? Is it the number of epochs?\n      2) How many experiments are repeated in Figures 1&2 and Table 1?\n      3) How to set the search space S for GSdyn? In your experiments in Section 5, how do the authors set the search space S?\n      4) What is the objective function for GSdyn and FABOLAS? In Section 5.1, it is mentioned that the DNN’s accuracy is the objective function, but which accuracy? The accuracy on the validation dataset or on the test dataset?\n      5) To evaluate BO, the standard practice is to find the hyperparameter set with the best accuracy on the validation dataset. Why in this work, the accuracy on the test dataset (but not validation dataset) is compared between baseline methods (Figures 1 &2)? And which accuracies are there in Table 1? I understand that GSdyn leads to good generalization but the accuracy on the validation dataset is also needed to be shown as it is the objective of the vanilla BO?\n       6) The experiments might include different hyper-parameters, and more hyper-parameters. \n\nMinor comments:\n- In the figures, the labels of each axis need to be added.\n- Third bullet in the summarized contributions in Section 1: Beyes --> Bayes\n- Line 5 of Algorithm 1: Should be either \\sigma_0 or \\sigma, not a mix of them?\n- Line 5 of Algorithm 2: What is Sample function? I understand it is the acquisition function but a rigorous formula of the acquisition function needs to be provided.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Contribution is unclear despite ideas worth trying",
            "review": "This paper proposes an online Bayesian optimization algorithm GSdyn to optimize learning rate and weight decay at each epoch. The main idea is that instead of proposing different hyperparameter values and using each of them to train from scratch, continue training the current neural network for one epoch using proposed values. For the next epoch, use Bayesian optimization to propose a different learning rate and weight decay. Therefore, the total number of training epochs is equal to the number of BO proposals. The second idea is to add two state variables into the Gaussian processes surrogate model, i.e., the training loss and the dominant eigenvalue of the Hessian matrix. That enables the GP model to account for the current training state after each epoch. With these two ideas, the paper conducts experiments with a modified Resnet50 on CIFAR-10 and CIFAR-100 and compares with a multi-task hyperparameter optimization method FABOLAS as well as manual tuning. GSdyn reaches better accuracy than FABOLAS in 28h and 36h on CIFAR-10 and CIFAR-100 respectively.\n\nPros: \n\n1. The online optimization idea fits with the specific tuning task well, as DNN training is expensive but iterative. Using Bayesian optimization for this specific online optimization is a reasonable idea to try, because even a suboptimal learning rate and weight decay is used for one epoch, there is chance to make corrections in later epochs. So it is possible that certain degree of exploration is affordable and training from scratch with different hyperparameter values is not necessary. \n\n2. Adding the state variables into the BO surrogate model makes sense in the online optimization scenario, as the model needs that information to propose values according the current training phase. \n\n3. Some justifications about using the dominant eigenvalue as the state is given, mainly from the observations in the literature that the top eigenvalues have an empirical correlation with the behavior of SGD. \n\nCons: \n\n1. The overall position of this paper is not clear. There are several claims of the contributions but each of them has some flaw. First contribution includes \"To our best knowledge, our algorithm is one of the first works that can effectively optimize\nhyperparameters on the fly, in contrast to existing works that have to wait the completion\nof the overall evaluation in each step. Thus it significantly saves the time required for\nrepeated and complete evaluations.\" This work is not the first to optimize hyperparameters on the fly and save time. A well known and often-cited method in that category is population-based training: \nMax Jaderberg et al., Population Based Training of Neural Networks, arXiv:1711.09846, 2017.\nThe second contribution is \"We solve the unfitting problem through the non-stationary training process by tracking\nmodel states. It accelerates convergence and surpasses the performance under manual tuning\non multiple public benchmark and empirically shows better generalization.\" There are other methods changing learning rates adaptively. For example, see\nZhenxun Zhuang et al., Surrogate Losses for Online Learning of Stepsizes in Stochastic Non-Convex Optimization, ICML 2019.\nfor a method with theoretical guarantee and its references for earlier heuristic methods. \nThe third contribution is \"Our work can also provide a new viewpoint for the Hessian spectrum, loss surface, etc, as\nBeyes is an excellent tool to construct a black-box function between variables. As shown\nin 5, GSdyn gains a good generalization while behaving to utilize the local information of\nthe top dominant eigenvalues and control the learning rates away from too small.\"\nThe experiments do not prove that the dominant eigenvalues are critical in controlling the learning rates. More will be discussed in the next point.\nOverall, to establish the contribution of this work as a good online tuning method, some other online tuning methods should be included as baselines. To establish the importance of using top eigenvalue from Hessian, more solid experiments are needed.\n\n2. The experiments have several flaws. First, as mentioned above, the compared method FABOLAS is not an online optimization method. There are stronger baselines if the online optimization scenario is the target scenario. Second, it is not clear how long is FABOLAS set to run, and Table 1 only presents a single data point of FABOLAS at one time point instead of a learning curve for each dataset. That does not convincingly prove FABOLAS is worse as the evaluation goal is not clearly specified. Third, to prove that top eigenvalue is necessary to model the dynamics, we need to see an experiment of removing it or replacing with an easier-to-compute state variable, such as the gap between training and validation loss.\n\n3. Clarity in writing. End of sec 3.3, \"Our goal here is not to build a practical algorithm,\nbut to explore online Bayesian optimization, which saves large evaluation overheads and\ntakes advantage of local information through training dynamics.\" It is somewhat contradictory with the motivation of saving time consumption which is a practical concern. Sec 4.2, \"However, once the incumbent $x \\in S$ from random search only\nperforms well in the beginning, it will take a long time to get rid of the greedy trap, especially using\na small SGD step.\" I don't get the meaning of it. Sec 5.1, \"we train the neural network only on the trainset and validate its\naccuracy on valset, while the baseline trains with all training data.\" what is the baseline referring to? Section 5.2, \"Without accounting for all other overheads and focusing on the training process\nitself, we find it’s novel that GSdyn accelerate the convergence almost 2x, while the only effect\nfrom GSdyn to DNN is adjusting hyperparameters.\" I don't understand what is novel and why it makes sense not to account for the overheads.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}