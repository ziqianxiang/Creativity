{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper studies the decision boundaries of shallow ReLU network using the formalism of tropical geometry. Its main takeaway is to provide a new interpretation of the lottery ticket hypothesis in terms of network pruning strategies that preserve certain geometric structure. \n\nReviewers were appreciative of the clarity of the exposition, and the novel perspective on interesting and elusive phenomena such as the lottery ticket hypothesis. On the other hand, they also expressed some doubts about the significance of some aspects of the theory (such as proposition 1 and corollary 1), as well as the computational considerations required to elevate the analysis to large-scale architectures from applications. \n\nUltimately, and after taking into consideration all the reviewing discussions, the AC believes that this submission is not yet ready for publications, but it is in a trajectory to become an important piece of work. In particular, the AC encourages delving deeper into the tropical network pruning. Additionally, the authors might want to discuss [Breaking the Curse of Dimensionality with Convex Neural Networks, Bach'17] in the related work, since this is the first instance the AC is aware of where the connection between zonotopes and shallow ReLU networks is established. "
    },
    "Reviews": [
        {
            "title": "Review of \"On the Decision Boundaries of Neural Networks. A Tropical Geometry Perspective\"",
            "review": "Summary:  This work studies the decision boundaries of neural networks (NN) with piecewise linear (ReLU) activation functions from a tropical geometry perspective. Leveraging the work of [1], the authors show that NN decision boundaries form subsets of tropical hypersurfaces. This geometric characterization of NN decision boundaries is then leveraged to better understand the lottery ticket hypothesis, and prune deep NNs. The authors also allude to the use of tropical geometric perspectives on NN decision boundaries for the generation of adversarial samples, but do not explicitly discuss it in any detail within the main text of the paper.\n\nStrengths: \n+ The paper is insightful and novel. \n+ Tropical geometry (TG) promises to be a particularly convenient language to study (ReLU) DNNs, and this work does a good job of showcasing the versatility afforded by a principled, geometric approach in improving our understanding of DNNs. \n+ The efforts put into making this paper accessible to readers unfamiliar with TG are also worth appreciating.\n\nWeaknesses: \n- The paper perhaps bites off a little more than it can chew. It might be best if the authors focused on their theoretical contributions in this paper, added more text and intuition about the extensions of their current bias-free NNs, fleshed out their analyses of the lottery ticket hypothesis and stopped at that.\n\n- The exposition and experiments done with tropical pruning need more work. Its extension to convolutional layers is a non-trivial but important aspect that the authors are strongly encouraged to address. This work could possibly be written up into another paper. Similarly, the work done towards generating adversarial samples could definitely do with more detailed explanations and experiments. Probably best left to another paper. \n\nContributions:  The theoretical contributions of the work are significant and interesting. The fact that the authors have been able to take their framework and apply it to multiple interesting problems in the ML landscape speaks to the promise of their theory and its resultant perspectives. The manner in which the tropical geometric framework is applied to empirical problems however, requires more work.\n\nReadability: The general organization and technical writing of the paper are quite strong, in that concepts are laid out in a manner that make the paper approachable despite the unfamiliarity of the topic for the general ML researcher. The language of the paper however, could do with some improvement; Certain statements are written such that they are not the easiest to follow, and could therefore be misinterpreted.\n\nDetailed comments: \n- While there are relatively few works that have explicitly used tropical geometry to study NN decision boundaries, there are others such as [2] which are similar in spirit, and it would be interesting to see exactly how they relate to each other.\n\n- Abstract: It gets a little hard to follow what the authors are trying to say when they talk about how they use the new perspectives provided by the geometric characterizations of the NN decision boundaries. It would be helpful if the tasks were clearly enumerated.\n\n- Introduction: “For instance, and in an attempt to…” Typo – delete “and”. Similar typos found in the rest of the section too, addressing which would improve the readability of the paper a fair bit.\n\n- Preliminaries to tropical geometry: The preliminaries provided by the authors are much appreciated, and it would be incredibly helpful to have a slightly more detailed discussion of the same with some examples in the appendix. To that end, it would be a lot more insightful to discuss ex. 2 in Fig. 1, in addition to ex. 1. What exactly do the authors mean by the “upper faces” of the convex hull? The dual subdivision and projection $\\pi$ need to be explained better.\n\n- Decision boundaries of neural networks: The variable ‘p’ is not explicitly defined. This is rather problematic since it has been used extensively throughout the rest of the paper. It would make sense to move def. 6 to the section discussing preliminaries.\n\n- Digesting Thm. 2: This section is much appreciated and greatly improves the accessibility of the paper. It would however be important, to provide some intuition about how one would study decision boundaries when the network is not bias-free, in the main text. In particular, how would the geometry of the dual subdivision $\\delta(R({\\bf x}))$ change? On a similar note, how do things change in practice when studying deep networks that are not bias free, given that, “Although the number of vertices of a zonotope is polynomial in the number of its generating line segments, fast algorithms for enumerating these vertices are still restricted to zonotopes with line segments starting at the origin”? Can Prop. 1 and Cor. 1 be extended to this case trivially?\n\n- Tropical perspective to the lottery ticket hypothesis: It would be nice to quantify the (dis)similarity in the shape of the decision boundaries polytopes across initializations and pruning using something like the Wasserstein metric.\n\n- Tropical network pruning: How are $\\lambda_1, \\lambda_2$ chosen? Any experiments conducted to decide on the values of the hyper-parameters should be mentioned in the main text and included in the appendix. To that end, is there an intuitive way to weight the two hyper-parameters relative to each other?\n\n- Extension to deeper networks: Does the order in which the pruning is applied to different layers really make a difference? It would also be interesting to see whether this pruning can be parallelized in some way. A little more discussion and intuition regarding this extension would be much appreciated.  \n\n- Experiments: \n- The descriptions of the methods used as comparisons are a little confusing – in particular, what do the authors mean when they say “pruning for all parameters for each node in a layer” Wouldn’t these just be the weights in the layer?\n- “…we demonstrate experimentally that our approach can outperform all other methods even when all parameters or when only the biases are fine-tuned after pruning” – it is not immediately obvious why one would only want to fine-tune the biases of the network post pruning and a little more intuition on this front might help the reader better appreciate the proposed work and its contributions. \n- Additionally, it might be an unfair comparison to make with other methods, since the objective of the tropical geometry-based pruning is preservation of decision boundaries while that of most other methods is agnostic of any other properties of the NN’s representational space.\n- Going by the results shown in Fig. 5, it would perhaps be better to say that the tropical pruning method is competitive with other pruning methods, rather than outperforming them (e.g., other methods seem to do better with the VGG16 on SVHN and CIFAR100)\n- “Since fully connected layers in DNNs tend to have much higher memory complexity than convolutional layers, we restrict our focus to pruning fully connected layers.” While it is true that fully connected layers tend to have higher memory requirements than convolutional ones, the bulk of the parameters in modern CNNs still belong to convolutional layers. Moreover, the most popular CNNs are now fully convolutional (e.g., ResNet, UNet) which would mean that the proposed methods in their current form would simply not apply to them.\n- Comparison against tropical geometry approaches for network pruning – why are the accuracies for the two methods different when 100% of the neurons are kept and the base architecture used is the same? The numbers reported are à (100, 98.6, 98.84)\nTropical adversarial attacks: Given that this topic is not at all elaborated upon in the main text (and none of the figures showcase any relevant results either), it is strongly recommended that the authors either figure out a way to allocate significantly more space to this section, or not include it in this paper. (The idea itself though seems interesting and could perhaps make for another paper in its own right.)\n\n- References:  He et al. 2018a and 2018b seem to be the same.\n\n[1] Zhang L. et al., “Tropical Geometry of Deep Neural Networks”, ICML 2018.\n[2] Balestriero R. and Baraniuk R., “A Spline Theory of Deep Networks”, ICML 2018.\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting problem and solution, more experiments are desired",
            "review": "This submission proposes the use of tropical geometry to understand the decision boundaries of neural networks. The targeted problem is quite interesting and the proposed method looks to be solid; however, I didn't thoroughly check the correctness of the proposed theorems. \n\nIn the experiments on tropical pruning, since for VGG16, the proposed method only shows better performance on the CIFAR10 dataset, more experiments are desired to make a strong conclusion. For instance, performing experiments on ResNet. \nWhy changing to use LeNet when comparing to Tropical geometry approaches?\n\nHow about the efficiency of the proposed approach? Is it practical to use the proposed method in a deep neural network?\n\nA minor issue: In the results section, \"Figure 4\" should be \"Figure 5\". ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "Interesting but incomplete development of applications of tropical geometry to pruning",
            "review": "Building upon the observation of Zhang (2018) that a class of deep neural networks have decision boundaries that correspond to tropical rational maps, the paper proposes new methods for pruning networks and constructing adversarial attacks that are based on the idea of minimizing or maximizing the changes to the decision boundary.  The methods focus on optimizing objectives related to the dual polytopes for the networks.\n\nThe strength of this paper is in its ambitious agenda: it is difficult to reason about the nonlinear functions learned by neural networks, so the paper’s proposal to use tropical algebra to try to provide new insights is a worthy goal.  Extending beyond Zhang 2018, the paper works out an explicit characterization of the two-layer two-dimensional dual polytopes which is good to see.  The experimental results on pruning of small networks (e.g., Figure 3,Appendix Figure 7) are suggestive that geometric issues may be important for understanding the success of lottery ticket pruning.  The simple observation (beginning with Appendix Eq 9) that adversarial attacks can also be analyzed as attacks on the first layer weights is interesting, although seems like a second separate topic.\n\nWhile the tropical geometry perspective is welcome, this reviewer found several lines of reasoning insufficiently convincing or unclear in the submitted paper.  The central assertion is that tropical geometry can lead to promising new pruning methods (or at least promising new insights about pruning methods).  However, why the proposed tropical pruning (Section 5) should be expected to work (or why it should be expected to provide insights on the pruning problem) is unclear for several reasons.\n\n1. The tropical pruning method is inspired by the explicit analysis of small networks in the paper, but the method is tested only on deep networks that are beyond the reach of this explicit analysis. This skips an important step in the analysis: is tropical pruning effective on small toy problems?  For example, in the small cases illustrated in Figure 3, tropical pruning is not one of the methods compared.  The paper would be strengthened if the new pruning method could be developed and either explicitly proved or experimentally verified on the small cases which are closer to the settings where the geometry has been explicitly characterized, before exploring claims and experiments in large networks.\n\n2. Why would insights about the geometry of the boundaries be preserved after retraining?  The method reasons about the geometry of the network after it is initially trained but then the paper measures the effect on the network after it is retrained.  The paper would be strengthened if it explained or argued why the lengthy retraining process would be expected to preserve rather than obliterate any geometric properties of the function.\n\n3. The paper does not provide enough intuition and explanation behind the unproved leap from Theorem 2 to Eq 1, and then from Eq 1 to Eq 2.  The text refers to subfigures of Figure 3 (e.g., a first subfigure showing explicit decision boundaries) that seem to be missing.  Figure 4 is a good illustration of the idea, but how the selection of the best change in geometry is related to the proposed objective in Eq 2 is not explained beyond the assertion that “decision boundaries tend to be preserved.”  This assertion should be backed up by more explicit reasoning, more explicit examples or some statistical data.\n\nThe work in the appendix bringing in analysis of adversarial examples is interesting but seems to be a second major topic that is not fully developed in the main paper and could be the subject of a different paper.\n\n**edit, based on revision and after discussion**.  Thanks to the authors for answering questions 2 and 3 in discussion and adding an experiment to the paper validating the tropical pruning method in a small setting.  The additional experiment provides some evidence that the tropical pruning method is working as argued, and I change my rating of the paper to 6.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Outer approximates decision boundary of shallow ReLU network with tropical hypersurface dual to convex hull of two zonotopes.  Applies to various tasks and real data sets, notably network pruning using interesting optimization to preserve the tropical hypersurface.  Tropical geometry content seems more about language.",
            "review": "This paper shows the decision boundary of a shallow ReLU network is a subset of a tropical hypersurface, and this tropical hypersurface is dual to a convex hull of two zonotopes given by the weights of the network.  The paper then considers various learning tasks and real data sets, most notably neural network pruning by using an interesting optimization to preserve the tropical hypersurface.  The tropical geometry content seems mostly about language to me.  In particular, the containment of the decision boundary in the tropical hypersurface (first part of Theorem 2) is quite evident, once notation is unpacked.  Also Proposition 1 and Corollary 1 in my opinion can be removed from the document.  On the other hand, the network pruning application that seeks to preserve the convex hull of the zonotopes seems rather substantial to me, with a nice derivation in the appendix.  I would put more emphasis on this myself.\n\nItemized comments follow.\n\n\nPage 3: Please be more clear about what type of objects $UF(\\mathcal{P}(f))$ and $\\delta(f)$ are.  Polyhedral complexes?\n\nPage 3: “For ease, we use ReLUs as the non-linear activation, but any other piecewise linear function can also be used.”  Is it not required for the tropical viewpoint that the slopes of the piecewise linear function be integers?  “Without loss of generality, as one can very well approximate real weights as fractions and multiply by the least common multiple of the denominators as discussed in Zhang et al. (2018).”  Can you remark whether the decision boundaries are stable to such approximations?  A brief discussion on how tropical is using the integral weights assumption may help the reader.\n\nPage 4: typo, “each output can be expressed as a tropical rational as per Theorem 1.”  Tropical rational function\n\nPage 4, Theorem 2: $\\delta(R(x)) = ConvHull(\\mathcal{Z}_{G_1}, \\mathcal{Z}_{G_2})$.  The LHS is a polyhedral complex or subdivision, the RHS looks like just a polytope?  Confusing, until some bit below where it is stated $\\delta(R(x))$ actually is not subdivided because there is no bias (so it is just a polytope).\n \nI worry there is only a fine line between “decision boundary” (this paper) and the boundary between the linearity regions of a single output ReLU network (I think early works).  In particular, is $T(R(x))$ also a superset for the boundary between the linearity regions of $(f_1 + f_2)(x)$?\n\nPage 5: “fast algorithms for enumerating these vertices are still restricted to zonotopes with line segments starting at the origin Stinson et al. (2016).”  I find it disingenuous to describe this as a restriction and then to present Proposition 1 as a fix.  This issue is very minor, and I think polytopes people would just say “without loss of generality…”\n\nPages 7-8: Tropical pruning sounds significantly more computationally intensive than the other simple pruning methods it is being compared to, even when the separability in rows is used.  There also seems to be some awkwardness with the biases since the tropical approach assumes no biases.  While not knowing about pruning of NNs, I still actually found this to be the most substantial and interesting part of the paper and appendix.  It uses the zonotope description of the tropical superset, and involves interesting optimization.  I would suggest the authors emphasize this subsection more. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}