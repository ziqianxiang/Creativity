{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper performs visual odometry using variational information bottleneck. It assumes video and pose observations and aims to find a latent state that is maximally predictive of the pose observations, while minimizing the mutual information between the image observations and the latent state. It approximates this cost using variational inference. The paper also makes use of deterministic+stochastic latent transition models, as in Hafner et al 2019, 2020. The paper contributes generalization bounds that are based on recent work by Xu and Raginsky 2017 and Zhang et al 2018. This is useful to include, but this contribution is not the main focus of the work in my opinion, and it is not clear how tight the bounds are, especially considering that the original cost function is approximated. \n\n\nPros:\n\nThe idea of using the deterministic+stochastic transition models of Hafner et al and related works for visual odometry is very interesting and promising avenue for research. \n\nThe fact that the experiments are done on some of the major camera and IMU datasets is great.\n\n\n\nNeeds fixing:\n\nMajor: The paper mentions \"Extensive ablation studies were conducted to examine the effects of (1) the deterministic component, (2) sample size and (3) extra sensors.\". These are great, but I would also have expected to see a range of variations in terms of the weight gamma, including a value of zero. The appendix is vague in this regard and says \" and\nperform a non-intensive and small-range grid searching.\" The utility of the information bottleneck idea depends heavily on the weight gamma, and I would have liked more results confirming that the method does well under a range of choices for gamma.\n\nMajor: The rotation results produced by this method on EuroC should be improved to be more competitive with okvis. As it stands, it is unclear why the method does not perform as well and the explanations offered in the paper are speculative.  \n \nMedium: The paper also mentions in the appendix: \"Though 3D von Mises-Fisher distribution and 4D-Bingham distribution can be\narguably more appropriate to model Euler angles and quaternions respectively, it is non-trivial to evaluate and use them for training in practice.\" So, the paper represents rotations using Euler angles. The authors are encouraged to look at https://www.gilitschenski.org/igor/publication/202004-iclr-deep_orientation_uncertainty_learning/\n\nMinor: MSCKF was originally coined by Mourikis and Roumeliotis https://ieeexplore.ieee.org/document/4209642 and even though the term is used by follow-up works,  it is worth adding the reference.\n\nFinally, I would disagree with one of the reviewers that this paper needs to compare with ORBSLAM2. I think comparing with OKVIS and an MSCKF variant is sufficient for \"classic\" SLAM and odometry methods.  \n\nI think the paper needs one more iteration to fix these issues, even though it is very promising work.\n\n    "
    },
    "Reviews": [
        {
            "title": "Odometry, tracking or localization?",
            "review": "The authors seem to have great knowledge of interesting information-theoretical tools that can be used to analyze the performance of pattern-recognition methods, and guide the design of model fitting procedures. There are however very important details regarding the application being studied that are not well-discussed which are fundamental to establish the relevance of the paper. The main contributions of the paper are also not well defined or demonstrated experimentally, making it mostly a paper with apparently interesting theoretical foundation that lacks clear and compelling experimental evidence or application appeal. The recommendation is unfortunately not to publish.\n\nThe first issue that can be pointed out regards what is even the problem being attacked. From the start the authors present the problem as one of odometry, what means fusing and integrating the readings from sensors such as IMU, wheel counters or images and provide relative pose measurements that can be accumulated over time. Odometry has no motion model or global localization sensors. A motion model would imply tracking or localization, and the ability to make pose predictions instead of strictly relative pose predictions implies (global) localization.\n\nNaturally these different tasks and available information all relate to each other in different ways, and it gets more fuzzy when we get closer to practical application. Being able to perform tracking and obtain better pose estimates may be a good thing in an application, and why would any engineer stick to pure odometry if it were possible to employ a better solution?\n\nA scientific paper must make great efforts to elucidate these differences, though, and it would appear the authors have not been careful enough here. The confusion might be shared with other recent authors bringing deep-learning into geometric vision and mobile robotics. All these authors must be urged to more carefully look at what is being claimed, and at what exactly different models can do, and what exactly are the benefits and costs of the proposed methods to potential applications.\n\nThe following two sentences from the start of the paper may be a good illustration of the issues being raised here:\n 1. \"Odometry is challenging due to the difficulties to model the complexity and diversity of real-world scenarios from a limited number of on-board sensors.\"\n\nWhat exactly does that mean? For example, is it that most sensors have peculiar noise distributions now well-modeled by Gaussians, and yet oversimple models are often used?\n\nRegarding 6DOF odometry, this is from the start a pattern recognition problem with complex geometry. From its very nature the problem involves challenges such as how to even represent poses and deal with the non-euclidean spaces involved, and then how to deal with the ill-posedness of unavailable information, the integration of measurements, scale invariance of monocular vision, etc.\n\nAre the authors referring to these classing great challenges of the problem, or are they focusing on the even greater challenge of taking into account time-variant systems and dynamical environments? If the former is the case, these greater challenges might better go unspoken of. Just focus on the more fundamental issues first. It's understandable that the proposal might eventually contribute to the greater challenges. It's important to convey the message of where the current contribution lies first, though.\n\n\n 2. \"Furthermore, since odometry is essentially a time-series prediction problem, how to properly handle time dependency and environment dynamics presents further challenges.\"\n\nApart from the previous note regarding the focus of the proposal and dynamic environments, etc, this sentence demonstrates some confusion regarding the understanding of the nature of the odometry problem. Can odometry be accurately described as a \"time prediction\" problem? Would it not be better understood as interpolation, or maybe reconstruction / regularization / smoothing?\n\nAnother important detail not mentioned in the paper is how the proposal follows a strict filter-based approach, while in general odometry might be performed with regression applied to a longer sequence of observation, as done in OKVIS. Would it be fair to say that\nthe latent state learned by the proposed technique can somehow encode some of the information that is retained in the alternative method by not following a strict filtering scheme. This is the kind of question that would be interesting to see investigated here, and the authors do not seem very aware of that.\n\nEven more relevant is the issue that odometry in principle merely integrates physical measurements, without a motion model. In practice one might argue that there's some modeling regarding the connection between inertia and accelerations. There should be no exploitation of biases such as a mean height, for instance, or upright constraint, or the fact that a car moves mostly straight-ahead and following the dynamics of Ackermann steering, or whatever. These are all constraints that can be taken into account in a tracking system, and they might greatly benefit the tracker's performance in an application. It's very interesting research. Such a tracking system should not be directly compared to a stricter odometry technique, though, since there are fundamental differences in what kind of data can be taken into account, and what is being modelled --- sensor noise, not motion.\n\nBy approaching the problem as one of pose prediction in general, it might be possible to go even further. The PoseNet paper cited performs precisely what we might perhaps understand as a complementary problem to odometry. Given a sensor reading, come up with a global pose estimate. This is excellent, and certainly relevant to many applications. It is concerning, though, that anyone may be using techniques capable of that, and then compare it to odometry systems. In especial because odometry is more or less fated to contain drift error that will accumulate in time, and a global localization technique will therefore eventually seem infinitely superior.\n\nAny occasion where learning techniques are employed for strict odometry, or even tracking, it is paramount to verify that there is no way the model is picking up on clues in the environment to improve on its pose predictions be performing global localization, and not relative pose estimations. And this may be very challenging. Take the Euroc challenge for instance. The occurrence of high z-axis acceleration may serve as a clue for especially high height values to be predicted. It's just bias that is naturally in the data. This sort of bias must be guaranteed to be removed, either through constraints in the model itself, of for instance through data augmentation (much less desirable). The author cite PoseNet as an inspiration, and do not seem to worry that there may be characteristics in their system that fundamentally go against this being a research on odometry, a term utilized all the way from the title of the paper.\n\n\nApart from these issues regarding the nature of the research, and its motivation, there is another related concern with what was achieved. Taking again another paper sentence to motivate the discussion:\n\n\"Their hard-coded systems require extensive parameter tuning under different environments\"\n\nAnd deep learning requires no extensive parameter tuning?\n\nOne great thing about learning methods is precisely that they can be tuned to specific applications to improve their performance. The authors seem to be proposing something different than that, though, that a model would be trained that will exhibit great performance with no tuning. This would maybe replace the geometry processing core from alternative methods, with rotation encoded somehow in the latent state, and then different sensors would require just training part of the complete model. Is this really what is being sought? Is it interesting? And how do we test that this precise goal has been reached, opposite to a system that requires extensive parameter tuning under different environments?\n\nMethods such as OKVIS require things like camera calibration and inertia measurements. How does the proposed method differ from that? Is the research somehow related to the possibility of a self-calibrating system?\n\nThese are all important questions that should be discussed in the experiments, although in the end the authors seem only to care more about how they compare to other learning based methods in different benchmarks, and then with the issue of detecting failures. This is indeed a very interesting thing, even with practical appeal. If this is the main point of the research, though, it should be given much more attention, from the start, and then more comparisons with alternative methods should be made with attention given to that specific issue, etc.\n\nAnd is this what the authors mean by dealing with time variance? Fault detection? It certainly makes sense, and it's interesting. It would be nice to make it clear this is what is being considered, from the beginning of the paper.\n\nThe authors should be advised to try to make a more clear case regarding what is the application they have in mind, and how their method compares to others, and prepare a paper that attacks a more specific problem, concisely. Good papers have specific issues that are addressed, discussed from start to finish, preferably on top of solid theory. The authors seem perfectly capable of producing this with some more discussion and work put in the research.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This paper proposes a novel solution for learning odometry by using an information bottleneck constraint with GRU. The information bottleneck constraint aims to eliminate the pose-irrelevant information from the latent representation so as to enhance the generalization ability of unseen test data. ",
            "review": "Pros:\n+ This paper proposes a novel solution for learning odometry by using an information bottleneck constraint \n+ This paper is well-written with clear derivation.\n\nConcerns: \nThe main issue of this paper is the insufficient experiment to validate the advantages of the method.\n- The main weakness is the lack of the comparison with the state-of-the-art methods. The comparing methods, especially visual odometry methods are few. The experiment of visual odometry only compares with DeepVO [1]. However, to  the best of my knowledge, the visual odometry methods including non-learning methods (e.g. ORB-SLAM2 [2]), unsupervised methods (e.g. Bian et al. [3], Li et al. [4]), and the more recent supervised methods (e.g. Xue et al. [5], Xue et al. [6]) are not compared with the proposed method. Besides, the plots of odometry trajectory are preferred to present in the paper for demonstrating the qualitative comparison. One of the reasons is to visualize the drift of the odometry. The ground-truth pose \\xi_t serves as the input of the deterministic function f^p in the training phase. But the estimated pose is used in the test phase instead. This would somehow cause the drift due to the biased estimation of the previous pose. However, the RMSE of the entire trajectory is insufficient to examine the drift.\n- The comparing state-of-the-art methods are re-implemented and share the same network architecture. I am curious about the difference between the original results and the results of re-implementation. Thus, the trajectory plots would be a kind of evidence for demonstrating the re-implementation. Besides, I would like to see the quantitative results of both RMSE and absolute error, which is provided by Chen et al. [7]. The absolute error could be a reference to the original results of Chen et al. [7].\n\nMinor: typos:\n- \\xi = g(X, \\Theta) is \"an\" one-to-one function instead of \"a\" on page 5.\n- The formulation of information bottleneck implies that \"o \\to s \\to \\xi\" forms a Markov chain, instead of \"\\xi \\to o \\to s\" on page 12 (Appendix).\n\nReference: \n[1] Wang, Sen, et al. \"Deepvo: Towards end-to-end visual odometry with deep recurrent convolutional neural networks.\" 2017 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2017.\n[2] Mur-Artal, Raul, and Juan D. Tardós. \"Orb-slam2: An open-source slam system for monocular, stereo, and rgb-d cameras.\" IEEE Transactions on Robotics 33.5 (2017): 1255-1262.\n[3] Bian, Jiawang, et al. \"Unsupervised scale-consistent depth and ego-motion learning from monocular video.\" Advances in neural information processing systems. 2019.\n[4] Li, Shunkai, et al. \"Sequential adversarial learning for self-supervised deep visual odometry.\" Proceedings of the IEEE International Conference on Computer Vision. 2019.\n[5] Xue, Fei, et al. \"Local supports global: Deep camera relocalization with sequence enhancement.\" Proceedings of the IEEE International Conference on Computer Vision. 2019.\n[6] Xue, Fei, et al. \"Beyond tracking: Selecting memory and refining poses for deep visual odometry.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.\n[7] Chen, Changhao, et al. \"Selective sensor fusion for neural visual-inertial odometry.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Good contribution using an information bottleneck constraint to improve genealization in learning-based VO, but the exposition is a bit difficult to follow at times.",
            "review": "Summary\n\nThe paper addresses the odometry problem i.e. estimating the relative pose of a camera or device as it moves through the environment. The authors propose an information-theoretic model for visual and visual inertial odometry. The method is based on the hypothesis that features contain pose-irrelevant information that leads to overfitting which is alleviated through the using of an information-bottleneck (IB) objective. The information-theoretic formulation allows them to use existing results to provide guarantees related to generalization. The experiments on KITTI and EuRoC indicate that the IB objective does help to improve performance\n\nStrengths\n- The paper provides a principled information-theoretic formulation for learning-based VO. The observation that the features learned by a typical VO model might contain pose-irrelevant information that hurts generalization is sensible and does happen in practice and thus the proposed approach is very well motivated.\n\n\n- The generalization bounds for the problem are theoretically interesting as overfitting is quite a significant issue with learning-based VO models. \n\n\n- The empirical results in terms of effectiveness of the IB objective are strong. Specifically, the results support the effectiveness of the proposed IB-based loss with respect to the generalization ability of the trained model and the proposed method outperforms all the existing methods in terms of accuracy.\n\n\n- The intrinsic uncertainty obtained from the model seems to be well calibrated and can be used to infer anomalies such as missing or noisy data and are roughly predictive of the translation and rotation error.\n\nConcerns:\n- The derivations are not that clear and seem to skip steps making them a bit difficult to follow. As an example, how is Equation 13 obtained? According to my derivation the bound for $I(o_{1:T} || s_{1:T}|\\xi_{1:T})$ should be $E_{o^m_{1:T},\\xi_{1:T}} \\left[D_{KL}\\left[p(s_{1:t} | o^m_{1:T}, \\xi) || q(s_{1:t} | o^m_{1:T}, \\xi_{1:T}) \\right]\\right]$. Also, how does Corollary 1 follow from Theorem 3? It would be good if the authors could put all steps in the derivations. \n\n\n- A lot of emphasis is put on the theoretical guarantee of the generalization ability, however, it is not mentioned how tight this bound is or what practical implications it has. It would be good if the authors could demonstrate how this bound can be used to in practice.\n\n\n- A lot of the contributions in the paper seem to be based on (Zhang, 2018) and (Xu & Raginsky, 2017). Although I recognize that applying these to the VO domain is not trivial, it would be good if the authors could better highlight what their contributions are. \n\n\n- Overall, the structure of the paper is a bit difficult to follow. It would be better if the key results relating to the odometry problem being addressed are presented in the paper with a description of how these apply to the problem. The existing results can be put in the appendix. \n\nMinor points\n\nIn Section 4.3 the authors introduce Theorem 2 but then only refer to Theorem 4. Is this a duplicate?\n\nThere are some grammar errors that need ot be fixed throughout the paper. For example, “Besides,” is used incorrectly in a number of places where the authors probably mean “In addition,” e.g. section 4.4\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}