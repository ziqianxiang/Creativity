{
    "Decision": "",
    "Reviews": [
        {
            "title": "Interesting paper but some of the designs are not super intuitive",
            "review": "This paper aims to improve adversarial training for semantic segmentation. Based on the intuition that different pixels may have different properties with adversaries, authors propose to divide them into two groups to make the training for main branch $f_n$ easier. Experiments on VOC and Cityscapes show the effectiveness of the proposed method against regular adversarial training.\n\n\\+ The topic is interesting and important, and it is less studied before\n\n\\+ The proposed method does not involve any computation overhead at the inference time.\n\n\n\\- Although authors provided ablation studies in the appendix that DDC-AT is better than DDC-AT-M, I am still confused what is the advantage of DDC-AT over DDC-AT-M, since it seems that for the clean pixels with \"boundary property\", their adversarial counterparts should also be difficult to be classified. I am also wondering in Table 8 lower half, why DDC-AT or DDC-AT-M achieve highest results unstably. Also can the authors provide results from other attacks for Table 8?\n\n\\- Could the authors please provide results when the perturbation goes larger than 0.03*255?\n\n\\- The writing could be improved and be clearer. For example, in the middle of page 7, it's not super obvious that 0.008, 0.005 etc are the standard deviations.\n\nNitpicking:\nIn Eq 1, there are 5 \"(\" but only 4 \")\".\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Official Blind Review #3",
            "review": "This paper proposes an adversarial defense method against white-box and black-box attacks for image segmentation models by divide-and-conquer adversarial training. Experiments are conducted on PASCAL VOC 2012 and Cityscapes datasets and achieved superior performance compared to standard adversarial training. In addition, ablation studies are conducted to verify the effectiveness of the proposed defense. \n\nStrengths:\nThis paper proposes an innovative pixel-level adversarial training method for image segmentation. The idea of applying divide-and-conquer to pixel splitting is interesting. The comparison in the experimental part and ablation study are quite detailed.\n\nWeaknesses:\nThe main problem of this paper lies in the experimental comparison. First of all, the divide-and-conquer based adversarial training method proposed in this paper is only compared with standard adversarial training. Only DeepFool, C&W and BIM attacks migrated from classification task are used to generate adversarial examples,. There are some specific attacks on image segmentation, some of which are also cited by the authors, but no comparison is added ([1][2][3][4]). In addition, currently there is also work related to the defense of image segmentation task ([5]), which is also cited but not compared. Is this mainly because DDC-AT cannot be compared with it? The defense method may lack the convincing power of its effectiveness if only simply compared with attacks migrated from classification task. Because the attacker is also likely to optimize the attack method for image segmentation task. In addition, from the experimental results, it seems that compared to the improvement from no defense to SAT, the improvement of DDC-AT relative to SAT is not very obvious. \n\n[1] Universal adversarial perturbations against semantic image segmentation, ICCV 2017.\n[2] Adversarial examples for semantic segmentation and object detection, ICCV 2017.\n[3] MLAttack: Fooling Semantic Segmentation Networks by Multi-layer Attacks. German Conference on Pattern Recognition. Springer, Cham, 2019.\n[4] Adversarial Attacks for Image Segmentation on Multiple Lightweight Models, IEEE Access 2020.\n[5] Improved Noise and Attack Robustness for Semantic Segmentation by Using Multi-Task Training with Self-Supervised Depth Estimation, CVPR 2020.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review round 0 of « Dynamic Divide-and-Conquer Adversarial Training for Robust Semantic Segmentation »",
            "review": "The article entitled « Dynamic Divide-and-Conquer Adversarial Training for Robust Semantic Segmentation » proposes to apply adversarial training for semantic segmentation.\nAuthors claim to be the “ ﬁrst attempt to have comprehensive exploration on the effect of adversarial training for semantic segmentation.”\nThey proposed two models a baseline standard adversarial training (SAT) and a  divide and conquer strategies adversarial training (DDC-AT) for semantic semantic segmentation.\nThese model are extensively test and compared in the experimentation section.\n\nThe article is a bit difficult to read with long processus explanation in raw tex.\nFor example, in 4.2 the “implementation” section could be directly replace by the algorithms founds in appendix with a very short introduction.\n\nThough the theoritical and experimental sections sounds good I’m surprised not to find older works that combines adversarial learning and semantic segmentation in the related works section, such as:\nLuc, P., Couprie, C., Chintala, S., & Verbeek, J. (2016). Semantic segmentation using adversarial networks. arXiv preprint arXiv:1611.08408.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Toward more adversarially robust semantic segmentation, but major weaknesses prevail",
            "review": "Summary:\nThe submission takes a closer look at robustness against adversarial attacks in semantic segmentation. In particular, it proposes a novel training framework termed DDC-AT (for ‘Dynamic Divide-and-Conquer’) where pixel samples from a set of paired adversarial and non-adversarial images are classified into two sub-sets, depending on whether they result in the same or a different output classification. Adversarial images are generated synthetically by means of black-box or white-box adversarial attack algorithms. The two sub-sets are handled by two separately trained sub-branches of the neural network architecture. Both of these branches are optimized with weighted cross-entropy loss; weights are enforced by means of a pixel-wise masking algorithm.\nExperimental results yield modest improvements over a prior art baseline, termed ‘Standard adversarial attack and training’ by the authors.\n\nReview:\nA closer look at adversarial robustness in semantic segmentation could be a very useful contribution to the field, since segmentation problems have been explore less in this context than, say, pure classification models.The submitted work has major issues, though, that prevent me form rating it more highly.\n\nThe paper goes great lengths at describing the method (not always sufficiently clearly, see below), but the reader does not get much insight into why it improves or should improve results. Besides increased clarity, a more formal framework for describing the intention of the method is needed. Section 4.1 is unfortunately full of “hand-wavy” statements about “boundary property” of pixels pairs from adversarial and non-adversarial images samples, respectively. Statements like “likely to stay near the classification boundary” or “directly aligning (...) is difficult, since the distributions are complex” lack the scientific rigor needed to justify the approach.\n\nHalf of page 5 is spent on describing the masking strategy for determining which sub-branch a pixel gets assigned to. Unfortunately it did not become clear to me how “unsupervised learning” is used and why it would be needed in the first place, since we clearly have supervision on the classification of the “clean” and “adversarial” pixels, and the masking could be directly determined on the basis of that. Clarity is lacking since concepts are mentioned that have not been defined anywhere; e.g. what is the “ideal division rule in DDC-AT”? A core algorithm of this approach is relegated to the appendix (Section A.2, Algorithm, 3) and just dumped there without any rationale or explanation.\n\nExperimental results seem consistently better than the chosen baseline (in literally every single evaluation made), but by what may or may not be thin margins. I wish the authors had supplied standard deviations for each experiment on SAT and DDC-AT, in order to assess the relevancy of the results.\nI note that any visualization in the submission compares against the “no adversarial training case” but it was chosen to not compare against the “SAT” baseline.\n\nFinally, the terminology used in the naming of the method and title of the paper is inappropriate. The algorithm presented has nothing to do with what computer scientists would call a “divide-and-conquer” approach (https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm), which is (quoting Wikipedia) “an algorithm design paradigm based on multi-branched recursion”. The algorithm presented is unrelated. I find the misappropriation of standard terminology highly problematic.\n\nMore specific points:\n- Figures 2 and 4-7 remain quite unclear to me in various aspects. It is not clear what is done with the imagery from Fig. 2a) in Fig 2b). What do the arrows mean? Furthermore, if the output of the mask branch decides on the flow into main or auxiliary branches, shouldn’t the mask branch be depicted earlier? The flow is not clear.\nIn Figures 4-5, a block is described as a “branch”, but since there is no other branch in sight, this might as well not satisfy the definition of a branch.\n- Section 4.2, ‘The Implementation’, “f_m predicts the division for pixels as shown in Fig. 2(b)”: I do not see this division shown in Figure 2b).\n- Section 4.3, “E is the operation to compute the mean value”: This is imprecise.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}