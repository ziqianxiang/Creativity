{
    "Decision": "",
    "Reviews": [
        {
            "title": "Review of \"Exploring Target Driven Image Classification\"",
            "review": "# Summary \nThis paper proposes a neural network architecture to classify a combination of label and images. The network is target driven, because the prediction is conditioned on a query label. Results show improved accuracies for image classification (CIFAR10, STL10) and out-of-distribution detection\n\n# Strong and Weak points\n\n## Strong points\n\n  * Section 2.1 provides both background and intuition for the design choices of the model and training method.\n  * Experiment 8 provides deeper investigation into similarity of labels and how neural networks represent similar labels. \n\n## Weak points\n\n  * In terms of novelty, it seems the idea stems back to 2006 with Chapter 2 of [3]\nThe related work mentions many previous works from the past decade, but misses context in the earlier works on neural networks.\n  * The results miss a comparison against published works. Table 1 notes 95.10% accuracy on CIFAR10, which is incomparable to the 96.0% published in [4], possibly due to the use of a different architecture of the neural network. Moreover, the re-implemented baseline achieves 95.10% accuracy, while 33 models reported on paperswithcode.com [5] achieve higher accuracy on the same dataset (even without using additional training data). Likewise, 15 models achieve higher accuracy on the STL10 dataset [6], compared to the best proposed INN model, INN(N=9).\nFinally, Table 4 misses comparison against published works. For example, also published literature [9] and [10] evaluate Out-of-Distribution detection using AU-ROC, but their results are not compared against. I would want either a) a proper comparison, or b) an explanation why a comparison is not possible.\n  * For a dataset with 10 labels, the proposed method increases test time compute with a factor 10. Traditional methods like PixelCNN [7] or Normalizing Flows [8] have the same computational complexity. I miss the comparison with such models to evidence the choice of the proposed INN architecture. \n\n# Statement\n\nRecommendation: Reject\nReasons:\n  * The results miss comparison against published works [4, 5, 6]\n  * The motivation misses grounding in existing theory relating to Noise Contrastive Estimation, even though this was published in 2010 and received 600+ citations.\n\n# Questions\n\nClarifying questions:\n\n  * The training scheme is set up as an exhaustive K-way binary classification problem. Might there be a speed up using loss functions like InfoNCE [1], triplet losses [2] or max-margin [14]. These works are mentioned in the related work, but not compared in terms of required compute.\n  * How could one use this model for semi supervised learning? Chapter 2.2 in Chapelle 2013 [3] also employs a similar semi supervised setup.\n  * “We use a 2-layered MLP with no activation”: when there’s no activation function, why not collapse the 2 layers into 1 layer?\n  * What is the justification for constants K_1 and K_2, and how was their value determined?\n  * What is exactly the motivation for the research question? To quote from the introduction “Though seemingly tedious, to the best of our knowledge, this alternate approach has not yet been modelled by deep neural networks”. If the advantage would be in terms of adversarial attacks [12] or out-of-distribution robustness [13], then the evaluation section misses those numbers. \n  * How does this compare to traditional generative modelling? I.e. calculate p(x|y), instead of p(y|x)?\n\n# Minor feedback\n\nThese points are not part of my assessment\n\nMinor feedback\n  * Caption, figure 1: “represents” -> “represent”…\n  * Equation (1): there’s a definition for \\tilde{y} and \\hat{y}, but I miss the definition of normal y. May I assume it’s the correct label for the corresponding x?\n  * “It is widely popular architecture”. When using such adjectives I would prefer to see one or two references. \n  * Equation (3): the end condition of the summation is incorrect. There’s a sum over N-1 elements of the set $Y’ \\ {y}$. However, that iteration has no end condition $i < N$ which is noted on top of the \\Sigma sign.\n  * “However, in fgvc datasets since”. Could “fgvc” be either a typo, or an undefined abbreviation? \n\n\n[1] Oord, A. V. D., Li, Y., & Vinyals, O. (2018). Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748.\n\n[2] Schroff, F., Kalenichenko, D., & Philbin, J. (2015). Facenet: A unified embedding for face recognition and clustering. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 815-823).\n\n[3] Olivier Chapelle, Bernhard Schölkopf, Alexander Zien:\nIntroduction to Semi-Supervised Learning. Semi-Supervised Learning 2006: 1-12\n\n[4] Khosla, Prannay, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, and Dilip Krishnan. \"Supervised contrastive learning.\" arXiv preprint arXiv:2004.11362 (2020).\n\n[5] https://paperswithcode.com/sota/image-classification-on-cifar-10\n\n[6] https://paperswithcode.com/sota/image-classification-on-stl-10 \n\n[7] Van den Oord, Aaron, et al. \"Conditional image generation with pixelcnn decoders.\" Advances in neural information processing systems. 2016.\n\n[8] Kingma, Durk P., and Prafulla Dhariwal. \"Glow: Generative flow with invertible 1x1 convolutions.\" Advances in neural information processing systems. 2018.\n\n[9] van Amersfoort, J., Smith, L., Teh, Y. W., & Gal, Y. (2020). Simple and Scalable Epistemic Uncertainty Estimation Using a Single Deep Deterministic Neural Network. arXiv preprint arXiv:2003.02037.\n\n[11] Gutmann, M., & Hyvärinen, A. (2010, March). Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics (pp. 297-304).\n\n[12] Madry, A., Makelov, A., Schmidt, L., Tsipras, D., & Vladu, A. (2017). Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083.\n\n[13] Hendrycks, D., & Dietterich, T. (2019). Benchmarking neural network robustness to common corruptions and perturbations. arXiv preprint arXiv:1903.12261.\n\n[14] Taskar, B., Klein, D., Collins, M., Koller, D., & Manning, C. D. (2004, July). Max-margin parsing. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (pp. 1-8).",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Although, appreciated the proposed \"approach\" and quality of the paper writing, justification of the stated claims and insights were not convincing in our opinion.",
            "review": "The authors propose to utilize  (image, class label) inputs to a proposed Indicator Neural Network (INN), while the excepted binary output is a confirmation or not of the adequacy to the supplied label of the paired image.\nAs the proposed model outputs a real valued response for that adequacy measure, it can be considered the probability that the image belongs to its paired label/category.\nIn other words, an image classification application using an INN.\nQuestions:\n-\tIn 1.INTRODUCTION: You state “Hence, the classification task of the image is driven by the input target.”\n       o\tIsn’t this just a “traditional” image classification followed by a final post processing step, “does the predicted class of the image correspond to the foretasted one”?\n      o\tCan you detail how is this “driven” by the target supplied to the network?\n-\tIn 2.1: You state “We suspect that this reduces the burden of image encoder to produce strong category discriminative features and allows the network to attend to larger regions of the input image.” What drives you to make such an assertion or is it what occurred in your experiment results? \n-\tThis reviewer does not see the major difference with standard image classification approach (even with the supply of the to-be verified image class label). Nevertheless, Doesn’t your joint image-label representation and therefore end results vary depending on the labeling scheme used (and furthermore its encoding)?\n-\tIn 6 EXPERIMENT: IMAGE CLASSIFICATION: You state “which proves beneficial where categories are visually dissimilar.” Everything hinges here of the definition of “visually dissimilar”. Is it in the context of your approach, meant to describe different image categories/labels which relate to the objects contained in the images (case in the classification problems) or more global image features (style for example)?\n-\tIn 11 DISCUSSION & CONCLUSION: You state “the learnt label embeddings also mirror the visual similarity across different categories.” Isn’t this due to a bias due to the fact  that according to your approach the likelihood of the paired label of an image supplied as input to the network is high, as it is a verification task rather than a “pure” classification?\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting work, but motivation seems weak, relevant baseline missing",
            "review": "Summary: The authors substitute the question - 'Which one of a set of output categories does an image belong to ?' by 'Does a particular image $i$ belong to category $c$ ?', thereby formulating a multi-class classification problem as a set of binary classification  tasks. They argue that in the standard multiclass classification setup the NN gets a negative feedback only at the loss calculation step, i.e. when the cross entropy loss tries to suppress the logit scores of the incorrect classes in order to enhance the logits of the correct one. This is insufficient. Instead, they propose an approach wherein an image encoder network yields the image representation, a label encoder network yields the label representation, and the dot product of the two representation vectors serves as the input to a classifier (an mlp). The label representation can in effect be viewed as an attention mask and the joint training of all the units in the pipeline, together with the explicit negative pairings ($i$ and $c$, when $i$ does not belong to label category $c$) could afford the learning of more meaningful representations.\n\nRemarks on quality: The language is clear, text is well supplied by visualisations, mathematical formulations are accessible, as is the implementation and experimental analysis.\n\nPros:\n\n(a) The proposed formulation is straightforward and easy to implement.\n\n(b) It has been analysed from various different angles, on tasks of classification, recognition of out-of-distribution samples, and also covers quality assessment of learned image and label embeddings.\n\nCons:\n\n(a) The motivation is a bit vague, why would the negative feedback during CE loss calculation not be sufficient for learning good visual representations?\n\n(b) Relevant references and comparisons are missing. For example, see [1], wherein the notion of using the label (inferred rather than supplied) is being used to estimate an attention mask that is then applied on the image feature map to learn more discriminatory representations for classification. What are the likely differences, advantages and gains of the current approach w.r.t. to [1].\n\n(c) The proposed approach (INN) seems to translate to results that perhaps statistically significant do not offer substantial and/or consistent improvements over existing methods:\n-- In Table 1 comparison with existing approaches (employing attention maps to boost performance) is missing.\n-- Table 4 that studies the performance on task of out of distribution detection, doesn't show a consistent gain by using INN\n-- learned similarity between labels in the label embedding space is sometime non-intuitive (see Table 3, deer-car and frog-car are confused).\n\n(d) Scalability to larger datasets (with bigger number of classes) is a crucial concern as noted by the authors themselves in Sec. 10.\n\nIn the light of above, I am not convinced of the novelty of the approach both in terms of the formulation and the resulting performance and hence vote to reject this submission in its current form. \n\n\n[1] Learn to pay attention, Jetley et.al. (ICLR 2018)",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Concern in Novelty",
            "review": "The paper proposes indicator neural networks, a model that classifies images using label embedding. Experiments are performed on various datasets such as CIFAR-10, STL-10, Pets, and others.\n\nThe main concern with the paper is that label embedding is something people have attempted before, with better or stronger results on larger datasets such as ImageNet. To the credit of the authors, section 3 cited many of these prior papers. I did not identify significant difference that warranties reasonable novelty for ICLR 2021.",
            "rating": "2: Strong rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting idea, experimental execution could be improved ",
            "review": "\nSummary\nThis paper considers an image classification setup where the input is an image accompanied by a category label, the goal is to predict if the category label applies to the image or not. \nThe difference of this problem formulation and binary multi-label classification is subtle.\nThe approach consists in learning a label embedding of the same dimension as a vectorial image embedding provided by a CNN. The image and label embedding are then multiplied point-wise, and fed to a final fully-connected layer that produces a score to indicate if the label applies to the image yes or no. \nTo classify an image across multiple classes, it is assigned to the class yielding the most confident score. \nTo train the model, the authors optimise the binary cross entropy for the correct label, and a random subset of N negative labels.\nThe model is also evaluated for out-of-distribution (OOD) detection, using the confidence score of the highest scoring class.\nThe results of the model are compared against conventional baselines that are trained using the cross-entropy across all classes, or using a multi-label setting using a binary cross-entropy for each class in parallel. Finally results are compared against Supervised Contrastive Learning (Khosla et al, 2020).\nQualitative experiments consider Grad-Cam heat maps, and relatedness of labels based on similarity of the learned label embeddings (both are quite anecdotal, see below).\nQuantitative experiments assess classification accuracy and OOD detection across a collection of five fairly small datasets (CIFAR-10, STL-10, BMW-10, CUB-20, Pets).\nSubstantial improvements in classification accuracy are observed over the baselines (except for CIFAR-10 where results are comparable).\nFor OOD detection significantly improved results are again observed.\nImage classification accuracy on the CUB-200 dataset, reported in supplementary, is worse than the multi-class cross-entropy trained baseline. \n\n\nComments\n\n1 - Overall I found this an interesting paper, but the experimental evaluation falls a bit short. Given how simple the idea is, I expected a more thorough experimental analysis, including evaluation on large benchmarks with many labels (see also below). \n\n2 - I felt that the relation to binary multi-label classification was not highlighted clearly enough. In my view, the proposed approach is basically doing binary multi-label classification (predict for each label if it is applicable to the image yes/no). The used loss function with negative sampling and weighting is not specific to the proposed approach and applies to the multi-label baseline as well. Which is recognised to some extent in the last paragraph (bullet point?!) of Section 10. In a way, we can understand the proposed model as an alternative architecture for multi-label classification. Note that if we fix the last weight vector in the predictor to a vector of ones, then we obtain *exactly* the multi-class baseline (except that the label embeddings are low-rank by the two-layer label embedding branch). \n\n3 - The element-wise product followed by linear classifier can also be interpreted as a generalised dot-product (by setting classifier weights to vector of 1's). From this perspective it seems natural to L2 normalize z and psi before the product, to get a cosine-classifier. Did you try that?\n\n4 - The activation scaling by psi can also be seen as a special case of FiLM conditioning [a]. This suggests applying such modulations throughout the image encoder. In this manner the internal CNN features can be made class specific. This might improve its effectiveness, but will prevent shared computation of the CNN across multiple-labels, see below.\n\n5 - In section 5 the GradCam heat maps are interpreted for the proposed INN method and baselines. This analysis is however, quite limited. (i) It is based on only 3 images. (ii) The analysis is only qualitative. (iii) It is not clear what the conclusion is except that the attended areas seem larger for  B-ML and INN than the other baselines. I would suggest to include quantitative analysis (eg measure the area of attention), and perhaps correlate it with object locations using a dataset for which semantic segmentations are available. It would also be useful to give a brief description of how the heat maps are computed, and to what extent they are comparable across images and classifier networks.\n\n6 - Section 6: do you expect further gains in classification accuracy beyond N=9 for CUB-20 and Pets? For these datasets the classification accuracy has not saturated yet with growing N, and more negative labels are available. It is not clear why this experiment was not included, given that for CUB-200 similar experiments are provided in the supplementary. \n\n7 - Section 8: When considering the relatedness of the learned class embeddings, a comparison with the other methods would be useful. The weight vectors of the last fully connected layer of classifiers trained with cross-entropy loss are also known to correlate with semantic class relatedness. A quantitative evaluation would be welcome to assess this aspect. Imagenet might be useful, leveraging the class hierarchy.\n\n8 - Section 10 discusses challenges to scale the presented approach to datasets with many labels. Which suggests that using N negative labels, scales the computational and memory cost of the model linearly, as if using a batch N times larger. This is, however, ignoring the fact that the most costly part is the CNN, which needs to be excused only once per image. After which the network can bifurcate to branch to the different loss terms for the labels. This suggests a scaling similar to the multi-class and multi-label baselines. The same can be done for testing. It is a pity the authors did not explore this in their paper.\n\nOverall impression\nThe authors explore an interesting rephrasing of the conventional multi-class image classification setup, much related but slightly different from the multi-label setting. Experimental results are encouraging, but are lacking in some respects (disappointing results on CUB-200, lack of testing on ImageNet, Grad-cam and label relatedness experiments are very anecdotal and lacking quantitative assessment). \nThe strong classification accuracy results given the simplicity of the approach and similarity to the multi-label setting, are appealing. My assessment, however, that the paper is not ready for publication at ICLR, and could be further improved.\n\n\nDetailed comments:\n- Section 6: define the abbreviation \"fgvc\" and write it in capitals, or just write it full out, it's used only at one other place.\n- In section 6 \"... which supports our theory.\" Please tone this down, not theory was provided, perhaps use \"hypothesis\".\n- Section 6: \"Thirdly, as the value of N increases the performance of INN increases. We believe this is a direct consequence of providing more negative label examples for a given input image during training.\"\nWell yes, obviously since N is the nr of negative label samples used in training. This phrase is a bit vacuous. \n\n\nTypos\n- Abstract: \"... classification via. deep ...\"\n\n\n[a] Perez, E.; Strub, F.; Vries, H. D.; Dumoulin, V. & Courville, A.  FiLM: Visual Reasoning with a General Conditioning Layer.  AAAI, 2018\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}