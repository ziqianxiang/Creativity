{
    "Decision": "",
    "Reviews": [
        {
            "title": "Lack of baselines and real data in experiments",
            "review": "This paper proposed EulerGAN for generating time series data. The underlying idea is to discretize Black-Scholes equation and base on that to train generator to generate fake time series examples using the GAN’s principle. The generator g calibrates two functions b and sigma to realize the Euler scheme in Eq. (2).\n\nThe idea is somewhat useful and novel. However, the paper lacks mentioning and comparing it with an important body of works regarding generating text and sequential data for example SEQ-GAN [1], [2], and so on. Although those works were demonstrated for sequence and text generations, I believe that they are sufficiently powerful for time series data.\n\nThe experiments conducted in this paper are not sufficiently convincing with only synthetic data. Moreover, there are not any baselines for comparison. Moreover, I cannot see any experimental details of how to design networks b and sigma.\nBelow are my questions:\n1.\tCan you compare your work and sequence and text generation approaches mentioned above? Can those approaches be applicable to your problem of interest?\n2.\tAccording to your recursive equations in Eq. (2), it seems that when evaluating X_t_N, it requires to invoke b and sigma recursively in a recursive chain. Does it make the network harder to train?\n3.\tComparing to using an RNN (or Bert) for generating time series data, what is the advantage of your approach? \n\n1. Yu, L., Zhang, W., Wang, J. and Yu, Y., 2017, February. Seqgan: Sequence generative adversarial nets with policy gradient. In Thirty-first AAAI conference on artificial intelligence.  \n2. Chen, L., Dai, S., Tao, C., Zhang, H., Gan, Z., Shen, D., Zhang, Y., Wang, G., Zhang, R. and Carin, L., 2018. Adversarial text generation via feature-mover's distance. In Advances in Neural Information Processing Systems (pp. 4666-4677).\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "The proposed idea could be useful for modelling of financial time-series. However, the made experimental verification and comparison with related works are not sufficient.",
            "review": "The authors introduce a GAN-style model for time series generation based on Euler embedding. The idea is to use as a generator some SDE sampled in a number of discrete points. Then based on a GAN objective the authors define the distance between the existing time-series realization and realizations, generated by the SDE-based generator.\nThe proposed mathematical formulation of the time-series simulation problem is quite simple and straightforward.\n\nIn Euler Model that the authors use, each time series element X_{t+1} depends only on the previous element X_{t}, the current time step t, and random noise. This assumption naturally implies modeling of time series by using recurrent neural networks. In fact, this is exactly what the authors do. However, for some reason, the authors everywhere avoid RNNs in their exposition! What if we use some RNN model instead of (1)? Will the results be better/worse?\n\nTaking the previous paragraph into the account, it is absolutely unclear what is the relation of the authors' method to other existing methods to model time series via GANs and RNNs. The authors provide only a very brief discussion of related work which by no means sheds light on the current situation and open problems in time series modeling and generation.\n\nIn the experimental section the authors do not benchmark their method against any existing alternative for time series generation. E.g. J. Yoon (2019) can be a nice comparator. Another good references is “Takahashi, Shuntaro, Yu Chen, and Kumiko Tanaka-Ishii. \"Modeling financial time-series with generative adversarial networks.\" Physica A: Statistical Mechanics and its Applications 527 (2019): 121261.” This fact does not make it possible to understand the drawbacks or benefits of the proposed method.\n\nIn the experimental section the authors mainly concentrate on modeling of financial time-series using the proposed model. \n- They consider 1d Black-Scholes model and demonstrated that some statistical characteristics coincide for the MC and GAN-based simulators. However, it is not clear whether this is enough to confirm that GAN-based simulators are accurate enough.\n- Then they consider option pricing based on the proposed model and on the theoretical Black-Scholes model. However, it is no clear whether the observed descripancies are significant compared to other existing approaches to pricing.\n- The next application is multi-dimensional modeling of BS process. However, the authors did not provide enough evidences on whether  the replicated distribution is close enough to real one. Definitely figure 7 is not enough.\n\nIf the main point of the paper is about modeling of financial time-series, then the authors should compare their model with standard approaches used for estimating parameters of stochastoc models and simulations from them. And in this case I would recommend to consider some journal related to stochastic financial mathematics and applications for submitting the paper. Moreover, I would propose to specify in more detail what could be the specific use cases of such time-series generator, how to estimate its performance in practice, etc. The proposed comparison with pricing is not enough, as I would expect to see how option pricing works on real data in comparison with existing approaches to pricing.\n\nThe authors did not explain actual neural network architectures they used for modeling of the function b and the function sigma in (1). The did not make any study on how properties of these architectures influence the results.\n\nUnfortunately, I can not recommend this paper for publishing in ICLR.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review of \"Euler-based GAN for time series\"",
            "review": "This manuscript parameterizes the drift and diffusion terms to generate continuous Markov processes. The idea is natural. However, there are a few concerns that are not well addressed in the manuscript.\n\nFirst of all, parameterizes the drift and diffusion terms are more expensive in high dimensions than directly parameterizing the time series itself. d^2, instead of d number of functions need to be taken into account. How does this scaling affect computational complexity?\n\nAnother concern is about numerical stability. Similar to the neural ODE work, it is of paramount importance to understand the numerical stability of both forward solving the SDE as well as backward inferencing it. A more thorough understanding of this issue is necessary to evaluate the validity of the current approach to different scenarios.\n\nAlso, if the dynamics contains jumps, how to incorporate these?\n\n################################################################################\nTLDR\n\nPros:\nParameterize the drift and diffusion coefficients for time series GAN based on Euler discretization is a natural idea.\n\nCons:\nLack of understanding on numerical stability, computational challenges, and incorporation of jumps that are common in some of the time series data.\n\nImprovements that can be made to the manuscript:\nA detailed analysis on scalability of the algorithm when the features and length of the time series increase.\nMore understanding on the numerical stability of the parameterization and the corresponding algorithms associated with Euler discretization.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Official Blind Review",
            "review": "*Summary:*\nThe paper introduces a GAN-based generative model for time-series. Namely, the paper proposes approximating a Euler solution to differential equations, and investigate some standard GAN loss functions.\n\n*Quality*\nUnfortunately, doesn't meet the standards of a top-tier publication venue. There are fundamental problems in presentation (see below in the clarity section) that makes a good assessment of the technical contributions quite difficult. The paper doesn't provide a strong motivation for the proposed model. In addition, the experimental section mainly reports results without provided any analysis. Finally, the paper doesn't provide any conclusion section that provides a more general perspective on the paper.\n\n*Clarity*\n- Many important terms are used throughout the paper without a clear definition, e.g., \"model-free\", \"Euler embedding\", \"Ito processes\", \"volatility structures\", \"risk management\", etc.\n- Notation and modeling choices are not clearly defined. For example, is X a sequence of one observation? How are $b^\\theta, \\sigma^\\theta$ defined? how does $g_\\theta$ \"calibrate\" these two functions?\n\n*Originality*\nThe paper applies standard techniques from GANs to the time-series domain. The paper lacks many details to assess the originality of the proposed approach.\n\n*Significance*\nI am not an expert in the time-series domain so I cannot assess the significance of the work.",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Official Blind Review #3",
            "review": "#### Summary and contributions\nThe paper presents a Generative Adversarial Network for time-series data. A generator is used to model the drift and volatility of a stochastic differential equation (SDE) and \"fake\" time-series are generated via an iterative procedure using the Euler discretization of the SDE. A discriminator (critic) is used to discern between the real and fake time series by treating them as vectors in $R^N \\times R^d$. The authors experimented with the Jensen-Shannon, 1-Wasserstein, and Regularized 2-Wasserstein minimax objectives for GANs. Experiments are presented on the Black-Scholes process and S&P500 showcasing the generation and transfer-learning capabilities of the proposed Euler-based GAN.\n\n#### Strengths\nDeep generative modeling for time-series has not received significant attention from the community, particularly when compared with other data modalities such as images and text. This paper presents an interesting idea in the usage of a generator to model the drift and diffusion of a stochastic differential equation. However, the paper in its current form has weaknesses that do not warrant acceptance. (see below)\n\n#### Weaknesses\nThe paper appears to be an incomplete, last-moment submission. It ends abruptly without offering any concluding remarks or discussion. The experimental evaluation is particularly inadequate. Firstly, it lacks background details about the experiment being conducted. The section is poorly written and reads as an incoherent collection of statements about the results. Secondly, the experiments are arguably too simplistic in nature. They do serve as a proof of concept but in the absence of new theoretical results or other contributions, the lack of larger-scale experiments makes this work a weak contribution. Thirdly, no comparisons are conducted against other traditional or deep approaches to model time-series. For example, the authors do cite Yoon et al. (2019), Yu et al. (2017), and Luo et al. (2018) but do not offer any comparisons against them or a discussion of why such comparisons are not possible. \n\n#### Additional Feedback\nSome suggestions to improve the quality of this work:\n- Add more experiments and include comparisons with competing methods, e.g., take a look at the experiments and comparisons performed in Yoon et al. (2019).\n- Include a discussion about the experiments before going into the detailed setup. For example, for the Black-Scholes model experiment, offer some background and the purpose of the experiment for readers unfamiliar with this line of work.\n- Include the primary contribution of this work in the algorithms as equations. It is just mentioned as \"generation from Euler scheme\" which offers little information without reading the entire section.\n- Add a concluding discussion.\n\nQuestions:\n- Did the authors consider using a sequence discriminator instead of representing the time-series a vector in $R^N \\times R^d$? I feel that such a discriminator would be better suited for the task at hand.\n\nMinor comments:\n- Abstract: \"time series\" instead of \"time serie\".\n- In section 2, para 1, $X$ is first defined as a vector in $R^d$ and then in $R^N \\times R^d$.\n- It's unclear what the authors mean by \"For example, the log return ... ease our problem\" in the given context. This line seems out of place.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}