{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper proposes to introduce ideas from singular theory to deep learning. All reviewers agree that the work is not yet ready for publication. The key issue seems to boil down to the fact that the paper does not propose nor verify any clearly motivated scientific hypothesis. Relatedly, the work includes many too broad or unscientific claims such as \"To understand why classical measures of capacity fail to say anything meaningful about DNNs\". Such statements should be given more precisely and with a proper citation.  \n\nBased on this I have to recommend rejecting the paper. At the same time, I would like to thank the Authors for submitting the work for consideration to ICLR. I hope the feedback will be useful for improving the work."
    },
    "Reviews": [
        {
            "title": "Useful probabilistic framework for singularity of NNs",
            "review": "The paper is a terse account of singularity of deep learning with a probabilistic view. Clearly written, gives an overview of the contributions and related work quickly and dives into the setup. The main byproduct of singularity is the inapplicability of classical methods. This is no news to many people in the field, yet I find the perspective provided in this work fresh and I think it has potential for further developments, although its current applicability is limited and it doesnâ€™t say something that was not already known. Here are further comments:\n\n- The paper would benefit a lot from clearly laying out the concepts and definitions. Especially section 3 would benefit a lot from such clarity and would help a wider audience to follow the work. \n- The end of section 3 contains the key idea and would benefit from further clarity.\n- How does the measure compare with the other frameworks? What does it imply for existing models (examples)?\n- What is the relevance of the tasks and experiments at the end of section 5? How can one move from regression to high dimensional classification tasks?\n- In light of the under/over-parametrization debate, can the framework account for such a phase transition, or can the experiments reflect this?\n- What are the promises of this framework? What benefits would people in the community expect if they study this?\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "insufficient intellectual contributions",
            "review": "This paper studies the manifold of the weights in a neural network. The paper discusses the singular learning theory approach of Sumio Watanabe and argues for more exploration of this theory for understanding generalization performance of deep networks.\n\nMy opinion of this paper is lukewarm. There is a large amount of existing work on singular learning theory. I agree with the paper that the approach is a promising direction to understand generalization in deep learning. However, the intellectual contributions of this particular paper to the existing literature are difficult to ascertain and insufficient warrant publication.\n\nSome comments.\n1. I like the section on how flatness of the energy landscape connects with Real log canonical threshold (RLCT). The RLCT gives a much more refined treatment of different measures of local geometry of the energy landscape used in the literature (Hessian-based, local-entropy based, Bayes free energy etc.).\n2. The paper would benefit from Appendix A.1-4 to the main text. Some of these calculations have appeared elsewhere in the literature (see the work on K-FAC for the Fisher information) but the development in A.2-A.4 is interesting.\n\nSome questions that the authors could think about.\n1. The singular learning theory argues that the Bayes predictive distribution generalizes better MLE/MAP. How does this explain the fact that one sample from the posterior distribution also results in good generalization for deep networks?\n2. Singular Learning Theory is not new. While it is true that this approach has been overlooked in the recent work on deep learning, better experimental evidence is necessary in order to make a convincing case that it is a promising one. The results shown here are accurate computations using MCMC for small models. Can you also investigate whether one obtains non-vacuous generalization bounds for large deep networks using an estimate for the RLCT?\n3. Section 7: Is the true distribution of data really unrealizable? The reviewer is of the opinion that the fact that we can learn very good generative models for complex data indicates that it might be more viable to study the case when the true distribution is realizable for large-enough models.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "The paper studies the connection of Deep Learning to Singular Learning Theory but falls short in convincing why is this the right perspective.",
            "review": "The paper studies the connection of Deep Learning to Singular Learning Theory making the claim that the later could be a good foundation of the theory of Neural Networks as they are singular models. \n\n+++++++\n\nWhile I enjoyed the primer to singular learning theory, I found the paper's contribution marginal given the related work. The claim 'deep learning is singular' has already been claimed by Watanabe 07' in a much more general statement.  Moreover, each of the claims the authors made is unconvincing both from a theoretical and experimental perspectives. \nFor instance, the claim that RLCT governs the effective number of parameters. While the math looks sound to me, it has both has many strong assumptions on the model and lack of novelty given Watanbe 09'. To show that the calculation is meaningful, I would suggest showing the relationship to a real neural network and see how close the estimate to the real number of parameters (E.g,. in the random features (Rahimi & Recht 2008) model, the number of features is a good way to measure the effective number of parameters. Another way to estimate the real number of parameters is the location of the double descent peak (Belkin 18'). \n\nRegarding the empirical claims, the experiments are not convincing. In order to make a claim about deep learning, (say the bayes predictive error is superior to MAP or MLE) there should be either an extensive experimental demonstration of the claim (not two experiments) with proper ablation of when the claim fails (not to mention that the std of the experimental results puts all the claims to question). Same comments apply to the last section.\n\nTo conclude, my main comment is that while Deep Learning is singular (which is not a deep claim) to make the statement that the right way to study deep learning is by singularity theory, I would like to see either experiments or theory that give me insights about deep learning. This could be done by example by doing a theory on a toy model and showing that it holds for real deep learning applications (or at least for an array of synthetic distributions). I would like to qualify by saying that statistics is not my main field of study and I would be happy to receive clarifications if I misunderstood anything. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A review of singular learning theory",
            "review": "This paper is more like a review of singular learning theory and its implication on deep learning. The authors point out that deep neural networks are singular models and ways to characterize generalization error for regular models cannot produce satisfactory results in this setting. Then the authors introduce the singular learning theory, which has been developed for decades. Then, a series of topics for deep learning, such as flatness and generalization, are studied within the framework singular learning theory, with a combination of theoretical analysis and numerical experiments. The paper is clearly written and well organized. \n\npro:\nThe authors point out that the study of deep learning should be put into the framework of singular learning theory. They verified this point from different aspects, where it is shown that results drawn from singular learning theory is better than those drawn from regular learning theory.\n\ncon:\nIt seems most results in the paper are illustration or clarification of existing results.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        }
    ]
}