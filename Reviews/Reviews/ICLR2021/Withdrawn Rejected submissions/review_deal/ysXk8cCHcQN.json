{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The authors were responsive to the comments of the reviewers, both in\nthe rebuttal and in the revision to the manuscript.  However, the\nreviewers were still concerned about the lack of clarity of the\nmanuscript, the motivation for the design decisions, and errors,\npresent also in the rebuttal revisions.\n"
    },
    "Reviews": [
        {
            "title": "Impressive results but method is not properly explained",
            "review": "This work introduces a new architecture for predicting the acoustic scattering fields from an object and an incident plane wave. This is done by describing the object using a point cloud mesh whose local geometric properties is encoded in a set of latent space vectors and processed by a deep neural network. The resulting architecture can predict the acoustic scattering fields quickly with high accuracy for a given test set.\n\nThe problem formulated is an interesting one and the numerical results are very impressive. The description of the method, leaves quite a bit to be desired. The details of the network are described in vague terms and when formulas are introduced, much of the notation is not defined or not well motivated. As a result, it becomes very hard to understand exactly how and why the proposed method works. For this reason, I do not recommend that this work be published as part of the proceedings.\n\nAs stated above, the numerical results are impressive. The authors state that their network is able to calculate the acoustic scattering field in less than one millisecond for a given object. It is not clear how this compares to the baseline method or the state of the art (PointNet and DGCNN). Section 5.1 mentions it taking twelve days to generate the ground truth data set of 100000 objects, which comes out to about 10 seconds, so this would be a considerable speedup. Still, it is not clear how much faster the proposed method is compared to the state of the art.\n\nThe main problem is the description of the method, starting in eq. (4), where “differential coordinates” are defined. These seem to be vectors in R³, but what is their purpose? What do they encode? Then a variant of this is introduced in (5), where a learned latent space is used in the form of the z coordinates. How exactly are these latent space coordinates learned? What is the objective? Then the vector in eq. (6) is introduced. It is sometimes referred to as a discrete Laplacian, but it is not clear how (in the equation, it is simply labeled “feature”). Sections 4.4 and 4.5 are similarly impenetrable. Furthermore Section 4.5 refers to Appendix B, which defines a theorem, but which has no proof.\n",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting but narrow scope, technical inconsistencies and lack of details",
            "review": "This paper proposes to train a neural network to predict the acoustic scattering effects of a 3D object. The input of the system is a 3D point cloud representing the object, and the outputs are 16 coefficients from the spherical harmonic decomposition of the sound field resulting from an incoming planar wave to the object at a given frequency (4 frequencies are considered, with one specialized network trained for each). The main methodological contribution is a carefully crafted learned representation of the 3D point cloud. Reported results show that the proposed architecture outperform two other architectures while using less parameters and is able to predict sound fields with relatively small errors, using orders of magnitude less computational time than the acoustic simulators used to train the network.\n\nPros:\n- The proposed 3D point cloud representaiton is interesting and potentially applicable to other tasks\n- The general idea of using deep learning to accelerate acoustic simulation is interesting\n- Reported results and comparisons look reasonnable\n\nCons:\n- The scope of the paper is very narrow, making it of limited interest. The approach is only tested on simple simulations (no real data involved) with rather unrealistic assumptions (zero Neumann boundary, perfect plane wave, SH decomposition to order 3 only) and few frequency bands (125,250,500,1000 Hz), but several days of computations to generate the training data are still reported by the authors. It is not clear if and how the proposed approach would scale to more realistic/useful settings.\n- I found sections 4.4, 4.5 and the Appendix cryptic. A context of what exactly is discussed here and how it relates to the proposed method is seriously missing.  Two obscure lemmas and a thorem are packed in a dozen lines of text without any references. I was not able to follow the mathematical soundness of this, or indeed even to understand how it precisely relates to the rest of the paper.\n- In general the paper looks like it has been typed in a rush, with some typos but more importantly several technical inconsistencies, making ts soundness hard to verify. One important source of confusion is the radial basis function \\phi. Below equation (4) it is defined as exp(-||.||^2). In equation (5) an exponential of norm is used but this time with no square. This is again used in the denominator of the first line of eq. (6), although this is presumably a typo? Then in section 4.4, \\phi is defined as a function of completely different nature, from a scalar to a vector of powers, alllegedly \"without loss of generality\". I do not see how to make sense of all these different definitions of phi. Another issue are the cryptic 4 lines preceding Lemma 4.2, ending with \"the distribution on \\theta has density\" : has density what? Also, below equation (6), the authors write \"Equation (6), is further fed into the MLP, forming the differential coordinates in Equation (5)\" it is not clear in what sense eq. (5) relates to the MLP or equation (6). Last, details are missing in the description of the neural network architecture: in what precise sense are the MLP weights shared? Over which dimension is the Max pool applied? What non-linearities are used?\n\nOverall, I feel like the flaws of the paper outweights its strength. It would benefit from an expansion to a longer format in order to better explain the theoretical and methodological aspects and extend experiments to more diverse and/or realistic settings.\n\n===== Edit after authors' revisions ======\nThe authors made some efforts to improve the exposition of the most obscure parts of the paper, but in my opinion this is not sufficient and I am still not able to fully grasp the connection between section 4.4 and 4.5 and the rest of the paper. The added parts (in blue) contain additional typos and, like the rest of the paper, look like they have been type in a rush. For instance:\n- \"First of all, we show that f_i can be regarded as a sum-of-power mapping defined by the coordinate function\" -> I don't see where this is showed in the paper\n- \"f_i(v_1, · · · , v_N ) can rewritten as\" -> can be rewritten as\n\nI'd encourage the authors to resubmit their work using a longer paper format that would allow them to better expose the details of their investigation.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Applied geometric deep learning for sound modelling",
            "review": "Summary: This paper outlines a geometric deep learning approach for predicting acoustic scattering fields at different frequencies. The fields are represented with spherical harmonic coefficients (only the directional parts), and they use a nearest neighbor approach to construct an implicit surface in a latent space, and leverage a Laplacian in this domain. In their experimental section, they show superior results to other geometric deep-learning architectures that use point clouds, and also perform an ablation study.\n\nStrengths: The results for the method seem to beat out other similar point-cloud-based methods and I appreciate the application to a specific sound-modelling problem.\n\nWeaknesses: I found their description of the geometric encoding part to be sparse on the expository front. Their use of differential coordinates, use of a surface in latent space, and the construction of their feature vector are presented without much discussion of motivation. It would help to compare and contrast with existing point-cloud based methods.\n\nRecommendation: I gave a rating of 6, as I found it difficult to see what insights I should glean from their method. On the other hand, their method seems to work well from a practical standpoint, and has a concrete application that seems useful. For a higher score, I think the paper could benefit from a clearer exposition and a more extensive appendix describing the details of their network architecture. This could include a clearer delineation of the differences between their method and similar geometric deep-learning models.\n\nTypos:\n* typologies -> topologies in 3.3\n* exponential powers squared in (5)?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}