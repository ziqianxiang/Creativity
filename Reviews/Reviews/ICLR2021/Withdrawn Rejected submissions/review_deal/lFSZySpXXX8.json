{
    "Decision": "",
    "Reviews": [
        {
            "title": "Idea seems okay needs better exposition",
            "review": "In this paper the authors propose a method for training a deep learning network so as to enforce independence between input samples and network output when conditioned on and intermediate representation of the network. This is done by using a kernel method for estimating dependence between random variables, an idea related to the Hilbert Schmidt independence criterion. The authors validate their method experimentally.\n\nWhile the core idea of the paper seems like it may work I find the exposition of the paper very confusing with many technical points stated with no justification; pages 2 and 3 are particularly bad. I will simply list some examples of what I found poor\n\n-Why does having an intermediate that is an isotropic Gaussian in distribution imply that the representation is disentangled. Disentanglement implies that the covariates are meaningful, multiplying the an isotropic Gaussian distributed RV by an orthogonal matrix yields another isotropic gaussian distributed RV, yet muddles the disentanglement. This seems to be rather large claim from the authors that doesn't appear justified. Disentanglement is also not addressed at all in the experimental section, the word \"disentangle\" doesn't appear here at all.\n\n-(7) seems like a VERY strong claim for there to be no justification. I think this may be related to the (AS) property and Thm. 4 from Fukumizu et al 2009? This needs some addressing. \n\n-Around (10) the authors introduce f as a function from R+ -> R, yet is is being applied to a a differential d \\mu_Z / d\\gamma_d*, both \\mu_Z and d\\gamma_d* are distributions (measures) on multidimensional space, therefore their differential would be a Jacobian presumably, or a radon nikodym derivative? I don't understand why the authors don't simply use distributions to keep things simple and easily understandable. (smaller point)\n\n-For the whole paper \\gamma_d is used as the d-dimensional isotropic gaussian, but this fact is merely mentioned in passing in Lemma 2.1. This sort of notation should be clearly defined somewhere, especially since it is regularly getting muddled with other notation eg (2).\n\n-F and F* are confusing, F is introduced as simply \"a map,\" without any particular properties and then above (13) it is stated \"Z_i = F(X_i) iid drawn from ... \\gamma_d*.\" This is a pretty strong property for F, did you mean F*? \n\n Along with the examples above I think that p. 2-4 could really benefit with some expansion and a better didactic aspect leading the reader a bit.  For example the F operator in section 2.2 should be introduced and explained with some intuition as to where it is heading in the greater view of the paper.\n\n\nOverall the paper needs someI think this paper needs a significant rewrite for clarity to be considered for acceptance.",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "REPRESENTATION LEARNING WITH RKHS AND GAN",
            "review": "\n##########################################################################\nSummary:\n \nThe paper provides an interesting explanation in the representation learning field. In particular, it formulates representation learning as a nonlinear map which characterizes information preservation and disentanglement. To capture such information, the authors develop a novel supervised representation algorithm, which is used to minimize the criterion they developed.\n\n\n##########################################################################\nReasons for score: \n \nOverall, I vote for marginally below acceptance. I like the idea of representation mapping in which RKHS is used to characterize conditional independence and GAN losses that are used to measure the discrepancy of two probability measures.\n \n##########################################################################Pros: \n \n1. The paper considers an important issue of representation learning: how to represent when the dimension is high. For me, the problem itself is real and practical. \n \n2. The proposed way to view the representation learning task as a nonlinear mapping with preserving the entanglement and f-gan is somehow novel for capturing the information preservation and disentanglement. This provides a practical way for supervised dimension reduction when we handle high dimensionality problem.\n \n3. This paper provides comprehensive experiments, including both simulation datasets and real-world dataset to show the effectiveness of the proposed framework. They also prove the effectiveness of their model from two different tasks: regression and classification.\n \n##########################################################################\nCons: \n1. I'm confused about how to estimate the kernel matrix G_X and G_Y for a pretty deep learning model. Please elaborately show how to do it except using the last layer's weights.\n\n2. To enhance the supervised learning model, the authors introduce a much more complex min-max optimization with additional GAN parameters required tuning, which in turn brings more new problems than solving the existing ones. I am not convinced by this fact.\n  \n2. The authors can do better jobs in presenting the theorem in a self-contained way:\n(1) On page 3, it's not clear to readers what it means by 'the inequality refers to the order of self-adjoint operators'. Under what mild conditions, does Eq (6) hold?\n(2) On page 3, it's not clear to readers what it means by '... the minimization refers to the minimal operators in the partial order of self-adjoint operators'.\n(3) \"Then, It follows from (6)-(7) that the target representation map F\u0003 in (2) is the minimizer of (8)\" Why? 'It' ->'it'\n(4) 'mu_z \\ll gamma_d^*' what does \\ll mean here?\n(5)  'By Lemma 2.2, we have F^*\\in F2.' why?\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "There are many suspicious or wrong statements in this paper",
            "review": "This paper combines the conditional covariance operator and f-divergence to propose a new objective function to optimize a reducer and a discriminator.\nThe reducer is a mapping of the original data to make the kernel as deep kernel.\nThe discriminator is used to minimize the discrepancy between the distribution of the mapped data and the reference distribution.\n\nThey stated that their method \"demystifies the success of deep neural networks.\"\nHowever, I don't think so.\nTheir objective function is a combination of existing concepts.\nLots of statements in this paper are not supported by theoretical results or explanations.\nThe authors stated that \"We prove the consistency in terms of the population objective function value.\"\nHowever, I cannot find the results about consistency.\nThis paper is not written very well.\nThere are many typos and undefined notations.\n\nThe following are the suspicious or wrong points in detail.\n\nWhy the word \"law\" can be used to replace \"distribution\"?\n\nWhat is the mathematical formulation of \"disentanglement\"?\n\nUnder equation (5), the cross-covariance operator is not defined in equation (3).\n\nHow do you guarantee the minimizer of equation (8) is a set of mappings in your own framework?\n\nWhat does the notation $\\mu_{Z} \\ll \\gamma_{d^{*}}$ mean in Section 2.3?\n\nWhat does $\\operatorname{dom}$ in $D: \\mathbb{R}^{d^{*}} \\rightarrow \\operatorname{dom}(\\mathfrak{F})$ mean in Lemma 2.2?\n\nIn the last sentence of Section 2,\nthe authors stated that \"Other GAN loss such as the 1-Wasserstein distance for the WGAN (Arjovsky et al., 2017) can also\nbe used here.\"\nWasserstein distance is one kind of integral probability measures (IPMs), not f-divergence.\nCould you explain more about why it can be used here, especially about the Fenchel conjugate in equation (11)?\nIf so, why don't you also try IPMs in your objective functions (14) and conduct the corresponding experimental verifications.\n\nIn Section 3, the authors stated that $F^{*} \\in \\mathcal{F}_1 \\cap \\mathcal{F}_2$.\nHow do you guarantee $\\mathcal{F}_1 \\cap \\mathcal{F}_2$ is not an empty set?\n\n$\\mathcal{T}^*_\\sharp$ in Lemma 2.1 is undefined.\nPlease refer to Definition 1.1 of (Introduction to Optimal Transport, Matthew Thorpe) to explain this notation.\n\nUnder Lemma 2.1, equation 1 should be equation (1).\n\nIn the step of updating the reducer in Section 3, the equation quotation is wrong.\n\nThe provided experimental results are far from sufficiency to support the authors' point that \"The resulting prediction accuracies are better than state-of-the-art methods\".\nMore state-of-the-art methods should be involved. For the real-world data sets, the authors didn't compare their method with any other state-of-the-art methods.\n\nThe experimental settings are not described very clearly.\nThere is a big gap between the algorithm described in Section 3 and the experimental results shown in Section 5. \nIt is hard for me to check the reproducibility of this paper.\n\nBy the way, the authors named their method as \"novel supervised representation learning approach (NSRL)\".\nThis name reflects nothing. Maybe they can name their method as \"novel supervised deep learning (NSDL)\" or \"novel supervised machine learning (NSML)\".",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Learning representations with supervision. Lack of experiments to justify their claims.",
            "review": "The author proposed a representation learning framework by combining the ideas of conditional independence and disentanglements. The former is done by Fukumizu et al., 2009 with deep kernels, while the later is using GAN to encourage the resulted embeddings follow Gaussian distribution. \n\n1. Several related works are missing, including learning deep kernels and learning disentangled representations. For deep kernels, it has been widely used in \n(a) supervised learning (e.g. Deep Kernel Learning)\n(b) GANs (e.g. MMD GAN)\nFor disentanglements, there are also several representative works, such as Burgess et al., (2017); Kumar et al., (2017); Rubenstein et al., (2018) and Locatello et al., (2019). \n\n2. The empirical results are relatively weak. I don't find much results to justify \"disentanglement\" ability of the learned representations. In above works as well as cited reference in the draft, there are lots of standard protocols, but the authors don't use any. Also, with supervision, it should be able to improve the impossibility arguments in  Locatello et al., (2019), which should also be interesting to show and important to study deeper. \n\n3. The usefulness of using conditional independence. Different from typical supervised learning, the objective using labels can be understood as (1) considering label covariance and (2) using kernel. How much advantage we can gain from using this? A simple baseline is typical cross entropy loss + any disentanglement objectives. From the experiments, in terms of the classification accuracy, I don't see it is much better than embeddings from state-of-the-art pretrained ones. A baseline with one step further can simple supervised learning with deep kernels, though it won't give much performance gain empirically. The authors should provide more studies on those. Also, the experiments on more challenging datasets can make the papers more promising and strong. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}