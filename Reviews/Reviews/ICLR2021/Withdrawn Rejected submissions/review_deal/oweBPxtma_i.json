{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "In this paper, the authors work on improving the interpretability of CNNs following distillation methods. The paper is written in such a convoluted way and with many changes in the notation that makes it hard to understand what they are proposing and what for. This is a major impediment for the paper going forward. But also, the reviewers point out some clear aspects of the paper and the interpretability that it provides for CNNs, for example, the entropy analysis and its variability or referring to the discrimination part of the CNN or mentioning an explainable alternative to CNNs, while still relying on the convolutional filters. The authors need to dedicate more time to explain this paper carefully before it can be properly reviewed and published at any major conference."
    },
    "Reviews": [
        {
            "title": "This paper proposes an interesting framework for training interpretable CNNs, similar to distillation methods. While I found the idea and the framework very compelling, the structure of the paper makes it challenging to evaluate the details of the procedure. Please see my concerns below.",
            "review": "This paper proposes an interesting framework for training interpretable CNNs, similar to distillation methods. The authors propose a probabilistic model to approximate CNN predictions (specifically the discriminatory part i.e. fully connected network, and a procedure for training CNN+ DCLM as a game. Results show interesting performance over benchmark datasets in comparison to existing distillation baselines. \n\nMajor concerns:\n1. While the motivation is easy to understand, notation is continuously introduced in the paper without clear description and definitions. This makes it very challenging to parse the technical correctness of the paper. \n\n2. What is the iterative optimization procedure described in Page 5? Highly unclear how the CNN model is actually updated in Algorithm 1 to do the minimization of Eq (14)\n\n3. Can the authors elaborate why the accuracy gap for more challenging datasets like FashionMNIST is much more than simpler datasets for the DCLM model? I also suggest authors to include other datasets instead of focusing on MNIST only.\n\n4. The entropy analysis is interesting but I would've liked to see more insight into why entropy behavior across different datasets is so variable.\n\n5. Way too many typos in the paper. Please proof-read and correct, I only highlighted a few:\n 1. Update_CNN_Gradient in Algorithm 1\n 2. Information Entropy in Figure 5 caption\n 3. Clarify what \"discrimination part\" of CNN means, very early on in the introduction and abstract.\n\n6. Did the authors do a qualitative analysis of where exactly the approximate DCLM has lower accuracy compared to the CNN model and why?",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Significant issues in the language severally limit this work, though there are content issues as well.",
            "review": "I found this paper very difficult to follow as it has many grammatical and syntactic errors. I believe it needs a significant amount of editing in order for the paper to be published in english. In particular careful attention should be made to omitted particles and pluralization.  This alone is a barrier to publication. \n\nSetting aside the grammatical errors, I believe there are some issues in the content of the paper that would need to be addressed as well in order to make this paper ready for publication. \n\nIf I understand the paper correctly, which I am not sure I do, I believe the authors propose a method for extracting an interpretable model which replaces the fully connected layers of a Convolutional Image Network. They present results on toy datasets, MNIST, Emnist, and FashionMNIST.   \n\nMy primary issue with the paper is that it attempts to provide an 'explainable alternative' to a CNN but this explainable model still relies on the features extracted from the convolutional section of a CNN. The paper does not put forward a convincing argument to justify the focus on the fully connected layers. It is interesting to extract an interpretable model from a fully connected network, but if this is the goal of the paper, then the authors should focus on datasets in which a fully connected network outperforms standard explainable models such as logistic regression but interpretability would still be desirable, such as the MIMIC medical dataset. \n\nThe paper would also be significantly improved if more realistic datasets would be explored. The only datasets used are variants of MNIST, in which good performance can be achieved with traditional explainable models.\n\n",
            "rating": "3: Clear rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "The paper is very hard to read.",
            "review": "### Paper Summary\nThe authors proposed Deep Cognitive Learning Model (DCLM) as a surrogate of \"discrimination part of CNN\" which is the fully connected layers after the convolution layers. The authors claimed that DCLM can explain the causal relationship between the features and the output result of the discrimination part of CNN.\n\n### Quality & Clarity\nI found the paper very hard to read. I tried my best to understand the paper. The major contributions of this paper are as follows.\n1. The authors proposed to use DCLM to approximates the fully connected layers (FC), i.e. $\\mathrm{FC}(x) \\approx \\mathrm{DCLM}(x)$ for any $x$. Because DCLM is in a logical formula, we can interpret the \"discrimination part of CNN\" approximately by interpreting DCLM.\n2. The authors further proposed to use DCML to \"regularize\" FC. That is, train CNN so that its FC to be close to DCLM.\nThe first contribution is described in Sec3, while the second contribution is described in Sec4 and Sec5.\n\nBelow, I list the points that makes the paper hard to read.\n* The definition of the term \"discrimination part of CNN\" is described at the beginning of Sec3, although the term is frequently used in Sec1. I could not understand what the \"discrimination part of CNN\" means when I first read the paper. This problem is fatal because the readers cannot understand the problem the authors want to solve in this study.\n* The paper does not describe why interpreting \"discrimination part of CNN\" is important. Thus, the paper failed to motivate the problem. Although the authors cited some related studies, such as [Wan+20], the importance of the problem need to be described in the paper. This problem is fatal because the readers cannot understand why the problem is important.\n* Algorithm1 contains undefined notations. For example, the inputs and the outputs of $\\mathrm{CN}$ and $LN$ are not defined. There are no descriptions what $FMs$ and $f_{nn}$ are. Moreover, the second $\\mathrm{CN}$ in Algorithm1 outputs $FCMs$ in addition to $FMs$ and $f_{nn}$. This problem is fatal because the readers cannot understand how the proposed method operates.\n* The authors merely compared the accuracies of DCLM and its approximation performance. There is no demonstration nor discussion that DCLM can resolve the problem of interpretability of the \"discrimination part of CNN\", which should be the primal goal of this study. This problem is fatal because the readers cannot understand whether the problem considered in this study is solved.\n\nOverall, I think the paper needs major rewriting so that the main message of the paper to be clear: what the problem is; why it is important; how the authors solved the problem; and how the authors confirmed the problem is solved.\n\nIn addition to the readability, I also found some technical errors.\n* In Eq.(5), the partition function $\\log \\Xi$ should appear because it is a function of $y_{dclm}$ and $a$. The authors somehow ignored it.\n* In Eq.(13) and Eq.(14), the partition functions $\\log \\Xi_1$ and $\\log \\Xi_2$ should appear because they are functions of $w$. The authors somehow ignored them.\nThere should be some justifications why one can ignore the partition functions. Or, the experimental results need to be updated based on the objective functions with the partition functions.\n\n### Originality & Significance\nThe use of decision tree for approximating the \"discrimination part of CNN\" is considered by [Wan+20]. This paper proposes using a logical formula instead of the decision tree. The idea seems to be straightforward, and the innovation made in this paper is marginal.\n\n### Pros & Cons\n[Pros]\n* I could not find anything positive about this paper.\n\n[Cons]\n* The paper is very hard to read. The major rewriting is needed.\n* There are some technical errors.\n* The improvement over [Wan+20] seems to be marginal.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}