{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper proposes a trick for stabilizing GAN training and reports experiment results on spectrogram synthesis. All the reviewers rate the paper below the bar, citing various concerns, including a lack of clarity and unconvincing results. Several reviewers suggest conducting evaluations in the image domain as most of the GAN training techniques are proposed in the image domain. After consolidating the reviews and rebuttal, the area chair finds the reviewer's argument convincing and would not recommend acceptance of the paper."
    },
    "Reviews": [
        {
            "title": "Lacks motivation and clarity, and why spectrograms? ",
            "review": "Summary:\nThis paper introduces an additional objective to GAN training called “difference departure from normality” that is meant to encourage correlation between real and generated samples projected into some subspace. This is intended to prevent instability during training.  The technique is applied to audio spectrogram generation.\n\n\nReason for score:\nHonestly I didn’t completely understand this paper, so I’m marking low confidence.  However, I do feel like the paper was quite low on clarity.  The technique wasn’t well motivated or concretely explained.  And I found it odd that it was applied to spectrogram generation exclusively rather than image generation which is the standard testbed for GANs algorithms.\n\n\nComments:\n* This paper could really use some improved motivation (e.g, Why is DDFN a good metric? Why would it improve training stability?).\n* Some of the terms and symbols need to be defined for clarity, e.g., p_g, p_r.\n* Section 3 would be improved by the inclusion of intuitive explanations to help the reader (and me) understand why the DDFN metric makes sense and what it represents. \n* I would recommend including the steps of the overall learning algorithm for those who want to better understand the concrete steps involved in implementing the approach and how the DDFN objective is integrating into the standard GAN learning algorithm. \n* There’s some parameter matrices that show up as $`_g$ and $`_d$ (backticks) in Section 3. Are these latex typos?\n* I would recommend testing the approach on common image datasets, since that is the typical testbed for generic GAN improvements. \n",
            "rating": "3: Clear rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "The paper proposes a novel conditioning mechanism to stabilize GAN training, but the audio reconstruction is limited only to the spectrograms with missing phase information.",
            "review": "The paper proposes a novel conditioning-based regularization of GAN training. While it has been known that tying up the generator and discriminator's latent variables can help stabilize gan training, the proposed method is based on a different theory, thus making the algorithm novel. The experimental results also support the authors' argument about the improved stability and results in terms of objective metrics.\n\nOne thing I wish the paper could improve is about the reason as to why the proposed method is superior to the existing regularization techniques, which is somewhat buried in the mathematical details. \n\nAnother more serious issue is that the method is strictly limited to spectrogram reconstruction. I am not sure if this is the best practice when it comes to generate audio signals, compared against the other generative models that are based on time-domain approaches (e.g., WaveNet or MelGAN). More specifically, the authors proposed to preserve the original phase information from the real examples and reused it to reconstruct the time-domain signal. Given the generative nature of the system, I wonder if this option is always possible. The authors might as well compare to the alternative cases, such as estimating the phase from the magnitude spectrograms (e.g. Griffin-Lim) or by trying to reconstruct both real and imaginary spectrograms to recover the full complex spectrogram. Also, given that the signals (mostly environmental sound) used in the experiments are less sensitive to the phase distortion compared to the other kinds, such as speech and music, I believe that the phase mismatch issue wasn't thoroughly handled in this paper. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Limited evaluation, some contradictory results for stabilized training",
            "review": "Summary\n\nthis paper propose a constraint in GAN training, to improve generated samples fidelity and stabilize training. The proposed conditioning is based on limiting the generator from departing normality function of real samples, which is computed in the spectral domain of Schur decomposition. It is claimed that this conditioning will not limit the exploration of all modes of real data distribution\n\n\n\nMissing references: \nGAN for unsupervised and semi supervised speech classification\n\n1- Hosseini-Asl E, Zhou Y, Xiong C, Socher R. Augmented cyclic adversarial learning for low resource domain adaptation. ICLR 2018\n\n2- Hosseini-Asl E, Zhou Y, Xiong C, Socher R. A multi-discriminator cyclegan for unsupervised non-parallel speech domain adaptation. INTERSPEECH 2018\n\n\n\nComments:\n\n1- what is the relation of batch size to # iteration before collapse? in Table 1, on US8k, it shows larger batch using spectral normalization result in faster collapse, while this is reverse on ESC-50 dataset. Figure 1 is only shown for US8k dataset only.\n\n2- If using spectral normalization stabilize training, the results in Table 1 indicate this is not always true with different batch size and different dataset. \n\n3- Table 2: there is no evaluation of SA-GAN and BigGAN on 256 resolution for MCV. Also no 128 resolution for all models on US8k dataset. what is the reason behind selecting some resolutions only. Is the proposed normalization only better on some selected resolutions?\n\n4- [1] and [2] in missing references proposed multi-discriminator to provide more informative gradient to generator on spectrogram space. It would be also interesting to explore this in combination with proposed normalization\n\n5- what is the impact of the proposed normalization on speech recognition performance? It would be very helpful to add classification metric, since the proposed approach is evaluated on class-conditional GAN. \n\n6- The evaluation on image generation is also required for the proposed normalization approach. ",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Proposes a novel conditioning trick for stable training of the generator in the GAN architecture, but lacks in providing the supporting evidences.",
            "review": "This paper proposes a conditioning method to train the GANs. The conditioning trick is based on the DFN (departure from normality) metric computed in the spectrogram domain of Schur decomposition to ensure the correlation between real and generated samples. Experiments were performed on a few public audio datasets, and the results suggest that imposing the proposed constraint on the generators not only delays the collapse in training but also yields the better reconstruction performance.\n\nPros:\n\n+ An important issue of stable training of the GANs is addressed.\n\n+ The proposed conditioning trick is novel and interesting in some sense.\n\n\nCons:\n\n- The major concern about this paper is the lack of thorough experimentation to prove the usefulness of the proposed method. The experiments and evaluation don't seem to sufficiently support the main arguments. In particular, the authors put an emphasis on the importance of generating the high-fidelity audio spectrograms for higher classification accuracies. This was never supported by any experiments. The reconstruction of speech samples are not sufficient to back up the arguments. Furthermore, another advantage of the proposed method the authors state was its ability to generate the samples with high diversity. This too was not demonstrated with experiments.\n\n- The authors state that the proposed method is generalizable but it should be confirmed through more experiments on the other domains. Otherwise, it is recommended that it must be explicitly stated that the proposed method applies to audio or speech, including the title.\n\n- The paper is not easy to follow. Some terms and notations are not adequately explained. So are the descriptions of the figures. For example, in Figure 2, it is difficult to follow the tradeoff between the quality and the diversity according to different alpha, epsilon values.\n\n- Speech samples in the supplementary material don't seem to match the corresponding DWT spectrograms and waveforms. There are some clipping noises and sudden silences in audio while the spectrograms and waveforms look almost identical to those of the original audio.\n\nTo summarize, the paper presents a novel and interesting idea to tackle the important problem in the field, but fail to provide the experimental evidences to support the idea. Therefore, I recommend the paper is not ready to be published in its current form.\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}