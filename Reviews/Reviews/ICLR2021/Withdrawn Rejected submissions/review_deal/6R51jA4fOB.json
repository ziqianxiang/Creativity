{
    "Decision": "",
    "Reviews": [
        {
            "title": "GAN adaptation by updating the singular value of pre-trained weights only, motivation unclear, experiment incomplete",
            "review": "This work presents an adaptation-based generative model for few-shot scenario via fine-tuning a pre-trained GAN. The key idea is to update the singular values and freeze the singular vectors of the pre-trained weights. Experimental results look interesting. I have a few concerns as follows:\n\n(1) In Section 3.1, I understand the effect of singular values but I'm a little confused about why this can be leveraged for adaptation. If a certain singular value $\\sigma$ could change the head pose, for adaptation with a few cartoon faces for example, I guess the authors want to preserve such an ability of changing the head pose or assume the change of pose should be shared between the original face and cartoon face domain. Then why updating $\\sigma$? Freezing the the singular vectors sounds more important to this task as some level of knowledge is distilled. But those are not clearly presented.\n\nBy the way, is performing SVD on the weight space of a GAN to discover meaningful directions from [A]?\n\n[A] Shen et al., Closed-Form Factorization of Latent Semantics in GANs\n\n(2) Quite a few references are missing (some are listed below). It is better to do a more in-depth literature study in addition to recent GAN work. Understanding the origin is sometimes also as important as beating an existing work.\n\nLake et al., Human-level concept learning through probabilistic program induction\n\nReed et al., Few-shot autoregressive density estimation: Towards learning to learn distributions\n\nLiu et al., FUNIT: Few-Shot Unsupervised Image-to-Image Translation\n\n(3) The visual results (e.g., Figure 7) look somewhat still close to the real faces, plus some simple color/texture from the art portrait. Relatively the results of FD look more like artworks. I feel FSGAN stays somewhere between original and new data.\n\n(4) For comparisons with other methods, more explanations are expected instead of just mentioning results of other methods have more artifacts, especially the schemes of those non-SVD based methods are totally different from the proposed one. In addition, a closely-related method [B] is missing:\n\n[B] Wang et al., MineGAN: effective knowledge transfer from GANs to target domains with few images",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper proposed to adapt a pretrained GAN to a new domain in a small data regime using an SVD decomposition and reweighting of its weights.",
            "review": "Summary\n\nIn this paper the authors proposed an approach to do few-shot adaptation of an already pretrained and effective GAN on a close or more distant domain. The main contribution is to adapt the initial GAN by reweighting layerwise the eigenvalues of the SVD decomposition of the flattend 2D weights connecting any pairs of connected layers. The training phase consists in optimizing those weights with respect to a standard GAN loss, and early stop to prevent overfitting. The approach is extensively tested on a collection of dataset including faces (FFHQ, CelebA, Anime images), landscapes, Kannada charactersâ€¦\n\nReason for score\n\nI would propose to accept this paper since this paper proposes a novative approach with good qualitative and quantitative results with a potential wide scope of application. The main reserves I have are that the study is limited to StyleGAN2 while the approach may be useful more generally, and that the propose approach, unlike models from competition, seems to deform the latent space in a way that does not preserve features that are clearly shared between source and target domains.\n\nPros\n1. Studying how to train GAN in small data regime is very interesting to the field given large datasets in the targeted domain are not always available and that even big data regimes can encompass a collection of small subdataset.\n2. Considering the limitation of FID on small data regime is relevant and interesting for the field.\n3. The qualitative results are numerous on very different datasets, and always convincing and superior to other approaches. In addition the approach presents good qualitative results even in very small data regime (see Fig.7).\n\n\nCons\n1. Given the first target application is training GAN in small data regime, the results (both qualitative and quantitative) could highly depend on the given sample of data used for training. You sould repeat your experimentations several times to get an idea of how your results vary across various sampling (especially in very small data regime) for the proposed approach and the competition you are comparing it to.\n2. There is no clear criterion to stop automatically the training process, which would require manual and qualitative appreciation, or an additional validation set to calibrate the training process (which contradicts the usage in a small data regime).\n3. According to Fig.6 for isntance, unlinke competition, the proposed approach seems to forget good properties of the source domain that should be transferable to target domain (see question 3.). Altering globally the style rather just slightly adapting local texture is good, but pose and expressions could be kept from original pretrained image.\n4. The presented experiments are limited to StyleGAN2, which may reduce the actual scope of the contributions of this paper. It would be very interesting to enlarge the analysis and see if the principles of the proposed approach apply practically to other standard archiectures.\n\nMajor comments\n1. FID seems to be computed on the statistics from $X$ (the comprehensive dataset from which the real data are drawn) rather than the real distribution of subset $T$. It's not clear why. The sampling of T can clearly affect the capacity of the generator and the FID against $X$ (see Cons 1.). \n\nQuestions\n1. Why not using a \"tensor\" generalization of SVD (HOSVD) to deal with 4D convolutional filter weights ?\n2. If $\\lambda$ is a scalar $W_{\\Sigma}^{(l)} = \\lambda W_0^{(l)}$ which remove the interest of SVD. Does $\\lambda$ represent a diagonal matrix to adjust each eigen vector independently ? If so, please, adjust notation and explain accordingly. If not, justify the interest of SVD.\n3. Other approaches seem to keep some characterics of the orginal GAN: for instance, faces with the same pose and expression, but a style adapted to the target domain. Do you have an intuition why it is not the case for your approach ? So far it is not clear which properties are kept from the original GAN. Would it be possible to find a transformation to remap the latent space and avoid this loss ?\n4. Do you see an alternative to early stopping to prevent overfitting ?\n\nMinor comments\n1. Section 2/\"sample-efficient Image Syntehsis\" is repeating the end of section 1.\n2. In section 2, \"internal distribution\" and \"external knowledge\" could be replaced by intra/inter images knowledge for clarity.\n3. GANSpace paper is clearly different in how there are using PCA/SVD technics. (SVD) section could be shorten a bit accordingly. But, I was wondering if similar ideas (SVD on model weights), more relevant in terms of bibliography, has been used in transfer learning of classification models or in metaoptimization or in model pruning.\n4. section 3: \"entanglement\" and \"orthogonal factors\" seem to be fairly antinomic. Singular values represent the weight/importance to their respective eigen vectors (the importance of the factor in the whole combination of eigen-models).\n5. The matrices on which SVD is performed is not introduced before section 3.2. It would be useful for clarity just to add it is done \"layerwise\" across all weights connecting each layer to the next one (+ refering to 3.2 section for details).\n6. Notations:\n- since each decomposition is different at each layer, $(l)$ subscripts should be used for $U_0$, $\\Sigma_0$ and $V_0$. For the same reason, \\lambda should be subscripted by $(l)$ as well.\n- $\\hat{\\mu}$ and $\\hat{\\sigma^2}$ notations are introduced but never used.\n7. Table 1: you can add arrows pointing up or down to indicate if lower or higher value is best\n8. Would be interesting to have a figure to illustrate the dataset used for training (especially for 5 and 15 shot settings), like in Fig.5 for instance. It would help to evaluate the degree of overfitting.",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting Idea, but the results are not good.",
            "review": "Summary: This paper proposes a method for adapting a pre-trained GAN (e.g. StyleGAN2) to generate novel images with few images from a new target domain. Specifically, they apply SVD to the network weights of a pre-trained GAN, and optimize the singular values on the target few-shot domain, with singular vectors fixed. Overall, the result of this paper is not very good, and it does not meet the acceptance criteria.\n\nThis paper is well written, and the proposed method has a clear background and detailed description.\n\nBelow are my major concerns:\n1. The main results shown in Figures 1 and Figures 5 are neither like the input face nor the face in the target domain. In addition, the visual quality of these faces is much worse than the faces generated by Stylegan2. \n2. In Figure 6, the result of FSGAN has nothing to do with the content of the original image and is even worse than the result of the comparison methods.\n3. The current method is only applicable to images generated by pre-trained GANs. What about real images? Except for StyleGAN, what about other GANs?\n4. I feel the current method may be difficult to achieve satisfactory results on the face dataset. It may be better to show some adaptation results on fonts or animal data sets.\n\nOverall, although the proposed method has a certain novelty, I am not convinced by the results shown in this paper.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review of Few-shot Adaptation of Generative Adversarial Networks",
            "review": "Summary\n----------------\nGANs exhibit poor generalization outside of their original training data distribution and require large amounts of data to be successfully adapted to new domains. In this work, the authors propose a new method to adapt GANs to new data distributions from few-examples. Instead of directly fine-tuning all the network weights, which tends to result in poor results, the authors propose to only train the singular values of the SVD decomposition of the weight matrices. This results in a significantly reduced parameter space that allows the network to adapt to new domains with with fewer examples while reusing previously acquired knowledge.\n\nOverall Review\n--------------------\nThe method is sound, the results are good, and the work may be of interest for the research community, as there are not that many papers on GAN adaptation from few data. On the other hand, the results rely on proxy and qualitative metrics and the effect of SVD on the generative model weights is not properly studied. This last part is the most interesting part of the paper, which would provide some insight to readers rather than an increment in performance, and I would invite the authors to put more emphasis on it. Furthermore, the use of \"few-shot\" in this work is misleading, since one would expect adaptation with 1-5 samples instead of 5-100, as usually happens in the few-shot classification literature. Thus, I cannot recommend this paper for acceptance right now but I encourage the authors to work on improving it to change this decision (see weaknesses).\n\nStrengths\n-------------\n1. The quality of the reconstructions matches and improves over the quality of TransferGAN, FreezeD, and SSGAN. This is especially patent in far-domain adaptation results.\n2. The authors are careful by not only comparing with FID and also including sharpness and face quality index (FQI).\n3. The related work and baselines are relevant for this work.\n4. The paper is well-written and easy to understand.\n\nWeaknesses\n-----------------\n1. Although the intuition for using SVD in this problem makes sense, it is not clear what different singular vectors represent and what is exactly happening when modifying their corresponding singular values. The authors point to the works of Saxe et al. 2019, and Martyn et al. 2020 to support the validity of their method, however the referenced works only deal with supervised classification, which is far from image generation (I think [1] will be of your interest too). In order to clarify this point, I encourage the authors  to use a GAN pre-trained on CelebA and check whether singular values correlate with the different facial attributes. This result would be highly beneficial not only for the paper but for the research community in general. \n2. Sharpness and FQI only quantify the quality of the image, regardless of its semantic content. Thus, there is no quantitative measure showing how good the domain transfer has been. One possible metric that could be used would be to train an image classifier to differentiate from both domains and check if the classification of the generated images coincides with the correct domain. If the mentioned classifier is trained with proper calibration an uncertainty quantification, the uncertainty value could be used as a quality measure as well.\n3. Most of the adaptation experiments use more than one sample per class (up to 100 samples), and thus it is confusing that the main topic of the paper is *few-shot* adaptation. The authors should either change the terminology or switch experiments to the 1-shot to 5-shot regimes (as commonly done in the few-shot classification literature). I would suggest the authors either to not use this terminology or add some clarification in the text.\n\nQuestions\n--------------\nI would suggest that the authors look at the suggestions in the \"Weaknesses\" section.\n\nTypos\n--------\nwe then adapts -> we then adapt (End of first page)\n\n\n[1] Chen, Xinyang, et al. \"Catastrophic forgetting meets negative transfer: Batch spectral shrinkage for safe transfer learning.\" Advances in Neural Information Processing Systems. 2019.\n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}