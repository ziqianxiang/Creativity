{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper presents work on temporal logic representations in neural networks.  The paper builds on work on Neural Logic Machines (Dong et al.), adding temporal quantification.  The main positives to the method are this contribution of the temporal reasoning layers (e.g. iii in Fig. 2).  This layer provides an interesting extension of existing literature in the area.\n\nThe main concerns raised by the reviewers were the following:\n- Contribution of the paper over previous NLM techniques\n- Relation to graph neural networks and other message passing techniques\n- Use of hand-crafted initial features and resultant comparisons to baselines\n- Empirical validation\n\nAfter reading the authors' responses the reviewers reconsidered their positions and engaged in discussion.  While the reviewers appreciate the addition of temporal reasoning layers as an interesting contribution, there is still concern over the magnitude of this contribution and its effectiveness.\n\nAdditional points raised in the discussion include\n- Lack of evaluation on standard, challenging datasets and comparisons to state of the art\n- Ablation study in response (Fig. 6) does not consider absolute removal of temporal layers (main contribution).\n\nOverall, while the paper does contribute an interesting inductive bias for learning with temporal data, the current evaluation is limited in terms of its effectiveness at the classification tasks in the experiments.  Based on the concerns raised in the initial reviews and subsequent discussion, it was determined that the paper is not ready for publication in ICLR.\n\n"
    },
    "Reviews": [
        {
            "title": "Interesting application of logic formulation in complex event understanding",
            "review": "This paper overall presents a model that defines the multi-person activities using logic expressions and uses neural logic models to generate recognitions and predictions over events. Specifically, the model follows the neural logic machines (Dong et al.) to define the operations in the networks. Authors demonstrate their model under two tasks, trajectory-based soccer event detection, and robot object manipulation event understanding. Using their self-generated datasets from simulators, the authors found that their model performs better than other baselines.\n\nPaper strengths:\n\n+ The logic forms of event understanding is a quite interesting direction, this paper could be a nice contribution towards that field.\n+ The experimental results support authors' claim on the model\n\nPotential cons:\n1. There are not very unique modeling contributions in this paper. The model used is an application of neural logic machines.\n\n2. Although I like the logical way of defining the events, it seems that the current refinement modules are quite similar to graph neural networks' message passing operations. Is the reason for the proposed model outperforming baselines that there are higher-order terms considered compared to baselines? What if a graph net/relation net with high-order interaction terms is used? Is the logical form of expressing the events really necessary (v.s. a natural language/semantic expression of events + graph nets + high-order terms)?\n\n3. Two relevant and missing citations on soccer analysis and human interaction analysis [1,2].\n\n[1] Large-Scale Analysis of Soccer Matches using Spatiotemporal Tracking Data\n\n[2] Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper proposes Temporal and Object Quantification Nets (TOQ-Nets), which can be used for learning composable action concepts from time sequences that describe the properties and relations of multiple entities. The authors test their model on two artificial benchmarks and demonstrate the effectiveness of their approach.",
            "review": "Strengths:\n- The authors address a well formulated and an important problem for lots of practical scenarios.\n- The paper is well written.\n- The experiments demonstrate that the proposed method outperforms several baselines.\n\nWeaknesses:\n- I personally found the proposed approach to be very cumbersome and complicated. It consists of many different components that are not conceptually intuitive. Contrary to some of the recent approaches for modeling visual relations (i.e. Non-Local Networks or Space-Time Video Graphs), the proposed model is much more difficult to understand. In my opinion, this is a big disadvantage because the models that are most useful to the community are usually conceptually (and technically) simple, yet effective.\n- The authors assume that the input features to the TOQ net are hand-engineered, and thus, are not learnable. This is very different to most modern approaches, which typically try to learn all the features from raw pixels end-to-end. Very few recent methods (to the best of my knowledge) rely on hand-engineered features for video modeling/action recognition. This begs the question how applicable the proposed approach is to modern computer vision community.\n- The biggest weakness of the paper is its experimental evaluation. The authors evaluate their approach on 2 small-scale artificial video datasets. Thus, it is not clear whether the proposed approach would generalize to real datasets such as Kinetics, Something-Something, EPIC-Kitchens, etc. Most current action recognition methods evaluate their model on these large-scale real-world datasets. Thus, I think it is imperative that the authors would conduct thorough experiments not only on their small artificial datasets but also on the datasets that are most often used by the action recognition community. In particular, datasets like Something-Something, EPIC-Kitchens, or Charades require spatiotemporal relation modeling as demonstrated by prior work (i.e. Space-Time Video Graphs). \n- The comparison with the pixel-level baselines (i.e. Non-Local Networks, or Space-Time Video Graphs) might not be exactly fair. The authors adapt these baselines to the dataset/task specific scenarios. Compared to their own model, the authors don't have as many incentives to tune these baseline models for their specific tasks. Thus, I believe that the experiments on the real-world large scale datasets such as Kinetics, Something-Something and Charades are essential for validating that the proposed approach is better than these prior methods.\n- Missing relevant work: Wang et al., \"Something-Else: Compositional Action Recognition with Spatial-Temporal Interaction Networks.\" (CVPR 2020).\n\nRebuttal Requests:\n- The authors should include thorough experiments on the real-world large-scale datasets such as Kinetics, Something-Something, and Charades. The currently used datasets are not sufficient to verify the generalizability and usefulness of the proposed approach.\n\n==Post Rebuttal Response:\n\nI read the rebuttal, and unfortunately it didn't address most of my pressing concerns. I appreciate the authors' efforts to add new experiments on other datasets. However, in my opinion these new datasets are not very relevant for the action recognition community, i.e. they are small, and they are rarely used to compare the effectiveness of a particular model. In my initial review, I listed a few datasets that are most commonly used for action recognition comparisons. In my view, without comparisons on these more popular datasets it is very difficult to tell the real value of the proposed approach. If the authors could demonstrate close to state-of-the-art performance on those datasets I would be more convinced that the proposed approach is effective. Currently, most of the comparison are done w.r.t baselines that are implemented by the authors which is insufficient in my opinion. Therefore, I stand by my original recommendation of rejecting the paper.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The proposed model is promising but the experiments are not sufficient",
            "review": "########################################################################\n        \nSummary:\n\nThis paper proposes TOQ-Nets which is a structured neural network that learns to describe complex activities over entities and time. The model leverages relational reasoning layers which are the Neural Logic Machines (NLM) to capture the spatial information. To further capture the temporal information, this paper proposes temporal reasoning layers.The results show that their method outperforms conventional graph neural networks with high accuracy and generalization with a large margin.\n\n########################################################################       \n \nPros:\n\n- This paper extends the NLM into temporal. The proposed temporal reasoning layer borrows the idea from temporal logic \n\n- programs which is interesting and promising.\n\n- The Results show that their proposed model outperforms the STGCN with a large margin.\n\n- The paper is well-organized and easy to read.\n\n######################################################################## \n\nAlthough the proposed method is promising, the experiment settings are not convincing.\n\nCons:\n\n- Missing reference : A line of research focuses on Group Activity Recognition [1, 2] which has the similar settings as Soccer Dataset. This paper collects the soccer dataset by themself and sets STGCN as their baseline which is not originally used for this task. \n\n- Both datasets used in the paper are collected by the simulators. Compared with the Volleyball dataset [1, 2] that handles videos, the task in the paper seems much more simple and less practical.\n\n- The inputs of TOQ-net and STGCN are different. The distances between players are not input to the STGCN, however the significance of this input variable is unknown. For example, the actions “Control ball” and “Movement (without ball)” can be easily distinguished by the distance of the target player and the ball. Please explain this.\n\n- Missing Ablation study of the temporal reasoning layer. There is no experiment to show the improvement of the proposed temporal reasoning layer. Please explain how much important the temporal information is in your experiment.\n\n\n##########################################################################\n\nReasons for score: \n \nOverall, I like this idea of extending NLM into temporal. However, the experiments fail to convince me of its performance. So I tend to vote to reject temporarily. If the authors can show more evidence about the improvement of TOQ-net and eliminate my concerns, I will change my mind.\n\n##########################################################################\n\nQuestions during rebuttal period: \n \nPlease address and clarify the cons above \n\n\n\n\n\n\n##########################################################################\n\nReference\n\n[1] A Hierarchical Deep Temporal Model for Group Activity Recognition. Mostafa S. Ibrahim et. al.\n\n[2] stagNet: An Attentive Semantic RNN for Group Activity Recognition. Mengshi Qi et. al.\n\n\n--------------------------------------------------------------------------------------------------------------------------------------------\nI have read the rebuttal. The experiments in the rebuttals shows the effectiveness of TOQ-Nets in other large, real-world dataset. These experiments should be added in the revision of the paper and I would like to change my score to 6.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}