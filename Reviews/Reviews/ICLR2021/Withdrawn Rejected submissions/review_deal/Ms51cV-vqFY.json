{
    "Decision": "",
    "Reviews": [
        {
            "title": "A meta-learning based semi-supervised learning method",
            "review": "This paper propose meta-learning based semi-supervised learning method. The proposed method is based on the well-known mix-up augmentation, and the authors try to reduce the noisy label introduced in the mix-up procedure by re-weighing each unlabeled data with pseudo labels. By using a meta-learning based optimization mechanism, the proposed method could learn the weights and classifier simultaneously. To solve the meta optimization efficiently, the authors also provide an approximation procedure and justify the equivalence to the original objective. Experiments on several datasets show the effectiveness of the proposed method. \n\n\npros\n1. The experiments are complete and sufficient to show the effectiveness of the proposed method. The authors also provide detailed hyper-parameter sensitivity analysis and running time tests to show the practical potential.\n\n\ncons\n1. Assigning weights to the unlabeled data to reduce the negative effect of those unrelated ones is a common practice in semi-supervised learning. These weights are rarely tuned artificially. This paper lacks the discussion of the advantage of introducing the meta-learning based optimization to learn these weights. \n2. Compared with the Mix-Match algorithm, the proposed method proposes a re-weighting strategy to resist the noisy labels introduced by the mix-up. But as shown in the experiments, the improvement over the Mix-Match is limited.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good application of meta learning for SSL however novelty is limited",
            "review": "This paper presents Meta-Semi, a meta-learning based approach to leverage unlabeled data for semi-supervised learning. Unlabeled samples are dynamically weighted and a meta optimization objective is defined by minimizing the loss on labeled data when applying the model trained with the reweighted samples. Optimizing the meta-objective is approximated by leverage M-steps of gradient descent in training the actual model and the meta objective is back-propagated to allow meta-parameter updating. Empirical results on CIFAR-100 and STL-10 demonstrate the effectiveness of Meta-Semi over a series of semi-supervised learning methods.\n\nThe paper is a good application of applying meta-learning to the semi-supervised setting problem and good results are shown in contrast to previous SSL methods. However, one main concern is that the idea of reweighting unlabeled samples with pseudo-labels within a meta-learning framework has already been explored in several previous works, including [1,2]. In addition, for SSL self training (non-meta learning based) [3,4, to name a few] is another major chunk of work to leverage unlabeled examples, which the paper doesn't seem to clarify and compare with. Novelty is thus limited and experiments could also be improved if evaluations are conducted on more tasks.\n\n[1] Learning to Self-Train for Semi-Supervised Few-Shot Classification. Li et al. NeurIPS 2019.\n[2] Meta Pseudo Labels. Pham et al. arXiv 2003.10580\n[3] Self-training with noisy student improves imagenet classification. Xie et al. CVPR 2020\n[4] Rethinking Pre-training and Self-training. Zoph et al. arXiv 2006.06882",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The benefit of pseudo label selection by meta-learning need to be further justified",
            "review": "##########################################################################\n\nSummary:\n \nThe paper introduces a new pseudo labeling approach, Meta-Semi, for semi-supervised learning (SSL). In particular, it aims at selecting the optimal pseudo labels in each mini-batch by meta-learning. In doing this, an efficient algorithm is proposed to approximate the solution of the meta optimization problem. Experiments show Meta-Semi is {superior to} / {on par with} several recent SSL methods on {CIFAR-100, STL-10}/{CIFAR-10, SVHN}.\n\n##########################################################################\n\nReasons for score: \n\nMy current vote for the paper is weak reject. I like the solid math derivation of the solution and the intuitive interpretation. Other than this, it is not clear to me what is the real benefit of using meta-learning for pseudo label selection and SSL in general.\n\n##########################################################################\n\nPros: \n\nThe idea of using meta-learning for pseudo label selection is neat.\n\nThe paper is well written. It includes theoretical justifications and empirical evaluations. The math derivation is concise and solid. The interpretation is also intuitive. In general, the presentation of the paper is of high quality.\n\n##########################################################################\n\nCons:\nMy main concern about the paper is, it is not clear to me what is the real benefit of using meta-learning for pseudo label selection and SSL in general.\n\nThe proposed Meta-Semi approach combines pseudo labeling and a consistency-based regularization, MixUp, for SSL. The potential novelty is selecting optimal pseudo labels by meta learning. Experiments show Meta-Semi outperforms several pure consistency-based SSL baselines (e.g. ICT, MixMatch). However, I wonder if the improvement is from combining pseudo-labeling with consistency regularization alone or the meta-learning based pseudo label selection. To justify the claim, it would have been better to include another baseline: pseudo-labeling + MixUp, where the pseudo labels are selected by thresholding the prediction scores. This baseline requires only one extra hyper-parameter: the score threshold.\n\nAnother potential benefit of Meta-Semi, as claimed in the paper, is Meta-Semi only uses one hyper-parameter (\\beta in eq(12)), while other approaches “introduce multiple tunable hyper-parameters”, which is “unreliable” when “the annotated data is scarce”. I don’t think this claim is well justified. It would have been better to include at least some discussions about how many tunable hyperparameters the baselines (e.g. ICT, MixMatch) require.\n\nThe claim about “outperforming SOTA” is not fully correct. One published SSL method is missing: ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring (ICLR 2020), which I believe is the current SOTA. It would make the paper stronger if Meta-Semi is shown to be at least complementary to ReMixMatch (e.g. Meta-Semi+ReMixMatch > ReMixMatch)\n\n##########################################################################\n\nMinor comments: \n\nI’m also curious if Meta-Semi is sensitive to the batch-size? As from the supplemental materials, the batch-size used for CNN-13 and WRN-28-2 are different.  From eq (10), the weight for each unlabeled sample is determined by the labeled samples in the same mini-batch. Intuitively, a larger batch of labeled samples could make the gradient in eq(10) more stable?  \n \nIntro: “the annotated data are scarce” → “is scarce”\n\n#########################################################################\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}