{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "While the reviewers in general liked the ideas proposed in the paper, the experimental evaluation has several issues that need fixing before it can be accepted."
    },
    "Reviews": [
        {
            "title": "A good submission that aims at a valuable computer vision task.",
            "review": "The authors cast the saliency problem as finding an optimal ablation path between two images.\n(1) According to the formulation of the saliency problem proposed in this study, the authors try to connect previous notions of saliency, notably integrated gradients and ablation tests via guiding where to add regularisation.\n(2) One of my main concerns is that although the effect of the proposed strategy is illustrated based on several instances, more objective evaluation of specific tasks on large scale datasets needs to be compared to show if the formulated idea really works. \n(3) As is known, the saliency mechanism is closely related to concepts in the field of neuroscience, so it would be better if the proposed formulation could be discussed based on its essences of cognitive neuroscience mechanisms.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A saliency method that helps to understand the network decision",
            "review": "Summary: \nSaliency problem for black-box classification is the main focus in this paper, which means to find out  the part of the image that is most relevant for the current model decision. Authors propose to find an optimal ablation path between two images to get such saliency maps. The finding in this paper suggest a new view based on ablation path optimization. Several examples are presented to show the behavior of the proposed method for one image classification model.  \n\nPro:\n+ Treating the saliency problem as finding an optimal ablation path between two images is interesting. Formulating the saliency problem as an optimization problem on paths is a kind of new. \n+ Reasonable results can be obtained on several example images to show the decision of the model.\n\nConcerns:\n- The proposed ablation path saliency method requires the existence of example pairs, which limits the application of the method. It seems cannot handle the case if we are only interested in the saliency map for one single image without any support images (baseline image). \n- It is also not clear how to select baseline images from a large image dataset (e.g. ImageNet) to get the optimal saliency map for one target image.\n- There is a lack of quantitative evaluations to validate the effectiveness of the proposed method. Only showing several examples based on fixed image pairs is not that convincing. Why not follow some existing evaluation tools to conduct quantitative evaluations and compare with existing saliency methods? Evaluations could be Pointing Game or weakly-supervised localization/segmentation as in Grad-CAM (Selvaraju et al. 2016) as well as the sensitivity-n property proposed in (Ancona et al. 2017).\n- Only examples for image classification models are presented. It is not clear whether the proposed method can be applied to other problems such as neural machine translation, question classification (Sundararajan et al. 2017), image captioning (Selvaraju et al. 2016) and etc. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Experimental evidence needed",
            "review": "The paper describes the black box approach to saliency prediction using ablation paths gradually replacing the parts of the image of one class with the image of another one. The idea has certain novelty, but the reviewer cannot see that it is backed by the evidence. The following comments are describing the reasons for the current paper rating and must be addressed for the rating to be improved:\n1. The main concern of the reviewer about the paper is the lack of experimental evidence: it only provides the results for use cases and no quantitative assessment over the larger dataset.  For example, Fong&Vedaldi [1] assessed the method of 50K ImageNet validation images. As far as the reviewer can see, there is no qualitative assessment on a sufficient number of samples which would prove the efficiency and compare the method against the alternatives. This concern is critical for the given score of the paper.  \n2. Besides of that, it would be also important to emphasise the novelty: why do we need to have another saliency method, does it give any new insights other than the existing ones mentioned in the related work section? \n3. It is also said in the paper: \"We performed a small, non-rigorous statistical study suggesting that scores > 0.9 are p < 0.01 significant against a null hypothesis of smoothly random masks, and extremely unlikely with pixelwise-random masks.” It would be beneficial to see some further details of it as it could improve the analysis\n4. In a light of the following description and the  given details of the optimisation method : “Since the optimisation problem is constrained (since φ is constrained by the requirements in Definition 3.1), following the gradient direction will lead us to violate the constraints. Since the constraints are convex, it is straightforward enough to project each gradient-updated version back to something that does fulfill them, and indeed that is the idea behind our algorithm, however in practice it does by itself not yield convergence without impractically many iterations” it is not clear, what the theoretical justification of it is. How do we know that the proposed artificial saturation could be generalised to other samples of data, beyond the use cases? \n5. Further to that, the paper claims black box optimisation approach but the tests have only been reported for  Inception v4 pretrained on ImageNet. Would It still work if we use something different from it? \n6. In a few qualitative examples given, the method is compared only to Integrated gradients. Is it possible to add a comparison with other methods,  e.g. Fong&Vedaldi[1] which is mentioned throughout the text as a closely related method?\n \n[1] Fong&Vedaldi (2018) Interpretable Explanations of Black Boxes by Meaningful Perturbation",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}