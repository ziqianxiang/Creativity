{
    "Decision": "",
    "Reviews": [
        {
            "title": "Attempt to solve GANs by ignoring the point of GANs.",
            "review": "Summary : The goal is the paper is to reparametrize the difficult min-max objective from generative adversarial networks into a single objective that can be maximized in the traditional way. The authors propose a method by which a single network can take the place of the two networks traditionally used (i.e. generator and discriminator).\n\nThe strong points of the paper are that it is attempting to simplify a relevant problem and that the paper itself is relatively straightforward in its structure.\n\nHowever, the central problem with this paper is that the authors do no appear to realize that there is no magic reformulation that converts a GAN min-max objective into a traditional one without making a lot of concessions or simplifying assumptions.\n\nThe paper is constructed in a way that make it seem like the authors found a simple solution that just involves an almost trivial reparametrization two neural networks as a single network. They relabel a few things, and then a simple maximization problem comes outs. This is highly suspicious, but the authors do not even seem interested to point it out, or to discuss what was lost in the conversion.\n\nThe paper presents this \"unified network\" as some function that basically does the work of the generator and discriminator, and does a kind of intelligent switching between the two. The authors even refer in Equation 6 to a kind of definition \"by parts\" in which the function F knows if it's supposed to act like a generator or a discriminator. Figure 1 also shows a sketch of this function having two separate ways in and two ways out.\n\nEquation 7 leads them to a formulation of the GAN objective where the min and max involve the *same* function F. This should be a dead giveaway about the problematic nature of this, but they reassure us by using a notation F* for an \"alias of F\". They later on use a certain method of holding one of the copies of F to have a frozen copy of the parameters (similar to Double Q-Learning in RL), which is interesting to consider. Also, the authors did not describe when they would want to update their F_bar. Is it at every update of theta?\n\nEquation 8 arrives as basically the sum of what would have been the two quantities to maximize in the original GAN updates. It contains three terms; the first two being what the discriminator wants to maximize in the traditional context, and the last one being what the generator wants to maximize. This feels really haphazard. Is it going to produce something plausible if you maximize it? Sure, it will probably land at some place where the generator is somewhat satisfied and so is the discriminator. Rolling the two networks into one does not solve the tension between the two networks. Again, this connects with main issue about this paper: the authors appear to fail to appreciate that a GAN objective is not the same as a loss to be minimized.\n\nThere are a motivating experiments in the paper that demonstrate that acceptable results can be achieved on MNIST and SVHN with this approach. These are good as a sanity check, but they do not really convince me beyond the fact it means that the authors implemented their method properly and that, as expected, it does something sane.\n\n\nSome typos or minor things :\n\nFigure 2 should say \"higher is better\" or something to that effect. Otherwise, we can always figure it out based on the fact that it's a negative lower bound, but it requires some extra thinking that is better spent interpreting the plots without second-guessing if higher is better. We're dealing with more than double negatives here : it's a lower bound, then it's the negative of that, but we want the lower bound to be larger (closer to +infinity), which means that we should want the values on the plot to be closer to -infinity ?\n\nThere's the word \"dag\" in a citation and it looks like a placeholder that's been forgotten.\n\nMissing a period at the end of the statement of Theorem 1. Please also find a way to squeeze that loose period in the first sentence of section 2.3.",
            "rating": "2: Strong rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "clearly below the threshold of ICLR",
            "review": "This paper proposes to train a multilayer perceptron (MLP) under the VAE or GAN framework. The same network has multiple roles: decoder and encoder in VAE and generator and discriminator in GAN. The results of the proposed method are comparable to the baselines. \n\nMotivation&Significance: \n\nI think this paper does not really propose a new framework but instead modifies the network architecture a little bit to play multiple roles in VAE and GAN. I didn't see any theoretical or empirical benefit of tieing the weights in these models. The motivation and significance of the paper should be substantially strengthened.\n\nClarity&Presentation:\n\nThis paper is poorly written and organized.  In section 2, F(z) = x, F(F(z))=z' implies that x and z share the same dimension, e.g. d, and then F should be a function from R^d to R^d right? However, in the last panel of figure 1, it seems that F can take both x and z as input. Then what is the dimension of the input of F? F should be formally defined.\n\nIn Eqn. (1) what does p_\\theta(z|x) mean? In the literature, it refers to the true posterior of the model distribution, then it is not a bound but an equation. If it refers to the \"posterior\" defined by F taking different inputs, then I think it can be viewed as a special \"variational distribution\" with tied weights to the model, right? What is a NON-VARIATIONAL lower bound? Besides, Sec. 2.1 should be a subsubsection under section 2.2. \n\nIn section 2.3, it is explicitly claimed that x and z share the same dimension. Clearly, this is another limitation of the method. So what is the benefit? I don't think simply tieing weights can significantly reduce the model size without harming the performance.\n\nI notice some typos and herewith a list.\ni) Eqn. (2) the second expectation should be over q_\\phi(z|x).\nii) In Page 2, \\hat z, \\hat z', z', and z are abused.\niii) All equations should be referred to as Eqn. (xxx).\n\nExperiments:\n\nWhere is the analysis of Fig. 2? Using a comparable number of parameters, I cannot see the benefits of the proposed method. What is your point? \n\nOverall, this is clearly below the threshold of ICLR. \n\n",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting idea but lacking essential contents",
            "review": "The authors propose to leverage the same neural network (with the same set of parameters) to build the decoder/generator and encoder/discriminator of a VAE/GAN. Several tricks are proposed to address related concerns, e.g., different output dimensions and ranges.\n\nThe idea is interesting. However, essential contents, including the underlying motivation or the convincing justification, are believed missing. Besides, the presentation is not in good shape (so many typos exist). Accordingly, I don’t think the current manuscript is ready for publication. \n\nThe main motivation of utilizing one shared network for both encoder and decoder is missing. No convincing justifications were given on why we should do this instead of utilizing two separate networks. I would suggest the author to elaborate on this. Also, it remains a question whether the shared network has enough model capacity.\n\nIn the second paragraph of Section 2, the definition of F() indicates that x and z should have the same dimensionality. However, as discussed below, x and z could have different dimensionality. So the definition of F() should be revised to remove the ambiguity. Also, what’s the meaning of the last sentence? It’s confusing.\n\nIn the paragraph below Eq (1), q_{\\phi} is introduced to approximate the optimal posterior, not \\theta^{*}. \"Classicaly’’ is a typo.\n\nEq (2) is wrong. Also, in Eq (3), what’s the definition of the subscript i?\n\nIn the paragraph before Eq (4), it’s clear from the definition of F_{\\theta} that both x and z are (conditionally) gaussian distributed. However, this might not be true as discussed below. Again, the definition of F() must be carefully revised.\n\nIn Algorithm 1, it’s not right that z is sampled from the prior. \n\nThe proof of Theorem 1, as well as the whole paper, doesn’t take into consideration the model capacity issue raised by sharing the same network for both encoder and decoder.\n\nIn the experiments, the detailed comparisons on trainable parameters of different methods are necessary, for example, in a table given in the appendix.\n\nI think the experiments might be a little weak. Since the model capacity is of concern, I think the proposed method should at least be tested on CelebA faces.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Simple approach to share encoder/decoder in a generative model, but limited experiments/results",
            "review": "-------------------------\nSummary\n-------------------------\nThis paper proposes to use one parameteric model for the encoder/decoder for learning deep generative models. The method works both for learning VAEs and GANs, and is found to perform on par with baseline methods across a range of toy image datasets. \n\n-------------------------\nStrengths\n-------------------------\n- Simplicity of the approach.\n- Reasonable performance against baseline models\n- Experiments on both VAEs/GANs.\n\n-------------------------\nWeaknesses\n-------------------------\n- This method only seems applicable to cases where the latent/output variables are both continuous, which limits its applicabilty.\n- Experiments are only conducted  with multilayer perceptrons, so it is not clear if the method will generalize to architectures such as CNNs or Transformers.\n- Experiments are only conducted on toy datasets and it is not clear to more complex image datasets or other modalities (e.g. text)\n- The writing and organization of the paper could be improved substantially. \n\nThere are additional many incorrect statements and typos, e.g\n- Equation (1) should be an equality of p(z|x) is the true posterior\n- Equation (2) should have the prior in the KL portion\n- \"It is of interest to perform a maximum likelihood estimation or maximum a posteriori...\": There is no prior on $\\theta$ so MAP inference here doesn't make sense \n\n-------------------------\nQuestions\n-------------------------\n- Have you considered an approach which only shares part of the encoder/decoder parameters? This may make it possible to deal with cases where (for example) z is continuous and x is dicrete.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}