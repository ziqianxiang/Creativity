{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper explores meta-learning of local plasticity rules for ANNs. The authors demonstrate that they can meta-learn purely local learning rules that can generalize from one dataset to another (though with fairly low performance, it should be noted), and they provide some data suggesting that these rules lead to more robustness to adversarial images. The reviews were mixed, but some of the reviewers were very positive about it. Specifically, there are the following nice aspects of this work:\n\nA) The meta-learning scheme has interesting potential for capturing/learning biological plasticity rules, since it operates on binary sequences, which appears to be a novel approach that could help to explain things like STDP rules.\n\nB) It is encouraging to see that the learning rules can generalise to new tasks, even if the performance isn't great.\n\nC) The authors provide some interesting analytical results on convergence of the rules for the output layer.\n\nHowever, the paper suffers from some significant issues:\n\n1) The authors do not adequately evaluate the learned rules. Specifically:\n\n- The comparison to GD in Fig. 2 is not providing an accurate reflection of GD learning capabilities, since a simple delta rule applied directly to pixels can achieve better than 90% accuracy on MNIST. Thus, the claim that the learned rules are \"competitive with GD\" is clearly false.\n\n- The authors do not compare to any unsupervised learning rules, despite the fact that the recurrent rules are not receiving information about the labels, and are thus really a form of unsupervised learning.\n\n- There are almost no results regarding the nature of the recurrent rules that are learned, either experimental or analytical. Given positive point (A) above, this is particularly unfortunate and misses a potential key insight for the paper.\n\n2) The authors do not situate their work adequately within the meta-learning for biologically plausible rules field. There are no experimental comparisons to any other meta-learning approaches herein. Moreover, they do not compare to any known biological rules, nor papers that attempt to meta-learn them. Specifically, several papers have come out in recent years that should be compared to here:\n\nhttps://proceedings.neurips.cc/paper/2020/file/f291e10ec3263bd7724556d62e70e25d-Paper.pdf https://www.biorxiv.org/content/10.1101/2019.12.30.891184v1.full.pdf https://proceedings.neurips.cc/paper/2020/file/bdbd5ebfde4934142c8a88e7a3796cd5-Paper.pdf https://openreview.net/pdf?id=HJlKNmFIUB https://proceedings.neurips.cc/paper/2020/file/ee23e7ad9b473ad072d57aaa9b2a5222-Paper.pdf\n\nAnd, the authors should consider examining the rules that are learned and how they compare to biological rules (e.g. forms of STDP), if indeed biological insights are the primary goal.\n\n3) The paper needs to provide better motivation and analyses for the robustness results. Why explore robustness? What is the hypothesis about why these meta-learned rules may provide better robustness? There is little motivation provided. Also, the authors provide very little insight into why you achieved better robustness and insufficient experimental details for readers to even infer this. This section requires far more work to provide any kind of meaningful insight to a reader. What was the nature of the representations learned? How are they different from GD learned representations? Was it related to the ideas in Theorem 4? Note: Theorem 4 is interesting, but only applies to a specific form of output rule.\n\n4) In general, the motivations and clarity of the paper need a lot of work. What are the authors hoping to achieve? Biological insights? Then do some analyses and comparisons to biology. More robust and generalisable ML? Then do more rigorous evaluations of performance and comparisons to other ML techniques. Some combination of both? Then make the mixed target much clearer.\n\n5) The authors need to tidy up the paper substantially, and do better at connecting the theorems to the rest of the paper, particularly for the last 2 theorems in the appendix. Also, note, Theorems 2 & 4 appear to have no proofs.\n\nGiven the above considerations, the AC does not feel that this paper is ready for publication. This decision was reached after some discussion with the reviewers. But, the AC and the reviewers want to encourage the authors to take these comments on board to improve their paper for future submissions, as the paper is not without merit."
    },
    "Reviews": [
        {
            "title": "Learning to learn... a reboot of an old idea.",
            "review": "The authors propose to encapsulate the update rule for a neural net into a look-up table specifying weight changes for each combination of \"pre-synaptic\" input to the weight, and \"post-synaptic\" activation of the unit receiving that incident connection. They learn the elements of this matrix by gradient descent, and then use that learned update rule to train neural nets on a new task. This is motivated by a separation of timescales biologically, wherein learning rules might be evolved over long timescales, and then act within each brain over shorter ones.\n\nThere is a nice discussion of related previous work, but it misses a few key items that, to me, diminish somewhat the novelty of this work. That's okay: being first isn't everything. But I think it is important to point out to readers what is new and better about this work vs previous work.\n\na) The auto ML zero paper from Quoc Le et al. (arXiv 2003.03384). They learn both architectures and learning rules via simulated evolution\n\nb) Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M. W., Pfau, D., Schaul, T., ... & De Freitas, N. (2016). Learning to learn by gradient descent by gradient descent. In Advances in neural information processing systems (pp. 3981-3989). They use GD to learn plasticity rules.\n\nc) A few recent papers on bio-plausible backprop-type algorithms.\ni)  Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits. Biorxiv: https://doi.org/10.1101/2020.03.30.015511 from Naud and colleagues\nii) Guerguiev, Jordan, Timothy P. Lillicrap, and Blake A. Richards. \"Towards deep learning with segregated dendrites.\" ELife 6 (2017): e22901.\niii) Sacramento, João, Rui Ponte Costa, Yoshua Bengio, and Walter Senn. \"Dendritic cortical microcircuits approximate the backpropagation algorithm.\" In Advances in neural information processing systems, pp. 8721-8732. 2018.\n\nAside from the relation to prior work, I have a few technical and conceptual questions / comments:\n\n1) Fig. 2: were all three nets given the same initialization? That could matter for comparing the training curves of accuracy vs. training time because a good initialization could give one learning rule an apparent advantage. And given the accuracy at t=0, it doesn't look like they are the same.\n\n2) I like that the authors studied generalization of the learned rule between tasks: that is important (although, SGD also generalizes well). I'm a bit less impressed by the performance obtained in the MNIST and fashion MNIST tasks. At the same time, using two-factor rules (update is a function just of pre- and post-synaptic inputs) to solve MNIST sounds hard given that there's no credit assignment signal. I think that the authors would be well served to read up on the papers on bioplausible deep learning, and consider variants of this work that include a credit assignment signal.\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Learning plasticity rules",
            "review": "Summary:\n\nThis is a fascinating paper which push the bounds of artificial neural network knowledge and understanding, while questioning the typical approach of considering various neural networks branches in isolation. Concretely, it shows that by using concepts from neuroevolution together with deep learning concepts, we can learn how to learn learning rules (i.e. plasticity rules) which can generalize across tasks and can train neural networks which are more robust to adversarial attacks than typical networks trained with stochastic gradient descent. \n\nStrong points:\n\n•\tIn my opinion, the paper is visionary. It answers few questions, while opening the path for a large number of new research directions and new unanswered questions.\n\n•\tThe paper has a very well-balanced content of novelty, math, computer science, neuroscience, and even philosophy.\n\n•\tThe paper is very well written and anchored in a multidisciplinary literature. It has the potential of becoming a “must read” paper in the future.\n\n\nWeak points:\n\n•\tThe datasets used, including MNIST and Fashion-MNIST are rather simple. It would be very interesting to see how the approach behaves on more complex datasets.\n\n\nDuring the discussion phase, I would recommend to the authors to address the following comments:\n\n1. In the limit of time, try to perform experiments also on CIFAR 10/100. I believe that it would be interesting to see on CIFAR 100, the behavior of three types of learned plasticity rules: (1) plasticity rules learned on the simple datasets, (2) plasticity rules learned on CIFAR 10, and (3) plasticity rules learned on a subset of the CIFAR 100 training set.\n\n2. Are you encountering problems with ReLU activation in recurrent networks such as exploding or vanishing weights? Does your approach work also with hyperbolic tangent?\n\n3. I believe that it would help the paper clarity if you can add a table towards the end of the paper to summarise the main results in terms of accuracy, training time, etc.\n\n4. Perform a proof-read of the whole paper to improve the English usage and the presentation. For instance: typos (e.g. “rule, The next theorem”), unit measures for axis labels (e.g. figure 5 – accuracy [%]), etc.\n \n\n\n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Well-written, exciting ideas, but lacking in experimental evidence",
            "review": "Summary:\n\nThis paper uses meta-learning to search for novel, local learning rules in artificial neural networks. This is done by parameterizing local learning rules for feedfoward and recurrent neural networks, then using mini-batch gradient descent to update the parameters of the learning rule.  The authors argue that this is a promising strategy for discovering the learning rules used by biological systems, with three main contributions: (1) they provide proofs that this approach does what we would hope it would do when applied to a single linear layer; (2) experiments demonstrate meta-learning for simple non-linear and recursive architechtures; and (3) the authors provide an argument that evolution could replace gradient descent as the method of searching over possible learning rules. The authors also show through experiments that models trained with these non-gradient methods are more robust to (gradient-based) adversarial attacks. \n\nOverall, I thought this paper was well-written and provided interesting arguments and proofs. However, the experiments are not enough to support the main claims, so I think this paper is borderline. \n\nPros: \n\nWhile the main idea of using meta-learning to search for new bio-realistic learning algorithms is not new, the particular formulation used here with recursive neural networks was new as far as I know, and I found this idea very interesting. Most of the work in this area has been focused on feed-forward networks, but as the authors emphasize, recurrent neural networks add a whole new dimension to the space of biologically-plausible, local learning algorithms. An example of such an algorithm is Recirculation, described in Hinton and McClelland 1987, \"Learning Representations by Recirculation\", which is closely related to Feedback Alignment (Baldi and Sadowski 2018, \"Learning in the machine: Recirculation is random backpropagation\"). \n\nCons:\n\nMy main criticism is that the experiments are not enough to show that the \"discovered\" learning rule does anything useful in the RNN. As the authors admit, one can achieve good performance in a multi-layer NN by fixing the random weights in the hidden layers and by training only the output layer. I would have really liked to see how the meta-learned algorithm compared to fixed, random representations. The experimental performance of the meta-learned algorithm on MNIST is quite poor (~80% test accuracy, Figure 3), so its unclear what is going on. \n\nThe results of the adversarial robustness experiments are not surprising. Adding additive or multiplicative noise during training will also make the trained networks more robust. It think these experiments actually distract from the main ideas of the paper. It would have been better to more carefully explore whether the learning algorithm can learn more difficult functions.\n\nSection 2 describes two possible alternatives for the plasticity rules: one that incorporates information about the error, and one that does not. I think it is important to highlight the fact that the latter is an unsupervised plasticity rule --- the meta-learning algorithm has access to the target output, but the local plasticity rule does not. So while a plasticity rule trained on Dataset 1 does have some information about the Dataset 1 targets (by way of the meta-learning updates), when it is applied to Dataset 2 it never receives any information about Dataset 2's target, and is thus unsupervised. This is an important distinction between the two approaches.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Nice new method for meta-training plasticity rules",
            "review": "This paper introduces a new method for meta-training plasticity rules, allowing networks to learn new instances of a given domain quickly and efficiently. The method consists in implementing plasticity as an arbitrary function of the past few timesteps of local activity at a synapse (input and output). Experiments show that the method finds reasonably successful rules, that these rules generalize across (some) domains, and that the learning seems more robust to (some) adversarial attacks than plain gradient descent.\n\nWhile meta-training plasticity rules is not new, I believe the method is novel and quite interesting. I also appreciate the experiments to demonstrate cross-domain generalization and robustness to adversarial attacks.\n\nA possible caveat is that the experiments, though diverse, are still a bit limited. The paper only uses relatively small feedforward networks and recurrent networks with only 3 timesteps. In terms of \"real\" datasets, only MNIST and Fashion-MNIST are considered. Similarly, the trained plasticity rule seems robust to a certain type of adversarial attack, but is it more robust to other forms of distortion - such as plain noise, deformations, etc. ? I suppose this is tolerable for an introductory paper.\n\nMinor comments: \n\n- Bengio  et al. 1992. “On the Optimization of a Synaptic Learning Rule.”, used gradient descent to meta-learn plasticity rules and should be included in the Related Work section. \n\n- Similarly, Metz et al. 2019: https://openreview.net/forum?id=HkNDsiC9KQ. \n\n- Sometimes, in the figures, it is not clear what exactly is shown. E.g. Which type of plasticity rule is used (network-based or lookup tables)? Also in Figure 4, how exactly are these image generated - what's the criterion for a sufficient error?\n\nSpeculative comment: IIUC, the networks in this paper are binary and can be seen as spiking networks.  Interestingly, the space of rules explored by this method seems to include standard models of biological plasticity, such as spike-timing dependent plasticity, as well as more complex \"triplet\" rules (see e.g. https://www.pnas.org/content/108/48/19383). There's probably some interesting work to be done in this direction (for future work of course, not for this introductory paper).\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}