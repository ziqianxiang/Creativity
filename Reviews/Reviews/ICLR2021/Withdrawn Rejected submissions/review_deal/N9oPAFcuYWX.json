{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This papers considers the problem of accuracy disparity in regression for the case of binary sensitive attributes. It provides bounds for accuracy disparity and introduces two methods to enforce this criterion based on representation learning. \n\nThe reviews are in agreement that the paper is generally clear and well written, but have different opinions regarding the significance of the contribution and the experimental section. I did read the paper with care myself and overall I do share the concerns raised by Reviewers 3 and 4 that the paper does not place itself accurately wrt to the current literature, both in the discussion and the experimental section. The response to the reviewers about methods that can achieve accuracy disparity for classification is not satisfactory, also considered that two of the analysed datasets are about binary classification tasks. Regarding the results on these datasets, it would be useful to report classification accuracy rather than (in addition to) R^2. \nThe proposed methods do not seem to show a significant advantage versus the methods considered for comparison.\n\nMinor comments:\nThe proposed methods are inspired by Theorem 3.2. However, is not enforcing accuracy disparity by minimising some distance between conditional distributions what the literature does? I cannot think of other meaningful ways to achieve this criterion. In fact, referring to this theorem, the authors says 'However, it is nearly impossible to collect noiseless data with group-invariant input distribution. Moreover, there is no guarantee that the upper bound will be lower if we learn the group-invariant representation that minimizes dTV(D0(X), D1(X)) alone, since the learned representation could potentially increase the variance. In this regard, we prove a novel upper bound which is free from the above noise term to motivate aligning conditional distributions to mitigate the error disparity'. But minimizing dTV(D0(X), D1(X)) might not be desirable if the dependence between the sensitive attribute A and the data is considered legitimate. The point of using conditional distributions is to allow that dependence to be retained. \n\n\n\n\n"
    },
    "Reviews": [
        {
            "title": "Overall, I vote for accepting. The discovery between accuracy parity and the distribution gaps across groups is interesting.",
            "review": "This paper theoretically and empirically studies accuracy disparity in regression problems. It proves an information-theoretic lower bound on the joint error and a complementary upper bound on the error gap across groups to depict the feasible region of group-wise errors. It further proposes to achieve accuracy parity theoretically and empirically by learning conditional group-invariant representations using statistical distances. \n\nOverall, I vote for accepting. The discovery between accuracy parity and the distribution gaps across groups is interesting.\n\nPros:\n    1. The paper provides a deeper understanding of the accuracy parity, which is interesting to me and motivates the proposed algorithms.\n\nCons:\n    1. The motivation for the studied problem is not very clear to me. I know the importance of both regression and accuracy parity. But why we want to consider the combination of these two notions? What is the main difference between considering classification with accuracy parity?\n    2. Page 4, Geometric Interpretation. Mention Theorem 3.3 by a mistake?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This work proposes an adversarial training procedure for reducing disparity in fairness of regression tasks. The main contributions are theoretical bounding the disparity using distance between label populations and conditional distributions. The bounds are used to motivate the adversarial training cost function. Overall the paper is well written and motivated. Experimental results are reasonable. I have a few comments in the following for clarification below.",
            "review": "1. Figure 1 (left) is illustrative and insightful. I suggest authors include a simulated/semi-synthetic dataset (semi-synthetic versions can be created using the datasets that are already being used for experiments) and show clearly that their adversarial training procedure is likely to learn hypothesis within the feasible region that guarantees or is close to minimizing the disparity. I think the cost function and training procedure will have additional grounding with such analysis.\n\n2. Missing citation - https://arxiv.org/abs/1901.10566 and comparison in related work.\n\n3. \"Nevertheless, throughout this paper we mainly focus accuracy parity as our fairness notion, due to the fact that three widely used commercial face recognition systems have been shown to exhibit substantial accuracy disparities between different demographic subgroups (Buolamwini & Gebru, 2018). This observation has already brought huge public attention (e.g., see New York Times, The Verge, and Insurance Journal) and calls for commercial face recognition systems that (at least approximately) satisfy accuracy parity\". I have concerns about this claim in the paper. The takeaway of highlighted problems with commercial face recognition is not that that the methods will be ready for practical use by ensuring approximate accuracy parity. I suggest the authors remove this motivation as facial recognition as a system is fraught with many other societal challenges that cannot be resolved by ensuring parity of performance. \n\n4. Please be more elaborate in proofs in the appendix rather than having the reader fill in many gaps. \n\n5. What is the sensitivity of regularization to performance and how was the parameter selected?\n\n6. Minor - \ntypos in appendix:\n1.  \"follows immediately the triangle inequality and Lemma\" in proof of Thm 3.1\n2.  \"Now it is suffice to bound the term\" proof of Thm 3.3",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good result and writing but better differentian to fair representation in classification is needed.",
            "review": "This paper has two parts: (i) in the first part the authors provide an upper and a lower bound for error disparity among groups in the regression setup. (ii) In the second part, they propose an adversarial learning method to mitigate the disparate error among groups. Mainly they focus on reducing the error disparity by reducing the distance between the joint distribution of Z (the new learned representation) and Y between the two groups. The paper was finely written, and it was interesting. I will address my concerns regarding this paper as follows:\n\nFirst part: \n\nI did not understand the importance of Theorem 3.1 the lower bound is dependent on the classifier (thus is not inherent) and the authors only focused on the first term and did not talk about the second term.\n\nRelated work: There is some related work after Chen 2018 paper which focuses on understanding the source of error disparity among groups (e.g., https://proceedings.icml.cc/static/paper_files/icml/2020/1320-Paper.pdf which also points out the difference between the distribution of the groups or https://arxiv.org/pdf/1906.08386.pdf ). I think the authors should explain the other work on understanding the source of error disparity.\n\n\nSecond part:\n\nMy main concern regarding this part is that I feel like the authors did not place their work accurately among the related work for the fair representation part. In particular, why we cannot readily use Madres 2018 approach for the regression task. I think the authors should explain why the regression setup provides new challenges on fair learning in comparison to the classification setup. In the experiment section, for the binary datasets do we get the same result as this paper if we use the fair representation methods in classification? What is inherently different here. \n\n\nMinor suggestion: I got a bit confused about equation 3, you wrote that the signature of f is Z-> R but it seems that you are trying to minimize joint distribution. I think instead of the game-theoretic interpretation (which is kind of clear) if you can expand on this and why the optimization is easier is better. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Weak theoretical results and suspicious experimental results",
            "review": "This paper deals with a fair regression problem in which the accuracy disparity is employed as a fairness measure. The authors derived the upper and lower bounds on the difference of accuracy between groups to demonstrate that imbalance in the groups' sizes leads to accuracy disparity. Furthermore, they propose learning algorithms enabling us to mitigate the accuracy disparity, which is accomplished by minimizing the upper bound they derived. The empirical evaluations show that the present methods achieve a better trade-off between accuracy and fairness than some existing fair regression methods.\n\n\nThe strong points are as follows:\n- The authors tackle an important and interesting problem, disparate mistreatment in the regression problem, which is not much investigated so far.\n- The authors give some theoretical insight into the hypothesis that the imbalanced groups lead to unfairness by ignoring the minor group.\n\nThe weak points are as follows:\n- The theoretical results are somewhat weak to support the claim that the imbalance groups lead to the accuracy disparity.  \n- This paper lacks a comparison with some important existing methods that share the same concept for mitigating unfairness.\n- There is something suspicious in the experimental results.\n\nOverall, my recommendation is rejection because the theoretical and experimental results are somewhat weak to support the authors' claims. Also, I have concerns that the experimental results are something wrong.\n\nThe theoretical contribution the authors claim to make is to clarify the cause of the accuracy disparity. The cause here is the imbalance in groups, as discussed in the geometric interpretation paragraph on page 4.  Theorem 3.1 and Theorem 3.2 give insight into the authors' claim; however, they are slightly weak to support the statement that the group imbalance yields accuracy disparity. Because Theorem 3.1 and Theorem 3.2 only provide the upper and lower bounds, the feasible region can be an arbitrary shape in the green area in Fig. 1. The possibility remains that the actual feasible region is cone-like shape such that its apex is on the diagonal line. In this case, the minimization of the overall error can result in matched accuracy. Indeed, there is a counterexample of the claim. Suppose the hypothesis class consists of functions that output a constant, and the conditional variances $\\mathrm{Var}[Y|A]$ are equivalent for any $A$. Then, the optimal regressor, which minimizes the overall mean squared error, achieves the matched accuracy because $\\mathrm{Err}_{\\mathcal{D}_a}= \\mathrm{Var}[Y|A=a]$ in this case. I guess some assumptions on the hypothesis class and underlying distribution are necessary to prove the authors' claim. \n\nThe authors design the proposed algorithm to match the distribution over the representation conditioned on the true outcome and sensitive attribute. This requirement is equivalent to the equalized odds. There are several works for tackling the fair regression under the equalized odds constraint, including \n- J. Mary et al. Fairness-Aware Learning for Continuous Attributes and Treatments. In ICML'19.\n- H. Narasimhan et al. Pairwise Fairness for Ranking and Regression. In AAAI'20. \nSince these methods' design concept is equivalent to the presented one, the authors should clarify their method's merits compared with these existing methods.\n\nI'm very suspicious about the experimental results of BGL and CoD. We can find in the original papers of BGL and CoD that these methods can achieve $R^2$ from 0.32 to 0.64 in the crime dataset by choice of their hyperparameters. These values are calculated by my hand from the MSE shown in these papers using the relationship $R^2 = 1 - \\mathrm{MSE} / \\mathrm{Var}[Y]$. However, in the experimental result shown in Fig. 2 (c), the values of $R^2$ for BGL and CoD are at most 0.55. \n\nIn Section 4.2, the authors claim that Fig. 2 shows that trade-offs exist between accuracy and fairness. However, I cannot find such an inclination from Fig. 2. \n\nIt is unclear that the presented methods can achieve a better fairness-accuracy trade-off than the existing fair representation methods. The fair representation methods may work in the regression setting with small modifications, even if the original ones are designed for the classification setting. Hence, these methods can apply to this paper's setting.\n\n### Minor comments\n- Why are the Game-Theoretic Interpretation helpful? Why can we obtain new insights by interpreting the Eqs. (1) and (3) in a game-theoretic manner? I cannot find any new insights from the game-theoretic interpretation.   ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}