{
    "Decision": "",
    "Reviews": [
        {
            "title": "Interesting blend of VI and MCMC, but suffers from complexity, clarity issues, a possible correctness issue, and underwhelming experiments",
            "review": "Review Summary\n--------------\n\nOverall I think this is a paper that has some nice ideas, but just doesn't have the experimental results or conceptual story to make a convincing case to the reader at present. The technical approach seems new, but I have some technical confusion about why a key optimization step in Eq 6 is correct and overall presentation quality concerns that the high-level story gets lost amid many details. I further worry about significance: seems most beneficial in cases where data augmentation techniques are known already (and thus a reader will ask why not just use a Gibbs sampler?), and that the method's complexity will hinder widespread adoption.\n\n(There's a chance I'll be persuaded by a careful rebuttal, as I may have misunderstood some parts like Eq 6.)\n\n\nPaper Summary\n-------------\nThe paper presents a new method -- MCMC interactive variational inference (MIVI) --  for posterior approximation that benefits from the strengths of MCMC and variational inference.\n\nThe key idea is to imagine that posterior *samples* can be obtained in two steps:\n* Using a tractable density family q with parameter \\phi, produce a good initialization z_0 ~ q_\\phi\n* Evolve T steps forward, from z_0 to z_T, using a Markov chain with transition distribution h_\\eta with parameters \\eta\n\nThe claimed contribution is that the parameters involved in the approximation (\\phi and \\eta) can be efficiently optimized using a standard \"ELBO\" variational bound objective in Eq 3 (broken into more tractable coordinate ascent problem in Eq 4-6) to avoid challenging joint optimization of variational and generative parameters. Interestingly, to avoid a problematic KL term they replace the KL with a separately estimated \"discriminator\", inspired by previous work by Mescheder et al 2017.\n\nThe method requires that both the base distribution q_\\phi and the MC transitions h_\\eta are *reparameterizable*, so that we can compute gradients of expectations using the reparameterization trick.\n\nTwo possible ways of constructing the transition distribution h are provided:\n* 1) One based on Langevin dynamics, where \\eta defines the (learnable) step sizes\n* 2) One based on Gibbs sampling taking advantage of tractable conditionals in the true posterior, where \\eta defines parameters of an (approximation to) the Gibbs conditional\n\nA key feature of both approaches is that each can be \"extrapolated\" beyond the required T steps to improve the posterior approximation even further.\n\nThe key hyperparameters of the procedure seem to be an integer T, which is the number of Markov transitions using the h_\\eta kernel\n\nExperiments assess the proposed posterior approximation technique in several ways:\n\n* Sec 4.1 has Qualitative comparisons to mean-field VI and gold-standard Gibbs sampling on a Negative Binomial dataset\n* Sec. 4.2 has Qualitative comparisons to a Polya-Gamma augmentation of Bayesian Logistic Regression\n* Sec. 4.3 looks at sampling weight coefficients in bridge regression under various L-norm penalities on the weights\n* Sec. 4.4 looks at variational autoencoders, and compares to several previous methods in terms of importance sampled bounds on marginal likelihood\n\n\nStrengths\n----------\n* The core idea is natural and straightforward: warm-start with fast variational approximations to the posterior, and then sample T further steps using an MCMC transition kernel (based on Gibbs or SGLD)\n* There is useful effort to decompose the optimization objective from a challenging joint optimization (where all parameters are updated simultaneously via gradient methods) to one that takes more advantage of substructure.\n* I like the effort to balance qualitative and quantitative experiments\n* I like the revival of interest in Gibbs sampling methods when applicable, it's a nice approach (if involved).\n\nWeaknesses\n----------\n* The derivation of Equations 4-6 which define the method's core optimization problem needs far more justification, esp. Eq 6\n* Not clear to reader when to prefer each of the MCMC transitions covered here (SGLD or data augmentation Gibbs sampling). In a way it is like the paper presents two separate methods, with no lessons learned about when each would be preferred for a specific model.\n* Lack of comparison to \"modern\" flexible MCMC methods like HMC or NUTS (couldn't we use such methods easily for bridge regression results in Fig 2 b and c? with much less derivation effort than required for MIVI?)\n* The application of the Gibbs sampling method seems to rely on knowing some useful data augmentation techniques for the problem at hand (e.g. the Polya gamma techniques in Sec 4.2 or the scale mixture of normals in Sec 4.3). Thus, the applicability of the Gibbs sampling MIVI technique may be limited to cases where such augmentations are available.\n\nSignificance and Novelty\n-------------------------\nThe paper addresses some core problems in developing fast but effective approximate posteriors.\n\nIn considering significance, I think the paper might provide a useful tool for specialized cases when data augmentation techniques are known to be relevant, however in general the procedure is rather involved with at best modest gains compared to simpler approaches. Unfortunately, I think its complexity will somewhat hinder widespread adoption.\n\nIn my view, I do think the method has the required novelty for a venue like ICLR. However, I would note that while the paper claims to be the \"first\" to combine VI and Gibbs sampling, there are other papers that have used Gibbs sampling within VI for latent variables models like LDA, for example see Alg. 1 of:\n\nSparse stochastic inference for latent Dirichlet allocation\nMimno, Hoffman, and Blei 2012\nhttps://arxiv.org/ftp/arxiv/papers/1206/1206.6425.pdf\n\nThe details are certainly different than the present paper (which uses a Gibbs conditional as a parameterizable part of the variational distribution), but still useful to know about another prior work that combines Gibbs and VI.\n\n\nTechnical Concerns\n------------------\n\n## T1: Why is Eq 6 correct?\n\nEq 6 describes how to set the variational parameter \\phi, but surprisingly this optimization problem in Eq 6 only contains an expectation involving \\log q_{\\phi}. Earlier in the (ideal but more difficult) objective in Eq 3 it is clear that \\phi impacts the sample z used in several other terms, including the generative joint \\log p_\\theta(x,z) as well as the discriminator term D(z). Why aren't these terms used to update \\phi?\nPerhaps I am missing something, but more clarity is needed. \n\n\nExperimental Concerns\n---------------------\n\n## E1: Missing study of sensitivity to hyperparameter T \n\nThe choice of the number of h transitions (integer T) matters to performance. Would be nice if the NB example in Figure 1 or some other example helped the reader understand the impact of this choice. Is T=5 or T=10 always \"good enough\"? Or if we set T larger can we get more accurate posteriors (at cost of increased runtime)? Please help the reader understand tradeoffs here.\n\n\n## E2: Why not use Hamiltonian MCMC for bridge regression in Fig 2b or 2c\n\nSeems like with the bridge regression example the authors are trying to advocate that their method can handle \\alpha values like 0.5 or 1.5 that do not have a valid Gibbs sampler. However, can't we compute derivatives of the log joint pdf here? Thus, wouldn't it be easy to develop an HMC sampler (or NUTS sampler) for this problem? This way could use off-the-shelf toolboxes like Stan or PyMC to develop an *exact* sampler and not need to derive auxiliary sampler steps in the proposed MIVI. Perhaps there are problems with this approach (speed? convergence issues?), but I think a bit more is needed to convince readers that the conceptual effort required for this technique is worth it here.\n\n\n## E3: Advantages of the method relative to Gibbs sampling are not presented\n\nThe experiments show how the proposed MIVI can recover posteriors that are \"close to\" the result of Gibbs sampling.\nHowever, if we already have a reliable method (Gibbs sampling), what is the purpose of the new technique? It might be argued to be faster in some cases or have other desireable properties, but the experiments in Sec 4.1 and 4.2 do not really sell the reader on any advantages of MIVI relative to Gibbs.\n\n\n## E4: VAE experiments on MNIST underwhelming\n\nIn the VAE experiment, the presented method is compared to several other methods (e.g. standard VAE from Kingma & Welling, DSIVI from Molchanov et al AISTATS 2019, VCD from , etc.). The improvement in MNIST performance is rather small, especially considering since other work such as DSIVI gets better performance than any reported here just by making the encoder and decoder use 300 units rather than 200 units as used here (e.g. they get better than âˆ’82.3 while this paper reports -83.0 as the best of this method's results. Given the complexity of the presented method, it is not clear that it is worth it here.\n\n\n## E5: VAE experiments on fashionMNIST need more rigor to be decisive\n\nThe fashion MNIST experiment is potentially more interesting, but overall its a bit unclear if the improvement is truly due to the new method presented here, or due to other factors (e.g. local optima or choice of hyperparameters). VAE objectives are quite difficult to optimize. I'd like to be more sure that at least a few other methods presented here were treated rigorously (e.g. taking the best run (on train or validation) of multiple randomly initialized runs, allowed to optimize as many hyperparameters as MIVI was, etc.)\n\nAlso, why use stochastic binary images for MNIST, but a deterministic threshold for fashionMNIST?\n\n\nPresentation Issues\n-------------------\n\n## P1: Collision of notation in the SGLD presentation\n\n\\eta is defined in Eq 4-6 as the parameter of the transition distribution. Later in Eq 7 \\eta_t (with subscript t) is denoted as a step size at a specific discrete time t in the chain. It is not clear until several paragraphs later that these are meant to be the same variable. It would help if as soon as the ideas in the SGLD are introduced, you remind the reader that even though \\eta is a step size (and thus not usually thought of as a learnable parameter), that it is the parameter of interest. I'd further recommend reminding the reader how \\eta is reparameterizable in this case e.g. (by drawing epsilon from a standard normal and then multiplying by \\eta).\n\n\n## P2: Explanation of Polya-Gamma model for Bayesian linear regression needs some clarity\n\nOn page 6, the explanation of Bayesian logistic regression using a PG augmentation felt rushed and cramped. I had to reread several times to try to make sense. Here are some key questions outstanding:\n\n* What does it mean to have an estimated posterior of \\beta and \\omega \"averaged over data\"?  Don't we condition on data in a posterior?\n* Why, if covariates x1 and x2 have a negative correlation in \\Sigma, should we expect a positive correlation in their weights \\beta?\n\n\n## P3: Missing guidance about which MCMC transition to use\n\nThe proposed MIVI can use two kinds of MCMC transitions. Seems like the SGLD approach is more \"universal\", while the Gibbs approach might be possible when data augmentation works. I'd like to see a side-by-side comparison of both for the same model, or at least some general guidance about when it is expected that the effort to develop a Gibbs approach is worth it.\n\n\n\nMinor Presentation Issues\n-------------------------\n\npage 7: I'm confused by \"... the point estimates of \\beta resulting from MIVI\"... don't you learn a posterior over \\beta? How do you get a point estimate?\n\nTable 1 caption should make clear what performance metric is reported here.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Some issues",
            "review": "The paper concerns with using outputs of MCMC as a variational approximation in Variational Inference and seeks to optimize both the MCMC kernel and the initial point distribution with gradient descent. This is an interesting area of research that has seen much progress recently.\n\nUnfortunately, I have some issues with the paper.\n\nFirst, it appears that the approach of (Mescheder et al., 2017) is applicable and the elaborated tri-level optimization in formulas (4-6) is not necessary. The core observation is a well-known observation that $\\mathbb{E}\\_{q\\_\\Omega(z)} \\nabla\\_\\Omega \\log q\\_\\Omega(z) = 0$, which means one does not need to pay attention to how ELBO's log p(x,z)/q(z) depends on variational parameters, only its dependence on the latent variable z matters, which can be captured by the optimal discriminator: \n$$\n\\begin{align*}\n\\nabla\\_\\Omega & \\mathbb{E}\\_{\\tilde{q}\\_\\Omega(z)} \\log \\frac{p(x,z)}{\\tilde{q}\\_\\Omega(z)} \\\\\\\\\n= & \\\\;\n\\mathbb{E}\\_{q(\\varepsilon)} \\left[ \\nabla\\_z \\log \\frac{p(x,z)}{\\tilde{q}\\_\\Omega(z)} \\Bigr|\\_{z=g(\\varepsilon; \\Omega)} \\nabla\\_\\Omega g(\\varepsilon; \\Omega) \\right] - \\underbrace{\\mathbb{E}\\_{\\tilde{q}\\_\\Omega(z)} \\nabla\\_\\Omega \\log {\\tilde{q}\\_\\Omega(z)}}\\_{=0} \\\\\\\\\n= & \\\\;\n\\mathbb{E}\\_{q(\\varepsilon)} \\left[ \\nabla\\_z \\log \\frac{p(x,z) q\\_\\Omega(z)}{q\\_\\Omega(z) \\tilde{q}\\_\\Omega(z)} \\Bigr|\\_{z=g(\\varepsilon; \\Omega)} \\nabla\\_\\Omega g(\\varepsilon; \\Omega) \\right] \\\\\\\\\n= & \\\\;\n\\mathbb{E}\\_{q(\\varepsilon)} \\nabla\\_z \\left( \\log \\frac{p(x,z)}{q\\_\\Omega(z)} - \\underbrace{\\log \\frac{q\\_\\Omega(z)}{\\tilde{q}\\_\\Omega(z)}}\\_{=D^*(z)} \\right) \\Bigr|\\_{z=g(\\varepsilon; \\Omega)} \\nabla\\_\\Omega g(\\varepsilon; \\Omega) \\\\\\\\\n= & \\\\;\n\\mathbb{E}\\_{q(\\varepsilon)} \\nabla\\_\\Omega \\left( \\log \\frac{p(x, g(\\varepsilon; \\Omega))}{q\\_{\\Omega'}( g(\\varepsilon; \\Omega) )} - D^*( g(\\varepsilon; \\Omega) ) \\right)\n\\end{align*}\n$$\nWhere g(Îµ; Î©) is assumed to be the reparametrization of $\\tilde{q}_\\Omega(z)$ and $\\Omega'$ means $\\Omega$ that does not pass gradients (`stop_gradient` or `detach`).\n\nAnother issue is some misleading statements. Lemmas 2 and 3 refer to a Gibbs sampler, which provably moves chain distribution towards the distribution of interest. However, in the last paragraph of section 2.2. authors suggest to use learnable functions $h^{(1)}(w|z, x)$ to approximate Gibbs updates in a reparametrizeable way (setup used in 4.2 and 4.3). The resultant scheme is not a Gibbs sampler and would probably require an accept-reject step to ensure convergence to the target distribution, but will make the whole procedure non-reparametrizeable. Next, the SGLD discussion assumes diminishing discretization steps, but I don't think such SGLD kernel would have the posterior density as the invariant distribution at every finite timestep t. As I understand, SGLD with diminishing step sizes only guarantees that this holds in the limit of t â†’ âˆž. Hence Lemmas 1-3 are confusing: they seem to imply that performing several finite MCMC steps can only improve posterior approximations, but the particular choices used in the paper do not guarantee this.\n\nExperiments in sec. 4.2 and 4.3 seem to use weak baselines. Can one use other methods such as VCD or VIS, perhaps without augmentation? Another important question is how long it takes to generate samples and whether specialized hardware such as GPU are required? It the proposed scheme is more computationally demanding, one needs to clearly show why such scheme is still beneficial.\n\nRegarding experiments with VAEs (sec. 4.4): first, it is my understanding that (Sobolev & Vetrov, 2019) have improved upon (Yin & Zhou, 2018) with a tighter bound. It appears to me that such bound can be beneficial both during training (and lead to improved likelihood and thus be a stronger baseline) and testing (to get better estimates of the likelihood). More importantly, MCMC methods are sequential, whereas SIVI and related methods are embarrassingly parallel and thus are better able to take advantage of modern hardware. Thus special care is needed to ensure fair comparison: number of samples K in SIVI has to be adjusted s.t. the total computation time of MCMC-based and SIVI-like methods is approximately the same. Unfortunately, the paper does not report run times in its current form.\n\nOverall, I have to recommend to reject this submission in its current form. I see the paper as more of a case study of techniques proposed by (Mescheder et al., 2017) applied to certain transformations that are meant to approximate MCMC, but lack guarantees thereof. While such study might present certain interest in itself the present description appears unnecessarily complicated, misleading and lacking a proper evaluation.\n\nReferences:\n1. (Mescheder et al., 2017):  Adversarial variational Bayes: Unifying variational autoencoders and generative adversarial networks, http://proceedings.mlr.press/v70/mescheder17a.html\n2. (Sobolev & Vetrov, 2019): Importance Weighted Hierarchical Variational Inference, http://papers.neurips.cc/paper/8350-importance-weighted-hierarchical-variational-inference\n3. (Yin & Zhou, 2018): Semi-Implicit Variational Inference, http://proceedings.mlr.press/v80/yin18b.html",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Theoretical guarantees not as strong as the paper claims",
            "review": "Summary\n\nThis work proposes a variational inference (VI) algorithm called MCMC-interactive VI (MIVI). The main idea is to run an MCMC or stochastic gradient Langevin dynamics (SGLD) algorithm targeting the posterior distribution of interest. The marginal distribution of the $T$th step of the Markov chain induced by one of these algorithms is then used as the variational distribution. This is motivated by the fact that as T increases, this marginal distribution converges to the posterior distribution, thus removing the bias of VI.\n\nUnfortunately, the time-$T$ marginal distribution of is typically intractable. To circumvent this problem, the authors propose to approximate the ratio of the densities of the marginal and initial distribution of the Markov chain via a standard discriminator approach.\n\n\nStrengths and novelty\n\nUsing MCMC algorithms to facilitate variational inference seems sensible, especially given the better performance of (suitably scaled) MCMC kernels in high dimensions compared to other Monte Carlo methods such as importance sampling. The algorithm presented in the paper appears to be novel.\n\n\nWeaknesses\n\nAre the assumptions of Lemma 1 really satisfied by SGLD? I don't see why the Markov chain induced by SGLD would have the posterior of interest as its stationary distribution, even if the step sizes are appropriately annealed.\n\nMore generally, the paper makes several strong claims of \"fast posterior simulation\" and \"guaranteed superiority of $\\tilde{q}_{\\eta, \\phi}^{(t)}$ over $q_\\phi$\". However, the results stated in Lemma 1 to 3 could be seen as motivation for the proposed approach but do not constitute rigorous theoretical guarantees for the actual algorithm.\n\nFinally, it is not clearly justified why we can use samples from all $T$ iterations (instead of just the samples from the $T$th iteration) to estimate the gradients. Since the marginal distribution of the Markov chain is different for each time $0 \\leq t \\leq T$, using samples from all $T$ time steps would seem to add an additional layer of approximation compared to the objective stated in Equations 4--6. It would help to move Algorithm 1 (and any mention of practical approximations needed to make the algorithm work in practice) into the main body of the paper.\n\n\nMinor comments\n\n- MCMC SGLD and VI are not proper nouns (i.e. it should be \"MCMC algorithms\" instead of \"MCMCs\")\n- P. 1: what does \"$$q(z)-mixed Markov chain\" mean?\n- P. 2: two-way -> two\n- P. 2: by (richly) ... functions -> by a (richly) ... function\n- P. 2: \"inspirition-driven designs\"?\n- P. 2: because marginal -> because the marginal\n- P. 3: \"are variables on a Markov chain\" sound grammatically incorrect to me\n- P. 4: markov -> Markov",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review MCMC-Interactive Variational Inference",
            "review": "Summary: The paper 'MCMC-Interactive Variational Inference' provides a method for combining MCMC transitions with variational inference for approximating the posterior distribution. \nThe suggested approach is based on introducing a parametrised version of the MCMC transition kernel that is optimised using the ELBO as well as a discriminator-based framework following Mescheder et al. (2017). The presented paper introduces a series of theoretical results in order to justify the improvement brought by combining MCMC and VI and sits well in a series of other work on this topic. However, the presentation of suggested approach is sometimes contradictory and needs improvement. The presented experiments are lacking robust comparisons (i.e. runtime, complexity and comparisons with other state of the art methods like HMC) and are not convincing compared with standard approaches (see for instance Section 4.1. where the posterior is not correctly recovered). I think ultimately the paper merits publication but in the current form the paper does not meet the bar. The structure and writing of the paper also need improvement. \n\nIntroduction:\ncan used -> can be used\n\nExperiments:\nI am missing a comparison with more recent sampling schemes like HMC based samplers. \n\nSection 4.2 Bayesian logistic regression\nI am missing a comparison in terms of the runtime of the respective methods. How much more expensive is MIVI in comparison with the suggested data augmentation scheme?\n\nSection 4.4. VAE\nThis section provides an extensive comparison to other approaches, but it reads like a literature review and it I would suggest to use the available space to explain the evaluation methodology and the results. Also, I am missing results on the uncertainty (i.e. variance) of the presented results. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}