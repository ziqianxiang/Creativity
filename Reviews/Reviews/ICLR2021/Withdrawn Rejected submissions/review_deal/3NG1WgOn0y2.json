{
    "Decision": "",
    "Reviews": [
        {
            "title": "An interesting idea to represent areal spatial data, however the limited application and over-simplified building reconstruction seem to make the paper less contribution.",
            "review": "This paper presents a new representation for areal spatial data and introduces an encoder-decoder network for spatial data generation.\nPros:\n+ Presents a new tree structure to represent spatial data and encodes this structure to network.\n+ Experimental results show the ability of the network to encode the structured representation.\n\nCons:\n- I don't really see the user cases of this research. To me, this paper is more like an application of the encoder-decoder network. The novel part is the representation of areal spatial data. I'm not sure where the network will be used on.\n- The assumption of using cuboid to represent building seems to over-simplify the problem. It would be nice to see buildings generation with other representation.\n- For the generation part, why isn't variational auto-encoder used? How will that compare to GMM?",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Some key references are missing.",
            "review": "This paper presents an interesting tree-based deep auto-encoder network for generating areal spatial data. However, the authors have failed to compare with some key/strong baselines such as LayoutGAN[1] and LayoutVAE[2], which can be easily adapted to synthesizing graphic layouts comprised of 2D/3D box sets . In this regard, some critical comparisons are missing in the paper such that the current experimental results seem not to be that convincing.\n\n[1] LayoutGAN: Generating Graphic Layouts with Wireframe Discriminators, ICLR 2019 \\\n[2] LayoutVAE: Stochastic Scene Layout Generation From a Label Set, ICCV 2019\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Very similar prior work omitted",
            "review": "This review proposes an autoencoder architecture, with a GMM on the latent space for generation, for encoding and decoding trees representing 2.5D spatial layouts of cuboids. The encoders and decoders are recursive neural networks with MLPs or LSTMs as the recursively applied merge/unmerge kernels. The authors apply their architecture to generating cityscapes with each cuboid representing a local cluster of buildings standing on (and rotated on) a ground plane.\n\nWhile I think the work is largely technically ok (though I'm not sure about some details such as the use of an LSTM for encoding just two feature vectors instead of a longer sequence -- and does this also imply P and F have to have the same dimensionality?), the authors appear unaware of extremely similar related work in the graphics literature. Spatial recursive neural networks for 3D and 2D layout synthesis, as in this paper, have been studied in e.g. the following papers:\n\nLi et al., \"GRASS: Generative Recursive Autoencoders for Shape Structures\", SIGGRAPH 2017.\n\nZhu et al., \"SCORES: Shape Composition with Recursive Substructure Priors\", SIGGRAPH Asia 2018.\n\nLi et al., \"GRAINS: Generative Recursive Autoencoders for INdoor Scenes\", ACM Trans. Graphics 2019.\n\nMo et al., \"StructureNet: Hierarchical Graph Networks for 3D Shape Generation\", SIGGRAPH Asia 2019.\n\nGadi Patil et al., \"READ: Recursive Autoencoders for Document Layout Generation\", CVPR 2020 Workshop on Text and Documents in Deep Learning Era.\n\nThe authors will note that these works bear strong resonances to the current paper. Indeed, they are rather more sophisticated in different ways, such as not assuming a single encoding hierarchy per layout is available at training time, applying adversarial losses to improve output quality, modeling different types of binary and n-ary relationships with different encoder/decoder kernels and learning to select between them, etc.\n\nLastly: please keep the exposition gender-neutral. \"Child/father\" is better (and more standardly) written as \"child/parent\".",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Lack of Technical Contributions and Inadequate Comparisons Against Prior Works",
            "review": "=====Summary=====\n\nThis paper proposes a method to represent and generate aerial spatial data of cities, represented as a collection of 3D oriented bounding boxes of individual buildings. The key to the method is a binary-tree-based hierarchical representation of the buildings, extracted via heuristics focusing on location, shape, pose and compatibility. Using this representation, the authors design a tree-structured recursive autoencoder that learns from a novel dataset of city buildings. A Gaussian Mixture Model is then fitted to the latent space of the autoencoder to allow the generation of novel aerial layouts. The authors demonstrate that the proposed method can encode the buildings accurately, and that the fitted generative model performs better than a few simple baselines. \n\n=====Strengths=====\n- Introduces a new relatively novel task for 3D deep learning and collected a novel dataset, which requires a decent effort of pre-processing, for this task (Section 4.1).  \n- It is also quite nice that the proposed method can work on a hierarchy that is larger than those seen in works on related topics\n\n=====Weaknesses=====\n- Missing *a lot* of related works. The paper claims that “there exist two major strategies, set-based or sequence-based…” (Section 1, page 2). To my understanding, this claim is incorrect. There exists a lot of work, both 2D and 3D, that focuses on the structure of the objects and/or uses a hierarchical representation e.g. [1]-[4]. Although these works target slightly different domains, the underlying representation (oriented bounding boxes) are similar enough to warrant comparisons.\n- Following the previous point: the novelty of this paper is very limited after factoring in all the missing related works, since those works all argue that spatial hierarchy is important.\n- The comparisons are inadequate. 1. the baselines are too weak as none of them are designed to specifically handle oriented bounding boxes. Even if comparisons against works such as [1]-[4] can’t be made, I would at least want to see comparisons against “sequence-based” models that directly outputs OBBs. 2. I don’t think the tasks is different enough that the authors can’t compare the models on a more standard dataset e.g. PartNet/StructureNet. \n- I am not convinced by the quality of the generated samples, as none of the metrics here provides a convincing signal that the method can generate outputs with similar to the dataset, and is not memorizing the inputs. Some experiments that can show that: 1-NN accuracy [5], 2AFC perceptual study, qualitative comparisons to nearest neighbor in the training set, and more qualitative examples in general.\n\n=====Reasons for Score=====\n\nAlthough the work touches on an interesting new application, my general sentiment is that this task is not different enough from similar tasks to warrant the evaluation strategy chosen in the paper i.e. simple baselines. There are enough works using similar hierarchical representation and I think the benefits and novelty of the particular method proposed here is unsubstantiated without fairer comparisons. I would argue against this paper.\n\n=====Additional Comments & Questions=====\n\nIn addition to the questions I mentioned in the weaknesses section:\n- Why restrict the hierarchical structure to a binary tree? I would imagine that many building cluster can be represented more naturally with higher degrees, and there exists many viable aggregation functions to handle multiple child nodes (with the SUM used here as one of them) during encoding and one can implement the decoder as an RNN or a decoder with fixed amount of child nodes + a boolean value indicating presence of each node, etc.\n- How exactly is LSTM used to implement f_e?\n- What is F_l for the leaf nodes?\n- If seems that the decoder used here is sensitive to ordering. Will that cause any problems?\n- What is the motivation of training an autoencoder and then fitting a GMM? It seems to me that it would be much more natural to use a VAE here. \n- 4.4.2 I notice a lot of overlaps in the interpolation sequence, is that acceptable?\n\n=====References=====\n\n[1] Grass: Generative recursive autoencoders for shape structures\n\n[2] Grains: Generative recursive autoencoders for indoor scenes\n\n[3] Structurenet: Hierarchical graph networks for 3d shape generation\n\n[4] CSGNet: Neural Shape Parser for Constructive Solid Geometry\n\n[5] Revisiting Classifier Two-Sample Tests\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}