{
    "Decision": "",
    "Reviews": [
        {
            "title": "Review for ConEx",
            "review": "(Summary)\n\nLink prediction in Knowledge Graphs is a crucial problem as the natural graphs often exhibit a number of missing links that are critical for knowledge inference. When embedding such knowledge graphs into a vector space, it is important to support symmetric, anti-symmetric, inverse relations, and compositions. The proposed work ConEx aims to better capture all these qualifications of relations by incorporating benefits of using convolution and Hermitian inner products on the complex numbers.\n\n\n(Originality and Contributions)\n\nTo realize necessary qualifications of relations, the authors combine two sets of ideas: 2D convolution by Goodfellow et al (2016) and Hermitian inner products by Trouillon et al (2016). The proposed ConEx has its own design choices flattening and linear projection before running the entrywise rectified non-linearity. Thus the paper has some degree of originality, but still the main contribution is more on the extensive experiment and comparative analysis. \n\n\n(Concerns, Questions, and Suggestions)\n\n1) Referencing authors of some related work would be better either wrapped within in the parentheses or connected by a preposition like ‘by’. The current version reduces readability.\n\n2) While ConEx outperforms many other state-of-the-art models in FB15K-2357, KINSHIP, and UMLS, it does not perform well in the largest dataset WN18RR with the smallest types of relations. In Section 7, the authors conclude that ConEx cannot model the relations whose semantic bonding between object and subject is loose. However, the worst-performing relations: {_hypernym, _has_part, _member_meronym, _member_of} are anti-symmetric with clear semantic information. \n\n3) Indeed, “hypernym-hyponym” relation is one of the major benefits of using WordNet taxonomy. Seeing such low performance on this relation requires a follow-up analysis on the type of relations and the achieved per-relation performance on FB15K-237 even if ConEx performs the best among all models. \n\n4) Overall the paper becomes more useful if it includes some qualitative examples: none of the models work but ConEx performs well and some opposite cases. Currently readers would find difficulty what to take away from reading this paper because the performance on the largest dataset is not sufficiently explained; it is not clear whether the claimed property like anti-symmetric is indeed captured well; and no actual error examples are analyzed in the draft.\n\n5) The description about ‘vec’ operation below the equation (4) in Section 4.2, ‘flatting’ -> 'flattening'\n\n6) In Section 7, \"ConEx is not able model\" -> \"ConEx is not able to model\".\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Re-hashes some ideas form prior art, unfortunately without bringing better results. ",
            "review": "[I reviewed a previous submission of this paper to a different venue earlier this year. Having scanned through the paper, I have found no significant differences, hence I am posting pretty much the same review.]\n\nSummary: A knowledge graph embedding model that re-hashes some ideas form prior art, without bringing particular better results in either predictive power, memory footprint, or training time.\n\nThe paper describes a knowledge graph embedding model that blends the architectures of the popular ConvE and ComplEx into a single model.\n\nThe submission is structured along the traditional knowledge graph embedding paper template. It reads sufficiently well.\n\nThe novelty of the approach is rather limited: ConEx boils down to a “remixed” version of ComplEx and ConvE, and unfortunately the authors fail to convey the rationale for their choices (sec 4.1). The reader is left with the sense that is is yet another knowledge graph embedding paper with no particular innovative delta over the now crowded competitor landscape.\n\nDespite the claims, results are probably not at SOTA level. I would ask the authors to clarify the fine-grained details of the evaluation protocol they adopt, as described by Ruffinelli et al., ICLR-20 [1]. Unfortunately I have the feeling results from table 3 compare works unfairly, as slightly different evaluation protocol versions may have been adopted. It would have been more thorough to limit to a handful of models that really matter (e.g. ComplEx-N3) and compare ConEx using the same codebase.\nBesides, popular open source implementations of some os such models achieve higher predictive power than what reported in table3 for WN18-RR (e.g. [2]).\n\nI would recommend not to report results of ~50 competing works (table3), and limit to the most significant.\n\nKINSHIP, UMLS have been deprecated long ago, and should not be included in the evaluation.\n\nTable 5 does not report the parameters of more popular models such as CompLex, DistMult, which are likely to have a smaller memory footprint than ConEx.\n\nThe paper is missing a training time evaluation, which is paramount. Considered the level of maturity the KGE has reached, training time is a dealbreaker.\n\nI would recommend shorten the preliminaries (e.g. omit/move to appendix definition of convolution, table1 is found in dozens of other papers, shorten definitions, omit/move to appendix table2.). \n\n[1] https://openreview.net/pdf?id=BkxSmlBFvr \n[2] https://docs.ampligraph.org/en/1.3.1/experiments.html#wn18rr",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Recommendation for Rejection",
            "review": "Summary\n========\nThis paper is about the problem of missing links prediction by learning representations of knowledge graphs. The authors propose an approach called ConEx that infers missing links by leveraging the composition of a 2D convolution with a Hermitian inner product of complex-valued embedding vectors. They compare their approach to a variety of known state-of-the-art knowledge graph embedding methods in four datasets WN18RR, FB15K-237, KINSHIP and UMLS. They also include a study of the number of parameters used for each model on the link prediction task.\n\n\nReasons for score\n================\nOverall, the paper shows an interesting direction for computing KG embeddings, however the novelty is limited and the experimental setup and the results are not very convincing for the performance of the proposed model against the comparison. Also, most experimental results are taken from the original papers of the methods. The numbers of the evaluation metrics are very close/similar and no statistical significance is computed to strengthen the points made in the paper. With some more iteration on the paper, the authors will have better material and evidence to show in a future submission. \n\n\nStrengths\n========\n- The paper is about an interesting and popular problem that attracts the attention of a lot of researchers in the KG/graph representation learning domain.\n- The authors have collected a variety of the current state-of-the-art methods for KG representation learning and the paper could also serve as a survey paper if modified.\n- The approach, the training and the optimization are well-written and someone could replicate the methodology. The authors also have released the code in a GitHub repository.\n\n\nWeaknesses\n===========\n- The proposed approach has limited novelty, as it builds on top of the current state-of-the-art, with minor advancements in a known problem.\n- The experimental set up and the results are not convincing. The authors show the results as they are computed in other papers, and they run their own method in the same datasets to compare for performance. Their method shows better performance than the comparison methods in most cases, however the difference in the scores sometimes is even 0.001. There is not discussion on the statistical significance for those results (because they do not have the other methods’ outcome, but only their evaluation scores). These minor improvements are not strong enough to support this paper.\n\n\nQuestions during rebuttal\n=====================\n- Please address and clarify the weaknesses described above.\n\n\nMinor comments / Typos\n====================\n- In Section 2, the second time “Complex” is mentioned is in different format from the first time.\n- In Section 3, third line, and “P” is the set of all properties, “P” should be “R” based on the notation in the previous line.\n- In Section 4.1, the following sentence should be rewritten: “ This allows us to more accurately capture all four types of relations than approaches which solely apply 2D convolution in R …”.\n- In Section 5.3, a validation set is mentioned, however there is no information about it in Table 2. I would suggest that a corresponding column would be added in the table.\n- In Table 4, in results for UMLS, the score of ConEx is highlighted as the best (.994), however TuckER shows better performance (.997).",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "A link prediction model for knowledge graphs: easy to read but unmotivated and concerns over the results.",
            "review": "Summary: The work looks to combine aspects of previous KG representation models, namely 2-D convolution and complex numbers. \n\nQuality: The paper is relatively easy to read, but the model is poorly motivated and there is potential for concern over the results.\n\nClarity: \n - Grammatical: overall the paper is well written and readable. (Notation unclear - see below)\n - Interpretability: section (4.1) labelled \"Intuition\" provides no real intuition: \"We are interested in the composition of a 2D convolution with a Hermitian inner product.\" is stated (abruptly)  without following logically from the previous sentences. Importantly, no intuition is given for why 2-D convolution (naturally used for 2-D images) are at all appropriate for word embeddings. Where they have been previously used (ConvE), it has been subsequently shown to be unnecessary (Hyper), which is entirely unmentioned/unaddressed. The Discussion adds little explanation as to why either 2d-convolution or complex numbers relate to the task, let alone their combination. An early motivation for the model seems to be to \"capture composite relations\" (since ComplEx fails to, sec 4.1) but it is unclear how the proposed model resolves this.\n\nOriginality: The model combines aspects of 2 previous models (ConvE and ComplEx) in a novel way\n\nSignificance: Unclear. Under comparison to many models, the proposed model shows slightly better results on one (FB15K-237), slightly worse results on the other (WN18RR). Higher performance is shown relative to a much smaller number of models on two other datasets. It is unclear where any benefit comes from or for which type of data the model might be more suited. There are potential concerns with the results (see below).\n\nPros: The results are comparable to state-of-art so the model may contain useful aspects, if they can be understood.\n\nCons: \n - Motivation: as mentioned above, there is no clear motivation for the central components of the model (convolution and complex numbers), despite both having been considered previously and their benefit not being clear. The paper does not address this.\n - Related Work refers to (only) 2 models as \"state-of-art\": ConvE and ComplEx. This incorrectly represents the field and appears biased towards the two models inspiring the current work since several other models outperform each of them and \"Hypernetwork knowledge graph embeddings\" (as cited) shows that the 2-D convolution of ConvE can be removed and its performance *improved*, which seems highly relevant but goes unmentioned.\n - Query about results:  (i) The loss function includes several Relu functions, which have the potential to mean the same score is assigned to multiple triples (as has happened elsewhere). This can artificially inflate results if evaluation only considers whether a given test triple receives the highest score, without taking account of other triples with the same score. (ii) Parameter number - Model performance should be compared given similar numbers of parameters. The selected number of channels, dimensions of W and and the filters are not clearly stated, so the number of parameters is undeterminable. How does performance compare to competitive models (e.g. MuRP/MuRE) on a like for like total parameter number basis (not dimension).\n\n - Convolution is a mathematical operation, e.g. as found in Fourier analysis, and it would be better to have only one reference \"(e.g. see Goodfellow for an overview)\", not 3 references to one recent text, which is misleading as it does not invent the concept.\n - Equation (5) should perhaps be Re(\\sum x_k   e_{sk} x ...  )  ?\n - Notation would be far more clear if \\cal{H} and \\cal{V} were clearly identifiable as functions (e.g. using greek symbols to mirror \\phi);their domain and range explicitly stated when they are introduced e.g. \"\\psi : \\mathbb{R}^k \\to .... \"; and standard notation used, e.g. comma-separated parameters not semi-colons.\n - the use of complex numbers seems ultimately questionable since throughout the model they appear to cause only a single sign change (in Eq 6). Does this sign change actually enhance performance?\n - 4.2.2 mentions several \"bells & whistles\" that comparison models may not use, e.g. batch norm, dropout, label smoothing, \"Glorot intitialisation\" - to what extent do these help and to what extent might they help other models. \n - it is claimed without explanation that 1-N training \"has an effect akin to batch normalization\"\n - Table 3 significantly breaches the page margins \n - Table 4 has ConEx H@!0 UMLS in bold (as if the higest value), but TuckER achieves a higher value (based on the numbers given).\n - Table 5 the number of parameters used by ConEx for FB15K-237 seems very low and is unexplained.\n - Fig 1: the dimensionalities tested for each model appears to differ, e.g. might TuckER overfit the small dataset going from one small number (c20k params) to one large number (c140k), given ConEx peaks at c 40/50k? The plots don't seem to reflect Table 4, e.g. TuckER has highest H@10 (.985), but this is not shown in the bottom right plot.\n\nMinor:\n - sec : \"RDF\" acronym used without explanation\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}