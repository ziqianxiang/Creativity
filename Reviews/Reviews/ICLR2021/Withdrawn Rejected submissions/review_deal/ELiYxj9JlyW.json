{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The authors propose a process to leverage the memorization effect of deep learning models to filter out examples at the boundary (hard) that the models are confident on, and argue that identifying those hard confident examples help improve the accuracy when learning under noisy data. The process essentially alternates between confident example selection and classifier updating, where the two parts are expected to help each other to form a positive cycle. Experiments demonstrate superior results over other self-purifying approaches.\n\nThe reviewers have a very diverse opinion about the paper. On the positive side, everyone agrees that the superior experimental results to be very impressive. The authors have addressed some concerns well, such as the running time. One reviewer pointed out that the current study has not been combined with semi-supervised learning yet, but during the discussion, most agreed that it is not a crucial negative point of the current paper. On the actual negative points, there are issues that were not cleared even after the rebuttal, such as whether re-initialization in the process helps escape local optimal, and the key difference between the \"small-loss trick\" and \"memory-momentum trick.\" While the authors argued the novelty with respect to SELF, more illustrations and experiments are needed to highlight the novelty aspect.\n\nGiven the diverse opinions, the AC read the paper in detail, and assessed the reviewer's opinions and the authors rebuttal. Overall a serious concern is the leap of faith that the proposed process is indeed (a) \"leveraging the memorization effect\" to (b) \"extract hard confident examples\" to (c) \"improve accuracy in noisy learning\". For (a), it is mentioned that deep learning models \"learns simple patterns on majority of data\" first, where the majority in this work is argued is the clean ones. But there is no validation of this claim in the experiments. For instance, there is no figure/discussion that shows how much \"clean data\" has been correctly captured/memorized by the earlier deep learning models. For (b), the terminology of \"hard but confident\" is ill-defined. If examples being hard means them to be around the boundary, one can argue that they could never be \"confident\" as one measure of the confidence is the margin. The authors may want to mean \"hard but clean\", but then more illustrations are needed to analyze whether the extracted examples are really the clean ones, or if there are noisy ones being \"confident\" from the proposed process as well. For (c), it is then unclear whether the improved performance is caused by noise removal (as the authors hope to argue), or by just zooming in to the boundary (regardless of whether the extracted examples are clean or noisy). The authors are encouraged to not just look at the superior performance on accuracy, but analyze more on what actually happened behind the scenes to understand the proposed process better.\n\nSome more comments from the AC that could help the authors (1) Are the examples kept by the proposed approach similar to the ones kept by SELF? Why or why not? Are there empirical studies on this? (2) For the competitors' approaches, what would their Figure 4 look like? In particular, for approaches that use \"small-loss trick\", what would Figure 4 look like? How would Figure 4 be different for the proposed process (i.e extracting hard \"confident\" examples) and others (like extracting just hard examples without considering confidence, or just confident examples without considering hardness)? (3) Are there studies that deliberately initialize the process with noisy data, to see how sensitive the process is before the \"positive cycle\" begins?\n"
    },
    "Reviews": [
        {
            "title": "Interesting Work",
            "review": "The authors introduce an interesting approach to handling hard \"confident\" samples in learning with label noises. At the heart of the proposed approach is an interactive method that jointly refines the classifier and the samples. The confident samples are initialized by utilizing the memorization effect of deep networks. Then, a classifier is learned from such samples. \n\nDuring the learning process, hard confident data are selected progressively by looking at the classification results, which further better select confident samples. \n\nExperimental results show that the proposed method achieves state of the art.\n\nPros:\n1. The task studied here could be of interest to a large number of readers in the community.\n2. The overall idea is quite interesting and intuitively makes sense. I like the fact that the core idea of the proposed approach finds its root in physics. \n3. The results are very promising, in spite of the simple nature.\n4. The manuscript is overall well-written and easy to follow. \n\nCons:\n1. The iterative nature is good and bad. It seems to me that sometimes it requires many rounds in the inner loop, as shown in Fig. 3, for example, the number is up to 20 to 30. Please show some numbers in terms of running time and compare them with the baselines. \n2. I might be missing something here but, what about the not-so-confident samples? Any scheme to take care of them?\n\nMinor issues\n1. The fonts in Fig. 3 should be enlarged.\n2. It would be better if the author could elaborate more on its connection with the momentum in physics.\n\n\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Simple idea, but many questions about novelty, presentation, and methodology",
            "review": "This paper proposes momentum of memorization as a way to distinguish hard examples needed for efficient learning from noisy examples which decrease classification accuracy. The method finds confident, hard examples and updates them dynamically during model training. This is done by iteratively selecting examples with labels that agree with model predictions and then training on only the confident data. Results show improved accuracy on standard image classification datasets with both synthetic and real world label noise.\n\n\nNovelty\n- In addition to the methods cited in \"Relation to existing work,\" the authors should cite and discuss self-training methods which have become quite popular over the past decade [1]\n- The paper also describes Algorithm 1 as adding an outer loop to the recent SELF algorithm [2], which considerably limits its novelty.\n\nCorrectness/Experiments:\n- Results show consistent improvement over baselines\n- A more thorough evaluation would include ablation on the parameters $N_{outer}$ and $N_{inner}$, as well as the modified early stopping \"trick\"\n- Figure 4 shows qualitative t-SNE visualizations of identified confident examples. qualitatively, these look well separated. However, t-SNE is known to preserve local structure better than global structure, making it a poor way to visualize how close confident examples are to decision boundaries. It's also impossible to tell whether any of the dots (in particular blue and red) are incorrectly labeled wrt ground truth class labels (i.e. \"noisy\" vs \"hard\")\n- Many claims are made without theoretical or empirical justification. For example, showing how training/validation accuracy varied with $N_{outer}$ and $N_{inner}$ would support the claim that Me-Momentum is leveraging the memorization effect.\n\nClarity\n- Example figures and problem formulation are quite nice\n- I believe this naming may cause confusion with the momentum update widely used in optimization. Additionally, I am not sure how this paper fits the notion of momentum more than any number of other training procedures. For example, increasing the learning rate at each epoch would fit the colloquial/physics meaning of \"traveling through hypothesis space\" just as well as this approach which uses repeated fine tuning.\n- Algorithm 1 and Section 2 would benefit from additional notation in addition to the pseudocode and text explanation\n- Unclear what the reader should take away from Figure 4 and 10-13 (see above)\n- typos: \"an surrogate\" should be \"a surrogate\", and \"clothing1M\" should be \"Clothing1M\"\n\nPro\n- Nice illustrations and problem description\n- Results perform well against baselines\n\nCons\n- Limited novelty compared to SELF and self-training methods more generally\n- Concerns about methodology and clarity, especially wrt visualizations\n- Empirical methodology/analysis should be improved\n\nQuestions:\n- How does the running time compare to normal neural network training, and to other baseline methods?\n- Do Tables 1-3 show a similar improvement to Table 4 when switching to clean validation set?\n- How sensitive is Me-Momentum to hyperparameters $N_{outer}$ and $N_{inner}$?\n- Is the recall of confident examples wrt accurately labeled data as high as the precision? Will identifying additional confident samples lead to even higher accuracy?\n\n\n[1] Huang and Harper. Self-Training PCFG Grammars with Latent Annotations\nAcross Languages, EMNLP 2009 https://www.aclweb.org/anthology/D09-1087.pdf\n\n[2] Nguyen et al. SELF: learning to filter noisy labels with self-ensembling, ICLR 2020. https://arxiv.org/abs/1910.01842\n\nEDIT: The author response addressed some of my concerns. In particular, it confirms that the experimental results are impressive compared to many baselines. However, I would appreciate the distinction between easy and hard confident examples much more if the authors went beyond illustrative figures and defined this concept more precisely. Without a precise definition, it's difficult to verify the paper's claims about why the method performs well. Based on t-SNE visualizations, the author response offers an alternate definition of \"far away from the cluster centroids.\" The submission would be much stronger if it developed this idea further and analyzed it quantitatively.\n\nNext, the authors suggest that methods cannot distinguish hard confident examples from mislabeled examples using the \"small loss trick\" alone, and that their \"momentum trick\" is necessary. However, they do not present a principled argument or strong evidence to support the claim. In fact, some recent methods do show a separation between these types of training data using measurable quantities, see Figure 1 of [3] and Figures 1-2 of [4].\n\nFinally, the authors claim that reinitialization helps escape bad local optima. However, I do not see how low standard deviation supports this claim.\n\n[3] Pleiss et al. Identifying Mislabeled Data using the Area Under the Margin Ranking, Neurips 2020. https://arxiv.org/abs/2001.10528\n\n[4] Swayamdipta et al. Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics, EMNLP 2020. https://arxiv.org/abs/2009.10795]",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review 2 for \"ME-MOMENTUM: EXTRACTING HARD CONFIDENT EXAMPLES FROM NOISILY LABELED DATA\"",
            "review": "This paper propose a novel and effective method called Me-Momentum to cope with noisy labels. The algorithm borrows the idea of momentum from physics and tries to identify hard examples. The authors alternately update the hard examples and improve the classifier to achieve the robustness to noisy labels. Experiments and comparisons with recent state-of-art methods are provided to verify the effectiveness of Me-Momentum. \n\nPros:\n\n1. Different from the existing methods, which aim to identify simple clean examples, this paper analyzes the importance of hard examples and provide a way to identify them. The method is interesting and effective. It gives a new perspective and makes clear contributions for learning with noisy labels. \n\n2. The design of inner loop and outer loop is interesting and insightful, and is proved to be very effective. \n\n3. The experimental results are promising. The proposed method achieves great performance (75.18%) on Clothing1M. In addition, compared with SOTA SELF,  Me-Momentum outperforms it by a large margin. The authors also provide an ablation study to analyze the sensitivity of the hyperparameter $tau$. Thus, the significance of the proposed method with respect to experimental results may be high in the community. \n\n4. The paper is well written. The description of the technical details is very clear. It is easy to reproduce this method.\n\nSpecific comments and questions:\n\n1. Insufficient analysis of visualization results and analysis of hyperparameter sensitivity. The authors should add them to improve this paper. In addition, the baselines are reimplemented with default parameters? I hope the author can emphasize or add some descriptions of the implementation details of the comparison methods. \n\n2. Adding more baselines will be better. Some recent methods achieve great classification performance for learning with noisy labels, such as [1]. The authors can compare the proposed method with them to make the results more convincing. \n\n3. The proposed method uses a noisy validation set to choose classifiers, and then identify confident examples with robust classifier. The authors should explain why a noisy validation dataset can be used to choose classifiers which perform well on clean datasets. This choice may not be accurate?\n\n4. There are some grammatical errors and typos. The author should proofread this paper. For example, “The results are presented in Figure XX”, the authors miss the figure number. Please check it carefully. \n\n[1] NLNL: Negative Learning for Noisy Labels, Youngdong Kim et al, ICCV2019. ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Potentially interesting work, but technical contribution is limited, and the method is not theoretically solid.",
            "review": "*quality*\nThe organization of this paper is barely satisfactory. The technique proposed to extract hard confident examples in this paper is not convincing, even though the experimental results seem promising.\n\n*clarity*\nIt is not difficult to understand the proposed method, however, the Figures in this paper are somewhat confusing to readers.\n\n*originality*\nIn this paper, the authors focus on extracting hard confident examples from the noisy training data for learning with noisy labels. There is no method to extract hard confident examples before, the idea is novel. However, the technical contribution is limited.\n\n*significance*\nThe idea of extracting hard confident examples is good, however, I do not think this paper solves this issue properly. How to extract hard confident examples correctly still remains a challenging problem.\n\n*pros and cons*\nPros:\n(1). Authors provide sufficient experiments which evaluate the methods on multiple datasets.\n(2). The proposed method achieves better performance than state-of-the-art methods. \n\nCons:\n(1). As for the question “How to validate the learned classifiers in Steps 3 and 5 without a clean validation set?”, the authors claim that the noisy validation set could be used as a surrogate to validate the classifiers if no clean validation set is available. I do not think it is reasonable here.\n(2). The confident examples can be extracted based on the memorization effect, it seems reasonable. But why hard confident examples can be extracted? The authors explained as previously extracted confident examples will help identify hard confident examples, it is so empirical and maybe another explanation is needed here. Moreover, in the corresponding paragraph, there might be some error with “Figure 6” (should be “Figure 2”?).\n(3). The intuition “better confident examples will result in a better classifier and a better classifier will identify better confident examples” have been mentioned many times, I wonder will the method proposed in this paper stuck in the local optimum when the two loops in Algorithm 1 execute.\n(4). The proposed method performs better than the state-of-the-art with 20% and 40% noisy labels. It would be better if the experiments with lager noise rate (e.g., >=50%) are also conducted.\n(5). Some minor issues, for example, “extract” should be “extracted” in the step 2 of Algorithm 1; “$\\times$” and “*” are abused in Section 3; and the resolution of some Figures in this paper is not satisfactory.\n\nGenerally, I feel that the method proposed in this paper is somehow too empirical, and more theoretical study is needed.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}