{
    "Decision": "",
    "Reviews": [
        {
            "title": "unclear novelty, performance, and application",
            "review": "In this submission, the authors propose a feature importance model and a binarized logistic regression model (FIBLR) to measure the feature importance across different feature values. However, the novelty of the proposed model is limited, its performance and potential applications are also unclear. The details of comments are as below. \n\n1. The authors propose a new definition of feature importance, but the motivation and advantage are not clear.  If not all, many machine learning methods are implicitly learning the measurements defined in Eq.(1). Why it is necessary and important to make them explicitly? \n\n2. The proposed model FIBLR lacks novelty. The majority contribution of the FIBLR (Eq.(2)(3)(4)) can be regarded as training the LR model on pre-processed data, which is pre-processed via discretization and one-hot encoding.\nAlso, can the proposed definition work well with other machine learning methods such as deep learning methods, tree-based methods? If for each different category of machine learning methods, people need to develop new methods in order to utilize this proposed feature importance score, what are the benefits?\n\n3. The experimental results are only conducted on very small datasets. Could the authors provide more experiments on large-scale datasets, especially the experimental results about efficiency (running time)?\n\n",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An interesting attempt to grasp an ellusive idea",
            "review": "This paper addresses the problem of defining a distribution-based alternative to feature relevance \"point estimates\".\nThe paper falls reasonably well within the scope of the conference.\nThe writing itself is below par and would require a thorough overall language revision.\nEven though the motivation seems more or less clear, at least in the medical domains it is illustrated with, I have serious doubts concerning the idea of relevance put forward here as depending on the distribution of the feature values themselves. It seems to me that you are not quite defining feature distribution of relevance but something more akin to what a univariate ROC curve could tell us. Using a sigmoid output activation fct. can lead, under certain assumptions, to the classifier output being understood as a probability. In that case, the own \"local shape\" of the ROC could be telling us about the distribution of relevance of the relevance of certain value ranges (bins) of the variable. It is also important to say that a bigger shortcoming than using point estimates of feature relevance is the fact of not considering the interaction between the relative relevances of subsets of variables (that is, moving from univariate to multivariate relevance)\nAnother issue is that you constrict the concept of relevance/importance to supervised settings, despite the fact that you could also\nconsider it in the unsupervised learning setting, where importance is in terms of finding \"grouping\" instead of class structure.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review of \"On the Discovery of Feature Importance Distribution: An Overlooked Area\"",
            "review": "Summary: The authors propose estimating a feature/variable importance measure that varies as the value of the variable varies. In this way, one can discover significant variation in feature importance that cannot be summarized using a single point estimate.\n\nPros:\n+ In the variable importance literature, much of the focus has been on measures at the level of the entire population or instance-level variable importance. The authors are studying an interesting in-between quantity. The univariate variable importance plots in the empirical analyses, especially differences between fitting a single logistic model vs a binarized one, were therefore quite interesting.\n\n\nMajor concerns:\n\n1. The paper fails to mention many previous studies on how variable importance may vary across subgroups/different variable values, and some have studied very similar measures. I'd like the authors to contextualize their work among the others. Relevant papers:\n    * W-specific variable importance: Van der Laan, M. J. 2006. “Statistical Inference for Variable Importance.”\n    * Local variable importance: Williamson, Brian D., and Jean Feng. 2020. “Efficient Nonparametric Statistical Inference on Population Feature Importance Using Shapley Values.”\n    * SHAP values: Lundberg, Scott M., and Su-In Lee. 2017. “A Unified Approach to Interpreting Model Predictions.”\n    * LIME: Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. “Why Should I Trust You?: Explaining the Predictions of Any Classifier.”\nNote that although SHAP and LIME provide variable importance for individual observations, you can obtain similar VIM as in this paper by simply averaging the VIM across observations whose i-th variable fall in the same bin.\n\nAlso, in the intro, the authors say that many feature importance measures are difficult to interpret. However, a number of these variable importance measures are actually on an interpretable scale, including the probability scale as discussed in the paper. Please clarify how the new variable importance definition is novel.\n\n2. The authors discuss evaluating the correctness of their variable importance estimates. However, there was no theory describing how well we can estimate this variable importance measure and what it means to correctly estimate its value. For example, can we correctly recover the true importance as the number of observations grows (i.e. consistency) and what assumptions are required? If the true model is fully nonparametric, I believe you can construct examples where it is impossible to recover the proposed importance measure at particular values of x because the measure at a specific x value is zero. In addition, there were no simulation studies that demonstrate the ability of this method to recover the true values.\n\n3. There are many approaches to solving a binarized logistic model. For instance, you can binarize all the features into the bins to create a new set of variables. These variables can then be given to the usual logistic regression model, and we will have obtained the solution to the binarized logistic regression problem. This seems to be the same procedure suggested by the authors. Thus, I don't think the gradient descent procedure outlined by the authors is new. Also, I don't see why \"zi in the binarized model (eq. 4) is the sum of zji in the importance model (eq. 3) across all the n features\". If I have two features with the same exact value, you cannot simply take the sum of the solutions to eq 3 for both features as the solution to eq 4. Although the authors have suggested to do the following: \"Once the binarized logistic regression model (eq. 4) is trained, we can plug the updated parameters bj(θjk) and wj(θjk) into the feature importance model (eq. 3) to obtain the importance distribution of each feature.\" -- I don't think you can interpret the solution to the binarized logistic regression as the solution to eq 3. You can perhaps interpret it as the solution to a logistic regression model with all the variables, but I don't think it is the solution of a univariate logistic regression model.\n\n4. The empirical analyses were interesting. However, to understand how much the variable importance estimates truly vary over different variable values, one should include confidence intervals in the analysis.\n\n5. There are many estimators one can use to estimate the solution to eq 4. Binarized logistic regression is one example, but one can also use nonparametric methods or off-the-shelf machine learning methods like random forests. These latter methods may even achieve higher classification accuracy than binarized logistic regression. Logistic regression and gaussian naive bayes are weak comparators, and a much stronger argument can be made if the authors compare against more flexible estimation methods.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}