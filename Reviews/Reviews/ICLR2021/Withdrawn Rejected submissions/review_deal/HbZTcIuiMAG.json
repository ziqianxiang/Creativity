{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper received 4 reviews with mixed initial ratings: 4, 8, 5, 7. The main concerns of R1 and R2, who gave unfavorable scores, included limited methodological novelty beyond the data generation and insufficient empirical evaluation of state-of-the-art methods on the proposed dataset. The authors submitted a new revision with a summary of changes and provided detailed responses to each of the reviews separately: it addressed some of the concerns, but did not change the overall position of the reviewers.\nAC agrees with R3 and R4 that the proposed dataset and the environment may have certain practical impact and enable new research in learning CAD reconstruction. However, the contributions are indeed specific to a narrow CAD community, and R1 felt that the paper needs another round of peer reviews before acceptance, as a significant number of new results have been added during the discussion stage. After discussion with PCs, the final recommendation is to reject."
    },
    "Reviews": [
        {
            "title": "Good dataset paper but insufficient evaluation of SOTA for the baseline approach ",
            "review": "### Summary and Contributions\nThe CAD reconstruction problem is defined as the recovery of the sequence of modeling operations used to construct the CAD model, from the raw geometry input (triangle meshes, point clouds, or, B-reps). The paper proposes a novel dataset as well as a generic framework implementing an MDP (Markov Decision Process) formulation for training a neural CAD reconstruction agent.  \n\nThis the first dataset which includes the sequence of CAD modeling operations as ground truth containing 8.5K+ human-designed real-world CAD models. The CAD reconstruction task is formulated as that of training a generic neural MDP agent and provided in an programming environment to the research community to train such models. Finally, a novel algorithm is provided as a baseline to solve the CAD reconstruction problem.  \n\n### Detailed Review \nThe following is the detailed review of the paper, organized into strengths and weaknesses subsections. \n\n#### Strengths\n\n##### Relevance and Significance \nThere is a large number of man-made objects that we interact with that are created using computer-aided design. The modeling steps, which are often lost, are important in understanding, editing, simulation and manufacturing such objects, and need to be reconstructed. This topic is of considerable importance to the CAD community. In addition, approaches, that can reverse engineer the generative process should be of general interest to the wider ML and computer vision community, as well.  \n\n##### Relation to Prior Art \nThe paper does a good job of presenting the prior art, identifying the challenges and need for the presented work. The dataset including the modeling sequences for real, human-designed CAD models is the first of its kind. Since it’s a novel problem (first dataset of the kind), the proposed baseline implementing a learning-based approach to this problem is novel as well (though simplistic, see below).  \n\n##### Reproducibility \nSince the entire dataset and the baseline is released in an open-source programming environment, it should be easy to reproduce and verify the results. \n\n##### Clarity \nThe paper is written well and is easy to understand. \n\n#### Weaknesses\n \n##### Methodology \nThis is largely a dataset paper. Introduction of a new dataset to the research community needs to demonstrate that the tasks to be solved on the dataset is not trivially addressed by the known state of the art. The paper falls short of demonstrating that. \n\n1. Agent model: Two models are considered – MLP (trivial embeddings based on vertex features) and seemingly trivial embeddings of MPNs. The paper doesn't present enough details about the choices made for obtaining meaningful embeddings. This seems to be the heart of the approach and the authors don't present a compelling approach or a comparative evaluation of a set of choices based on the SOTA for graph embeddings, to model the agent. \n\n2. Search: Similarly, the search is trivially implemented using a random rollout. There are much better search strategies available in the SOTA to bring to bear on the problem. \n\n In summary. I don't think that the presented baseline properly brings the SOTA to bear on the problem and thus demonstrates a need for additional research to be spurred on by this dataset.  \n\n##### Novelty \nThe presented approach is a straight-forward application of known techniques.  \n\n##### Empirical Evaluation \nAn important question to consider when proposing a presumably difficult new problem when addressed by known art is to investigate what aspect of the new problem really taxes the state of the art and to stage the experiments and analysis carefully for the same. There are many questions to be addressed here, for e.g. (a) How is stationarity (or, invariance over the topologies) achieved across training, validation and  test sets, (b) Does the training overfit (are the architectures used of enough capacity)?, (c) Is there generalization gap? If so, why? Etc. \n\n### Assessment\nThough the problem seems relevant and of significance to the research community, the dataset of considerable value, the paper doesn't make a strong case whether and how this problem challenges the known state of the art. In its current form, I do not recommend the publication of this paper. \n\n \n\n ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Very interesting paper, unfortunately out of my field of expertise",
            "review": "I have to admit straight away that this paper is far from my field of expertise (computer vision, generative networks). I have not worked with CAD models, and I am not in expert in reinforcement/imitation learning. My review is thus written from the \"educated outsider\" viewpoint.\n\nFrom that viewpoint, the paper is very strong. It introduces a meaningful problem (CAD modeling sequence reconstruction), motivates the need for a new task and the direction of research, describes the full task and the compromises it makes (face extrudes rather than sketch extrudes are considered in the simplified task). The paper then introduces a new training/test dataset and an environment for training agents, and evaluates a reasonable set of agents rather extensively.\n\nAs a slight criticism, I found that too many details are moved from Section 5 to the supmat. E.g. what is meant by MLP with\n\"an auto-regressive connection between the two target faces\" was completely unclear before I looked into the supmat (and the phrase did not refer me to supmat either).\nOtherwise, the paper is well-written and has nice visualizations (though they crash my PDF viewer) that aid understanding.\n\nOverall, I really enjoyed reading the paper, and I am not able to identify any flaws. As far as I can judge based on my limited knowledge, the paper (together with associated dataset and environment) is likely to spur new research and to be impactful. I therefore give it a strong rating, but I cannot exclude that I have missed some flaws that would be identifiable by an expert.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "Comprehensive submission, albeit somewhat domain specific to CAD community",
            "review": "The paper describes a new dataset of 3D geometry construction sequences based on sequential sketching (i.e. sets of two-dimensional curves) and extruding (i.e. axes, angles and distances for extrusion profiles from sketches) combined with Boolean solid geometry operations. The dataset comprises the resulting objects as well as the human designed sketch-extrude sequence that lead to the object geometry. The 8625 objects are available in three different geometry representations (boundary representation, mesh, and construction sequence in structured format). Furthermore the submission describes a new infrastructure (\"gym\") to train and evaluate algorithms that estimate such construction sequences, as well as evaluation metrics to gauge the efficiency and effectiveness of such estimation algorithms. The paper also provides a reference method for sequence estimation based on imitation learning as well as several baselines and their empirical evaluation with respect to the posed benchmarks.\n\n### Strengths\n**[S1]** The paper is written well and takes a comprehensive look on a new dataset from the perspective of the data itself, semi-synthetic generation of new data, evaluation metrics and benchmarking on the data as well as a reference method and its performance analysis.\n\n**[S2]** I particularly appreciate the synthetic data generation/augmentation capability. This may enable more structured studies in the future, for instance with respect to specifics of the constructed geometry: Does complexity of the design geometry matter, does the topology make a difference in achievable performance? \n\n**[S3]** New datasets are often valuable contributions to the community, in particular when they allow the discovery of new insight (however see W1 below)\n\n### Weaknesses\n**[W1]** The main contribution of the paper seems to me the database itself and the associated gym. While new datasets are a good contribution in general, I am not convinced that the target audience of ICLR will benefit in a substantial matter from the exposure. Specifically, I feel that the benefit of human-designed vs. synthetically generated designs is not worked out convincingly. What can I learn, what insight can I gain from the human designs that I cannot from, e.g., purely synthetical, procedural designs? Are there difference in the statistics? It would strengthen the paper to highlight evidence that the data does have benefit in the sense that I can achieve something substantially new. \n\n**[W2]** The submission claims a \"novel, neurally guided method\", but I do not see the novelty laid out clearly: outside of \"using common sketch and extrude CAD modeling operations from real human designs\" in section 2, the novelty is vague and the relation to the state of the art imprecise. Is it the use of sketch and extrude operations in an otherwise previously exposed sequence learning task? Is it using human-designed sequences (then, see W1)? It would strengthen the case for the paper if the novelty would be exposed more concisely.\n\n### Further comments:\nI do appreciate the comprehensiveness across data, benchmarks, reference solutions and evaluation of the paper and such data and gyms can be an important piece of the machine and representation learning puzzle. As it is, I am concerned that the submission is not appealing to a sufficiently large audience at ICLR.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Valuable new dataset, environment, and comprehensive evaluation metrics for 3D CAD design ",
            "review": "Summary:\n\nThe paper presents the first large scale CAD construction sequence dataset together with environment that allows us to synthesize 3D CAD from these sequences. The dataset and environment are essential building blocks for applying machine learning algorithms to CAD design process. Furthermore, the paper proposes comprehensive evaluation metrics and a baseline method for predicting the sequence of 3D CAD design from a CAD model. \n\nThe dataset and environment are highly valuable to the research community. Although the proposed baseline and task have room for improvement, I believe this work merits publication.\n\nPros:\n- The first large scale CAD dataset with the comprehensive construction sequence data. \n- The environment can construct these sequence data and allow us to synthetically generate new data. Together with the 360 Fusion Gallery, this would be a great step towards learning human design processes.\n- A good baseline method with comprehensive evaluation metrics.\n\nCons:\n- The proposed task of CAD sequence reconstruction requires a target geometry in the same CAD format. This would not be called \"raw geometry” as in the abstract. Raw geometry is often referred to as what we can derive from scan data including point clouds and meshes.\n- As the aforementioned CAD reconstruction task is not very practical, adding another practical task such as reconstructing the sequence from raw geometry data is highly recommended. \n- Regarding the evaluation metrics, it is not clear whether the conciseness is computed from only the successful reconstructions or the entire test set. If the former is the case, comparison using this metric across different approaches would not be fair. Otherwise, this does not necessarily provide a sense of how efficient the evaluated algorithm is. Clarification on this is recommended.\n\nQuestions/Remarks:\n- In terms of accuracy, the augmentation rather hurts preciseness with more steps. Why is this happening? Is this due to the limited capacity of the proposed network? Discussion on this would be helpful.\n- The following reference can be cited and discussed. \n﻿\"Modeling 3D Shapes by Reinforcement Learning” Cheng Lin, Tingxiang Fan, Wenping Wang, Matthias Nießner ECCV 2020",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}