{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper improves on previous work (adv-BNN) with hierarchical variational inference. It observes that mean-field VI training for BNNs often result in close-to-deterministic approximate posterior distributions for weights, which effectively makes the BNN closer to deterministic neural network, thereby loosing the robustness advantage of stochastic neural networks. To address this, a hierarchical prior is proposed on the weights, which, together with the corresponding approximate posterior design, aims at preventing the collapse of the variances of the weights towards zero. This improved version of adv-BNN is shown to be reasonably better than the original adv-BNN and their deterministic counter-part against the PGD and EOT attacks on a various of benchmark dataset in the adversarial robustness literature.\n\nReviewers initially had questions about whether the comparison is fair to the original adv-BNN since the reported results were very different. This issue has been addressed by the authors during the author feedback period, after that reviewers agreed that the proposed approach is a good extension of adv-BNN towards making it more robust. They also agree that the analysis of the original adv-BNN in terms of posterior variance collapse is interesting and potentially useful, although they also pointed out the link of increased variance (with the proposed method) and better uncertainty estimation is unclear.\n\nIn revision, I would encourage the authors to clear up the confusions of the reviewers by clearly stating the comparison setting with the original adv-BNN, and better clarify the methodology."
    },
    "Reviews": [
        {
            "title": "Improving Adversarial-BNN with hierarchical variational inference",
            "review": "Updates:\nThe author addressed my concerns about the experiments. Though the improvement is marginal and I still have some concerns, I’m ok to accept the paper. I’ll change my score to 6.\n========================\n\nSummary:\nThe paper studied the adversarial Bayesian Neural Network and found that the stochasticity of it vanished. As stochasticity can help improve robustness against adversarial examples, the author proposed to use conjugate prior of Gaussian posterior to improve stochasticity of the model and robustness at the same time.\n\nStrength:\nExperiments show that the proposed method outperforms adversarial-BNN and adversarial training on several benchmark datasets and the stochasticity of the proposed model is larger than adversarial-BNN.\n\nWeakness:\nThe evaluation is somehow questionable. Checked the original paper of adversarial-BNN and found that the performances of adversarial-BNN is much better than reported in this paper. In both papers, VGG16 is the base structure of BNN, but the reported performances of adv-BNN and adversarial training are different in two papers on CIFAR10.\n\nCIFAR10 Results\n\n| $\\epsilon$ | adv-BNN | adv-BNN(in this paper) | adv | adv (in this paper)|\n|:------:|:-----:|:------:|:-----:|:------:|\n| 0 | 79.7 | 62 | 80.3| 72 |\n|0.015 | 68.7 | 54| 58.3 | 60 |\n\nIt could be a problem of hyper-parameter tuning. Could the author provide some explanation on this?\n\nIn experiments, the models on CIFAR10 and STL10 are trained with $L_\\infty$ perturbation magnitude of 0.03. They are evaluated under PGD and EOT-PGD with $L_\\infty$ in $[0,0.03]$. The range of attack perturbation magnitude on CIFAR10 and STL10 could be larger, such as $[0,0.08]$, to better compare the baselines with the proposed method.\n\nClarity and Correctness:\nThe paper is well written and easy to follow but the experiments might be problematic.\n\nReproducibility:\nCode of the method is not available.\n\nConclusion:\nThe idea is clear and novel but experiment results need more elaboration. Overall, I think the paper is marginally below the acceptance threshold. I like the idea of using conjugate prior to improve stochasticity and robustness. However, I'm a little bit concerned about the experiment results. If that can be addressed, I'm willing to accept the paper.\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Nice results and important direction, but too many misnomers. [Edited Post-Rebuttal]",
            "review": "In this paper the authors study the adversarial robustness of BNNs on large scale datasets. BNNs have been shown to be a more robust learning paradigm due to their uncertainty/stochasticity. Given the empirical observation that adversarially trained BNN posterior variances converge to zero (which the authors need to do much more to show as this is not a well-established phenomena), the authors propose a hierarchical prior where they put a prior over the parameters of the Gaussian prior normally used  in mean-field variational inference. The authors show that performing approximate inference with a hierarchical prior leads to an increased variational posterior variance, which the authors claim is correlated to the observation of increased adversarial robustness. \n\nI think the empirical results are solid, and the direction of the paper is ultimately an important one. I truly encourage the authors to continue to pursue this topic. \n\nUnfortunately, this paper is severely handicapped by its lack of clarity in terms of accurate contextualization, and its pervasive use of misnomers.  These misnomers are so prevalent that they would certainly lead uninformed readers to incorrect conclusions about Bayesian deep learning. \n\n* On the “true posterior:”  There are many places throughout the paper where the authors discuss/reference the computation of the true posterior for a Bayesian deep neural network. This can only be done by exact Bayesian inference. That includes (1) proper marginalization over the space of parameters (2) normalization wrt p(X). Given a DNN with non-linear activations, computation of the true posterior is intractable. Despite this, the authors claim that one can infer the true posterior via variation inference methods (bottom of pg 1). Variational inference makes a closed form approximation of the posterior that one tries to learn the parameters of. Even learning the optimal parameters does not guarantee convergence, outside of the case of conjugation.  Further on this, computing the true adversarial posterior is even more intractable given that the intractability of computing the optimal adversarial example compounds the issue of performing exact Bayesian inference.\n\n* Conjugate priors and hierarchical priors are distinct under the Bayesian framework. Despite this, the authors name their hierarchical prior the “conjugate” prior. In this work, the authors suggest placing a prior distribution over the parameters of their prior distribution (i.e. a hierarchical prior), yet call it a conjugate prior. A conjugate prior in the standard Bayesian literature is a prior which is known to be in the same family as the true posterior. It is not known, and likely not true, that for general approximate Bayesian neural networks (e.g. mean-field approximations) the true or approximate posterior is Gaussian. Thus, it is likely false to call a mean-field prior approximation a “conjugate” prior.\n\n * Robust Optimization is the special case of adversarial training where only adversarial data is used. The authors conflate adversarial optimization (optimization with respect to an adversarial objective) with robust optimization which has a rich history in optimization prior to its application to deep learning. The end of section 2.1 should have its terminology corrected.  \n\n* On the notion of ‘regularization’ in Bayesian deep learning. In several places the authors refer to the regularization term of the ELBO objective. This regularization term is the KL divergence with the prior distribution. While the prior distribution could be said to have a regularization effect on the posterior, saying that the prior distribution is a regularizer is reductive and probably misleading.\n\n\n----------------------------------------------\n\nFollowing the author's rebuttal I think the paper has benefitted from further experiments and from further clarifications. I would like to thank the authors for carefully considering my feedback and for modifying their paper in the directions I suggested. Ultimately, like I said in my original review, I think this is a very interesting and well-motivated problem, but I still have a few doubts. In particular, the doubt about the paper's use of the term of \"conjugate\" remains. In their rebuttal the authors use the term approximate-conjugate prior, but I am not sure that this is satisfactory as being conjugate means you have knowledge of the form of the true posterior's closed form, which is not the case for BNNs. \n\nI have increased my score to reflect that I think the authors are moving in a promising direction and I hope that they will continue with this work. One thing I will note on the experimental side of things is that having greater variance is indeed interesting, but it may or may not be correlated with increased uncertainty and this may be interesting to investigate in a future version of this work.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An extension to Adv-BNN to improve the robustness of BNN",
            "review": "Summary:\n\nThis paper presents a new adversarial training for BNNs with variational inference (VI). Specifically, Adv-BNN training of Liu et al. 2019 uses a standard normal prior for VI of BNNs.  The paper observes that the above method may have vanished stochasticity that reduces the robustness and the proposed method extends it with a conjugate prior constructed by a normal distribution and an inverse gamma distribution. This extension results in a stronger regularisation of the weights of BNNs, which can enhance the robustness against adv attacks and leads to a hierarchical inference. The method is reported to have better performance than vanilla adv training and adv-BNN training on several benchmark datasets.\n\nPros:\n- It is an interesting and motivative observation that AdV-BNN has vanished stochasticity issue, which is important for BNNs.\n\n- The proposed method is a straightforward way to address the vanished stochasticity issue.\n\n- The results in Table 1 are intuitive, which directly shows the proposed method has more stochasticity than Adv-BNNs.\n\nCons:\n\n- It is concerning that the reported performance of Adv-BNN in this paper has a significant difference than that reported in the original paper. In this paper, Adv-BNN performs worse than the vanilla adv training with a large margin, which is a bit surprised. Therefore, it is unclear whether it is Adv-BNN not working or it is the settings/implementations of this paper having something wrong. Given this fact, the performance reported in this paper seems to be ungrounded. It is hard to justify the true performance advantage reported in this paper.\n\n- The approach might be less related to the topic of \"hierarchical inference\", as it's only replacing the standard Gaussian with a normal-inverse-gamma distribution, which only affects the KL divergence in this case, where there are no intermediate variables are inferred.\n\n- Minor: Some of the notations and equations are a bit unclear. For example, q has been used to denote the posterior but it denotes the prior in Eq. (5)\n\n--------------------------------------------------------------------------------------------------------------------------------------------------\n\nThe author response addresses my major concern on the experimental results. Therefore, I have updated my rating from 5 to 6.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A sound method with unclear experimental settings",
            "review": "This paper studies the adversarial robustness of DNNs with Bayesian neural networks. Although BNN has been integrated with adversarial training for better robustness, this paper argues that the previous method lacks the stochasticity (i.e., the posterior tends to have zero variance), thus limiting the robustness performance. In this paper, a new hierarchical variational inference is proposed to enhance the robustness when integrating with adversarial training. The proposed method is presented well. The experiments show the effectiveness of the proposed method.\n\nBesides, I have few concerns about this paper.\n\n1. This paper argues that the previous method (ADV-BNN) learns the posterior distribution that has near zero variance, but does not analyze why ADV-BNN causes this phenomenon. Does normal BNN models (without adversarial training) also have this issue?\n\n2. The experimental settings are unclear in the context. The parameters of PGD and EOT-PGD are not stated (e.g., number of steps, step size, number of samples in EOT, etc.). Therefore, it is hard to judge the significance of the results.\n\n3. This paper lacks the comparison with the state-of-the-art methods. A common practice is to use Wide ResNet models for adversarial training and set the L_infty norm of perturbation as 16/255. I suggest the authors to compare with the public adversarial training models.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}