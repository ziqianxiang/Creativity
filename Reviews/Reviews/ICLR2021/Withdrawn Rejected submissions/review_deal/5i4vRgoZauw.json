{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper received 2 borderline accepts, 1 accept, and 1 reject.\n\nThis paper was discussed on the forum and no consensus was reached. The two reviewers who rated the paper as borderline accept emphasized that the biological claims are overblown, that the intellectual contributions (the initialization scheme and partial training) are incremental from a statistical learning perspective, and that the potential applications for the future (like alternate learning rules) are too speculative. I agree with both of these reviewers (and the negative reviewer) that the biological rationale is problematic and the approach is not credible as a model of biology. It is not evaluated as a computer vision model either. And I completely agree with the point raised by several reviewers that there is simply no data about how many synaptic updates to target. Hence, statements regarding % of total synaptic updates and % of brain matches seem empty without a precise target. For all these reasons, I recommend this paper be rejected."
    },
    "Reviews": [
        {
            "title": "How much can we rely on BrainScore's metric in studies like this one?",
            "review": "Summary\n-------\nThe paper is about ANN being best-known models of developed primate visual systems. However this fact does not yet mean that the way those systems are trained is also similar. This distinction and a step towards answering this question is the main motivation of this work. The authors demonstrate a set of ideas that while drastically reducing the number of updates maintain high Brain Predictability according to the BrainScore. The significance of this result in my opinion largely depends on how well we can map those observations and methods to biological meaning and knowledge on how primate brains are trained (see the discussion point below).\n\n\nCritique, Questions, Discussion\n-------------------------------\n(1) How good the \"match\" between the brain and DCNN is in the first place? For example, if we measure the match in terms of correlation (between responses, or predictions, any metric would work in the context of this question), then 80% of corr=1.0 would be very impressive and significant, while 80% of corr=0.2 (being corr=0.16) could well fall under the noise and while being significant numerically, does not give us the opportunity to say that we have captured 80% of the match between the artificial system and the ventral stream (because what we have actually captured is 80% of corr=0.2, which might as well be almost nothing).\n\n(2) \"squirrels to jump from tree to tree within months of birth\", \"macaques to exhibit adult-like visual representations after months\" -- hoe many synaptic updates happen during those months? Do we know? Maybe it is also in trillions? In which case this portion of the argument would fall apart. Emphasis on \"supervised\" would probably still survive.\n\n(3) \"a child would need to ask one question every second of her life to receive a comparable volume of labeled data\" -- are they not? I would say children get even more data if by \"question\" we will mean not only verbal questions and answers, but also answers that are tactile (\"how this will feel on touch?\"), auditory (\"what does this object sound like\"), visual prediction (\"will this thing now move to the right or to the left?\"), etc. Seen like this I would say that children receive tons of supervised data and \"one per second\" is an underestimation.\n\n(4) How does the \"match\" vary depending on random initialization? Is it consistently 54% or is there a substantial +/-?\n\n(5) How do we know the \"true zero\" in terms of the \"match\"? What would be a model (function? maybe a constant function?) that clearly has zero \"match\"? If we now take this function and run it through your pipeline to get the match%, would the result be indeed 0% or something else? Maybe 54% is the \"true zero\" and not 0%.\n\n(6) Why sampling from CORnet-S-based clusters of parameters is a good way of modeling \"at-birth\" situation? Compared to 54% achieved with this methods, what would be the match% if the network would initialized with vanilla Kaiming Normal? Uniform?\n\n\nRecommendation and justification\n--------------------------------\nMy main concern is with the interpretation of the meaning of this work. BrainScore's metric is a very approximate proxy that weakly reflects the match between models of vision. In this work, however, this metric is taken as a \"gold standard\" and it is assumed that achieving, for example 50% of BrainScore of 0.42 is something biologically meaningful. An ablation experiment that would demonstrate that achieving these 50% (or other numbers presented in the paper) is a non-trivial event which can only happen if the model is indeed becoming more \"brain-like\" would go a long way in making the case of this work strong. I suspect, however, that such an ablation study will show that there are ways to achieve high% of BrainScore using models that are completely dissimilar to the brain. I currently evaluate this submission as borderline, and am looking forward to authors' views on the concerns I have outlined above: do these indeed matter and affect the claims of this work (and how should we see them if that's the case), or are these concern largely irrelevant (and why we can ignore them if that's the case?).\n\n\nAdditional remarks\n------------------\nArguably missing references on modeling of the ventral stream with ANNs: https://www.nature.com/articles/s42003-018-0110-y, https://www.jneurosci.org/content/35/27/10005\n\n\nUPDATE - Nov 30\n-----------------------\nAfter looking at the revised version of the manuscript I am still concerned that the claims made in the abstract (and implied in the main text of the paper) about the match of ANNs to the brain are misleading the reader into assigning greater biological significance to the reported result than it actually holds. While the authors made slight modifications in the text and added a few sentences commenting on the issue, these changes did not constitute a change would make the reader \"extremely aware that when you say \"80% match\" you don't mean \"80% match to the brain\", but \"80% match to the score\"\". I find that a softer claim that would explicitly acknowledge that 5% of \"synaptic\" updates explain 80% of the predictivity score and not 80% of the match to the brain would make this work more scientifically precise and thus more valuable. I am keeping my original assessment of this paper as being borderline.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting yet unconvincing ideas about modeling the primate visual system with DNNs",
            "review": "The study starts from the fact that DNNs have been around and popular for a while for modeling the visual system, but that they are not realistic because they are trained via supervised learning approaches with a very large number of parameters and that this is not a feasible model of the development in the visual system.\n\nIn general, although the manuscript presents some interesting ideas, it makes many assumptions without providing clear bases for these assumptions (e.g. compressing the weights of a pretrained network to sample new weights is posed as a realistic approximation of the infant visual brain) and lacks a theoretical foundation for the claims and experiments that are presented. The authors acknowledge that this study is intended as a proof of principle, but given the arbitrary nature of the choices made, I do not see the added significant value of the results.\n\nWhile DNNs are indeed commonly used as models of the primate visual system, in my view, the current study is addressing a somewhat inconsequential problem. This is because to the best of my knowledge, no neuroscientist is claiming that a deep neural network is a complete and accurate model of the (development of the) primate visual system. Furthermore, it is well-known and acknowledged that deep neural networks are not biologically plausible models of (how learning occurs in) the brain. They are currently one of the best computational tools to use to study the sensory (and especially the visual) nervous systems, and that is all that they are. It is not clearly explained why it is necessary to claim that the learning in these models and the development of the brain has to be similar for them to be good models of vision. Of course, we should thrive for better and more accurate models of the brain, but in my view the current study does not serve to this goal.\n\nIn section 4 authors describe an initialization protocol for the network weights which involve compressing a trained model’s weights into clusters and then sampling from these clusters. What is not clear is why the authors assume that this can be a valid model of the infant visual system. At this point their approach sounds like arbitrarily selecting a set of criteria to make the networks perform worse than fully trained networks, and then training them. I could be missing something, but I do not see the relevance or necessity of an approach such as the presented one. A main concern is that no theoretical basis has been established in the paper besides some superficial ideas. For instance, why would an infant brain be made up of a DNN with connections whose weights are initialized with the method authors came up with?\n\nMuch of the methodological details are only included in the appendix. I found it rather odd to not find any information about, for example, the proposed weight initialization method in the paper.\n\nIt is not clear to me what is presented in Figure 1 and why. Why are the authors showing how models from another paper trains?\n\nAnother concern is that nowhere in the results seems to be a test for significance. The improvements of the results could be a coincidence, since the results are heavily dependent on one experiment.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Surprising reduction in number of weight updates needed to achieve a good Brain-Score",
            "review": "Summarize what the paper claims to contribute. \nPrevious work developed CORnet-S, a biologically inspired network that leads the Brain-Score benchmark of similarity with the primate ventral stream. A limitation of CORnet-S and other deep networks with high Brain-Scores is that they require many more weight updates than seem biologically feasible. In this paper, the number of weight updates used to train CORnet-S is reduced by two order of magnitude, while retaining a fairly high Brain-Score. This is done by combining three approaches, including reduced training, initialization of weights using compact distributions that describe trained weights, and updating only a minority of layers. \n\nList strong and weak points of the paper. \nStrong Points:\n-\tThe paper addresses an important problem that has not been given much attention previously\n-\tThe work builds on the state-of-the-art model in this domain\n-\tThe three approaches to reducing updates are complementary and interesting in different ways; the second and third thought-provoking with respect to their biological relevance\n-\tThe experiments and analysis are thorough\n-\tThe paper is well written\n-\tThe context of the work is clearly described and well referenced\n\nWeak Points: \nI wasn’t able to discern any substantial weaknesses. \n\nClearly state your recommendation (accept or reject) with one or two key reasons for this choice. \nI recommend acceptance. The number of updates needed to learn realistic brain-like representations is a fair criticism of current models, and this paper demonstrates that this number can be greatly reduced, with moderate reduction in Brain-Score. I was surprised that it worked so well. \n\nAsk questions you would like answered by the authors to help you clarify your understanding of the paper and provide the additional evidence you need to be confident in your assessment. \n-\tIs the third method (updating only down-sampling layers) meant to be biologically relevant? If so, can anything more specific be said about this, other than that different cortical layers learn at different rates? \n-\tGiven that the brain does everything in parallel, why is the number of weight updates a better metric than the number of network updates? \n\nProvide additional feedback with the aim to improve the paper. \n-\tBottom of pg. 4: I think 37 bits / synapse (Zador, 2019) relates to specification of the target neuron rather than specification of the connection weight. So I’m not sure its obvious how this relates to the weight compression scheme. The target neurons are already fully specified in CORnet-S. \n-\tPg. 5: “The training time reduction is less drastic than the parameter reduction because most gradients are still computed for early down-sampling layers (Discussion).” This seems not to have been revisited in the Discussion (which is fine, just delete “Discussion”).\n-\tFig. 3: Did you experiment with just training the middle Conv layers (as opposed to upsample or downsample layers)? \n-\tFig. 3: Why go to 0 trained parameters for downstream training, but minimum ~1M trained parameters for CT? \n-\tFig. 4: On the color bar, presumably one of the labels should say “worse”. \n-\tSection B.1: How many Gaussian components were used, or how many parameters total? Or if different for each layer, what was the maximum across all layers? \n-\tSection B.3: I wasn’t clear on the numbers of parameters used in each approach. \n-\tD.1: How were CORnet-S clusters mapped to ResNet blocks? I thought different clusters were used in each layer. If not, maybe this could be highlighted in Section 4. \n\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review for \"Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream\"",
            "review": "This paper presents an empirical study that elucidates potential mechanisms through which models of adult-like visual streams can \"develop\" from less specific/coarser model instantiations. In particular, the authors consider existing ventral stream models whose internal representations and behavior are most brain-like (amongst several other models) and probe how these fair in impoverished regimes of available labeled data and model plasticity (number of \"trainable\" synapses). They introduce a novel weight initialization mechanism, Weight Compression (WC), that allows their models to retain good performance even at the beginning of training, before any synaptic update. They also explore a particular methodology for fine-tuning, Critical Training (CT), that selectively updates parameters that seem to yield the most benefit. Finally, they explore these methods/algorithms' transfer performance from one ventral stream model (CORnet-S) to two additional models (ResNet-50 and MobileNet).\n\nPros:\nThe problem that the authors present is an interesting one and undoubtedly useful for many applications. Deep neural networks such as the CORnet-S, ResNet-50, and MobileNet are data-hungry, and obtaining labeled data is an expensive process (and perhaps even implausible in many cases). Techniques to condense these models in terms of parameters and alleviate the need for vast amounts of labeled data while maintaining desirable traits (such as brain-like representations) are important for the machine learning community. Though a bit far-fetched at this point, tracking the developmental trajectories of these neural networks can also have other scientific implications in the form of data-driven hypothesis testing.\n\nThe most exciting part of the study is the transfer experiment (from CORnet-S to ResNet and MobileNet). This seems like an interesting and novel way to construct model taxonomies. For instance, sampling from the CORnet-S weight clusters works well for ResNets potentially because these two models can be construed as \"recurrent\" in a way. MobileNets, on the other hand, are purely feedforward and thus are not significantly influenced by knowledge from the CORnet-S weights.\n\nMoreover, the authors conduct a series of numerical experiments to identify \"when\" their proposed methods are most useful. The finding that WC+CT is more advantageous in regimes where data is scarce (as opposed to regimes where data is plenty) is not surprising but a good one to report. I say \"not surprising\" because WT distills knowledge from a fully trained model, and CT only updates a fraction of the parameters (updating more parameters would require more data to prevent overfitting).\n\nCons:\nThe authors take the analogy between \"a developing visual system\" and \"training a model\" a bit too far. They operate under the premise that visual circuitry develops purely via \"supervised\" learning. Is there conclusive evidence for this? It is also surprising that discussions of reinforcement learning mechanisms never feature, given that these are more biologically plausible.\n\nThe novelty (and utility; for ex: Fig 2b) of the proposed initialization technique is marginal. It is not articulated how their method (WC) overcomes the critiques they raise against Frankle et al. 2019. Moreover, claiming that WC achieves decent performance with \"zero\" synaptic updates is not fair. This seems to be closer to restoring pre-trained weights than to random initialization (like KN). \n\nFor CT, the authors choose \"critical\" layers to update. Is there a rationale (or a statistical metric) that justifies choosing these specific layers? \n\nThe WC kernel cluster center visualization analysis (Fig. 5c) seems out of place and poorly discussed. What can be gleaned from the 3x3 kernels shown here?\n\nMinor:\nBy \"supervised updates,\" the authors refer to the number of available labels and not the number of parameter updates that happen. This terminology is non-canonical. \n\nEmploying Gabor priors for the first convolutional layer: Doesn't orientation selectivity emerge in the primary visual areas from experience, rather than structurally hard-coded? \n\nThe authors allude to the possibility of using \"local\" learning rules on a subset of layers identified by CT. However, this is speculation from the point of view of the current manuscript. All the conclusions drawn are from \"global\" gradients.\n\nAmbiguous sentence (Pg. 6, Sec 6): \"Reducing the number of supervised updates minimizes required updates by a smaller number of epochs and images.\"\n\n(Pg. 8) \"synaptic updates primarily take place in higher cortical regions\": Is there evidence for this?\n\nNumerical imprecisions:\n(i) The authors claim that the performance of CORnet-S_wc is 54% (relative to the fully trained model). However, in Fig 2b (mean) and Fig 3c (top) the markings seem to be closer to 50%?\n(ii) (Fig. 4a) The performance of MobileNet seems to be slightly better than CORnet-S, which contradicts the initial claim that CORnet-S is currently the best available model of adult primate visual processing.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}