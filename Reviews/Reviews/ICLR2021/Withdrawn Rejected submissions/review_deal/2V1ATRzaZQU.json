{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "In this paper, the authors study the behavior of the Lookahead dynamics of Zhang et al. (2019) in bilinear zero-sum games. These dynamics work as follows: given a base algorithm for solving the game (such as gradient descent-ascent or extra-gradient), the Lookahead dynamics perform $k$ iterations of the base algorithm followed by an exponential moving average step with weight $\\alpha$. The authors then provide a range of sufficient conditions for the eigenvalues of the matrix defining the game under which the Lookahead dynamics become more stable and converge faster than the base method.\n\nThis paper received four reviews and generated a very lively discussion between the authors and reviewers. Reviewer 4 was enthusiastic about the paper; the other three initially recommended rejection. During the discussion phase, the authors revised their paper extensively, and Reviewer 3 increased their score to an \"accept\" recommendation as a result. In the end, the reviewers were evenly split, and I also struggled a lot to reach a recommendation decision.\n\nOn the plus side, the paper treats an interesting problem: prior empirical evidence suggests that the Lookahead dynamics can improve the training of some adversarial machine learning models, so a theoretical study is very welcome and of clear value. On the other hand, the setting treated by the paper (bilinear min-max games) is somewhat restrictive, and the authors' theoretical conclusions do not always admit as clear an interpretation as one would like.\n\nThe issues that ended up playing the most important role in my recommendation were as follows:\n1. The Lookahead dynamics with period $k$ involve $k$ gradient evaluations, so their rate of convergence should be compared at a $k:1$ ratio to GD and EG (with an additional $2:1$ ratio between GD and EG to put things on an even scale). To a certain degree, this $k:1$ ratio is present in the last part of Lemma 3; however, the exact acceleration achieved by the \"shrinkage\" of the spectral radius is not clear. This can also be seen in the semi-log plots provided by the authors, where the corresponding slopes of GD/EGD methods should be multiplied by $k$ when compared to the respective LA variants. In this regard, a comparison with the values of $k$ provided in Appendix D reveal that the performance of the Lookahead variants in terms of gradient queries is very similar (if not worse) to the non-LA variants. This is a cause of concern because, if LA does not accelerate convergence in simple bilinear games, it is not credible to expect faster convergence in more complicated problems. During the AC/reviewer discussion of this point, Reviewer 3 pointed out that this might be due to a suboptimal tuning of $\\alpha$ (i.e., that it was not chosen \"small enough\"), and went out to note that this echoes the arguments of other reviewers that the characterization of acceleration may be problematic and not significant (even if it takes place).\n2. Another major concern has to do with the stabilization provided by the Lookahead dynamics: using a benchmark game proposed in a recent paper by Hsieh et al. (2020), the authors showed that the Lookahead dynamics converge to a point which is unstable under GDA/EG (and hence avoided). This is fully consistent with the authors' theoretical analysis, but it also highlights an important problem with the Lookahead optimizer: if $k$ and $\\alpha$ are tuned to suitable values for stabilization, the algorithm converges to a non-desirable critical point (a max-min instead of a min-max solution). This is a major cause of concern because it shows that the algorithm may, in general, converge to highly suboptimal states.\n\nThe above create an inconsistency in the main story of the paper. In fact, it seems to me that the authors' results form more of a \"cautionary tale in hiding\": even in very simple bilinear problems, the lookahead step may not provide acceleration and, even worse, it could converge to highly undesirable critical points. I find this \"negative\" contribution quite valuable from a theoretical standpoint, and I believe that a thoroughly revised paper along these lines would be of interest in the top venues of the community (though a more theoretical outlet like COLT might be more appropriate). However, this would require a drastic rewrite of the paper, to the extent that it should be treated as a new submission.\n\nIn view of all this, I am recommending a rejection at this stage. I insist however that this should not be seen as a critique for the mathematical analysis of the authors (which was appreciated by the reviewers), but as a recommendation to reframe the paper's narrative to bring it in line with the algorithm's observed behavior. I strongly encourage the authors to resubmit at the next top-tier opportunity."
    },
    "Reviews": [
        {
            "title": "Require more work in terms of clarity",
            "review": "This paper studies the theoretical aspect of lookahead dynamics of smooth games, inspired by the recently introduced Lookahead optimizer, in the spirit of studying the game dynamics of multiple agents. \n\nThe overall writing of the paper is not clear enough and should be organized better. For instance, in Sections 3.2 and 4, there are several consecutive theorems which should be better organized to enhance readability. The *Proof.* environments should also be omitted. Not being an expert in this area, I cannot judge the novelty of this work. The usage of the English language should also be improved to avoid grammatical mistakes. \n\n\nPros: \n- Possibly novel theoretical study of the game dynamics driven by the recently proposed lookahead optimizer.\n\n\nCons: \n- The main text is not self-contained; see below:  \n    - Lots of non-standard notation are not defined before being used. And the main text does not contain any pointers to the supplemental material for the list of mathematical notation. The notation $ \\mathbb{M}_{m \\times m} $ is never defined. How is it different from $ \\mathbb{R}^{m \\times m} $? Or does it stand for a matrix group like $ \\mathrm{GL}_m(\\mathbb{R}) $? I also think the principal argument $ \\mathrm{Arg} $ should be used instead of vaguely defining $ \\mathrm{arg} $ which is multi-valued in complex analysis.\n    - Some of the propositions and theorems in the paper are not mathematically precise or rigorous enough. E.g., proper choice of $ k $, small enough $\\alpha $, etc. Without making the statements precise, I found some theoretical results in the paper vacuous and hard to interpret.\n\n- The numerical experiments are not sufficient. Results of GAN optimization are expected as in other papers in this line of work, in order to demonstrate the full effectiveness of the proposed scheme. \n\n- The figures, especially Figures 2 and 3, seem to be of quality not up to publication standard and unclear.\n\n\nDespite my unfamiliarity with this line of work, I think this paper needs to be improved before acceptance, and I suggest rejection for the current state of this paper. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An interesting idea that could be developed further",
            "review": "## Summary\nThis paper provides a spectral analysis of Lookahead dynamics. This paper’s main results state that lookahead dynamics can improve a given method’s convergence rate if the Jacobian’s operator has eigenvalues with non-zero imaginary parts and an imaginary conditioning (ration between the largest and the smallest imaginary part) smaller than 3.\n\nOverall I think that the idea of this paper is exciting and is motivated by recent empirical observation. However, the theoretical results of this paper are relatively weak because of some restrictive assumptions. \n\n### Pros \nThe motivations of this paper are clean and propose a promising line of analysis. \n\n### Cons \nThe theory is only developed in a very restrictive setting (Bilinear with condition number smaller than 3 and general games with non-real eigenvalues and imaginary condition number smaller than 3) where the optimization problem is easy to solve. (a small condition number corresponds to an easy optimization problem.)\nThe experiments are relatively weak since they are only on well-conditioned bilinear games, a 2D non-linear problem, and do not explore the necessity of the assumptions of the theorems of the paper.\n\n## Questions/comment: \n\n- It seems to me that the condition that the Jacobian has non-real eigenvalue and $\\frac{\\mathcal I_\\max}{\\mathcal I_\\min} < 3$ is an artifact from your technique proof because lookahead does converge in the context of minimization (only real eigenvalues). \nThough in the minimization case, it seems quite direct to see that look ahead slows down the dynamics $ 1 - \\alpha + \\alpha \\lambda > \\lambda \\, \\forall 1>\\lambda >0$ the interesting property of lookahead highlighted by this work is that it can positively affect the impact eigenvalues with a large imaginary part on the convergence. \nSince in games, it has been shown that eigenvalues with a large imaginary part may slow down the convergence of games [Mescheder 2017], lookahead seems to be a promising direction to improve the convergence rate of the gradient method. Specifically, in the context of games with large or infinite imaginary condition number.\n\n- Overall, I think that this paper would benefit from a more precise analysis of the convergence rates.  Then answer the following question: can we find some problems where lookahead provides a significant improvement in terms of convergence rate (against standard methods such as Extragradient or Gradient). \nThe concept of acceleration usually refers to a significant improvement of the convergence rate (see for instance [Azizian et al. 2020] for a discussion on acceleration on games.) In the case of Theorem 3 it would mean $\\rho(f(X)) << \\rho(X)^k$.\n\n\n- Also, I am not sure about the relevance of the “local stabilization properties”, usually one may want to diverge from certain points where $\\rho(\\nabla_x F(x)) >1$ e.g., local maxima. \nWhat can you say regarding the fact that Lookahead does not converge to “bad” stationary points (for instance, in multi-objective minimization one want to avoid a local maximum for each player’s loss)?\n\n- Regarding your experiment, you could try to test if the conditions in your theorem are necessary:\nCan I find hyperparameters to make lookahead converging even when there are real eigenvalues or a condition number larger than 3? \nCan lookahead provide improvement with respect to optimization methods that provably perform well on bilinear minimax such as extragradient with momentum or specific method for bilinear [Azizian et al. 2020]?\n\n\nAzizian, Waïss, et al. \"Accelerating smooth games by manipulating spectral shapes.\" AISTATS (2020).\n\n\nMescheder, Lars, Sebastian Nowozin, and Andreas Geiger. \"The numerics of gans.\" Advances in Neural Information Processing Systems. 2017.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Report",
            "review": "Summary: This paper investigates „lookahead dynamics of smooth games“. By this the authors mean discrete-time dynamical systems generating from a given algorithm by adding a relaxation step in the updates. The main aim of the paper is to solve smooth games. Under sufficient convexity assumptions Nash equilibria for such games can be identified as solutions to a Variational Inequality with a monotone and operator. This is in particular the case for convex-concave min-max problems. The main conclusion of this paper is that a combination of relaxation and lookahead effects stabilizes the learning dynamics and can lead to acceleration over the base algorithm.\n\nEvaluation: This is a very strong paper with an extremely large number of interesting results. In my opinion it makes an extremely good contribution to the flourishing literature  on game dynamics. I only have some small technical remarks which can easily be fixed. \n\n\nSpecific Remarks: \n\n .  Interchange the order of eqs. (5) and (6).\n. Define $F^{k}$ in eq. (7) \n. Check for consistency of notation: Sometimes $M_{m\\times m}$ is used for the matrix space, then $\\mathbb{R}^{m\\times m}$. If the former is used, explain which field of numbers is used. \n. Define $\\rho$ in Theorem 3\n",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An important problem to study but the results are somewhat limited and not so well presented",
            "review": "### Summary\n\nMotivated by the empirical success of lookahead in GAN training, the paper studies theoretically the convergence behavior of the algorithm in smooth games. In particular, the authors focus on bilinear games and local convergence around equilibrium points and derive sufficient conditions under which lookahead improves upon its base dynamics (by either stabilizing a non-convergent algorithm or accelerating a convergent one). \n\n### Pros\n\nThe lookahead optimizer studied in this paper is relatively new and worths more theoretical investigation.  In this spirit, this work consists in, as far as I am aware, the first attempt to understand theoretically the performance of lookahead in game optimization. The results concerning the potential stabilization and acceleration achieved by the lookahead mechanics provide us some insight into the reasons for its empirical success.\n\n### Cons\n\n#### On the significance of the results\n1. The sufficient conditions provided by the authors appear to be too restricted and cannot paint a global picture of what would happen in practice (even in the bilinear case). \nIn more than half of the theorems, we require the (imaginary) condition number to be smaller than 3. Is this realistic? What happens if this is not verified? Is it even reasonable to suppose that every eigenvalue of the matrix $J$ has non-zero imaginary part given that we would be at the other opposite if we consider a minimization problem (every eigenvalue would be real)? \nThe work would be much more complete if the authors could also discuss what may happen if these sufficient conditions are not verified.\n2. The implication of Theorem 12 is unclear. The fact that the dynamics avoids unstable equilibrium points of the dynamics itself seems to be of little interest for the problem that we are solving (and is a quite standard result). In effect, we are more interested in the characterization of the set of stable equilibrium points which may contain undesired solutions. This is clearly illustrated by the nonlinear game experiment in which the algorithm converges to a spurious attractor of the problem (to be explained in more detail below).\n\n#### On the presentation of the results\nThe presentation of the results needs to be improved. In its current form, the authors provide plenty of theorems that could be difficult to decipher for the readers. \n1. For example, it seems that both Theorems 3 and 4 are mainly used for deriving the rest of the theorems. This can be explicitly stated and I even feel it would be better to call them lemmas instead of theorems since it is not immediately clear what these two results imply. \n2. The authors could comment on the existence of $k$ for Theorems 5~11. While this is easy to derive it would be helpful to clearly state this somewhere (such as a sentence saying that such $k$ will always exist in all the theorems.)\n3. For both Theorems 10 and 11, corollaries for different base dynamics under different assumptions on the Jacobian of the vector field can be provided. Again, this may be straightforward but can help to understand the results.\n\n### Detailed comments\n\n#### Bilinear game reduction\n\nFor the paragraphs at the bottom of page 5. The authors describe why we only need to be interested in a bilinear game of the form (11). I understand this is due to the fact that modulo some transformation (9) and (11) have in fact the same trajectory. However, given the presentation of the paper, we may feel that to solve (9) we first solve (11) but this does not really make sense because the real goal is not to solve the problem (otherwise for (11) we know the solution is the all-zero vectors) but to understand how the algorithms perform in this problem. I feel that this point is much better explained in, for example, Zhang & Yu (2020).\n\n#### Diagonalizability\n\nI fail to understand the authors' arguments about the diagonalizability of the matrices in the proofs of Theorems 5\\~8.  Nonetheless, I feel this can be easily proved by using the fact that all real symmetric and skew-symmetric matrices are diagonalizable and we do not even need the extra assumptions on $k$ of Theorems 6~8.\n\n#### Nonlinear game experiment\n\nIn my opinion, the nonlinear game example considered in the experiments is not very appropriate. Actually, it depends on the problem that we are looking at. For (13), the origin is not a saddle point and not even a min-max solution (while it is a max-min solution). If our goal is to find the zeros of the vector field, we indeed want a convergence to the point. However, the whole paper is motivated by the computation of a (local) nash equilibrium, then we would like to avoid this point. Notice how this example is presented in (Hsieh et al. 2020): we want to escape from the origin and not converge to it. \nWhile the above points are not in conflict with what the authors want to demonstrate, this should be made clear to the readers to avoid confusion.\n\n#### A very minor point\nEquation (25) and the following analysis are actually for the proximal method, not EG.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}