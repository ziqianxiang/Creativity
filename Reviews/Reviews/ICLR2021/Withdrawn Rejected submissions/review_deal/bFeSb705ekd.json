{
    "Decision": "",
    "Reviews": [
        {
            "title": "Interesting idea and well-written, but lack of sufficient motivation and contribution",
            "review": "This paper proposes Order Attack (OA), an adversarial attack for attacking deep ranking systems. Unlike previous attacks that focused on perturbing absolute ranking of candidates, OA considers the relative order of targets. In the white-box attack, a triplet-style loss is added to reflect the relative position of the candidate, and in the black-box attack, a Short-range Ranking Correlation metric is proposed as a surrogate objective for optimization. Extensive experiments prove the effectiveness of the proposed algorithm.\nStrong points:\nIt is an interesting idea to consider the relative position of candidate solutions in a depth ranking system.\nThis paper is well written and easy to understand. In the beginning, readers can have a clear understanding of the ranking attacks that this paper focuses on, rather than an immediate concept. \nThe authors did very extensive experiments to evaluate the effectiveness of the proposed method.\nWeak points:\nThe method in the paper lacks sufficient motivation. Intuitively, absolute ranking seems to be more common in practical applications. So the author should clearly indicate the importance of relative ranking research. However, the article only stated that the relative order is critical and did not elaborate further. Also, from the example of conten-based image retrieval (2nd paragraph of section 1) and the attack on the actual application of \"JD SnapShop\", the advantages of the relative ranking attack are not seen. This inevitably makes us doubt the significance of the study.\nThroughout the full text, the triplet-style loss and Short-range Ranking Correlation used in the ranking attack are mainly proposed, but these two metrics are only reasonable designs in the relative ranking attack scenario and have no outstanding contribution.\nThe core optimization methods of Order Attack, PGD and SPSA, are all used in the field of adversarial attack or prior ranking attacks. Therefore, the proposed attack lacks novelty.\nIn the experiment, the author mentioned that Fashion-MNIST has a smaller intra-class variance than SOP when explaining the different trends of mR in the two datasets, but there is no relevant experimental support.\nIn the 2nd paragraph of subsection 3.1, the author suspects that the different curve patterns of mR stem from the optimization difficulty due to limited search space (768-dimensional v.s. 3072-dimensional), and different dataset properties. However, compared to Fashion-MNIST, SOP has a higher dimensionality, and optimization should be more difficult, so it seems unreasonable to explain from the dimensional level.\nMinor issues\nAbstract: realword -> real-word\nBeta in subsection 2.1 is not defined, and it and the Gamma of this paragraph seem to indicate the same margin.\nSubsection 2.1: an Euclidean -> a Euclidean\nIn subsection 2.1, T represents the number of iterations in the PGD attack. However, in the experimental settings, first set T to 10000, and then set the number of iterations of PGD to 24, which is contradictory.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An extension of an existing work from white-box to black-box",
            "review": "This paper describes a novel targeted adversarial attack against deep ranking models, that is applicable under both white-box and black-box setting. In the ranking scenario, the ranking model is input with a query image and then outputs a candidate set containing k items, where the candidate images are sorted by the similarity between the query image and itself. \nThe attack tries to assign the candidate set to be sorted in a specific permutation order by adding a perturbation onto the query image. As for the white-box setting, the perturbation is computed by optimizing a proposed Order Attack (OA) loss function, which contains two terms considering the relative order and the absolute rank respectively. The traditional PGD method is utilized. As for the black-box setting, attacker design a Short-range Ranking Correlation (SRC) measurement to approximate the ranking correlation, and attacker has tried several mature query-based black-box methods to do the optimization such as NES and SPSA. Experiments on several open dataset and a real-life ranking API have proven the effectiveness of the proposed Order Attack.\n\nMajor concerns:\n1) This paper considers both the while-box and black-box scenario, and the experimental results are adequate and quite impressive, which reflects the hardworking of authors. However, I think the white-box version of Order Attack is just a variant of the Query Attack proposed in [1], and even the definition of semantic-preserving term is the same. Except this, only the Short-range Ranking Correlation (SRC) is novel. As a result, the contribution of this paper is quite limited in my opinion, and this paper is more like a display of plethora experimental results.\n2) In my understanding, the proposed Short-range Ranking Correlation in the black-box scenario, which is equivalent to Kendall’s ranking correlation, acts as a surrogate loss function for Order Attack loss function. However, the Kendall’s ranking correlation is not well defined. More details and explanations about the SRC are required.\n\nMinor concerns:\n1) As a real-life experiment on JD SnapShop is conducted, I wonder why the image space is still set as [0, 1] float. Since the images in real life are drawn from [0, 255] integer exactly, will the Order Attack still work then?\n2) Plot lines and captions in Figure. 2 are hardly visible.\n\n[1] Zhou, Mo, et al. \"Adversarial Ranking Attack and Defense.\" arXiv preprint arXiv:2002.11293 (2020).\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting ranking order attack against ranking systems",
            "review": "This paper proposed an adversarial attack to deep ranking system. In particular, the proposed attack can alter the relative order of a subset of items. \n\nStrengths: \n\n1. This paper proposes the first order attack against ranking system.  \n\n2. Evaluating the proposed method on benchmark datasets and real-world e-commerce platform. \n\nWeaknesses:\n\n1. Could the authors show some practical attack scenarios, where the relative ranking is important compared with absolute ranking. In most scenarios, we only care about these highly ranked items. The paper may discuss the practical relevance of the attacks since the proposed attacks will decrease the ranking of the target items. \nAlso, \"search by image\" is not a good scenario for adversarial examples since its unlikely that a genuine user will add noise to obtain \"misranking\" results? I am not sure how an attacker can perform the attack in this scenario. \n\n2. The technical contributions of the paper is limited. In particular, the paper defines some loss functions that can be used to find adversarial examples, which does not have enough technical contributions.  \n\n3. This paper uses l_{\\infty}-norm to measure the noise. The added noise is actually very large. For instance, when \\epsilon = 8/255 or 16/255, the noise is visible based on Figure 3. In other words, it's very likely that the defender can detect the attacks (under search space dimension reduction. The defenses of the attacks are not touched, e.g., the defender can train more robust model or detect the attacks. \n\n4. The paper needs to be further polished, e.g., C = {c_1, c_2,...,c_m}, I guess it should be c_k? i.e.f --> i.e., f?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Similar methodologies have got accepted to ECCV2020",
            "review": "This paper proposes a white-box and a black-box order attack against deep learning based ranking systems. The main contribution is how to formulate the non-differentiable ranking objective into a differentiable surrogate loss. The objective of the white-box order attack is formulated by  a set of triplet losses along with a semantics preserving QA term which is also triple-style loss. The objective of the black-box attack is formulated as a Short range Ranking Correlation which can be solved by zeroth order optimization methods.\n\nBigger issue:\n\nTechnically, the first white-box method proposed in this paper is similar to the one that recently got accepted to the ECCV2020, i.e., “Zhou et al. (2020)”. \n\nI strongly suggest other reviewers to have a look at the ECCV paper, equations (9) - (11), and the equations (1) - (4) in this paper.\nLink to the ECCV2020 paper: https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590766.pdf\n\nI don't think simply changing the attack setting is a good justification for the technical novelty. \n\nThe second contribution of the black-box attack is a straightforward application of zeroth order optimization algorithms to a non-differentiable ranking correlation metric. \n\nThese two extensions over the ECCV paper are marginal, and are not good enough for ICLR.\n\nI would like to hear more explanations if the authors turn out to be different from the ECCV paper.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}