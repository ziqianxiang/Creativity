{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper presents an KL-divergence minimisation approach to the action–perception loop, and thus presents a unifying view on concepts such as Empowerment, entropy-based RL, optimal control, etc.  The paper does two things here: it serves as a survey paper, but on top of that puts these in a unifying theory.  While the direct merit of that may not be obvious, it does serve as a good basis to combine the fields more formally.\n\nUnfortunately, the paper suffers from the length restrictions.  With more than half of the paper in the appendix, it should be published at a journal or directly at arXiv.   Not having a page limit would improve the readability much.  ICLR may not be the best venue for review papers."
    },
    "Reviews": [
        {
            "title": "Unifying information-theoretic objective",
            "review": "The authors formulate a general framework that unifies inference, action/perception, control, and several other tasks. The framework is based on minimizing the KL divergence between a parameterized \"actual\" distribution and a \"target\" distribution. The authors argue that this formulation unifies a wide range of previously proposed objectives. They also argue that it has some advantages when compared to Friston's \"free energy principle\" framework, with which it shares many similarities, in particular that probability matching is preferred to surprise minimization.\n\nThe paper is clearly-written and provides a very thorough literature review. However, generally I question the scientific value of such all-encompassing unifying frameworks, and this paper in particular offers no concrete formal or empirical results, while promising a lot. At the end of the day, the divergence minimization objective is nothing more than MaxEnt, decorated with various interpretations and decompositions. Without empirical support, I do not find the interpretations and decompositions very convincing -- as one example, does divergence minimization *really* mean that \"expressive world models lead to autonomous agents that understand and inhabit large niches\"? \n\nOne of the issues is that the paper appears to treat the \"heart of the matter\" (i.e., the source of interesting solutions) as if it lay in the elegant and generic objective. In my opinion, however, the real heart of the matter will be encoded in (1) the structure of the target distribution, (2) the structure/parameterization of the actual distribution, and (3) the optimization algorithm that can actually minimize the (typically) high-dimensional  objective. The quality of resulting solutions depend on 1-3 -- all of which need to be exogenously specified --- because divergence minimization cannot on its own produce interesting behavior. \n\nAt the end of the day, I do think there is some value in providing a unifying framework, and developing information-theoretic decompositions and interpretation. However, I think the paper would be *much* stronger if it was considerably longer and had more room to breathe (which it doesn't have right now -- given all the connections it tries to make), and if qualitative statements (of the type discussed above) were accompanied by empirical results (even if simulations with simple toy models).",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper discusses about the general training objective for perception, action and beliefs. The authors formulate a joint KL minimization objective and derived modern methods like variational inference,  control, MaxEnt RL to show the correspondance to their unified framework. This work is a theorectical-based paper without empirical studies. ",
            "review": "The authors proposed to use the joint KL divergence between the generative joint distribution and the target distribution (containing latent variables which could correspond to latent parts we wanted to model (e.g. beliefs). It was illustrative to discuss decomposing the joint KL into different ways and thus forming information bounds in different scenarios. The decomposition of past and future in Eq.6 also provided a unified perspective for looking at the most currently used objectives.\n\nThe examples shown in the paper and appendix give a good illustration of how people can make assumptions or design the terms to convert prevalent objectives into objectives that follow from this joint KL divergence framework. This is, in my mind, one of their key contributions for connecting the past progress in a general and unified way.\n\nHowever, one concern about this paper is that the proposal of such a unified KL minimization framework is in fact a bit too general and abstract. In fact, many methods mentioned in this work shared a similar insight of deriving objectives from a KL-minimization perspective, but some factors are omitted to better fit the corresponding tasks. The general decomposition discussed in this paper provides little hint on how new objectives could be derived for problems. The general framework does somehow serve as the guideline, but my worry is that its effect will be limited as we still need to design the mapping for the terms in the general objective accordingly in different tasks.\n\nGiven the pros and cons of this paper, I'm putting a borderline decision for now. The authors should clear any of my misunderstandings and perhaps show the potential for this general framework as a source for new objectives.\n\n=====================================================================================================\n\nAfter reading the authors rebuttal, my major concerns are fully addressed and I decide to keep my decision as weak accept",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "I reject this paper since the formulation of the information-theoretic (i.e., divergence minimisation-based) view of action and perception is already established and well-known.",
            "review": "The authors of this paper propose a unified optimisation objective for (sequential) decision-making (i.e., _action_) and representation learning (i.e., _perception_), built on joint (KL) divergence minimisation. As also mentioned by the authors, this is a concept paper and it includes no empirical study.\n\nIn particular, the authors demonstrate how existing ideas and approaches to (sequential) decision-making and representation learning can be expressed as a joint KL minimisation problem between a target and \"actual\" distribution. Such examples are (a) MaxEnt RL, (b) VI, (c) amortised VI, (d) KL control, (e) skill discovery and (f) empowerment, which are all cases of the KL minimisation between a target and an ``actual'' distributions.\n\n**Concerns**:\n1. Although the proposed perspective and language is rich and expressive, I question the novelty of the proposed framework, since the information-theoretic view of decision-making and perception is a rather established and old idea, even the term/idea of perception-action cycle is already defined [1]!\n2. The power of latent variables for decision-making and their interpretation is also a known idea [1].\n\n**References**\n\n[1] Tishby, N. and Polani, D., 2011. Information theory of decisions and actions. In Perception-action cycle (pp. 601-636). Springer, New York, NY.\n\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Impactful work, but with a few concerns",
            "review": "##########################################################################\nSummary:\n\nIn this manuscript, the authors propose a unifying framework for a large class of inference and reinforcement learning objectives, which have been studied in prior works by various authors. They demonstrate that approaches and central ideas from many different fields in the ML/AI community can be derived as limiting cases of their framework.\n\n##########################################################################\nReasons for score: \n\nOverall, I vote for acceptance (7). Like many, I have employed various variational approaches in the past and see its merit. While I agree with the main idea, this work is not without problems. This is especially problematic for such a broadly applicable work that will most likely influence plenty of future research. My main problems with this submission are:\n1.\tPresentation. While the paper is, for the most part, well written and well organized, there are some gaps/ jumps that render understanding difficult. Two examples:\nA)\tThe parameters \\phi. The authors start by introducing parameters \\phi as abstract placeholders for (i) parameters of the true joint distribution of data and latents of the underlying system and (ii) a set of actions an agent can perform to interact with this world. The agent's target distribution has no explicit parameter dependence. So far, so good. Then, one is redirected to the appendix A.1 and A.2. Section A.1 is already a bit confusing because suddenly, additional latents w are introduced that were not mentioned before. Then, suddenly in A.2. the target \\tau is suddenly dependent on the parameters \\phi, which were initially parameters of the underlying system's true joint distribution. This also happens in Figure 2. C), which is also never referenced in the text. I find this strange mixing of parameters of agent and system very confusing. It also sheds some doubt about the generality of the framework.\nB)\tI have read the paper carefully and still do not understand Figure 1 completely. This may also be due to the reason that it is only referenced in the appendix. Related: Why does Information gain play such a central role if all derived objectives only contain (upper) bounds for it appear?\n\n2.  \t(Unsupported) Claims: In the abstract, the authors promise to offer \"a recipe for designing novel objectives\". As much as I can see, they only come back to this promise in the conclusion, where they say that one could look at other divergence measures to arrive at new objectives, and they will leave it for future work. \nI would not call this a recipe, but an outlook at most. \n\n\n3.\tToo many ideas: It is hard, if not impossible, to explain a broad framework well in a conference proceeding. This work contains so many ideas and establishes many connections that following this work, and understanding them in detail becomes very hard. I would suggest sacrificing some connections in favor of a more concise presentation.\n4.\tFixation on KL-divergence: This is more of a suggestion. I understand that many works use the (non-symmetric) KL due to its favorable analytic properties. Thus, I agree that it makes sense to focus this framework on this measure. However, I believe this work's main idea still holds if one would exchange the KL with some other measure of similarity between distributions. Maybe it would make sense to first introduce and discuss the abstract idea of aligning target and belief before fixation on a particular measure. This would also go well with resolving my concern 2.. \n    \n\n##########################################################################\nPros: \n1.\tUnifying framework of many inference, and RL objectives.\n2.\tWell written.\n3.\tWill be impactful to a lot of future research.\n\n##########################################################################\nCons: \n1.\tSee my Reasons for score.\n\n##########################################################################\nQuestions during the rebuttal period: \n\nPlease address and clarify the cons above. \n\n#########################################################################\n\nMinor: \n· Please consider citing \nToussaint, M., & Storkey, A. (2006). Probabilistic inference for solving discrete and continuous state Markov Decision Processes. International Conference on Machine Learning (ICML), 945–952. https://doi.org/10.1145/1143844.1143963\nin the \"control as inference\" section. To my knowledge, it is one of the first to establish the connection between planning and inference. \n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}