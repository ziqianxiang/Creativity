{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This submission considers the problem of learning disentangled representations from data in which there are correlations between underlying factors of variation (FoVs). Much of the work on learning disentangled representations has considered simulated datasets in which the FoVs are conditionally independent. The authors perform an extensive experimental evaluation (4000+ trained models). The main findings of this evaluation are that:\n\n- Existing methods fail to disentangle when ground truth FoVs are correlated, in the sense that learned factors will reflect the correlations in the training data\n- Metrics for disentanglement do not necessarily reveal correlations in underlying factors\n- Semi-supervision and weak supervision can be used to induce learned factors that align with true FoVs\n\nReviewers expressed diverging opinions on this paper:\n\n- R2 is a favor of acceptance, but does note that the paper is somewhat difficult to follow, owing to the fact that it presents a large number of results and does not quite arrive at a streamlined narrative.\n\n- R4 was initially critical and posted detailed comments relating to framing, interpretation of existing work, and the conclusions that can be drawn from the presented experiments. The authors were able to address a number of these concerns in a detailed discussion with the reviewer. \n\n- R3 is critical of the experimental setup, which considers linear correlations between two underlying factors, and feels the semi-supervised and weakly supervised experiments have limited novelty. This reviewer did not respond to author feedback. \n\nThe metareviewer has carefully read the reviews, author feedback, and subsequent discussion. Owing to the fact that reviews are diverging the meteareviewer also read the paper. \n\nAs R4 notes, the results in this paper are in some sense unsurprising – we would expect correlations between underlying factors to lead to correlated learned factors. In fact one could even argue that dimensions in the latent space should reflect correlations in the training data. That said, the metareviewer feels that a paper need not present results that are surprising, as long as the experimental evaluation is rigorous and there are no major problems with framing and exposition. \n\nIn this context, the metareviewer would like to express their appreciation to R4 for taking the time to follow up in detail with the authors, and for checking their revisions. The metareviewer feels that the fact that these revisions have a fairly large edit distance should not in itself not impede acceptance, as long as reviewers are agree that the edits improve the paper. \n\nThe metareviewer is not entirely convinced by the criticisms presented by R3. The reviewer is of course correct that real-world datasets will not just have linear correlations between two factors. That said, an experimental evaluation of how correlations affect the degree of disentanglement has to start somewhere, and even these comparatively simple experiments represent a substantial effort on the part of the authors. \n\nHaving read the submission, the metareviewer agrees with R2s assessment that the exposition is difficult to follow, even for readers who know the relevant literature. As the reviewer notes, the overall narrative could be clearer. Extracting a clear narrative is challenging when there are many experiments to report, but it is nonetheless something that the authors should spend additional time and thought on. Another factor that hurts clarity is that experiments are described in long paragraphs that often would benefit from an equation or two, for example to describe the substitution function in Section 4.1, or to more precisely describe the form of weak supervision that the authors employ in Section 4.2. \n\nAs a final note, the metareviewer would suggest more explicit discussion on what authors think a VAE *should* do when factors are correlated. Arguably learning factors that reflect correlations is the \"correct\" when the training data exhibits such correlations. Currently the authors do not provide much of an arguments for *why* they think a VAE should learn a representation that ignores these correlations. A possible argument is that train-time correlations might not be representative of test-time correlations. Here, testing to what extent a learned representation generalizes to test-time data with a shift in correlation would also strengthen results.\n\nOn balance, the metareviewer's assessment is that this paper falls narrowly below the threshold for acceptance. While the experimental evaluation represents a substantial effort that in itself is above the bar, there are problems with narrative and the clarity of  writing that rise above the level of minor revisions that could be addressed by camera ready without additional review. Based on this, the metareviewer will recommend rejection. With a little bit more work on writing and exposition, this will make a great paper at a future conference. "
    },
    "Reviews": [
        {
            "title": "ON DISENTANGLED REPRESENTATIONS LEARNED FROM CORRELATED DATA",
            "review": "Summary: This paper systematically presents a large-scale empirical study on the disentangled representation learning when the underlying factors are possibly entangled. From the results of purely unsupervised settings, the authors have discovered the shortcomings of the existing metrics of disentanglement as well as the poor learned representations (in terms of disentanglement). However, with the help of small amount of factor labels or other weak supervision signals, recent approaches could learn fairly perfect representation.\n\nFirst of all, it is worthy to pay attention to the possible correlation between factors when you intend to learning a disentangled representation. And the whole empirical results are carried out by very large number of experimental batches, which to some extent could well support the conclusions displayed in the paper.\nHowever, there still exist several limitations in my opinion:\n(1)\tThe design of induced correlation is too simple. As you have mentioned in related work, there were some papers noticed the too ideal assumptions of traditional VAE-based models which may not be held in practice. IMO, the linear dependency between only two variables is far from reality as well. More complicated settings should be involved.\n(2)\tIn line with the former limitation, diagnostics of the potential entanglement should also not be limited to pairwise level, which cannot scale up to high dimensional latent factors.\n(3)\tThe novelty of Section 4 is somewhat limited as all the correction methods and even some conclusions were proposed by the previous work.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Timely empirical contribution to distangled representation learning with correlated factors of variation",
            "review": "This paper addresses the important problem that most existing disentangled representation learning algorithms analyze statistical independence rather than causal independence. The paper conducts a large scale study to investigate whether statistical correlation prevents learning disentangled representations (according to human defined ground truth factors of variation). \n\nPro:\n\nThis is a timely contribution to clarify problems in evaluating disentangled representation learning algorithms. The paper argues that assuming statistical independence is unrealistic, in practice factors of variation are often causally independent but statistically correlated. This seems like an important missing piece in current empirical evaluation benchmarks. \n\nThere are several interesting observations: \n\n1.The existing metrics for disentanglement do not apply to situations with statistical correlation between the factors of variation. New metrics will be needed. \n\n2.For correlated factors of variation, even though disentanglement fails, the latent space still extrapolates to never seen combinations. \n\n3.Several semi-supervised or weakly supervised methods for disentanglement work well when the factors of variation are correlated. \n\nCon:\n\nSection 3 and 4 are a little hard to follow. There are many results with no clear logical connection to each other. Maybe it’s better to have some bullet points of the empirical findings, then point to specific paragraphs that explain the empirical methodology that produced these findings. \n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Evaluation is extensive, but the conclusions drawn from them are either 1. not justified very well by the evaluation 2. unsurprising/already known.",
            "review": "The paper studies the behaviour of disentanglement methods and metrics on data where a couple of factors of variation (FoV) are correlated, a more realistic setup compared to the usual independent FoV setting in the literature. The paper shows how the correlation in the FoV is reflected in the representations learned by the models, and claims that the widely used disentanglement scores fail to capture these correlations. A couple of solutions that use weak supervision are suggested.\n\nStrengths:\n1. The paper attempts to address an important limitation of current unsupervised disentangling methods, in that they assume independent FoV. I agree that this is an unrealistic assumption, and only holds for the synthetic datasets used in the literature.\n2. The experimental evaluation of the paper is extensive\n3. The paper is presented clearly for the most part.\n\nWeaknesses:\n1. At the beginning of Section 3.2, the claim that the existing disentanglement metrics fail to capture correlations in the training data seems flawed. Figure 2, that the violin plots of metrics for 180 models (with different loss/hyperparam combinations/random seed) shows no clear trend, is used as evidence for the claim. However this argument ignores an important confounding factor, which is the behaviour of the models (trained with losses originally designed for data with independent FoV) when trained on a dataset with correlated FoV. Without understanding the behaviour of models after training, it is difficult to draw any conclusions from Figure 2. Moreover comparing violin plots of all 180 models does not seem sensible - the models with poor disentangling performance will likely be uninformative, creating noise for comparisons between different settings. Hence I think it makes more sense to compare results for the top models for a given metric (as is done in Fig3).\n2. I also have doubts regarding the conclusion itself, that all existing metrics fail to capture correlations in the training data. I think this only holds for some metrics and not for others. Suppose the representations that we are evaluating are the ground truth FoV values. Then the BetaVAE and FactorVAE metrics will give a perfect score regardless of the degree of correlation by design. But the MIG/SAP/DCI scores will be lower for higher correlation in the FoV, since the mutual information/prediction accuracy between the two correlated factors will be higher than between uncorrelated factors. \n3. The result presented by Figure 3, that training disentanglement models on strongly correlated data gives representations encoding mixtures of the correlated FoV, is unsurprising in my opinion, and adds little value to the pool of knowledge in the literature.\n4. In Section 2, I think that the statement “it has been shown that purely unsupervised learning of disentangled representations is impossible (Locatello et al., 2019b)” is a wrong interpretation of Locatello et al. They show that optimising marginal likelihood in a generative model (such as a VAE) cannot achieve disentangling without any inductive biases in the model. But the inductive biases in the models used by disentangling methods, along with the loss (that is a variant of the ELBO and not the marginal likelihood), are what allow disentangling in practice. There are also theoretical works such as [1] that explain this behaviour.\n5. In Section 3.2, the conclusion “These results suggest that we cannot expect disentangled representations learned unsupervisedly to help reduce unfairness beyond the benefits discussed in Locatello et al. (2019a)” seems problematic. It’s not the unsupervised learning that’s problematic, rather it’s the model assumption that the FoV are independent that is problematic in the scenario of correlated FoV, which is an unsurprising conclusion. \n6. The conclusion in Section 3.3, that disentanglement methods can generalize towards unseen FoV configurations, is old news that is already shown in the literature in disentanglement models trained on datasets with an incomplete set of FoV configurations e.g. 3D Faces, CelebA\n7. In Section 4.2, the claim “This kind of extra knowledge is often available at no cost , e.g., in temporarily close frames from a video of a moving robot arm where some factors remain unchanged” is unjustified. We still need to know the number of factors that have changed, which usually requires human labelling\n8. The weak supervision for the correlated FoV when applying Ada-GVAE relies on being able to generate data where the correlation is broken, which seems like an unrealistic assumption. The authors seem to address this by assuming a causal relation between the two factors. However even if there is a causal relation between the two factors (C1 causes C2), the correlation implies that some (C1,C2) pairs are very unlikely to appear in the data, so you cannot “sample any value in C1” given C2. Hence I don’t understand how the causal setting at the end of Section 4.2 helps address the problems of having to generate data where the correlation is broken.\n\nOverall the paper does address an important problem in the disentanglement literature, but the conclusions drawn from the extensive evaluation are either unsurprising or unjustified. Moreover, the proposed solution via weak supervision appears flawed because it requires generating data where the correlation is broken, a very unrealistic assumption.\n\nOther points:\n- Typo in Figure 2 caption: “lower \\sigma indicates less correlation” <- “higher \\sigma indicates less correlation”\n- Section 3.1: “P(z_c1, z_c2) ~ N(z_c2 - \\alpha z_c1, \\sigma)” How does the RHS define a joint distribution? The RHS shows a scalar normal distribution, whereas the LHS is a joint density. Do you want to replace “\\sim” with “ \\propto” ?\n- Why doesn’t entanglement decrease with #labels > 100 in Figure 6?\n- It might be helpful to also look at the disentanglement metrics for just the two correlated factors, to further highlight the differences between different models.\n\n[1] Rolinek, M., Zietlow, D. and Martius, G., Variational Autoencoders Pursue PCA Directions (by Accident). CVPR 2019.\n\n===========================\n\nScore raised to 5 following response to the rebuttal below, then to 6 following the re-rebuttal.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}