{
    "Decision": "",
    "Reviews": [
        {
            "title": "Embedding semantic relationships in hidden representations via label smoothing",
            "review": "Review: This paper proposes an approach for embedding semantic relationships into learned representations via category-aware label smoothing. The paper mostly focuses and MNIST and CIFAR 10 showing that they can additionally incorporate hierarchical information. The authors also used Neurodynamical Agglomerative Analyisis (NAA) to analyze the target vector relationships as the data is projected deeper into the network.\n\npositives:\n\nLabel smoothing is an important problem and understanding it better if of interest to the community.\n\nOverall, the paper is well structured. In particular, the method section. Despite the method having limited novelty (sliding window instead of a growing window), the limitations expressed are so meaningful and motivates the needed work.\n\nThe results section is well structured covering both MNIST and CIFAR10 datasets. It's nice to see how sigma influences the results.\n\nnegatives:\n\nSome of the key assumptions in the paper lacks clarity. For example, mentioned in the paper \"generated randomly consisting of four superclasses\", justifying that \"optimal hierarchy will be application-specific\". However, this application-specific hierarchy is likely causal and hence probably far from random.\nAnother key concern about the paper is the lack of rigorous experimentation to study the usefulness of the proposed method. Experiments were mainly focusing on small-scale datasets like MNIST and CIFAR10 making it hard to conclude if the results in this paper may scale/generalize.\n\nLack of novelty and solid conclusions. Despite that the paper is well structured, the writing itself lacks sufficient analysis and discussions and it needs significant work to reach a rigorous state. For example, there is big space focusing on parameters of resNet architecture (Table 3), confusion matrices (Fig2).\n\n-More comparisons are needed to other smoothing techniques and why they are useful and whether hierarchies can be learned vs choosing random ones (e.g., causal hierarchies through meta-learning for example R1). [R1] Bengio, Yoshua, Tristan Deleu, Nasim Rahaman, Rosemary Ke, Sébastien Lachapelle, Olexa Bilaniuk, Anirudh Goyal, and Christopher Pal. \"A meta-transfer objective for learning to disentangle causal mechanisms.\", ICLR, 2020\n\nMinor comment:\n\ncolors of Fig2 can be improved. size is a bit small to see",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Official Blind Review #2",
            "review": "This paper focuses on exploring semantic relations between labels leads to hidden representations, in addition to enabling the enforcement of preferable error profiles. Additionally, this work uses a smooth target vector representation that adheres to predefined relations between label classes. However, there are several fatal weaknesses of this work.\n\n1) The novelty is weak. Actually, the label relation and class hierarchy were explored on lots of previous methods on image classification, retrieval and so on. For instance, Deng et. al (Large-Scale Object Classification Using Label Relation Graphs, Best Paper Award at ECCV2014) improved large-scale visual recognition of object categories by forming a semantic hierarchy that consists of many levels of abstraction. Another work in Yolo9000 (Yolo9000: Better, faster, stronger. CVPR 2017), the label relations of objects were also modeled for better performance on object detection. Comparing with this work, previous works are more in-depth and rigorous. The priority and speciality of this work are supposed to be clarified clearly.\n\n2) The experiments are limited. The semantic relations among the class labels are supposed to be explored on other larger academic datasets, e.g., ImageNet, not just the small datasets, i.e. MNIST and CIFAR10. (1) The labels like the numbers in MNIST  are not good instances to explain the semantic relations and the results on MNIST dataset are not the strong provety for the SEMANTIC relation models among the labels.  (2)There are  only 10 classes in the CIFAR10 dataset. It is not the suitable dataset for modeling the semantic relations of the class labels  due to the few labels. The experiments are supposed to be taken on the datasets with  more labels, especially the class labels with actual semantics\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review",
            "review": "The paper argues that one-hot targets do not capture the necessary semantic prior information when training classification models, and proposes a way to inject this information by smearing the target labels. \n\nWhile the paper poses an important problem and proposes a reasonable solution, I have concerns as to its novelty. The problem of optimization with different costs for different errors is well established (and often referred to as Cost-sensitive learning, e.g. http://web.cs.iastate.edu/~honavar/elkan.pdf). Building relationships into the prediction target also has a rich body of prior work. This includes knowledge distillation (see e.g. https://arxiv.org/abs/1503.02531 and https://arxiv.org/abs/2002.03532) where the relationships between classes are dependent on a previously-trained model, https://arxiv.org/abs/1607.05691 where they are based on external information, and https://arxiv.org/abs/2003.02819 which uses a noise model for the labels.\n\nThis paper presents empirical analysis using the MNIST and CIFAR-10 datasets. It was not clear to me what these experiments showed, or how the results could be extrapolated beyond these datasets. For example, the CIFAR-10 results (table 4) do not seem to indicate that smoothing is helpful, nor that the semantics-aware smoothing (grouping_3) is better (or worse) than random. \n\nThe analysis of the activations-induced class distances in Figure 3 seems to suggest that the activations learned by the model for a particular choice of sigma result in the distances similar to those between the target embeddings (also smoothed using the same value of sigma). It was not clear to me why this is surprising (as I would expect for this dataset that the model outputs closely match the targets, regardless of the intervention applied to the targets). \n\nA few other concerns: the smearing applied to MNIST does not seem to be well-motivated: misclassifying 3 as a 4 being better than misclassifying it as a 7 is a function of how the predictions are used, and arguably in most situations (including recognizing multi-digit numbers) all misclassifications are equally problematic. In a few places there was a mention of the \"k-means classifier\" but I did not understand how, or why, the k-means classifier was trained, nor the details of this classifier including the value of k.\n\nI think that to make this paper stronger, it would be important to position it in the context of the related work on cost-sensitive learning and label smearing, and demonstrate the empirical evidence on larger-scale problems, with conclusions that can inform whether, and how, the reader should use label smearing in their problems.",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "I cannot accept the authors' claim fully",
            "review": "The authors claim they show a simple approach for embedding semantic relationships into learned representations via category-aware label smoothing. In section 3, after presenting label smoothing method, they claimed embed hierarchical information into CIFAR-10 target vectors to show that it is possible to enforce arbitrary class hierarchies using the method.\n\nIn section 4, they conducted experiments on two dataset MNIST and CIFAR-10. They claimed they used a new method for analyzing class hierarchy in hidden representations, Neurodynamical Agglomerative Analysis (NAA), to show that latent class relationships in this analysis model tend toward the target vector relationships as the data is projected deeper into the network.\n\n- Major points\n\nAlthough the paper is try to “hierarchical information” into the dataset, I’m not sure how these figures should be interpreted because those are not fully explained. At least, the figures authors presented are very partial and thus, it would be not enough. \nAnd the paper suffers from lack of novelty because of applying label smoothing is quite common and the employment of NAA(Marino2020) is not novel. \nMoreover, I don’t see any comparison against conventional methods. It’s quite hard to judge the proposed method.\n\n- Minor points\n\nNo computational cost arguments are shown although they emphasize the ease of computation. As such, ImageNet (or ILSVRC dataset) would be better for this problem setting rather than using CIFAR-10.\n\n- Typo\n\nIn abstract \"Analyisis\"",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}