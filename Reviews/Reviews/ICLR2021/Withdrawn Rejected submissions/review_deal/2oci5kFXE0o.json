{
    "Decision": "",
    "Reviews": [
        {
            "title": "An interesting work with undisclosed limits",
            "review": "This paper proposes a scattering transformation model, which is basically a modular network with two sets of modules for attributes and relations respectively. Authors demonstrate its state-of-the-art performance in i.i.d. regimes and certain generalization capability in o.o.d. regimes. The proposed model is intuitive and easy to implement. And part from its impressive performance in i.i.d. regimes, it also demonstrates some success in learning attribute concepts and relational concepts.\n\nI have reviewed this paper in another venue, on which a set of comments was provided for revision. However, the authors did not revise their manuscript. In my last review, I conveyed my major concern that the authors overclaimed on the o. o. d.  generalization of their model, since their experiments cannot fully support their vague claims on what specific generalization is encouraged by the proposed inductive bias. In particular, for the t-SNE illustration in Fig. 3b, only the seemingly better results are given in the main text. According to Appx. F, there are 3 out of 7 tasks where the clusters of t-SNE are not separable. The clustering fails in settings of O-IG, 2Grid, 3Grid, as shown in Appx.F. Experiments designed reported in Appx.G did not involve O-IG, 2Grid, 3Grid either. In my last review, I requested authors to explain why they neither report nor analyze t-SNE from O-IG, 2Grid, 3Grid in the main text. But the authors did not provide a response to it. The point is, as can be seen from Appx.B , these three failure cases have one thing in common: they all contain multiple entities in one panel. That is, the enforced inductive bias, if we accept they can generalize according to authors' t-SNE, can only handle settings with only one or two entities at best. This is apparently a huge limitation of the proposed method. Unfortunately, the authors did not choose to disclose it to the public. I would be happy to adjust my rating if the authors would like to address this concern. \n\nEssentially, RAVEN is an artificial task. It was originally proposed to our community to quest for human-like capabilities to do abuctive abstract reasoning in few-shot. To this end, honestly I do not think overall performance is that important compared to general visual recognition tasks like ImageNet. Instead, forming a coherent scientific study is more crucial. Therefore, for any inductive biases assumed, authors should clearly justify what extra generalizability they are expected. Dedicated experiments should be designed and analyzed to validate these hypothesis.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Compositionality is indeed crucial for learning abstract concept, but the experimental results do not fully support the authors' claim",
            "review": "This paper proposes to adopt a compositional structure learner to solve an analogical reasoning task---Raven's Progressive Matrics. Specifically, the authors devise an architecture that composes neural networks in a sequence. In experiments, the authors highlight the improved performance on existing RPM datasets using the proposed method. Besides, the authors claim the proposed method achieves a better generalization capability compared with prior methods.\n\nPros:\n\n+ Literature review is comprehensive. Writing and logic are easy to follow.\n\n+ The ideas to integrate compositionality are important and mostly missing in the deep learning era. As authors also point out, only till very recent does this perspective started to resurge in our community.\n\n+ Performance is indeed impressive in terms of number compared with prior SOTA methods.\n\nCons:\n\n- Although the idea of compositionality is important, such an idea is not new even when we only consider the past few years. Modular networks already exist. The authors argue that they differ prior methods by the specific design of learning compositions of a sequence of neural modules. This statement is mostly valid, but it brings the novelty of this paper into question. To me, this seems rather incremental. If this is the central claim of the paper, the authors should demonstrate the proposed method in various tasks, instead of just RAVEN tasks. For instance, the authors could try CLEVER or CATER or other similar tasks.\n\n- It is a common misconception that people only focus on performance in abstract reasoning tasks (e.g., RAVEN). This paper starts very well in its intro, talking about the importance of generalization. However, in terms of evaluation in the experiments, it does not propose any new criteria for generalization; rather, it follows the prior definition and compares the performance. This seems to end a little bit short compared with the grand opening. The authors might want to have a tighter connection between the claims in the intro and the final findings in the experiments.\n\n- Then what would be a good metric? In this paper, it would be great if we can verify the proposed algorithm actually learn concepts in a meaningful way. The authors also did it, but not as a highlight of the paper, which I feel a little bit disappointed. Personally, I would like to see this analysis as the central piece of the experimental results as this would be the key difference and verifications of the proposed method compared with prior methods. If we look at the supplementary material on how well the concepts are learned by the proposed method, the results are actually perplexing. As authors also point out in the main text, only 4 out of 7 seem to be distinguishable; that's only around half of the rules in RAVEN. This significantly diminishes the claim that the proposed method learns good compositional concepts.\n\n- Some numbers reported here are using relative improvement. This is very odd; I have not yet seen any papers that use such a claim as this could easily lead to a misleading impression. I highly suggest the authors use the standard report when reporting the results. If the performance gain is not significant, the authors can compare in other aspects or try to justify that the task is intrinsically difficult.\n\nIn sum, I find the idea is interesting. However, the method to support the idea is not novel enough, and the experimental results do not fully support the claimed contribution. More analysis of the learned concepts is in need.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Strong Performance But Concerns on Novelty and Overclaim",
            "review": "The paper proposes a new neural architecture called Scattering Compositional Learner (SCL) for the task of visual analogical reasoning. The model performs reasoning by scattering the representation into different groups and apply a split-share-merge transformation. The authors show the new architecture out-performs existing models by a large margin on Balanced-RAVEN and PGM.\n\nThe performance boost is surprising and the strongest proof of the paper. The proposed model shows some levels of generalization in learning visual and relational concepts. And the work is cleanly presented and easy to follow.\n\nHowever, my concerns out-weight the sheer performance improvement.\n\n1. I'm particularly concerned on the novelty of this work. The split-share-merge transformation can be understood, from my point of view, a special case of the one applied in ResNeXt. Splitting a feature map into several components is not a new technique these days. And such a structure's performance has been independently verified in other works. Therefore, it can be expected that adding such a module will improve performance, though such a huge improvement is not one at least for me. From another perspective, the model has some ideas of modular networks. However, in another task of visual reasoning, VQA, their efficacy has also been verified.\n\n2. I would also like to point out the overclaims of the work. First, the intuitive idea of the work in the scattering transformation is that the split representation stands for different levels of concepts, such as attributes, objects, relations. However, the claim that this model does so lacks a solid proof. The authors show that there is a sort-of-linear relation in size. However, what about the object and relation level? Does representation of other attributes show the same patterns? Even if so, why does linearity show concept learning? Does relation representation have to be linear? If using ReLU, hidden representation is by design piece-wise linear. Can the sort-of-linear representation assert that good representation has been learned? Another major claim is the generalization ability of SCL. The evidence presented seems contradicting. While Figure 3 (b) shows good clustering, Figure 5 shows that on complex distributions, the clusters are far less discernable. I'm also wondering how the model will perform on PGM's generalization regimes, as there is at least some previous works that touch on them and show them to be harder.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}