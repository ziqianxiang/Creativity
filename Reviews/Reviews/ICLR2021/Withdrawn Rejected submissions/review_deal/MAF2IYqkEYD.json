{
    "Decision": "",
    "Reviews": [
        {
            "title": "Review",
            "review": "Summary\n\nThis paper proposes learning slow features to facilitate downstream regression tasks. Borrowing ideas from classical slow feature analysis (SFA), the proposed method augments ($\\beta$-) VAE objective with a constraint from a Brownian motion prior to encourage the slow moving of latent representations. The learned representations were tested in downstream regression tasks involving a synthetic 2D bouncing ball and the DeepMind Lab dataset, and showed higher data efficiency against baselines. My main concern is that the experiments are insufficient to support the authors’ claims.\n\nPros\n1. This paper is well motivated. The importance of slow features in computational neuroscience is well explained.\n2. The proposed method is clearly explained, and well-positioned in the VAE framework. Although I have concerns about the exact form of the regulariser (see Cons), this idea can be valuable for future work along this direction.\n\nCons\n1. The formulation of the regulariser needs better justification: why is Brownian motion, instead of any other stochastic processes, chosen as the prior? In particular, Brownian motion involves abrupt change of velocity, which seems to be at odds with the smoothness implied in slow features.\n2. The experiments are not clearly described. For example, how was the bouncing ball simulated? What are the parameters (e.g., gravity, friction) used in the simulation? Without them, it is hard to evaluate the complexity of the dynamics. In addition, what is the downstream regression task for DeepMind Lab?\n3. The empirical results are not sufficient to support the authors’ claims. The TD-VAE baseline, as the only baseline with a temporal component, is missing in the DeepMind Lab experiment. Additionally, it is unclear how the hyper-parameters are chosen for each model. Are they optimised for individual baselines? E.g., the same beta parameter value was used for both the $\\beta$-VAE and the proposed S-VAE, but I would expect it to be lower for the $\\beta$-VAE, without the additional slowness regularisation in S-VAE.\n\nOther comments:\n1. As a generative model (or at least an auto-encoding model), images from reconstruction or interpolation would be helpful to provide intuitions of the model.\n2. In Table 1, what’s the number of images for TD-VAE?\n3. What are the metric and unit for numbers in Table 2?\n4. In Figure 3, how to interpret the difference between panel a, b, c from the scatter plot? Would it be possible to quantify them?\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "review",
            "review": "Summary:\nTo capture the slowly moving features in sequential data, this paper proposes an additional regularization term based on the slowness principle. The temporal regularization term is implemented in the form of KL divergence between the inferred approximate difference distribution computed from the posterior distributions inferred from a pair of samples in a sequence (Eq.2) and a prior distribution derived from Brownian motion (Eq.3). The authors compared the proposed S-VAE model with two baseline models: TD-VAE and beta-VAE on the 2D ball bouncing dataset and the DeepMind Lab dataset.\n\nPros:\n- Provide a simple way to incorporate smoothness constraints for encoding sequential data.\n\nCons:\n- The experiments are not convincing and not comprehensive. First, for the ball bouncing experiments the authors evaluated the effectiveness of using the learned representations to predict the ball velocity. However, the representation is inferred from a still frame $q_\\theta(z_i \\mid o_i)$ and would not be capable of inferring the velocity information by design. The results seem very spurious. Second, the chosen baseline is either naive or not reproducing the results. beta-VAE was proposed to learn disentangled representation rather than model sequential data and is not expected to capture dynamic information since such information is never provided. This paper should have compared with sequential VAE models such as VRNN (Chung et al., 2015). Third, what is the prediction target for few-shot learning on the DeepMind Lab dataset?\n- It is unclear what the model is expected to learn. For the ball bouncing experiments, the authors first evaluated how useful the representation inferred from an image can be used to predict the velocity, but in Figure 3 the authors tried to establish the correlation between the representation and the absolute position. If the velocity is randomly chosen independent of the position and some latent dimension captures this information, then it is expected to see a uniform distribution of latent values for all x, y positions for some dimension.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Lacking experiments and analyses",
            "review": "The paper proposes a slow variational autoencoder, a variational autoencoder with an additional loss that encourages two hidden vectors that are close in time to be close in the hidden space. Specifically, in addition to the KL term between the posterior and prior, the paper proposes a KL term between the posterior and prior of the differences of hidden vectors. The paper includes two sets of experiments, one on a synthetic data set and another on the deepmind lab data set. The results suggest that fewer samples are needed in the downstream tasks given the hidden vectors learned from the proposed model.\n\nThe model itself is interesting, but the analyses and experiments are lacking. The questions that the paper tries to answer are somewhat shallow, purely focusing on performance metrics on simplistic, well-conditioned tasks. Detailed explanation are as follows.\n\nThe introduction seems to suggest that modeling slowness is universally beneficial. However, the statement is questionable even in the physical world. Not all data exhibit the slowness property. For example, there are sharp and abrupt transitions in audios and videos that are semantically important. Not all tasks benefit from the slowness property. Instead of asking whether introducing slowness is useful as is done in the paper, the questions should be what types of slowness the model can capture, what types of slowness the model cannot not, and what types of downstream tasks would benefit from a representation that respects slowness.\n\nFollowing this line of thought, the experiments only support that the slowness property is useful for the particular tasks in the paper when physical objects are moved around (in the synthetic data set or the deepmind lab data set). The settings are limiting. It is fine to focus on constrained settings, but the paper has to provide more analyses beyond the surface performance metrics.\n\nThere are many relevant questions not addressed in the paper. For example, what types of slowness can be learned and what cannot? How does the network architecture and the input affects the types of slowness being learned? How does the learned representation affect the downstream performance? As an example, figure 3 more or less answers what types of slowness is learned by the model, i.e., the change in coordinates. However, there are also other types of slowness that the model can potentially capture, such as the change in velocity, depending on the complexity of the simulator.\n\nThe bias and variance experiments (in the way presented in the paper) do not entail many meaningful conclusions. It provides another (implicit) approach to measure how slowness is learned. However, there does not seem to be a strong connection among the bias, the variance, and the slowness property.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Official Blind Review -- AnonReviewer4",
            "review": "**Summary**\n\nIn this work, the authors develop a new form of auto-encoder derived from the slowness principle. The idea behind the work is to apply a temporal similarity constraint to the previously published \\beta-VAE to constrain how the latent representations change over time. The authors achieve this through by appending a slowness loss to the overall objective which operates similar as the \\beta parameterization in \\beta-VAE. The authors compare their method to the \\beta-VAE and TD-VAE on two synthetic datasets and demonstrate competitive if not superior performance with far greater data efficiency.\n\n**Major Comments**\n\n*1. Strength of Experiments.*\nThe experimental section was light as the authors only investigated two small synthetic datasets across a small array of settings (e.g. varying dataset size). Even if the authors merely used synthetic datasets to validate their approach, I would strongly appreciate seeing more a more diverse and comprehensive set of synthetic experiments to validate this approach. Additionally, even in a synthetic setting, the author should experiment with adding noise to the dataset either adding by randomly permuting incoming pixels or adding systematic changes (e.g. occlusions, lighting changes) that may occur in the real world. That said, even if there were more comprehensive synthetic experiments, I would like to see this work applied on some real world data in which noise is present. Even a small scale experiment along these lines would ensure that the method can work outside of toy examples.\n\n*2. Experimental Details Missing.* \nSome additional details behind the experiments were missing.\n--> Was the same training schedule used for TD-VAE, \\beta-VAE and slow-VAE? If not, the authors should describe if or what hyper-parameter tuning was selectively performed on each architecture. (If there were selectively more hyper-parameter tuning on on architecture, this would need to noted and heavily discussed and justified.)\n--> I am a little bit concerned that the authors did not include TD-VAE for Section 3.2. This seems like an important control. Would the authors add more color as to why they were unable to recreate the results? Might they be able to show previously published numbers instead?\n\n*3. Bias-Variance Analysis.*\nThe authors needs to better explain the goals of this section of the paper. First, what is the 'Bias-Variance' decomposition? If the authors are referring to the decomposition of the MSE loss, then please state this explicitly in the section. It is interesting to note that one method achieves lower variance or bias than the other, but more importantly, what are the conclusions of breaking down the error based on these two dimensions? Does the lower value along one dimension allow us to conclude something about each modeling approach?\n\n*3. Statistical Significance of Table 2.*\nThis table needs error bars as I am worried that the small gains (e.g. ~2%) may be statistically insignificant.\n\n**Minor Comments**\n1. Misspelling 'paramter'\n2. Figure 1. Use consistent colors for both panels.\n3. Why not report the number of images for Table 1, \"TD-VAE Ball Exp\"?\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}