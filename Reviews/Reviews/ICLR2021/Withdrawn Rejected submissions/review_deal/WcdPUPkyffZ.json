{
    "Decision": "",
    "Reviews": [
        {
            "title": "Simple yet effective model for word alignment",
            "review": "This paper proposed a lightweight unsupervised word alignment model that learns word alignment by encouraging the source and target words in parallel sentences to be close while pushing away irrelevant pairs.  The paper also introduces a disagree loss to encourage the attention from source to target to be symmetric with that from target to source, and thus learns more symmetric alignments. \n\nStrength:\n\n1) The idea is intuitive and the proposed model is very efficient in training.\n2) Added in extra loss to take care of the symmetric issue\n3) Perform better than statistical methods on word alignment evaluations\n4) Good ablation study and case analysis\n\nWeakness:\n\n1) Weak technical contribution\n2) The notations can be more intuitive, for example,  you don't have to use both x_i and q_i to represent the source word vector just for showing that it's a query. \n3) It seems that your methods yield worse alignments than other more sophisticated neural network models. So what're the merits of having a more efficient but worse word alignment? Couldn't the users just compute the alignments offline? Perhaps you should give some use cases to show why your model can help users. Moreover, since more and more tasks are trained in an end-to-end fashion, less and less people are using word alignment for their tasks directly. Cao et al. (2019) https://openreview.net/forum?id=r1xCMyBtPS have shown that you can improve BERT's performance on downstream tasks with word alignment. It'll be better if you can show your alignment model can yield better results on downstream tasks.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An elegant method but not convincing enough",
            "review": "This paper introduced a mechanism that applies cross lingual word embedding to the alignment task in machine translation. The authors proposed a training objective using parallel text -- they first use attention to obtain weightings of words, and obtain embeddings for the context (sentences) by weighted aggregation of individual token embeddings. They then used NCE training to maximize cosine similarity between positive examples, and at the same time, push away negative examples. By comparing this scheme with other alignment methods (Giza, Nnsa and naive attention), the author showed that their method has superior performance, and is faster.\n\nThe method is reasonable and the writing is clear. The primary concerns for me are the following:\n\n1. The method seem to lack novelty. The mechanism is identical to what was originally proposed in the Seq2seq with attention model[Bahdanau 2014]. The authors takes the model, discarded the RNN component and then applied it to the alignment task. While there are several new components (NCE training objective and the \"symmetric penalty\"), they are not convincing enough to justify the novelty and contributions.\n\n2. The evaluation is not convincing enough. Specifically, I would like to see comparisons with methods of similar nature -- for example, comparing with the alignment performance of a) the alignment produced by Seq2seq with attention model, and b) the \"hard\" alignment by using softmax on the cosine similarity of aligned bilingual embeddings. The overall method raises the speculation that the entire mechanism produces something similar to multilingual embeddings into one latent space (e.g. https://arxiv.org/abs/2006.03652). As a result, comparisons with similar methodologies is crucial to show whether there are any distinctions or superiority. If one look at some anecdotal evidences (e.g. Fig 4), it seems that the the proposed method is \"correct\" because it does a better job in matching words with similar meanings -- this is achievable with lots of easier and more straightforward ways.\n\nDespite my overall affection of simple and elegant solutions (and this paper definitely proposed one of them), I am not convinced by the potential contribution and the evaluations and there are room for improvements -- I vote for rejection.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting and efficient method, but missing strong baseline",
            "review": "This paper presents MirrorAlign, an intuitive and efficient method (as fast as fast-align) for word alignment given gold parallel sentences (bitext). The MirrorAlign model is built based on noise-contrastive estimation (Gutmann & Hyvarinen, 2010), while the intuition behind is that two words are likely to be aligned if they frequently appear in a pair of bitext. The authors also briefly show theoretical guarantee of the proposed method. \n\nWhile the idea is neat and the experiments are clear, this paper misses a strong baseline: \\\nSimAlign: High Quality Word Alignments without Parallel Training Data using Static and Contextualized Embeddings \\\nMasoud Jalili Sabet, Philipp Dufter, Hinrich Schutze \\\nhttps://arxiv.org/pdf/2004.08728.pdf\n\nSimAlign is built upon XLM-RoBERTa or mBERT, which requires just separate monolingual corpora and sees no bitext, i.e., it requires less supervision than MirrorAlign; moreover, it achieves better alignment results on all investigated language pairs (de-en, en-fr, en-ro) than MirrorAlign. \n\nOne can still argue that compare to SimAlign, MirrorAlign is much faster to train (assuming we have to pretrain large language models from scratch for SimAlign), but I doubt if we would really need that in real applications -- it is very convenient for people to apply pretrained language models nowadays. Another advantage of MirrorAlign is that it has much fewer parameters than previous models including SimAlign, but I am not sure if real applications would significantly benefit from such an advantage -- if so, it should be discussed more explicitly. \n\nTherefore, I stand in the middle between acceptance and rejection for this paper. \n\n## Detailed comments\n- While I notice that the author(s) have added footnote 2 about Equation (6) and I can understand it, I would still appreciate it more if the equation is written in a more precise way. \n- I would rather not say that it is unfair to compare MirrorAlign with GIZA++ (and other models): the data availability for these models are the same, and we can definitely control the number of parameters, or tune it w.r.t. the development set -- both are approaches for fair comparison. When talking about fair comparison, my first impression is that models use different data and some uses more supervision than others, therefore the statements in the paper is perhaps misleading. \n- The reference needs some attention: there are duplicated items such as Stengel-Eskin et al. (EMNLP 2019) and Zenkel et al. (2020). \n\n## Questions\n- Did you use any labeled dev set? If so, DE-EN does not have standard dev set, and I wonder what you used instead; if not, how did you select the best model for each method? \n- Did you train MirrorAlign for multiple times with different random seeds? If so, are the performances consistent? ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper presents an interesting new method to learn word alignments but rely on wrong assumptions. This methods may work reasonably well for close language pairs but the evaluation lack of experiments on distant language pairs that may show some strong limits of the proposed method.",
            "review": "This paper presents an interesting new method to learn word alignments based on neural networks. It is claimed unsupervised, with better or similar performance with previous work, and faster.\n\n\nStrengths:\n- the method is well presented and easy to understand\n- results (AER) on European language pairs are convincing that the method can perform reasonably well for such language pairs.\n\nWeaknesses:\n- the main weakness of the proposed method is that it relies on the very strong and wrong assumption that word alignments are \"mirror-like\" symmetric. The paper does not discuss the problem of fertility (how does the method learn alignments for word aligned with several words) and the NULL alignment (word aligned with no other words as it may happen relatively often in a sentence aligned corpus that usually also contains translation errors). I assume that the method can successfully mitigate these problems for relatively close European language pairs, as shown in the experiments, but may dramatically fail for much more distant language pairs with very high fertility and for which word alignment is much more difficult (Japanese-English for instance).\n- the method is evaluated only for somewhat close languages while it is well known that word alignments methods that may work well for European language pairs may poorly perform on distant language pairs (for instance, the original version of fast-align)\n- the speeds comparison between GPU-based and CPU-based methods is not convincing. GIZA and fast-align can both be easily multi-threaded, while mgiza is not very efficient on exploiting multiple CPU, fast-align is much faster. I think the comparison is not fair regarding the cost of buying/running one CPU against one GPU and that clusters for computing are still all equipped with CPUs. I think nobody is currently still running giza or fast-align on a single CPU. It makes this setting rather artificial.\n\n\nTo improve the paper, I recommend the following:\n- introducing at least one distant language pair in the evaluation (e.g., European-Asian languages)\n- thorough discussion about the fertility problem and how the proposed method is addressing it.\n- running the multi-threaded version of GIZA and fast-align to make a realistic speed comparison.\n\n\n\nquestions:\n- does using sentence alignment not make the proposed method supervised? I do not know about previous work dubbing this requirement as still being unsupervised but it seems wrong since the method exploit alignment knowledge, at sentence-level, provided by humans. If this is right, how should we qualify a method that does not use any human alignment knowledge? I think \"unsupervised\" is unnecessary and may be confusing in this paper.\n- section 1: is word alignment really easier than translation? I am not sure about this. Do you have any reference to cite?\n- comparing speed between giza/fast-align and NN methods is very difficult as they exploit different computing devices. Any attempt to run them on multiple CPU and GPU, respectively? I actually expect fast-align to be much faster than what is reported in the paper.\n- section 2: why \"almost\" the fastest for fast-align? Any references for faster methods?\n- why did you chose grow-diag heuristic? In SMT, for instance, grow-diag-final-and usually shows much better results.\n- in section 4.3, MirrorAlign is trained on K80 while in section 4.5 it is trained on P40, is this correct? If so, why changing the GPU?\n\nStyle:\n- order reference citations chronoligically (abstract)",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}