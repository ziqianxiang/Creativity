{
    "Decision": "",
    "Reviews": [
        {
            "title": "a novel reformulation of object detection as a problem of density estimation of bounding box across multiple-scale output predictions",
            "review": "The paper proposes a novel approach that reformulates the object detection task as a problem of density estimation of bounding box across multiple-scale output predictions. Through density estimation, a detection network can be trained without too much heuristics caused by ground truth assignment. \n\nThere is a list of noteworthy contributions:\n\n1) The paper formulates the object detection task as a density estimation problem of a mixture model defined on the multi-scale predictions. The authors also propose a novel network architecture, Mixture Density Object Detector (MDOD) together with a new objective function for this formulation, which is proved to be elegant & effective.\n\n2) As a dense detector, the label assignment process is simple, and the training is done without too much heuristics. It seems that only three hyper-parameters (i.e., N_{roi}, IOU threshold 0.5 & loss weight \\alpha) are directly related to the training process.\n\n3) The foreground-background imbalance problem in the dense detector is solved naturally as the training progresses, and there no hyper-parameter directly involved.\n\n4) The proposed method is superior to some SOTA detectors in both AP and FPS.\n\n\nIn my opinion, the proposed model tries to learn everything a dense detector needed during the training process, so it might be suffering from the following problems:\n\n1) It seems that the proposed model takes longer training time. The paper does not show the results of the  1x schedule (12 epoch), which is long enough for most dense detectors. Nevertheless, the fully converged MDOD is still competitive under fair comparison with other alternatives.\n\n2) The paper does not show the results when input resolution becomes higher (e.g., short-800). I think this is because higher resolution input causes the K being much larger which makes the model hard to optimize.\n\nThe paper well written, and the motivation of using density estimation as a natural solution to avoid too much heuristics caused by ground truth assignment is clearly described. Overall, I think this work is worthy of acceptance and should encourage more investigation into the new framework of object detectors in the community.",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Comments for MDOD",
            "review": "This paper proposes the Mixture Density Object Detector (MDOD) that claims it can train object detectors without ground truth assignment. They formulate the object detection problem as a probabilistic density estimation problem. Experiments are conducted on MS COCO to prove the effectiveness of the method. \n\nThey use FPN to extract multi-level features from the input image, and predict density maps with different convolutions. There are four prediction maps, for center offsets, scales, object classification, and overall constraint respectively. \n\nStrengthens:\nThis paper formulates object detection into a density estimation problem and makes their efforts for totally end-to-end object detection frameworks. \n\nWeaknesses:\n1. My first concern for this paper is I do not think this paper is doing object detection without ground truth assignment. \nBecause there is still a RoI sampling procedure in this paper, and define positive / negative samplers with corresponding IoUs with GTs. I think the main claim in this paper is incorrect or at least not precise. \n\n2. The experimental part cannot support the effectiveness of the method. \nI think one crucial experiment for making the work publishable is to prove the method indeed outperforms GTA-based methods. We should not do no-GTA just because of the simple of no-GTA methods. We should do no-GTA because it indeed works. \nAs the authors stated in the related works, the anchor design is heuristic and complicated. But it works, and pushes forward the performance of object detection. While researchers recently find that the anchors are not necessary, because they obtain **better results** without multiple anchors. \nIt is the same for this paper. The authors should prove that we can obtain better results vs. ATSS [SOTAs in GTA] with the simpler framework. \n\n3. The experimental part of this is not satisfactory, especially the comparisional part. \nI think the authors should directly compare the method with recent SOTA methods stated in their related work. For example, Faster R-CNN, RetinaNet, FCOS, and ATSS. In my understanding, the only difference between this paper and related works are the objective functions. Because the feature extraction part is almost the same except for the number of output channels for different purposes. Current comparisons studies can not address my concerns. The results in Table 5 are unfair.\nThe only public detector compared in this paper is EfficientDet, because the authors are using the aggressive long-time training and data augmentations. The method outperform EfficientDet by 0.9 points with Efficient-D1. I recommend the authors compare their efficiency with EfficientDet as the paper has no strengths on performance. \n\n4. More analysis with keypoint-based methods are required. \nFor example, CornerNet and CenterNet. Because they are also using density estimation for classification.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Not good enough object detection submission",
            "review": "-This paper proposes a Mixture Density Object Detector (MDOD), which models the detection as a problem of density estimation. It claims to avoid the ground truths assignments (GTA) which is commonly used in almost all object detection works.  However, in the section of \"RoI sampling\", it clearly says that the proposed method still needs a threshold for roi sampling. This is no much different from the standard GTA, which is contradictory with the claim of this paper.\n\n-The idea of modeling detection as density estimation is OK, but not very interesting to me.\n\n-The results are OK, but not surprising good, especially when the baselines are kind of low. Please check the baseline of Detectron2, and the recent state-of-the-art detection results.\n\nA few questions:\n\n-Don't quite understand why the \"mixture model\" is across all spatial locations (\\pi summed over all locations equal to 1). There could be multiple objects presented in one image.  If \\pi summed over all locations equal to 1, the presence of an object will suppress the presence of the other object? And the value of \\pi at a location will be very small.\n\n-Why no class loss for ground truths bounding boxes in L_{MoC}?\n\n-The proposed method doesn't guarantee the +/- balance. You already did roi sampling, why not control the ratio explicitly?",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}