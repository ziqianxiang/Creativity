{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The reviewers appreciate the spatio-temporal formulation of amortised iterative inference.\nHowever, the paper does not clearly state what is the end goal: if the end goal is video object segmentation, it should compared against other unsupervised object segmentation methods. If the goal is representation learning, it should evaluate the merit of the recovered representations, e.g. by fine-tuning them on some downstream task. "
    },
    "Reviews": [
        {
            "title": "An interesting paper with insufficient experiments",
            "review": "This paper presents a new model for unsupervised video decomposition based on the multi-object scene representation of IODINE. Basically, it makes use of 2D-LSTMs to provide the IODINE framework with a better ability to capture temporal dependencies.\n\n1.  My first concern is about the novelty of the proposed model. The most important contribution, if I understand it correctly, is the use of 2D-LSTMs in the iterative amortized inference for temporal modeling. It does extend IODINE into the spatiotemporal context, but it only provides limited new insight into this research field.\n\n2. Another concern is about the CLEVRER experiments. From Table 2, a counter-intuitive observation is that IODINE significantly outperforms Seq-IODINE. There might be two reasons: (a) In this dataset, the temporal dependencies between frames are relatively weak, because future frames depend not only on previous ones but also on a series of actions. (b) Seq-IODINE may not be a strong baseline model; If so, the authors might include other existing approaches specifically designed for video data, such as R-NEM and DDPAE [Hsieh et al., 2018].\n[Hsieh et al., 2018] Learning to Decompose and Disentangle Representations for Video Prediction.\n\n3. Although I am aware that R-NEM and IODINE were also evaluated on the synthetic datasets only, I recommend that the authors validate the model on real-world datasets of non-rigid objects and more complex structures.\n\n4. If the authors can provide a direct qualitative comparison with R-NEM and IODINE in Figures 3-4, it will be easier to understand the advantages of the proposed model.\n\n5. In Section 2, the authors could use a separate paragraph to describe the main differences between the proposed model and previous ones, in particular R-NEM and IODINE.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A well-executed application of iterative inference to the video domain",
            "review": "The paper presents a model for the unsupervised decomposition of videos into objects. It builds on\nprevious models operating on individual images such as IODINE and GENESIS, and extends them to the\nvideo domain by conducting iterative inference also across the time dimension, leading to a\ncomputation graph resembling a 2D grid. It is shown that the proposed model provides more accurate\nscene decompositions than previous ones, and generalizes better to different numbers of objects.\nPredictions of future frames appear somewhat less accurate.\n\n\nStrengths:\n 1. The proposed method closes an important gap in the landscape of unsupervised object-based\n    models: It is the first such method to decompose colored videos using pixel-wise segmentation\n    masks. The method is well motivated and clearly presented.\n 2. The experimental evaluation follows the precedent set by R-NEM, IODINE, and others. It appears\n    to have been rigorously conducted and shows encouraging results in terms of scene decomposition\n    and generalization. The reduced reliance on color information, which has plagued previous models\n    such as MoNET, is especially welcome.\n 3. The main technical contribution, the two-dimensional refinement method, seems to provide clear\n    benefits over previous ad-hoc implementations such as SEQ-IODINE, both in terms of runtime and\n    performance.\n\nWeaknesses:\n 1. As noted by the authors, predictive performance is somewhat lacking, which may be explained by\n    the lack of relational components. \n 2. Using the inference network as opposed to the generative model for prediction seems to run\n    counter to the idea of learning a generative model to accurately model the distribution of the\n    data. In particular, because the generative distribution $p(z_t | x_{<t}, z_{<t})$ seems ill-equipped\n    to model object interactions.\n 3. Like all unsupervised object-models, this work is still quite far away from working on natural\n    videos. \n\nOverall, I believe this paper fills an important gap that many members of the community were waiting\nto see filled. It is well executed and adds some interesting ideas to the toolset of unsupervised\nobject models. I therefore recommend acceptance.\n\nQuestions:\n 1. It seems that during inference, interactions between slots may be taken into account through the\n    gradients of the likelihood. But during prediction, those are set to zero, and the prior\n    over $z_t$ seems to operate slot-wise as well. So can object interactions be computed at all\n    during prediction, or are the slots predicted independently of one another?\n 2. The choice of $\\hat{R}$ seems to express the idea that once a good latent state has been inferred,\n    a single refinement step is enough to update it given new observations. Would additional steps\n    be beneficial when receiving unexpected input, such as frames with newly appearing objects on\n    CLEVRER? Could the number of steps perhaps even be selected dynamically based on e.g. the\n    reconstruction error?\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Novelty and contribution should be clarified",
            "review": "In this paper, the authors propose to better explicitly utilize the sequential information in the video to improve the performance of unsupervised scene decomposition in video. Concretely, 2D LSTM is used to combine the advantages of iterative inference and temporal information. By appropriately using the inferred results in the previous time step, the number of interactive inference steps is decreasing, which finally results in the O(R^2+T) complexity. \n\nThe main concern about this paper is the novelty. First, unsupervised video decomposition, like Sqair and R-NEM all use the temporal information, and the iterative inference method has been used in previous work like IODINE. It seems that this paper extends the IODINE to the video setting with a modification that decreasing the iterative steps as time increases. The authors should better illustrate their novelty and contributions of this paper.\n\nThe presentation is generally clear in this paper. However, the figures can be improved. First, figure 1 seems meaningless. I don’t the relationship between the top row and the bottom row in the top panel of figure 1. The captions said about the emergence of new objects, but I cannot find them in the figure. Highlight them with some red bounding boxes is helpful. Second, panel (b) of Figure 2 is really chaotic. I don’t know what’s the main purpose of this panel. Again, highlight the part you want to emphasize.\n\nFinally, there are some related but not discussed work:\n[a] Chen, Mickaël, Thierry Artières, and Ludovic Denoyer. \"Unsupervised object segmentation by redrawing.\" Advances in Neural Information Processing Systems. 2019.\n[b] Arandjelović, Relja, and Andrew Zisserman. \"Object discovery with a copy-pasting gan.\" arXiv preprint arXiv:1905.11369 (2019).\n[c] Xu, Taufik, et al. \"Multi-objects generation with amortized structural regularization.\" Advances in Neural Information Processing Systems. 2019.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Appropriate evaluation is missing",
            "review": "The authors extend previous work of Greff et al. on unsupervised, multi-object scene decomposition to incorporate temporal information.  In particular, they apply the LSTM defined for each candidate object not only over inference steps, but also over time. This allows the model to capture temporal cues, such as object motion, to better decompose the scene into objects. In addition, this allows to speed up the inference, since they perform fewer inference steps at each consecutive frame, capitalizing on temporal consistency in videos (LSTM state can be largely refused between consecutive frames, since the appearance doesn't change a lot). Experimentally demonstrate that their approach indeed outperforms prior work on two toy datasets (bouncing balls and CLEVERER), while being more computationally efficient.\n\nThe paper is relatively well written, although it is very dense and is hard to follow for someone not already familiar with the field.\n\nI'm not an expert in iterative amortized inferences, so can't properly judge the technical contribution of the paper. That said, the novelty is non-trivial to the best of my knowledge.\n\nExperimental evaluation is sufficient to compare to the closely related approaches Greff et al., and  Van Steenkiste et al., demonstrating that the proposed method outperforms them when evaluation setting (number of objects in a video) matches the training setting. In a generalization experiments, however, when the number of objects in increased at test time, the gap between the methods becomes much smaller. Moreover, the proposed method seems to generalize worse than Van Steenkiste et al. A reasonable ablation study is provided to justify the design decisions made by the authors.\n\nMy main issue is with the positioning of the paper. The authors claim that their goal is learning disentangled, multi-object representations, but all the evaluations are on the task of unsupervised video segmentation on toy datasets. As the authors mention in the conclusion, the problem of unsupervised video segmentation is well studied in the computer vision community, featuring both heuristic-based (Brox and Malik, ECCV'10), and learning-based methods (Xie et al., CVPR'19, Dave et al., ECCV'19 Workshops). Unlike the proposed method, those approaches work on real videos in the wild, though they indeed do not claim to learn an interpretable, disentangled representation. In might well be that this direction of research has merit, even if existing method cannot compete with dedicated video segmentation approaches yet, but this has to be experimentally demonstrated. If video segmentation is indeed not the end goal of your approach, when it shouldn't be used as the main evaluation metric. In particular, when comparing to  Greff et al., and  Van Steenkiste et al., you should demonstrate that the representation learned by your method is more disentangled and more interpretable than theirs, instead of showing that you are better at video segmentation. Indeed, there is no evidence that the two metrics are strongly correlated. In addition, this would allow you to compare your method to other, not object decomposition-based methods for learning disentangled representations. \n\nAs mentioned above, I cannot adequately judge the technical contribution of the paper, so, if other reviewers find it convincing in itself, I'm ready to increase my score. The experimental evaluation of the actual task studied in the paper (learning disentangled representations) is completely missing, however, thus I recommend to reject the paper in this round.\n\n\nSome minor comments: \n\n1. Why not use mask IoU for segmentation evaluation?\n\n2. Why are ARI scores higher on CLEVERER in Table 2 compare to Table 1 (generalization scenario with more objects)?\n\n3. Please discuss and compare to Hsieh et al., NIPS'18, who also claim to learn disentangled representations via unsupervised video decomposition.\n\n\n\n\nIn the rebuttal the authors have argued that their method studies a different problem from that of unsupervised video segmentation, and thus a comparison to those methods is unnecessary. Moreover, they mentioned that no established metrics exist for evaluating the degree of disentanglement of a representation, thus no new experiments can or should be added to the paper. I can see that there is a difference between image-based scene decomposition and unsupervised video segmentation. Once you move to video-based methods, however, the difference start to elude me. At least in the classical works, such as Brox and Malik, ECCV'10, the problem is defined in exactly the same way - decomposing a video into object/background regions in a fully unsupervised way. The only difference I can see is that in those works decomposition was the end goal, whereas this paper attempts to use it as a surrogate task for representation learning. This would be a valuable contribution if the authors could show that the resulting representations are superior to those learned with other unsupervised objectives (say, contrastive learning) at least for some tasks (say, object detection). Unfortunately, such evaluation is missing from the paper, thus I still find find that the benefits of the proposed approach are not convincingly demonstrated.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}