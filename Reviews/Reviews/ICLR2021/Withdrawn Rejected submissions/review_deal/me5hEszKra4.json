{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper presents a new method to predict the performance of deep neural networks. It evaluates the method on three different networks: LeNet, AlexNet, and VGG16 under two different frameworks, TensorFlow and TensorRT.\n\nReviewer 2 thought that the results were promising but comparison with other approaches was weak (PerfNet being the only baseline). They also asked for motivation for the selected architecture as well as raised a number of points for clarification. R2 was also concerned that the single baseline appeared to have not yet been published. The authors clarified this in their response (it was published in ACM RACS, obtaining results directly from those authors).\n\nReviewer 1 said that the experiments were extensive, but did not find the approach novel (“a normal application of ResNet”). They suggested NAS as a motivating application rather than stopping at predicting execution time. The authors agreed with the importance of predicting execution time in NAS.\n\nReviewer 3 agreed with Reviewer 1’s assessment of lacking novelty and technical contribution. They also pointed towards NAS, where many methods are already using neural networks to predict execution time. They were also disappointed by the reduced set of architectural elements considered. The authors responded to R3’s comments, but R3 was still not convinced of novelty.\n\nThis looks like a fairly straightforward rejection on the basis of not enough technical merit. The authors are encouraged to explore their approach in the context of NAS as per R1’s suggestion."
    },
    "Reviews": [
        {
            "title": "The paper presents a method, based on a residual CNN, for performance prediction of deep neural networks on different hardware platforms. The results are promising, but there is a limited comparison with previous work.",
            "review": "The paper presents a method, called ResPerfNet, to predict the performance of deep neural networks. The method relies on a residual neural network that is trained on a large number of different network architectures and performance measures on real hardware. \n\nThe paper evaluates the proposed method on three networks, LeNet, AlexNet, and VGG16, in two different frameworks, i.e., TensorFlow and TensorRT. The results are promising, but comparison with other approaches is weak. For example, the proposed method, ResPerfNet, is only compared to one other approach, PerfNet (from a paper that don't seem to be published yet, at least I couldn't find it), using TensorFlow (but not using TensorRT).\n\nThe paper has potential to have impact, but it needs to be improved before publication. For example, the following issues need to be addressed:\n* Motivation for the selected structure / architecture of ResPerfNet.\n* Some confusion about kernels, filters, etc. in the description of the ResPerfNet architecture (Section. 3 + Fig. 1)\n* I'm a bit surprised that the dropout layer is very close to the end of the network. Why? Why 0.2 dropout (and not 0.1 or 0.4)?\n* It's a bit confusing (and inconsistent) that the index I is left out sometimes and sometimes not, e.g., Eq (2) vs. Eq (3) vs. how it is written in the text flow. \n* C(f,d) in Eq (5) is never defined.\n* Platform for sample selection / data collection should be mentioned in Section 5.2\n* Section 5.4. Although using defining the loss function as MAPLE does reduce the problem with a skewed distribution, it doe not solve it so \"cope with it\" is a bit strong formulation.\n* It is disturbing that one of the main references [Wang 2020] can't be found, despite extensive searching. This is problematic since the only other solution ResPerfNet is compared to is PerfNet, which is published in [Wang 2020]. This limits the possibility to compare this work with previous work. The conference where the [Wang 2020] paper was published took place in mid October 2020, which is after the deadline for ICLR.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Reviews",
            "review": "Summary: The authors design a specific ResNet for predicting the model execution time on different platforms.\n\nPros\n- conduct extensive experiments, particularly collect a large scale dataset for measuring different architectures, which can be helpful for further works if it can be released publicly\n\nCons\n- The idea is not novel. The main idea is to utilize a ResNet to perform regression on network latency data, which can only be considered as a normal application of ResNet. \n- The motivation is questionable. In my opinion, making model execution time prediction more accurate should not be the ultimate end. The proposed ResPerfNet should be applied in network evaluation and search stages in Neural Architecture Search (NAS) area, and validate that a more accurate model performance predictor is helpful for architecture search. But I didn't see any supporting experimental results in this paper.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Lack of Noverty and technical contributions",
            "review": "Topic\n\nUsing a residual-based network to the performance of another DL-based network.\n\nContributions:\n\nUsing a residual-based network for estimating the computing performance of DL applications on a variety of models-framework-accelerator configurations, which enables the users to explore the hardware/software design space.\nUsing three-phase performance modeling to estimate computation time.\n\nWeakness\n\n1, The main problem is the lack of Novelty and technical contributions. Using a DL-based model to predict the performance is not novel. Many NAS methods using the same trick to estimate the performance of one architecture ahead of running it directly on the hardware.\n\n2, Using a DL-base regression is better than normal regression when the sample size is large. The experiment results are not surprising.\n\n3, Box-cox transformation is a common technique in regression. That is not new.\n\n4, Need to prepare the dataset using a lot of samples, i.e. 100000, which is computationally heavy. \nRequire huge storage space to keep the samples for even one platform.\nThus the whole method is not efficient. It is hard to generalize it to other hardware/platform.\n\n5, Besides, the method only considers some common operations such as conv, pooling, and FC-layer. However, more operations should be considered for example ROI Pooling, NMS, Spatial-to-depth. Those operations are also commonly used in tasks such as detection and SR. \n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}