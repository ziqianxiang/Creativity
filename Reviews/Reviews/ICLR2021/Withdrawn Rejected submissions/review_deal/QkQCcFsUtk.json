{
    "Decision": "",
    "Reviews": [
        {
            "title": "Review",
            "review": "This paper proposes an unsupervised method to learn cross-lingual word embeddings that combines 4 steps: (i) initial mapping through an adversarial approach, (ii) refinement through symmetric re-weighting, (iii) further refinement through the coherent point drift method, and (iv) final dictionary induction.\n\nWhile the reported results are quite strong, I think that the novelty is very limited. Even worse, the paper tends to oversell, and does a poor job at putting the work into the wider context. Some very relevant references are missed, and some things that are presented as if they were an original contribution are not really new or are otherwise questionable.\n\nFirst, multi-step frameworks that combine an initial mapping (usually through an adversarial method) and one or several refinement steps are very common in this area. A systematic study was done by Hartmann et al. (NeurIPS'19), which should be cited. Regarding the individual steps, the first adversarial step is quite standard, and there is no empirical evidence that the proposed variant is stronger than similar ones from the literature (other than a comparison with MUSE). The second symmetric re-weighting step (repeatedly referred to as \"symmetric re-whitening\" in the paper, which is wrong) is taken directly from Artetxe et al. (AAAI'18, ACL'18), so there is no novelty there. Regarding the third step, the application of the coherence point drift algorithm to this problem was already proposed by Cao and Zhao (IJCAI'18), which is not even cited. In fact, even the title of their paper (\"Point Set Registration for Unsupervised Bilingual Lexical Induction\") is very similar to this one. There is nothing new about the last dictionary induction step nor the unsupervised validation criterion either, other than the bidirectionality in the latter.\n\nRegarding the experiments, the choice of baselines is broad and reasonable and the paper does report some improvements over them. However, the evaluation is done in a single task and misses alternative methods like Artetxe et al. (ACL'19) that obtain substantially better results. It is true that this is a common issue in this area, but it is still a weakness.\n\nMoreover, I was not convinced by the limited vocabulary experiments and some of the ablation study results. The limited vocabulary setup is not realistic and the provided motivation does not make much sense: even in a domain-specific context, you could use out-of-domain words to learn the mapping and, in any case, taking the 10k most frequent words from Wikipedia is not a realistic simulation of a domain-specific vocabulary. Regarding the robustness claims, I am pretty confident that most iterative methods from the literature would be able to converge to a good solution starting from \"Bad-GAN\", and there is no empirical evidence that the proposed method is better than other methods in this aspect.\n\nAs a minor point, the writing style feels overly pedantic and unnatural to me (e.g., \"a pictorial depiction of the overview of the functionality of the different modules is presented in Figure 1\"). Similarly, the names of the 4 steps are \"inspired by the 4 bases in DNA, the building block of life.\" This sounds rather pretentious to me, and it would have been much better if the authors used a standard terminology instead (e.g., adversarial mapping, symmetric re-weighting etc).",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Unsupervised Word Translation Pairing using Refinement based Point Set Registration",
            "review": "This paper proposes BioSpere, a framework for unsupervised mapping of bilingual word embeddings onto the same vector space, using adversarial initialization and point set registration algorithm.\n\nPros:\n1. The align module designs an adversarial training paradigm together with cycle-consistent training to distinguish synthetic distribution and true translation.\n2. They authors noticed the relationship between the word embedding alignment and point set registration in computer vision, and applied it to this problem.\n3. The experimental results are encouraging, even on a par wit supervised method.\n\nCons:\n1. The choice of using CSLS metric seems to be quite arbitrary. You uses CSLS in correspond for seeding the parallel dictionary, and then used it for evaluation, which makes the results doubtful. It is a serious issue.\n2. The introduction of CPD lacks proper motivation. It seems the GMM model is used to align the centroids and the other data points. But it lacks explanation.\n3. This paper put several components together but is short of a systematic description how these components work together to obtain improved results.\n\nQuestions:\n1. What is the hubbness problem?\n2. Is GMM used to align the centroids of one distribution (one language) and the data points of the other distribution (the other language)? \n \nAdditional Comments:\nThere are also many grammar, spelling and presentation issues with this paper.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Strong word translation result, but no downstream task evaluation and comparison against multilingual transformer",
            "review": "This paper introduces a new unsupervised cross-lingual word embedding (CLWE) pipeline by combining three techniques from previous work: (1) cycle-consistent adversarial learning, (2) symmetric reweighting, and (3) coherent point drift (CPD).\n\nStrengths:\n* This paper is the first to use CPD for unsupervised CLWE.\n* The proposed method beats previous unsupervised CLWE methods on MUSE, a word translation benchmark.\n\nWeaknesses:\n* No extrinsic evaluation on downstream tasks.\n* Unsupervised multilingual transformers are superseding CLWE, so the paper may have limited impact.\n\nDetailed feedback:\n\nWhile the proposed method is novel and has solid word translation accuracy, I recommend rejection for two concerns.\n\nFirst, the current method is only evaluated on the intrinsic task of word translation. While this was a popular evaluation metric for CLWE, more recent work shows that word translation accuracy do not correlate well with downstream task performances (Artetxe et al., 2019; Glavas et al., 2019), and optimizing word translation can hurt other tasks (Zhang et al., 2020). Therefore, it is unclear if the observed improvements in word translation accuracy will translate to other (arguably more important) downstream tasks.\n\nSecond, recent work shows that unsupervised multilingual transformers, such as multilingual BERT (Wu & Dredze, 2019) and  XLM-R (Conneau et al., 2020), outperform CLWE on almost every cross-lingual task. Therefore, the proposed method may have limited impact.\n\nSuggestions: \n* The paper could add experiments on downstream tasks. This will confirm that the proposed method is useful to multiple tasks and not over-optimizing word translation.\n* The paper could either extend the method to multilingual transformers (similar to Wang et al. (2020)) or compare against them (similar to Yuan et al. (2020)). This would show that the proposed method is useful even when we have multilingual transformers.\n\n\nReferences:\n* Artetxe et al., 2019 = Bilingual Lexicon Induction through Unsupervised Machine Translation\n* Glavas et al., 2019 = How to (Properly) Evaluate Cross-Lingual Word Embeddings: On Strong Baselines, Comparative Analyses, and Some Misconceptions\n* Wu & Dredze, 2019 = Beto, Bentz, Becas: The Surprising Cross-Lingual Effectiveness of BERT\n* Conneau et al., 2020 = Unsupervised Cross-lingual Representation Learning at Scale\n* Wang et al., 2020 = Cross-lingual Alignment vs Joint Training: A Comparative Study and A Simple Unified Framework\n* Yuan et al., 2020 = Interactive Refinement of Cross-Lingual Word Embeddings\n* Zhang et al., 2020 = Why Overfitting Isn't Always Bad: Retrofitting Cross-Lingual Word Embeddings to Dictionaries\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}