{
    "Decision": "",
    "Reviews": [
        {
            "title": "Borderline Reject",
            "review": "First of all, this paper provides better mathematical background. And the whole paper is better organized.\nPros:\nThe contribution is clearly derived. And this paper employs the VMF distribution so as to move the Gaussian distribution of the PFE framework into hyper-shperical space seems interesting and novel. This constitutes a good theoretical contribution. \n\nCons:\nI noticed that the final results show that the proposed method has little improvements over the baseline method, e.g. only improves the performance less than 0.1% in many cases when comparing with PFE and ArcFace. That makes the effectiveness of the proposed method doubtful.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Incremental idea with unfair comparisons in experiments",
            "review": "Summary:\n\nThe paper proposes HypersFace, a probabilistic framework for face recognition problems. It combines PFE (Shi & Jain, 2019), a probabilistic framework for face recognition, with hyperspherical embeddings (i.e. L2-normalized embeddings). In PFE the encoder model is assumed to be a Gaussian with diagonal covariance, but this assumption fails with hyperspherical embeddings because the dimensions in the latent code can be more correlated. To solve this issue, the authors propose to replace Gaussian distribution with r-radius von Mises Fisher distribution, essentially a von-Mises Fisher distribution (obtained by projecting a Gaussian to a hypersphere) but augmented with scale. The authors argue that this modification is the major source of improvement. In addition, KL divergence instead of mutual likelihood score as in PFE is used. Empirical results shown on face recognition tasks with multiple datasets and different architectures.\n\n\nPros\n-\tThe idea itself is easy to grasp - to replace Gaussian with some ‘spherical Gaussian’ in PFE so that the encoder assumption is more suitable for hyperspehrical embeddings.\n-\tThe final loss function is rather easy to implement.\n-\tThe paper shows some qualitative results on the distribution of predicted distribution parameters, which are helpful in understanding the properties of the proposed method.\n\nCons\n-\tThe idea seems incremental – using von Mises Fisher distribution to get around the Gaussian assumption is not a rare practice in ML. For instance, [1] builds a probabilistic model with von Mises-Fisher distribution for clustering. A straightforward application of a somewhat standard approach to a non-face-recognition-specific issue is not that interesting enough and we do not learn much additional knowledge that can be applicable to tasks outside face recognition.\n-\tIt is simply unfair to compare KL divergence + von Mises-Fisher with mutual likelihood score + Gaussian. Although the authors do show that with von Mises-Fisher, KL divergence is better than mutual likelihood score, it is not shown that with KL divergence, von Mises-Fisher is better than Gaussian. It is highly like that the improvements come from the use of KL divergence instead of the use of von Mises-Fisher distribution as argued by the authors.\n-\tThe experiments use an extremely wide MLP (‘FC(12544) − BN − ReLU − FC(6272) − BN − ReLU − FC(1) − exp’) for the concentration module (i.e. uncertainty module in von Mises-Fisher distribution), while in PFE the width of hidden layers in the uncertainty module is 512. I don’t think it is a fair comparison at all.\n-\tEven if we ignore the fair comparison issue, the empirical results do not show significant advantage of HyperesFace over the baselines. Moreover, I am afraid that the small increases in accuracy might not be statistically significant.\n\n[1] Banerjee, Arindam, et al. \"Clustering on the unit hypersphere using von Mises-Fisher distributions.\" Journal of Machine Learning Research 6.Sep (2005): 1345-1382.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper analyzes the failure cases of applying PFE into hyperspherical embedding in theory and practice. To explore uncertainty learning in the hyperspherical space, HypersFace, a novel framework for hyperspherical uncertainty learning, is proposed to address the failure cases of PFE.",
            "review": "Recent research found that it is more sensible to recognize face image in hyperspherical space. However, it is still underexploited on modeling the uncertainty in hyperspherical space. The paper first analyzes the failure cases of applying PFE into hyperspherical embedding in theory and practice. To explore uncertainty learning in the hyperspherical space, HypersFace, a novel framework for hyperspherical uncertainty learning, is proposed to address the failure cases of PFE. In HypersFace, facial images are represented using r-radius von Mises Fisher distribution (r-radius vMF) rather than Gaussian distribution. By minimizing KL divergence between hyperspherical Dirac delta and r-radius vMF, a robust and discriminative feature representation is learned from volatile facial images acquired in complex scenes. The extensive experimental results on six facial datasets demonstrate that the proposed HypersFace outperforms the prior probabilistic methods in both risk-controlled recognition task, face verification and identification tasks.\n\npros:\n- The paper is well-organized and focuses on the hypothetical paradox of multivariate independent Gaussian distribution in PFE. By analyzing PFE’s failure cases in theory and practice, the paper verifies the empirical findings of PFE, i.e., Arcface cannot make the PFE model converge well.\n- As we know, the paper first employs von Mises Fisher distribution, a specific distribution defined on the hypersphere, for face feature representation. In the new representation, mean directions denote input images' facial features, while concentration parameters represent the uncertainty of facial features.\n- In this paper, extensive experiments are conducted on six facial benchmark datasets. The superior performance of HypersFace against prior PFE demonstrates its effectiveness on face recognition.\n \n \ncons:\n- For the paper, it is the foundation to analyze the failure cases of applying PFE into hypersphere uncertainty learning. The authors should provide a more detailed formulaic explanation for the dilemma encountered in PFE.\n- The paper learns the feature representation by minimizing the KL divergence between hyperspherical Dirac delta and r-radius vMF. However, Theorem 1 and Corollary 1 suggest that minimizing KL divergence would make the model converge to a naïve optimum, i.e., \\kappa approaches positive infinity. This naïve solution means that HypersFace does not learn the data uncertainty of facial images well.\n- Some typos:\n Page-1: 'recoginition' should be 'recognition' (From \"and ArcFace further …  face recoginition models by proposing … the geodesic distance margin on a hypersphere (Deng et al., 2019).\")\n Page-5: 'perceptrons' should be 'perceptron' (From \"The concentration module κ(·) is parameterized by three-layer perceptrons with the architecture\")\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}