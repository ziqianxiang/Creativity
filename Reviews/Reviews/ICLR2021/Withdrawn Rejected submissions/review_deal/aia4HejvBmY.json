{
    "Decision": "",
    "Reviews": [
        {
            "title": "Initial Review",
            "review": "Summary of Contributions\n\nThe paper contributes to the application of spatial wildfire forecasting using convolutional neural networks. In particular,\n the paper utilizes a modified UNet architecture that includes fully-connected layers that are used to incorporate scalar weather data. The authors also demonstrate that incorporating multiple, previous timesteps of observed fire perimeters improves the model’s predictions.\n\nStrengths\n\nWildfire forecasting is an important application for study due to its current and projected future effects on the environment and human interests. Furthermore, it appears to be an application that is promising for improvement with machine learning due to the growth in widely available remote sensing data.\n\nThe use of a UNet-based architecture seems appropriate for the application because of its ability to capture global information and preserve local, high-frequency spatial patterns.\n\nThe problem setup of forecasting the spread of wildfire perimeters is similar to existing fire spread models making comparison more straightforward and is of key interest to scientists who study fire spread.\n\nThe incorporation of multiple, relevant input types (fire perimeters, topography, vegetation, and weather) are all key to wildfire spread. \n\nWeaknesses\n\nThe primary weakness of the paper is the lack of detailed experiments. As a paper primarily focused on the application of existing methodology to a valuable problem it is important that clear and detailed experiments provide information and guidance about the chosen methodology. Furthermore, a broader comparison of different models would be helpful. More extensive experiments and reporting also help with future comparisons made with your work done by subsequent authors.\n\nA secondary weakness of the paper is a lack of details about the models and experimental setup used for the results described. The details currently reported are insufficient for the proper reproduction of the reported results.\n\nAnother secondary weakness is the non-standard use of terms including the definition of IoU and the use of the term 3D convolution. I elaborate on the use of these terms in the context of this paper in the suggestions section. \n\nRecommendation\n\nBased primarily on the lack of extensive experimentation my recommendation is to reject the paper. While I believe the problem is of keen interest, the paper lacks substantive experimentation and evaluation to make a significant contribution to the community. \n\nClarification\n\nThe authors use the term “3D convolution” throughout the paper, but from the description of the model it appears that their approach is a 2D convolution with multiple channels (representing time). Specifically, the line “In this study, 3 previous days of wildfire profiles are combined to convert input images from 2D to 3D” from page 2 sounds consistent with a 2D convolution (over space), with temporal channels, not a 3D convolution which convolves over the spatial and temporal dimensions. If the model does convolve over space and time this should be more clearly described and the choice to do so elaborated on.\n\nThe authors describe IoU as “the area of overlap is simply the number of pixels that have the same value in both images.” The standard definition of IoU only defines the intersection term as pixels where both are labeled as the positive class, not as all pixels with the same value. Does this language reflect an intentional departure from the traditional definition, a misstatement, or a mistake in the way the evaluation metric was computed? \n\nAdditional information regarding the baseline models and experimental parameters would be helpful when analyzing the results.\n\n\nSuggestions\n\nThe issues identified on page 6 with “the model can obtain a high IoU score by simply predicting every pixel to be 0” appears to only be the case due to the alternative definition of IoU. \n\nThe captions on several figures could be expanded to provide more detail (especially figures 5 and 6).\n\nI think a more extensive set of experiments to help identify a) the effect of the amount of data on model performance, b) the performance of other CNN architectures (e.g. a simple fully-convolutional architecture),  c) the effect of various hyperparameters including model depth/size, and d) the effect of the inclusion/exclusion of specific types of input data (topography, vegetation, and weather).\n\nMore extensive reporting about the experiments that were reported in the paper. For example, the authors report the performance on three different groupings of data (rapid, moderate, and subtle), but the size of each group is not reported as a fraction of the total test set. \n\nCan the authors provide insight into the choice of fire perimeter dataset? There are a number of active fire datasets for both individual fire pixels/detections (VIIRS 375m, MODIS active fire product) and fire perimeters. Why was this set chosen, given the small size? Were others investigated?\n\nGiven the repeated reference about the benefits of a CNN-based model over more traditional, physics-based models it would be helpful to see quantitative or qualitative comparisons.\n\nHow was the threshold selected that was used in the final evaluation? “Various thresholds were evaluated and selected threshold yielded the highest metric scores.” Was there a validation set (separate from the training and testing datasets) that was used for threshold selection?\n\nYour figures of predicted perimeter versus observed perimeter could be improved by ensuring that subfigures a) and b) have the same spatial scale. It appears subfigures (a) and (c) in figure 4 and subfigure (a) in figure 5 are slightly smaller due to the scale bar. It may also be of interest to more specifically identify the part of the fire perimeter that the model forecasted the spread of (beyond the previous day’s perimeter) by shading it in a different color. \n\nThe authors may be interested in this (https://arxiv.org/abs/2010.07445) paper which takes a similar approach to fire spread forecasting. This is not a suggestion, but just a relevant paper that the authors should be aware of.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper solves an interesting application. However, the proposed method is not novel.",
            "review": "This paper proposes a 3D CNN model to segment wildfire range from remote sensing data. The proposed model takes both spatial dimensions and the temporal dimension as 3D inputs. The proposed idea is similar to U-Net architecture. Some evaluations on a real-world dataset show that the proposed model outperforms U-Net and logistic regression. \n\nThe paper solves an interesting application. However, the proposed method lacks novelty compared with the popular U-Net model. The proposed extension has limited novelty from the machine learning research perspective. The paper may fit better for an applied research venue (e.g., interdisciplinary deep learning applications).\n\nStrengthen:\n1. The paper solves a significant real-world application of wildfire mapping. \n2. The paper is well-written and easily readable.\n3. The results show that the proposed model outperforms several baseline methods.\n\nWeakness:\n1. The main concern is on the novelty of the proposed model. The proposed model seems a minor tuning of the U-Net model with a slightly different input shape. For a research paper, it will be helpful to identify some unique challenges in wildfire mapping that motivate the novel design of the model and algorithms. \n2. The baselines in evaluation comparison can be broader with other states of the art image segmentation algorithms, e.g., DeepLab.\n\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "A good application report but novelty is limited",
            "review": "This paper studies the wildfire prediction problem by using remote sensing data. The authors propose a 3D-CNN based methods named WildﬁreNet that leans from historical data in both temporal and spatial dimensions to predict the upcoming fire of the next day. The study is of great application signification.  \nMy main concern lies in the novelty of this paper. In my opinion, almost all the technical components used by the authors, including the binary cross-entropy loss, the UNet-like architecture, and 3D convolutions are all widely studied before. The integration of the weather data and temporal data to the network flow is also intuitive and trivial. I would consider this paper a very good application report but may not be the best fit for an ICLR venue.\n\nOthers: \nThe term “wildﬁre proﬁles” is not clearly defined. Is that mean the binary pixelmap of the wildfire regions?\n\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper overall presents weak (and incomplete) results, authors do not compare their model with state-of-the-art baselines. The paper also does not have a strong novel contribution either in terms of novel model architecture or in terms of showcasing new previously unknown facets or characteristics of a popular known model.",
            "review": "### **Decision**: Reject\n\n####  **Review**: \n- The authors propose WildFireNet, a 3D CNN architecture based on the popular U-Net model for forecasting the progression of wildfires. Specifically the authors address the problem of day-ahead wildfire profile forecasting.\n\n-  Wildfirenet input data (D): \n   * Daily weather data including mean wind speed, mean temperature and mean relative humidity for the region of interest. \n   * Topography (i.e elevation, slopes and other terrain characteristics) data. \n   * Normalized Difference Vegetation Index (NDVI) indicating the water content of the crop in the region of interest. \n   * Daily fire perimeters. - Fire perimeters are constructed as a binary map (1 indicates fire, 0 indicates no fire). These binary maps are input the the model as fire perimeter profiles.\n\n- Given the data D for the current day and the past 2 days, the model is tasked with predicting the fire perimeter binary map on the next day. The problem is formulated as a pixel-wise binary classification using a binary cross-entropy loss. The authors present results by comparing their method WildfireNet with a logistic-regression based model and a 2D CNN based U-Net model.\n\n####  Positives:\n\n* The authors adapt the U-Net architecture to the task of wildfire profile growth estimation. Through the course of the paper, the authors provide a good review of state-of-the-art models used for wild fire profile growth estimation task and also elucidate the types of fires and their properties, enabling the readers to appreciate the complexity of the task at hand.\n\n#### Concerns:\n\n**Lack of State-of-the-art Model Comparisons**:\n\n - In the related work section (sec. 2), the authors mention a model FARSITE [1] which uses a vector propagation approach to estimate the growth of the fire perimieter. The authors acknowledge that the approach is effective in certain conditions. However they fail to include the performance comparison of the FARSITE model performance in the current paper. \n\n- Further, the authors cite multiple models for wildfire profile spread estimation but fail to compare with any of the models. The only claim of novelty the authors make is that they utilize 3D CNNs in their U-Net architecture (which is not in itself a novel contribution).\n\n\n**Lack of sufficient motivation for selected architecture**:\n\n- At the outset of section 3.2, the authors appear to (somewhat) justify their use of a U-Net architecture by claiming that the output of a U-Net is \"different than the typical use of CNN\" and go on to say that CNNs typically used for classification tasks output a single label for input images wherease U-Nets output multiple labels (i.e., per pixel of the input image). Such a pixel-wise classification is not something that is restricted to be unique to U-Net architectures (or not something that CNNs or other architectures don't enable). Hence this motivation for using a U-Net architecture is weak at best. However, detailing the effectiveness of the U-Net architecture (which in itself has proven to be fairly effective in representation learning across various tasks due to its unique architectural properties) as a motivation for its usage in the current task would have been slightly more appropriate. Although this change by itself still does not make the paper any stronger.\n\n**Experimental Setup not fully detailed**:\n\n- In section 3.4, it is stated that to obtain the binary map of future fire perimeter, the authors binarize (based on a threshold) the per-pixel probabilistic output of WildfireNet. However, the only commentary about how this threshold is chosen is the following:\n \"Various thresholds were evaluated and selected threshold yielded the highest metric scores\" - How exactly did this parameter selection occur? Such hyperparameters often have a significant effect on the results and hence such information is critical to supply for effective utility of the model by readers. \n\n**Insufficient results (not enough strong baselines) which don't allow for clear contextualization of WildfireNet performance**:\n\n- In the results, section (sec. 5) the authors present results for the proposed WildfireNet model with logistic-regression and a U-Net model (with 2D convolution sans the weather data and including only the most recent day of historical fire profile data).\n\n- Why is logistic-regression a competitive baseline for WildfireNet? The authors themselves acknowledge that the logistic regression model is \"simple\" and that it lacks \"convolution\" to extract features. However, the motivation for the selection of logistic regression is not detailed.\n\n- In Table 1. for the overall expanded Recall (i.e., prediction of how fires expand), the authors mention that WildFireNet achieves a 54% recall whereas other models achieve lower recalls. However, since other state of the art models (designed specifically for or previously applied for wildfire profile evolution forecasting), have not been evaluated, it is hard to contextualize how good or bad these results are in the context of this task.\n\n**Minor Details**:\n\nThere is also a discrepancy between the result values included in the text (Page 6. last paragraph: \"WildfireNet achieved 0.541 on recall while the U-Net and baseline model scored 0.458 and 0.154, respectively\") and in Table 1 (where the corresponding values for U-Net and baseline model - which I'm presuming is Logistic-Regression - are 0.498 and 0.154 respectively). There are also other places in the text where such errors are made (e.g., Page 5, penultimate paragraph).\n\n#### Summary: \n\nHence, overall the paper presents weak (and incomplete) results. It also does not have a strong novel contribution either in terms of a novel model architecture or in terms of showcasing new previously unknown facets or characteristics of popular (U-Net like) models. The only potential novelty (or strength) of the paper could have been the effectiveness (i.e., superior performance) of the adapted (slightly modified) U-Net architecture (i.e., proposed WildfireNet model) but unfortunately the authors do not contextualize the performance of the proposed WildfireNet model in terms of the previous state-of-the-art learning models employed for this task.\n\n\n#### References:\n1. Finney, Mark A. 1998. FARSITE: Fire Area Simulator-model development and evaluation . Res. Pap. RMRS-RP-4, Revised 2004, Ogden, UT: U.S. \n   Department of Agriculture, Forest Service, Rocky Mountain Research Station. 47 p.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Sensible baseline approach but no comparison to the state of the art",
            "review": "Strengths:\n- the paper proposes a sensible approach to an interesting problem\n\n\nWeaknesses:\n- there is no clear motivation of why a fast approach for wildfire prediction is desired (in comparison with Finney et al. 98).\n- the experimental validation lacks comparison to any state of the art method.\n- coverage of related work should be much more extensive; at least on prior works focusing on the prediction of wildfire, but also perhaps on other applications of deep learning in the modeling of physical processes, eg. for weather nowcasting.\n- while the proposed approach is a sensible baseline for the problem at hand, it is not novel, or at best it is incremental. UNet has also been previously employed for modeling other spatiotemporal processes such as weather nowcasting. eg. [1] (and several others - in fact, [1] refers to this architecture as the “ubiquitous U-Net”.)\n- in terms of reproducibility, there are no apparent plans to publish the code; data preprocessing and dataset splits are insufficiently described.\n- The concern raised by the authors about the IOU metric (“…sign of imbalance in the dataset. There IOU is not the best metric…”) does not sound valid. The IOU should be averaged over relevant classes, which means that the metric is unaffected by imbalanced classes. The background class is certainly generally easy; however, one could simply report the IOU of the positive class, or report per-class IOU for each class. In any case, the extremely high reported numbers, in light of this invalid concern, look suspicious; perhaps they have been reported for the background class instead of the positive class. Furthermore, the qualitative samples (although they are hard to interpret) do not seem to indicate the perfect segmentation ability that these scores imply.\n- Finally, the authors do not mention a validation set for the setting of the thresholds they employ, “Various thresholds were evaluated and selected threshold yielded the highest metric scores”, implying that the reported results might not be a good estimation of expected performance.\n\nComments:\n- qualitative results are difficult to interpret: colour and superimposed predictions and ground truths should be used to improve in this respect.\n- AI is an overloaded and imprecise term - I would encourage the authors to name specific methods whenever possible.\n\n\n[1] Machine Learning for Precipitation Nowcasting from Radar Images, Agrawal et al. NeurIPS 2019",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}