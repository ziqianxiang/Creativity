{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper received mixed reviews: two positives (6, 6) and two negatives (5, 3). However, the positive reviewers have very low confidence, do not show strong supports for this paper. The reviewers raised various concerns about this paper, and there still exist remaining critical issues although the authors made substantial efforts to answer the questions.\n\nAfter reading the paper and all the comments by the reviewers, I decided to recommend rejecting this paper mainly due to its weak technical contribution and ignorance of privacy issues. Note that this opinion is shared with two negative reviewers. The proposed model and alternative training scheme are straightforward, and the novelty is not distinct. Also, the authors seem to assume that \"the extracted feature vectors and corresponding gradients are not sensitive\". This comment is given by R2 but has not been clarified. The proposed method is lacking in this aspect and it is hard to say that it is an FL approach.\n\n"
    },
    "Reviews": [
        {
            "title": "The paper is okay to me",
            "review": "Graph neural networks and federated learning are both promising directions of works individually. This papers is apparently one of the first few attempts to combine them for spatio-temporal data modeling. The time series data in the local nodes is modelled by an Encoder-Decoder architecture and spatial locality property of various nodes is captured by the server. The Encoder at each node projects the time series data into an embedding space. This embedding is used by the GNN at the server as node features. The server side GNN outputs node embeddings. The Encoder embeddings and the GNN embeddings are then concatenated and fed to the decoder that predicts the outputs for the subsequent time steps. To ensure that all the nodes encode their temporal data in a common space, the encoders are shared by the clients. Overall, the results look promising.\n\nFollowing are some doubts / concerns I have:\n\n1. In Eq. 3, the specifics of how the edge features and global features are extracted is never mentioned in the paper. All that is mentioned is how they connect two nodes based on their distance of separation.\n\n2. Can authors please elaborate more on Step 25 of Algorithm 1? Given \\delta h_{G,c,i}, and l_i, can we compute \\delta \\theta_{G_N} Overall, how the parameters of GN are updated is not very clear to me.\n\n3. In Algorithm 2, why is the client sending gradient of node embeddings back to the server?\n\n4. In Table 3, why are we not comparing the computational cost on the server?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "To broaden the application of federated learning, the author proposed a node-level distributed training framework for an existing spatial-temporal model (GCN + GRU), which aims to protect the privacy or circumvent the difficulty of centralizing datasets.",
            "review": "The proposed framework is demonstrated with two datasets from the transportation sensor\nnetwork. The experimental results on model performance and training property demonstrate the\nefficacy of the proposed method empirically. The model used is from existing works, but the\ntraining framework is relatively novel in the FL community.\nStrengths\n1. It is very encouraging to support advanced models for federated learning. The author\ngoes in the right direction. As far as I know, this is the first time that GCN+GRU is\ndiscussed under the context of federated learning.\n2. The techniques discussed in this work is comprehensive since the authors introduce\nboth the model and the training method.\nWeakness\n***1. Motivation is not well-discussed***\n(1) From the introduction section, the author claim that the node-level datasets cannot be\ncentralized. But in practice, at least sensors in IoT networks CAN be centralized to edge\nservers.\n(2) Especially, the datasets used in experiments does not have any privacy issue. It is very\nstrange to me why we should concern the privacy of the *traffic speed* from road network\nsensors. We can check the road network speed in real-time using Google Map. In other words,\nthe speed of a specific sensor is not sensitive and can be acquired by public service. Currently,\nthe Google Map example demonstrates that the road network sensors can be uploaded to\nservers from transportation agencies without any privacy concerns.\n(3) Another serious problem is that the DNN-based model (encoder-decoder used in the\nproposed method) are not deployable in the sensor device due to computational resource\nconstraint. In practice, the number of road network sensor in transportation is huge, so it is\nimpractical to ask for an expensive upgrading which requires to install a powerful DNN enabled\nchips.\n***2. No technical contribution***\nThe focus of this work is diverse (both model and training), but lack of contribution in each\naspect.\n(1) The authors argue the contribution of modeling (e.g., 4.1 modeling spatial dependencies, 4.2\n“inductive v.s. transductive”). However, for the modeling part, I believe the contribution is from\nGCN+GRU-based modeling, which is already there in many data mining publications (Equation\n(1)(2)(3) are not newly proposed models). Please refer to [1][2]. The model used in this paper is\na simplified version of these two GCN+RNN-based models in transportation. More advanced\nmodels following these two can obtain better performance than the model used in this paper.\n[1] Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic\nForecasting\n[2] Diffusion convolutional recurrent neural network: Data-driven traffic forecasting\n(2) The authors also claim the benefit of alternating optimization (4.3, 4.4). It is good to know\nsuch an alternating method works well in practice. However, the author does not provide any\nin-depth analysis or comprehensive experimental evidence (see my comments 3 below for\ndetails).\nIn short, I suggest the author focuses on one aspect of federated learning to consolidate the\ncontribution. At least, the current version raises my concern that this work is a simple\ncombination of many techniques without meta-contribution in each one. If the overall\ncharacteristics are good, it should be encouraged. However, the effectiveness is not obvious:\nhigher accuracy, security, fairness, privacy, communication, and computation efficiency, I\ncannot see any of these advantages of such a combination:\n[Model Performance] In terms of higher accuracy, as mentioned in (2), the model used is not\nnovel. More advanced models can obtain higher accuracy. See following works of 2-(2) [1][2] for\ndetails.\n[Optimization] The experimental results of the alternating optimization has some\ncounter-intuition results. See 3 for details.\n[Security/Privacy] As for security and privacy, the hidden vector exchange may leak privacy but\nthis work does not discuss it. See 8 for details.\n[Computational Efficiency] The model used in edge devices are too computational expensive for\nresource constrained sensors. See 4 for details.\n***3. The training Algorithm is novel but the experimental result is not convincing***\nThe training method is relatively novel in federated learning. However, the authors should either\nprovide enough intuition to explain why this work (any related works in optimization theory?) or\ndemonstrate it with experimental design. The author attempts to prove that alternating training\nworks better but it’s not convincing. In Section 4.3, all the experimental results are not\nconvincing or counterintuitive:\nFirst, I am surprised that the authors have a result to say that split learning performs worse than\ncentralized training. In the essence of optimization, split learning is the same as centralized\ntraining. The only difference is that split learning offloads part of the model architecture to the\nserver-side to reduce the communication/computation cost.\nSecond, due to the first reason, that “AT w/o FedAvg” and “AT + FedAvg” works better than SL\ncan NOT demonstrate the effectiveness of alternating optimization. As I mentioned previously,\nto prove the effectiveness of alternating optimization, we need more analysis or comprehensive\nexperimental design.\nThird, another counterintuitive result is that AT + FedAvg performs better than centralized\ntraining (the red curve is lower than the blue curve). Normally, in federated learning, one should\nbelieve that centralized training is the lower bound of training/validation errors. An alternating\nlocal SGD method normally leads to variance bias in the training process, thus I believe it’s\nimpossible to obtain a better performance than centralized training.\nThe last concern is that the experiments only perform at one dataset (METR-LA). Please also\ncheck whether the same conclusion holds in another dataset.\n***4. ​Communication and computational cost***\nThe computational cost is evaluated, but what’s the implication of the number showing in terms\nof FLOPS? I don’t think the resource constrained road network sensor can handle so many\nFLOPS. Does any running time result in a real-world sensor device? If testing the sensor is\nprohibited, please provide the running time result at a low-performance smartphone or other IoT\ndevices (NVIDIA edge GPU devices).\n***5. ​Overall training time***\nThe overall training time and the bandwidth of exchanging hidden vectors should be mentioned.\nIf the network size of the exchange information is too high and the bandwidth is limited in\nwireless communication (e.g., road sensor networks), a single iteration will cost too much time\nor failure due to communication protocol constraint (e.g., in IoT setting, maximum payload\nlength is only 65535 bytes), which will lead to a long training time or impractical assumption.\nPlease discuss the size of exchange information (hidden vector/gradient) and the total training\ntime in revision.\n***6. Scalability issue is ignored***\nThe proposed method does not use a client sampling strategy, a common practice in\ncross-device FL (see the original FedAvg paper [1]), to mitigate the scalability issue. What the\nperformance if we want to learn 10 thousand sensors? Especially in the transportation setting,\nthe scalability is very important. However, the authors do not discuss this.\n[1] Communication-Efficient Learning of Deep Networks from Decentralized Data.\nhttps://arxiv.org/abs/1602.05629\n***7. Dataset: Non-I.I.D. is not properly discussed***\nA key assumption of Federated Learning is that datasets across devices are non-I.I.D. This is\nlargely ignored by the proposed methods. Slightly mentioning the heterogeneous property is not\nenough. Please discuss the details of this in revision (e.g., show the distribution diagram). More\nsignificantly, DNN models like encoder-decoder architectures normally eat a lot of samples, but\nthe number of samples in each node is small in practice. The assumption that each node has\nenough dataset to train a good model is too strong (we cannot assume the edge device has the\nstorage capability to store months of time series data since the storage ability is limited at the\nedge, ***4-6 months*** as the author mentioned). Maybe the alternating optimization method\nhelps, but it lacks analysis. In my opinion, it’s more interesting and practical to construct a\ngraph-level federated learning method since multiple nodes can be centralized to an edge\nserver belongs to a company or an agency like the transportation scenario.\n***8. ​Privacy***\nThe authors discuss some privacy-preserving methods in related works, but the proposed\nmethod does not include any privacy design. For example, [1] analyze potential leakage from\nthe hidden vectors, which proves that the proposed method does not have privacy advantages\nthan exchanging gradient/models.\n[1] Cronus: Robust and Heterogeneous Collaborative Learning with Black-Box Knowledge\nTransfer. https://arxiv.org/abs/1912.11279\n***9. Lack of Related works***\nSince alternating optimization (training algorithm) is the novel part of the proposed method,\nthere is a lack of literature review of this method, either in the general ML optimization literature,\nor the specific federated learning publications. Without such a comparison, the novelty is not\nconvincing.\n***10. Some misunderstandings of federated learning***\n(1) In the first paragraph of the introduction, the authors claim that decentralized training can\nimprove latency, but this argument is vague. Improving training latency or inference latency?\nFederated learning will cost time to train on devices, which requires a long time due to many\nrounds of communication synchronization. For the inference, to improve the latency, we need\nmodel compression techniques, which is also not the main goal of the proposed method.\n(2) The term “decentralized training” is misused. In federated learning, decentralized training\nalso refers to training using a decentralized topology (no central server). Note that FedAvg used\nin the proposed method is a centralized training with decentralized datasets. Please clarify the\ndifference in revision, making sure the readers understand which aspect is decentralized, the\ndatasets, the distributed optimization algorithm, or just computation.\n***11. Reproducibility***\nThe proposed algorithm is complex. Without the code release, it’s hard to check the correctness\nof the implementation. Deep learning normally costs time, I am curious to know how the authors\nimplement such a complex system/algorithm which can train so many nodes in parallel. If it is a\nsimulator, the training time will be too long since so there so many nodes (300+) with DNN\nmodels. If the authors can provide code, maybe all my confusion can be addressed, and I am\nwilling to increase my rating.\n***Suggestions***\n(1) I encourage the authors demonstrate the idea with more realistic datasets. For example,\nin social network, it is possible to run models on the smartphones of Internet users to\nprotect their privacy, which is much better than the transportation example.\n(2) In the current version, there is no contribution in modeling. Thus, I suggest authors to\nthink about customizing the model to obtain benefit of efficiency and privacy.\n(3) More intuition and discussion are requires for the training method. Why alternating\nminimization works well in the GCN setting.\n(4) Since the training results are not convincing, I suggest authors run more experiments to\nunderstand the proposed method and explain why there are some counter-intuitive\nresults.\n(5) Privacy is not the main focus, but some discussions and related works should be\nmentioned.\nOverall Comments\nDue to so many concerns mentioned above, I encourage the authors to have a deeper\nunderstanding of federated learning and address these issues in the revision, especially the\nmotivation, and demonstrating the effectiveness of the proposed alternating training method.\nAfter thinking a while, I cannot find a practical scenario that requires GCN-based node-level\nprivacy. At least, the sensor dataset is not a good example. Maybe the authors can search for a\npractical dataset to demonstrate motivation.\nIn addition, please focus on just one gist rather than intertwine too many aspects and claim all\ncontributions without any trade-off discussion. Besides the training framework, it’s also\ninteresting research if we can see newly developed model architectures can trade-off many\nimportant aspects in FL.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Network modeling using Cross-Node-Federated-Graph-Neural-Network (CNFGNN)",
            "review": "The paper proposes a new modeling framework which would utilize the spatio-temporal information in the data by developing a Cross-Node-Federated-Graph-Neural-Network (CNFGNN). The methodology seems to be clearly explained while it relies on many existing methods in the literature which limits the novelty of the paper. The model is applied to two real data sets and outperforms some existing methods. Overall, I find the methodology interesting.\n\nSome comments:\n\nIn the traffic flow forecasting data: (1) Have you tried different weights (W_{i,j}) instead of the Gaussian kernel function? Does the performance measurements change by using a different weight function? It would be appropriate to show the robustness of the method with respect to changes in the spatial weight selection. (2) Removing trend and seasonality is a common practice in time series forecasting, but it is not clear whether this step is addressed properly or not. What about the seasonality in the data? Is this issue resolved in the preprocessing? ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "This paper extends federated learning to graph-based spatio-temporal forecasting tasks. However, privacy issues, communication cost issues, and experiments need to be improved and clarified.",
            "review": "This paper presents an algorithm to model the complex spatio-temporal dependencies across multiple nodes under a federated learning setting. Specifically, the authors employ a GRU-based encoder-decoder architecture to construct the node-level temporal dynamics on each node and utilize a GCN to capture server-level spatial dynamics on the server. \n\nThe model consists of four major steps. First, each node encodes the local data and sends the extracted temporal vectors to the server. The server then collects all temporal vectors, builds the graph, extracts the spatial vectors, and broadcasts the server-level dynamics. Next, each node combines the node-level temporal dynamics and the server-level spatial dynamics to decode the prediction.  Finally, the backpropagation algorithm is performed. \n\nPros -------------\n\n- It is interesting to extend the concept of federated learning to graph-based spatio-temporal forecasting tasks. \n- The paper is well-written and structured.\n- Split learning seems to be a good idea to reduce communication costs.\n\nCons  -------------\n\n- Privacy concern: This paper introduces some privacy-preserving methods in Related Work, but the corresponding protection methods do not present in the paper. Or the author regards the extracted feature vectors and corresponding gradients are not sensitive. \n\n- Communication costs: Although the model makes several adjustments, the amount of data transmitted in a complete training phase is still very large (200+GB), which places a demanding requirement on the capability of edge devices. In addition, I am curious about where communication costs mainly come from. the vectors and gradients from SplitNN? or the model parameters from FedAvg?\n\n- Experiments:  An important baseline is missing, a model that aggregates all the data and directly combines GRU with GNN to predict the traffic flow without a federated setting (like DCRNN). In my view, this model should be the upper bound of the model performance, just like what the author did in section 4.3-(1). Besides, there is no explanation for the little change in the performance of GRU+FedAvg in section 4.2, what if we use more data like 90% or fewer data like 5%. Besides, the main difference between GRU+FedAvg and CNFGNN is whether to use GNN to capture spatial dependencies.  Is it spatial dependencies as the key reason that achieves better performances in an inductive learning setting?",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}