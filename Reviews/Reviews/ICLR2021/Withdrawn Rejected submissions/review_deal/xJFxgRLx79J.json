{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper received divergent scores (one strong negative and three positives). The positive reviews praise the clear intuition/motivation and strong empirical performance, while the negative review considers the proposed approach ad-hoc with limited novelty. I read the paper myself and found myself leaning more towards the negative score. In more details: \n\nI think the paper proposed a cleverly-engineered solution to employ two separate RNNs to model two different subsets of the users (active v.s. inactive). To combat overfitting, the authors proposed some tricks: 1) use MF to learn a better initialization and 2) tie some of the parameters together. The ablation study shows that both are quite useful, and not too surprisingly when you have two powerful RNNs and work hard to make sure they don't overfit, they perform better than a single RNN. As I mentioned earlier, this whole approach is quite cleverly-engineered and executed. But it's not clear to me if this is something that the ICLR community can benefit from (maybe except a relatively small proportion). I believe this paper can find a bigger audience in venues like KDD whose deadline is coming up. \n\nFurthermore, the authors presented some theoretical analysis to justify their intuition, which to me feels a bit forced. To start, a big assumption is that the optimal user embeddings are very concentrated, which is a rather strong assumption and I hardly believe it will hold in practice (what can even be considered as \"concentrated\" in high-dimensional space?). Following that, the theorem implies that the initial embedding for the inactive users should be the expected optimal embedding, but then later in the paper this point seemingly got completely ignored and instead the authors just proposed to learn a common initialization. Additionally, the theorem suggests that there is an optimal threshold, but later in the paper again this point got completely ignored. I know the theory makes assumptions and builds on simple cases. But my point is that you don't need theorem to show me that two RNNs can perform better than one when trained properly (which, I admit, is non-trivial and is the main contribution of the paper). There has been a lot of discussion around the ML community about the trend of making your paper look \"mathy\" and I don't think this is a good thing. \n\nMinor comment: in MF, the objective wrt each embedding is convex, but the whole optimization is not jointly convex and it is not likely that you can get to the global optimum. It is relatively insensitive to initialization though (comparing with neural nets). "
    },
    "Reviews": [
        {
            "title": "A reasonable work.",
            "review": "Given sequential interactions between users and items, the goal is to predict the next interactions of users.\n\nChallenges\n- For active users, common models such as RNNs have limitations when dealing with long-range sequences due to the difficulty in gradient propagation.\n- For inactive users (or new users), there exists the cold-start problem.\n\nMain idea\n- They partition the users into two sets: active and inactive users. Active users have many observed interactions; Inactive users have very few or zero observed interactions.\n- They pre-train user and item embedding vectors via the matrix factorization.\n- Two independent RNNs are trained for the active and the inactive users, respectively.\n- When training the RNNs, user and item embedding vectors are fixed.\n- For all the inactive users, a common embedding initialization is shared.\n\nStrengths\n- They tried to explain the intuition of the proposed model in detail.\n- The proposed method outperforms some previous methods on real-world datasets.\n- The ablation study shows the effectiveness of the proposed training algorithm.\n\nWeaknesses\n- The idea is very incremental compared to previous methods.\n- There is no theoretical analysis of the proposed method.\n- The presentation of the figures is not good (Colors in Figures 2 and 3).\n\nSummary\n- They suggested the need to separate learning for active and inactive users. The intuition behind the method makes sense, and it has been shown through experiments that it performs well.\n- Authors will be able to increase their contribution through thorough theoretical analysis or developed ideas.\n- Authors also need to improve the presentation of the paper.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting Approach towards solving for real-world challenges in RecSys",
            "review": "Authors propose an interesting application of Recurrent Neural Networks to build a sequential recommender system with a different model for active and inactive users. \n\nIn a real-world recommender system, handling cold-start users separately is a big challenge, and this paper proposes an interesting approach to solve that. \n\nAuthors propose a two-staged method, wherein the first stage, the aggregated user-item interaction matrix is factorized to generate initial transductive embeddings for users and items. These are later re-used in the second stage and for active users, their embeddings are fixed. \n\nSome strong points of the paper:\n\n1) A modular approach is taken to handle active users and inactive users separately. This would be helpful in designing real-world recommender systems, where the cold start problem is critical. \n\n2) The paper is generally well-written with an adequate description of the method and any equation.  \n\n3) The solution is well-motivated with proper justification in Section 3 and in the introduction. \n\n4) Performs well against strong recent methods like JODIE (Kumar et al) and GNNs. \n\nSome questions to authors:\n\n1) How are cold-start items handled in the method? I assume cold-start items is an equally critical problem faced in designing a RecSys system.\n\n2) Why are item embeddings kept constant in the second stage? For frequent items, learning/updating embeddings during RNN training would enhance their quality. ",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting idea, unclear if effective",
            "review": "The main idea in this work is to separately model users with a lot of activity in the systems and users with little activity and data. \nTo this end, two RNN's are trained on the items that the users have interacted with one for active users and one for less active users. User and item embeddings are generated with a matrix factorization process and these are used as input to the RNN's and to initialize its hidden state. For inactive users, a common initialization is used. \n\nWhile this is an interesting idea it is somewhat unclear what the real benefits of this method are. The split between active and inactive users is rather unclear, how many interactions are then left in the inactive users split? \nThe experimental results are also somewhat unclear. it seems that the last interacted item is concatenated to the user profile and item attributes are also concatenated to the item representations learned by matrix factorization. Are there additional data sources included in the other baselines as input somehow? It is also unclear if the improved results are due to inactive or active users. \n\nI also think that it would be interesting if the two models would be linked somehow explicitly rather than 'just' from the joint factorization. Overall an interesting idea but the experimental results I think are not convincing and the split modeling could be justified quantitavly. \n\nminor: In table 1 last column the second-best performing method is GRU4Rec.\n              Figure 2, is not very informative for large timeframes as most methods converge in a few hours (or minutes) on this data\n \n\nAfter reading rebuttal, I think the paper is somewhat improved hence I increase the score. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "The paper considers the sequential recommendation problem. The proposed method essentially combines the following two ideas: (i) two-stage learning: using conventional CF to pretrain user/item embeddings, and feed them (fixed, unlearned) into the 2nd stage learning. (ii) two-time-scale: using 2 RNNs to model active users and inactive users respectively.\n\nAlthough the model design makes sense, it seems too ad-hoc and not novel. For example, the idea (i) actually learn the model with pretrained embeddings, which achieves faster training speed. But this has been widely adopted in various domains. The comparing baselines certainly could easily adapt to use the same pretrained embeddings for faster speed. The claimed advantages are not convincing given important related work/baselines are missing. Specifically I have the following concerns:\n\n- Encoding long-range sequence: the proposed method doesn't model long sequences, while seeks to capture user history with a simple MF. This idea: (i) ignores sequential patterns in user previous history; (ii) has been widely adopted in the literature[1][2], especially before we have powerful deep sequential models.\n\n- Computational efficiency: (i) the efficiency advantage mostly comes from the use of pretrained embeddings, which can be adopted by almost all the baselines for acceleration. (ii) Another trick used is to cut off the sequence (only train the last 10/20 user actions). Such an acceleration, again, could be adopted by other methods.\n\n- Baselines: The paper claims SOTA performance on sequential recommendation, but baselines like SASRec(2018), BERT4Rec(2019) are missing. SASRec performed better than GRU4Rec and also showed much faster training speed. The GRU4REC is almost the 2nd best method among all the baselines used in the paper, and it's from 2015.\n\n- table 1 may have some typo. The recall of 2TS on lastfm-1K is worse than GRU4Rec, but the improvement shows 2.2%.\n\nThe proposed mode design, though, makes sense, but lacks novelty as it's a combination of various commonly used tricks. The improved training speed comes from pretrained emb and sequence cut-off, which are not a novel contribution for efficient sequential/recommendation model training. Several strong baselines are missing, which further weaken the paper.\n\n========================brief update after author response==============================\nI decided to maintain my rating due to several key claims in the response are unverified. For example, in Q1 \"We propose that NOT ALL users (but only active users) should use transductive embeddings to memorize their history, which is different from existing methods that treat all users in the same way.\", however, comparison against them is missing, especially for methods like [1] and [3] that uses both inductive and sequential embeddings; in Q2 \"Trivially cutting off the sequence could result in worse accuracy\", however, this is not verified: not clear what's the effect of cutting off on baseline models. I believe these are the core research questions that need to be verified in the paper, which are unfortunately missing.\n\n[1]Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation, ICDM'16\n\n[2]Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding, WSDM'18\n\n[3] Next Item Recommendation with Self-Attention",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}