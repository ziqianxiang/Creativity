{
    "Decision": "",
    "Reviews": [
        {
            "title": "the motivation seems unjustified and results need more work",
            "review": "This paper proposes a new architecture for CNNs that is more robust against adversarial attacks. The main argument of the paper seems to be about the low-dimensionality of the existing CNN representational spaces that lead to loss of low-level details at the classification level. This paper is an attempt to resolve this hypothetical issue. \n\nOverall, my main concerns were regarding 1. the correctness of the claimed relationship between representational dimensionality and adversarial robustness and 2. the effectiveness of the proposed method considering the presented results. \n\n* The authors motivate their work by claiming that the existence of adversarial examples is partly due to the low-dimensional representation in CNNs and that this is in contrast to the representations in the brain. This claim which seems central to the argument underlying the proposed architecture is very unintuitive to me since all CNNs retain the information about the features in their feature maps. Architectures with skip connections like ResNet and DenseNet additionally propagate the early feature maps to later layers too. However all of these networks still suffer from the adversarial examples. In addition, as far as I know the object representation in the primate brain has low-dimensionality [1] which is even smaller than those found in the higher levels of CNNs. \nRelated to this point, some statements in the paper like: page1, par2, sentence3 and figure-1 caption seem unjustified to me because they tie the lack of explicit low-level information to adversarial robustness. \nThe results in Fig3 are presented as evidence of “causal” role of the binding dimension on robustness but despite this these results don’t seem to portray in clear picture of such relationship. With increasing \\gamma parameter the L-inf distance seem to initially improve but remains unchanged for most of the range and then finally decreased. The possible explanations for the reduction with high \\gamma don’t seem logical to me. \n\n* Based on the results presented in Table-2 the proposed HBCNN architecture seems to be effective at improving adversarial robustness on MNIST dataset compared to the original CNN. One of the concerns with this comparison is the indirect effect that the proposed architectural change has on the size of the network. The authors have provided additional experiments in the appendix that aims to rule out this effect as the main driver of this effect however there is no description of how the network sizes were matched in this experiment. In addition, unlike the MNIST results, the improvement on Fashion-MNIST and Cifar10 results seem to be less evident as the improvements are mostly small or non-existent. This raises some concerns on the applicability of the proposed architecture on more meaningful datasets like Cifar10. It would also be helpful to see the results of network size matching for these experiments. Also I feel that fashion-MNIST and Cifar10 results should be part of the main manuscript instead of being pushed back to the appendix. \n\nOther comments: \n* what implementation was used for adversarial training? please include more details about the attack used during training \n* the specifications of each of the attacks are missing (e.g. number of iterations for deepfool)\n* PGD attacks are visibly missing from the reported results. \n* It would be interesting to see whether combining the proposed architecture with adversarial training would lead to an additive effect in robustness or not. \n* authors point to table-1 for results showing \"the new model is no more resistant to typical attacks\" but table-1 does not contain this result\n* Confidence intervals should be shown on results in all tables specially for the results with very close values across architectures\n* figure captions look like they are part of the text — they should be reformatted \n \n[1] Lehky, S. R., Kiani, R., Esteky, H., & Tanaka, K. (2014). Dimensionality of object representations in monkey inferotemporal cortex. Neural computation, 26(10), 2135-2162.\n\n**************************\nUpdate after the rebuttal: \n\nI thank the authors for providing a response to my comments. The authors' responses did not convince me on the arguments about the relationship between dimensionality and adversarial robustness. I still find the Cifar10 results unimpressive and several of my other comments still remain unanswered. Overall, my opinion about the paper has not significantly changed after the rebuttal and I keep my previous score. \n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "interesting architecture for feature binding, but lacking clarity in the results",
            "review": "This paper presents a neuroscience inspired architecture that incorporates hierarchical binding as a way to bind the low-level and high-level features of an input representation. The authors hypothesize that this binding will help constrain the network to have fewer off-manifold adversarial examples, and demonstrate that this is the case when the architecture is combined with label smoothing and noisy training data.  \n\nMy main concern about the paper is in the clarity of the presented results. The idea behind a hierarchical binding model is compelling, however it is difficult to separate out the contribution of  this model for adversarial robustness from the (less novel) label smoothing and added noise.\n\nPositives: \t\t\t\n* The geometric intuition behind the defense (particularly as laid out in Figure 1) is very interesting. \n* The neuroscience inspired unpooling-based hierarchical binding architecture is novel as a way to incorporate representations from multiple spatial scales. \n* The paper presents a thorough analysis of many different adversarial attacks to compare the different presented methods\n* The authors provide discussion and analysis of how gradient obfuscation is likely not the reason for the robustness that they observed.  \t\n\t\nConcerns and Questions: \n* The results are difficult to interpret, specifically separating out the effect of the hierarchical binding from the label-smoothing results (where the label smoothing results are not a novel contribution). It appears that Table 1 only includes results on the boundary attack -- the text says that the model is not more resistant to typical attacks such as transfer attacks but quantification of these results appears to be missing from the paper. Further, all of the models (except the AT model) in Table 2 seem to include label smoothing. \n* Similar to the above, the paper does not present results for an HBCNN+N (or control CNN+N) model, so it is not possible to separate out the effect of adding noise alone from the additive effect of smoothing plus noise. Especially given that label smoothing produced inconsistent results across the different attacks, is label smoothing helping more than just including noisy training data? \n* Given the importance of label smoothing to the main results, the paper would be more clear by introducing the concept in the introduction or related work (rather than just introducing in the experiment section)\n* How does the robustness due to hierarchical binding compare with other ways of preserving low-level information (ie ResNet or I-RevNet, as mentioned in the paper)? The authors claim that their result is novel in that it “captures which low-level neurons causally drove high-level representations”, but it is unclear whether it is this causality, or simply a preservation of multiple spatial scales, that is driving the observed robustness.  \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Not convinced that evaluation of adversarial robustness can be trusted; results beyond MNIST are underwhelming",
            "review": "UPDATE AFTER REBUTTAL\n\nI have read the authors response. However, the results remain underwhelming and the lack of a demonstration on a larger dataset is a crucial issue in my opinion. Therefore I stand by my assessment.\n\n\nORIGINAL REVIEW\n\nThe paper proposes a method of achieving adversarial robustness by focussing on the mechanism that combines features from different spatial locations (feature binding). The authors argue that invariant feature representations causes class manifolds to become overly simple, neglecting details. According to the authors, this leads to tight (close to object manifold) decision boundaries, which have arbitrary shape outside the class manifold. Hence, by manipulating details which are not captured by class manifolds the decision boundary can easily be crossed, i.e an adversarial sample is found. To prevent this, the authors suggest the novel hierarchical binding (HB-CNN) architecture. Instead of propagating max-pooled activations only, subsequent layers are additionally given the spatial positions the max-pooled activation originated from.\n\n\nStrengths:\n+ Evaluation of a large number of attacks using L_0, L_2 and L_inf distances\n+ Investigation of three datasets: MNIST, Fashion-MNIST and CIFAR-10\n+ Significantly more efficient method for adversarial robustness than competitors\n\n\nWeaknesses:\n- Evaluation of robustness seems to suffer from severe optimization issues\n- Results on Fashion-MNIST and CIFAR-10 are underwhelming compared to MNIST\n- Relation to feature binding in the brain is unclear\n- Some crucial details about model architecture are missing\n\n\nDetails on major issues (all of which would need to be addressed in a convincing manner for my score to change):\n\n(1) Evaluation of robustness seems to suffer from severe optimization issues\n\nThe median of half the L2 distance to the closest sample of a different class on MNIST is ~2.9. The authors claim a median L2 distance of successful adversaries of 3.4 for their method, which is implausible: simply finding the closest sample from a different class and linearly interpolating would make for a stronger attack. \n\nThe authors may need to run many more iterations (25–1000x) for the boundary attack, tune the step size or run multiple random initializations when attacking. In addition, more recent strong attacks like DDN attack, AutoAttack, BrendelBethge attack are missing from the evaluation. These issues cast serious doubt on the effectiveness of the method and would have to be resolved before the paper can be published.\n\n\n(2) Results on Fashion-MNIST and CIFAR-10 are underwhelming compared to MNIST\n\nThese results should not be hidden in the appendix. On these datasets, the method underperforms by quite a margin. It could be argued that the method is more efficient, but if it's not effective, I am not sure what's the value of efficiency. As it stands, I am not convinced of the value of the method.\n\nResults on ImageNet (or a smaller subset of it) could make the paper more convincing, in particular as the network is simple and computational efficiency is claimed in the conclusion.\n\n\n(3) Relation to feature binding in the brain is unclear\n\nI could not follow the reasoning what this approach has to do with feature binding -- and I think the paper does not need this story. You might as well explain what the method is doing without the reference to neuroscience, which is weak at best.\n\n\n(4) Some crucial details about model architecture are missing\n\nI think the model description of HB-CNN (Sec. 3) could be improved. While the local mechanism is well explained, I am missing a more detailed description of how this local block integrated in the network. \n\nFor the VGG-based architecture used for CIFAR-10 the integration of hierarchical binding is unclear. Is it applied at multiple layers? If yes, how are the differently shaped outputs integrated?\n\n\nMinor comments\n\n- I suggest to move Fig. 6 from appendix to main paper, because it helps understanding how the local block presented in Fig. 2 is integrated into LeNet-5.\n\n- As far as I can tell, HB specifically addresses pooling and striding. This should be clearly stated in the abstract and introduction.\n\n- The well-known SegNet architecture relies on unpooling but is missing from literature discussion (Badrinarayanan et al.: \"Segnet: A deep convolutional encoder-decoder architecture for image segmentation.\").\n\n- The only state-of-the-art baseline presented in the tables is CNN+AT, i.e. Madry et al. (2018). Performance in relation to Schott et al. (2019) is discussed in the text but not considered a fair comparison. The line of reasoning here is not clear to me. Why are the numbers not comparable?\n\n- Wouldn't it be sufficient to indicate the unpooled position only and ignore its value, which is the output of max-pool anyway. This means, in Fig. 2a, the output of unpool could be [[1,0],[0,0]] instead of [[8,0],[0,0]] without loss of information. The sample should apply for gradient unpool, since the convolutional filter is known.",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting and simple architectural change, but it seems to have rather marginal effects and the experiments should be more extensive.",
            "review": "Summary \nThe paper introduces \"hierarchical binding\" an extension of CNN architectures that uses feature unpooling to keep track of which low-level features drive the activation of high-level features. The experimental results demonstrate that this simple architectural extension leads to a slightly increased robustness w.r.t. a variety of adversarial attacks, for a limited range of architectures and on simple datasets. \n\nPros \n+ The proposed approach is simple yet seems effective\n+ The paper is well written and presents the proposed approach clearly\n+ The experiments involve a range of different types of attacks\n\nCriticism\n- The proposed is simple and does not involve any theoretical contributions (the methods section comprises one short paragraph). While this is not necessarily negative, it requires the experiments to be a very extensive empirical study in order to generate a strong enough contribution. However, the experiments in the paper only involve a LeNet architecture tested on MNIST. This is a significant limitation. More experiments are presented in the appendix, however, these also only involve simple datasets (FMNIST,CIFAR) and outdated architectures (VGG). To make a convincing argument about the general \napplicability of the proposed approach it is necessary to show that it also generalizes to modern architectures and complex datasets with higher resolution images. \n- The increase in the robustness of the proposed architecture is rather low. The final model is still very vulnerable to adversarial attacks compared to a standard CNN (CNN+S+N).\n\n--------------------------------------------------------------------------------------------------------------------------------------------------------------\nPost rebuttal:\n\nThank you for your brief answer to some of my comments. My major concern remains that the experimental evaluation is limited and should be much more extensive because the theoretical contribution is limited. I think the paper is not ready for publication yet. Therefore, I keep my initial rating.\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}