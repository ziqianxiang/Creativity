{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "This paper provides a unified view of some known methods for monotone operator inclusion problems like Forward-Backward-Forward (FBF) and OGDA, and provides new convergence results for the stochastic version of a variant of FBF called FBFp. All reviewers initially recommended rejection. The rebuttal and the manuscript update addressed several concerns from the reviewers, though the general consensus after rebuttal was still that the paper lacked in significance for the ICLR community. The AC thinks that the paper could make an interesting overview paper in a more optimization / theoretically minded venue."
    },
    "Reviews": [
        {
            "title": "Many unclear or doubting points",
            "review": "In this paper,\nthe authors first formulate the optimization problem of GANs as an abstract minimax problem (Equation(1)).\nAs compared to the original optimization objective of Goodfellow's GANs,\nthere is an additional term $h(y)$.\nWhy do you introduce $h(y)$ here? Just for facilitating the adoption of the MONOTONE INCLUSIONS on it?\nThe authors should provide a clear explanation about this point.\n\nLater the author restrict Equation(1) to a deterministic version,\nwhich means that the noise input of GANs will no longer be considered.\nThe noise input is an important ingredient of GANs.\nDespite many new variants of the GANs,\nat least, the noise input is import for the Goodfellow's GANs, which is adopted in this submission as a staring point.\nIt is very hard for me to decide whether this simplification is appropriate.\nExcept Algorithm 3.2 and Theorem 3.2 which suddenly provide stochastic versions,\nall the following results are on this deterministic version.\nIn my opinion, the authors should provide more explanations on this point.\n\nI cannot understand the first sentence of Section 2.2, after read it many times.\nWhat is the exact necessary and sufficient optimality condition for the coupling function being convex-concave and differentiable?\nBefore Equation (2), the authors didn't explain what is monotone and what is monotone inclusion.\nI don't think these concepts are very famous in machine learning community.\n\nIn Section 2.3,\nthe authors provided the introduction of lots of iterative methods.\nIt is difficult for me to distinguish which are completely new findings for solving their inclusion problem and which are the existing results.\nThe authors completed a literature review here.\n\nIn Section 2.4,\nI don't know why the problem (1) can be written as Equation (8).\nCould you provide more explanations about this point?\nLimited space of one submission should be on important points.\n\nIn Section 3,\ncould you explain more about why $G_B(w)$ in Equation (10) is defined as this form?\nJust for facilitating the proof of Theorem 3.1 and Theorem 3.2?\n\nIn Section 3.2,\nthe authors provided a generalized FBF algorithm.\nIsn't this Algorithm 3.1 a combined re-written version of Equation (4) and Equation (5)?\n\nThere is a big gap between Equation (9), Theorem 3.1 and Theorem 3.2 and the experimental results shown in Section 4.\nBesides, there are no open source codes provided.\nIt is very hard for me to figure out the details of the experiments and meantime to check the reproducibility of this paper.\n\nAlthough, the authors stated that \"Due to the theoretical nature of this work, the aim of this section is not to achieve new state-of-the-art\nresults.\"\nI don't think optimization is a theoretical branch of our machine learning community.\nIf a proposed optimization method cannot be proved to be very useful in certain ares or specific tasks,\nit will be very doubting.\nIf we intend to do theoretical contributions,\nwe should try to prove the theoretical properties or convergence bounds for the existing useful optimization methods.\n\nSince ICLR is a highly selective conference,\nthe originality and significance of one submission will always be in the first priority.\nI cannot accept this paper in current state.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Contributions seem incremental",
            "review": "Summary: This work studies minimax optimization (a.k.a saddle-point problems) with nonsmooth regularizers. By leveraging the monotone operator theory, the authors propose to use the forward-backward-forward method so as to avoids the notorious limit cycling problem. The classical FBF method requires two gradient evaluations per step, the authors introduce a new algorithm which reuses the past gradient in the same way as OGDA. In the setting of convex-concave minimax optimization, the authors claim to prove novel convergence rates for both methods. \n\nReview: This paper is well-written, though I think the difference with extra-gradient can be made much clearer. For example, the authors could compare FBF with EG for a toy example like Eqn. (13). As far as I can tell, the main difference with extra-gradient is just the regularization term. From this standpoint, the authors should clarify the motivations and importance of adding regularizers. In the current version of the paper, section 2.4 is vague and doesn't explain the role of regularizers well in GAN training.\nBesides, a similar convergence analysis has been done for EG and OGDA (the authors don't even cite properly), so I believe the convergence analysis of this paper is not novel. Given these reasons, I suggest the rejection of this paper and give a score of 4.\n\nComments:\n- It was shown in [1] that the ergodic (averaged) iterates of extra-gradient converge with a rate of O(1/k) which is the same as FBF. Could the authors clarify the novelty/difference of your proof technique for FBF?\n\n- It was shown in [2] that extra-gradient is NOT robust to gradient noise in convex-concave minimax optimization. Could the authors comment on that and explain why FBF could achieve the rate of O(1/sqrt(k)) in the stochastic setting (while EG fails)?\n\n- In GAN training, we typically care more about the last iterate since averaging could actually hurt the performance when the loss surface is highly nonconvex. Is it possible to derive the last iterate convergence rate? \n\n\nI'm willing to increase my rating if the authors could resolve some of my concerns, especially my concern on the novelty of the analysis.\n\n\n-------------\n**I've read the authors' response. I'm still concerned with the novelty of the paper given there are similar results for EG/OGDA. Therefore, I stick to my original rating.**\n\nReferences:\n\n[1] Convergence Rate of O(1/k) for Optimistic Gradient and Extra-gradient Methods in Smooth Convex-Concave Saddle Point Problems, 2019.\n\n[2] Explore Aggressively, Update Conservatively: Stochastic Extragradient Methods with Variable Stepsize Scaling, 2020.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Report on \"Two steps at a time --- taking GAN training in stride with Tseng's method\" ",
            "review": "Summary: This paper introduces the forward-backward-forward splitting for variational inequalities. The main results are an asymptotic convergence results and a non-asymptotic convergence results using a restricted merit function. A new method, FBFp, is introduced and studied. Complete proofs are given. Preliminary numerical results obtained by training GANs are reported. \n\nPros:\n+ complete proofs \n+ A new stochastic operator splitting method based on Tseng's FBF is introduced in which the operator needs to be evaluated once per iteration. This splitting, called FBFp, is indeed new, and has the potentially of being of practical relevance.\n+ Preliminary numerical results on standard GAN architectures. \n\nCons: \n- The paper takes a long time until it becomes clear what actually the monotone inclusion looks like. It seems that the problem of interest is formulation in eq. (9), preceded by a long and unnecessary discussion about existing solvers. It would have been much more accurate to simply start with the problem formulation, then propose your solution method, followed by a critical explanation of the contribution. \n- p.3 claim that FBF has not been rigorously analyzed for saddle point problems. This is of course not true. Even the original paper by Tseng (A MODIFIED FORWARD-BACKWARD SPLITTING METHOD FOR MAXIMAL MONOTONE MAPPINGS, SICON 2000) discusses the application to saddle point problems. See Example 5 in that paper.  \n- The stochastic FBF has been studied in Bot et al. Mini-batch Forward-Backward-Forward Methods for solving Stochastic Variational inequalities, forthcoming in Stochastic Systems. Note that the Arxive version of that paper is available since 2019. Overall, the paper contains only marginal contributions to the state-of-the-art. \n- Only convergence rates for the ergodic average is provided. It is known that the ergodic average might destroy important features of the true solution, such as sparsity. For SFBF we know non-asymptotic convergence rates of the last iterate. This is not mentioned at all. \n- I have some doubts that the restricted merit function is the appropriate one here. Note if the aim is to solve the VI over an unconstrained domain, then FBF coincides with EG, and there is nothing to be analyzed. The interesting case is thus only the constrained case. These constraints are usually encoded in the non-smooth part of of eq. (8), so there is no need to write this explicitly. In my opinion it would therefore be cleaner to assume at the outset that the domain of $F+\\partial r$ is bounded. The gap function used can in fact be traced back to Facchinei & Pang (2003) and is most likely even longer in use than that. \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Unifying Optimistic Gradient Descent Ascent and Forward Backward Forward For Convex-Concave Optimization",
            "review": "The authors in this paper, inspired by the applications of min-max optimization in GANs, study the problem of min-max optimization for convex-concave functions. The main contribution of the paper is proving novel convergence results for Forward-Backward-Forward (FBF) algorithms as well as Optimistic Gradient Descent Ascent (OGDA) based on tools from monotone inclusion problems. Their convergence results cover both deterministic and stochastic settings and the rates of convergence for suitably chosen gap function are non-asymptotic. Finally, they apply their algorithms both on toy problems but also on training GANs on CIFAR-10.\n\nPros:\n1) To the best of my knowledge, the connection between OGDA and monotone inclusion problems is new.\n2) Convergence results are non asymptotic for the specified gap function.\n\nCons:\n1) The connection of this work with GANs is a bit tenuous because, as the authors also acknowledge, training GANs is a non-convex non-concave min-max problem. The authors should try to express why they believe their  unification result informs practical applications.\n2) This lack of connection is reflected in the experimental section as well. Most experiments re-establish that optimism, extragradient updates or regularization are beneficial for min-max optimization, observations that are already widely known. Again, any experimental insight that is particular to this work, would go a long way towards closing this gap.\n3) It is not clear that the connection of OGDA to FBF and monotone inclusion provides any new insights about the convergence properties of either method.  It would be very helpful, if the authors provided any additional intuition why their result could be used to answer open questions related to OGDA or FBF.  For example, last iterate convergence of OGDA is still an open problem even in convex-concave problems.\n4) While the gap function used allows the authors to provide non asymptotic guarantees, the intuition behind this gap function when its value is non-zero is unclear. Does this gap function have any game theoretic interpretation?\n\nFor now, I am assigning a weak reject score mainly because it is unclear to me if there are significant implications of this unification result either in theory or practice. I am willing to increase my score substantially if the authors provide additional details that address my concerns outlined above.    \n\n---------------------------------\nPost-Rebuttal evaluation.\n\nI would like to thank the authors for their detailed answers, especially regarding the interpretation of the gap function.\nBased on their answers, I decided to increase my score to a 6.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}