{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "The paper proposes to model uncertainty by combining quantile\nregression and Chebyshev polynomial approximation. The paper addresses\nthe important problem of uncertainty quantification for black box\nmodels. However, some major concerns remain after the discussion among\nthe reviewers. In particular, there has been some concerns around the\nclarity of the presentation. The proposal lacks a clear use case, e.g.\nwhere satisfying constrained black-box uncertainty problem is a\nmust-have.\n"
    },
    "Reviews": [
        {
            "title": "This paper contains good contributions but is held back by poor presentation.",
            "review": "-------------------\n# Update\n\nAfter reading the updated version of the paper, I think my main issues with presentation have been addressed. I now see this work as introducing a relatively niche problem and solving it elegantly. The text is clear enough for an average ICLR attendee to understand and contains additional background information in the appendix. I have increased my score to a 7.\n\n-------------------\n\n### Summary / Contributions \n\nThis paper adapts quantile regression with NNs to settings in which a summary statistic is fixed (some percentile or moment). This is done by having a NN predict the coefficients of a Chebyshev polynomial which is then integrated to evaluate the predicted cumulative density function over targets. Freedom in the choice of the constant of integration is used to enforce a summary statistic provided by a black box model (BBM).  \n\nThe method is used to provide heteroschedastic noise models for black box regression systems and validated on standard regression benchmarks (UCI).  \n\n### Originality and Significance\n\nTo the best of my knowledge, the novel aspects of this work are:\n\n* The development of a derivative based approach to quartile regression which allows for the output distribution to be conditioned on an input x. This could be used very generally as a heteroscedastic noise model.\n* The extension of the above approach to allow enforcing some summary statistic like distribution mean or percentiles.\n* The introduction of post-hoc noise modelling for black-box decision making systems as a task. \n\n#### Pros:\n* Sound solution to a (to the best of my knowledge) new task: constrained heteroscedastic noise modelling with free-form / implicit distributions.\n* Good empirical performance on benchmark datasets. \n\n#### Cons\n* The paper is not very well written and hard to follow. I had to read it multiple times to understand it well. I felt important details where glossed over or missing in the provided explanations. \n* I would have liked to see the method being evaluated further by using it with a wider variety of black box models and different amounts of training data. \n* Motivation of adding noise models to black box predictors is a bit weak considering no evaluation is performed on real-world scenarios with BB models in deployment.  \n\n### Other Comments:\n\n#### Method: \n\nThis method is completely agnostic to the BBM and, as such, its uncertainty might be in contradiction with the BBM given statistic:\nWhen a noise model is learnt in conjunction with a predictive model (e.g. a NN that predicts mean and st deviation values for each input) , aleatoric uncertainty usually reflects what the model can’t predict. In the limited data regime, this is often a crude approximation to the inherent uncertainty in the generative process of the data. A not very flexible (e.g. linear) model will see non-linearity in the function being learnt as noise in the data. When using a very flexible model (e.g. NN) might be able to fit all datapoint and not see anything as noise.  As such, I would have liked to see more exhaustive evaluation of the proposed methods in the following settings:\n\n*  It would be interesting to see the effectiveness of this technique on varying sized datasets when the NN used for quantile prediction is very flexible.\n*  What happens when the BBM is not noisy (as in Fig 3.) but instead biased because it is not flexible enough for problem at hand. This his often the case in real world deployments when the model is chosen for interpretability (e.g. decision tree or linear regressor) — I imagine the inability of this approach to consider model specification uncertainty, could cause noise distributions to misbehave when the BBM is very badly specified. \n\n\n#### Experiments\n\nThe provided baseline methods seem relatively weak: just unimodal heteroscedastic noise models. However, I do not know of any existing approaches that impose summary statistic constraints on arbitrarily complex predictive distributions. \n\n#### Presentation\n* The language used is a bit ungrammatical at times. I would recommend going over the paper with a grammar checker. There are some paragraphs that are only 1 sentence and feel a bit disconnected. \n* A brief overview of key preliminaries would be convenient: Relevant properties of Chebyshev polynomials, how the DCT can be used to obtain coefficients, etc\n* Some important concepts are glossed over or referenced to succeeding sections, despite them being necessary to follow the paper well. It is better to reference previous sections than future ones. \n\t* It was not clear to me from the explanation at the end of section 2 why existing quantile regression methods would not be applicable to the constrained black box scenario.\n\t* It was not clear to me from section 3 why the solution to the above problem required using a UMNN style model. \n\t* In Section 4 it is not clear what “Due to the aforementioned truncation in ChePAN” refers to, as above you state both CCN and ChePAN calculate coefficients of truncated expansions. In general, it is not very clear to me how mentioning CCN in section 4 is helpful to the reader. I would recommend just explaining ChePAN in more detail and leaving CCN for the appendix.\n\t* The reference to section 4.1 in the paragraph after equation 3 leaves me wanting an explanation of why we want Chebyshev roots to fit in [0,1] instead of [0, \\tau].\n* What does the bolding in Figure / Table 4 refer to? It seems inconsistent. In table 1 it indicates best methods.\n\n### Summary\nI think this paper contains good contributions but is held back by poor presentation. If this is corrected by the authors, I would be happy to recommend acceptance. ",
            "rating": "7: Good paper, accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Neat approach to black-box uncertainty modeling",
            "review": "This paper proposes a novel approach to modeling uncertainty, as an layer added-on to an otherwise black-box system. The ChePAN uses a neural network to estimate per-quantile roots of a chebyshev polynomial, then uses a quantile regression loss to fit these coefficients using backpropagation. Importantly, the Chebyshev polynomial formulation gives the practitioner some flexibility around deciding which statistic of the conditional CDF should be matched by the black box system. Examples are given for matching the 0 and 1 quantiles, for cases of min and max estimation, as well as matching either of median or mean.\n\nThe authors make a case for why previous/related approaches to black box uncertainty modeling have deficiencies e.g. the roots considered by the Clenshaw-Curtis quadrature extension of UMNN (CCN) are bounded by the quantile being considered, which is somehow limiting, though I was a little hazy on why. \nI would be curious whether the authors have considered splines as another alternative, at least for modeling black boxes known to be in a bounded, e.g. 0-1, range. https://arxiv.org/abs/1906.04032 is perhaps relevant there.\n\nThe idea is quite a neat one. One uses a neural network to emit positive-valued roots of a Chebyshev polynomial, which are optimal function approximators on the 0-1 interval, perfect for a flexible CDF inversion, thus an extremely flexible distribution estimator. This is what enables setting a statistic of choice equal to the output of the black-box system. The actual implementation does not seem overly complex, which should make it widely accessible to practitioners. The idea of combining quantile regression with deep networks for fitting conditional distributions is not new, as the authors acknowledge, but this work provides a mechanism for matching a statistic to that distribution, while also being able to fit that distribution using a QR loss.\n\nThe experiments use datasets comparable to prior/related work. However, tables and plots don't seem to include for comparison reference points like Brando, 2019's UMAL which appears to provide a nicely calibrated estimator for the AirBnB datasets. For example, I would prefer to see the calibration plot on the AirBnB datasets in Fig 4 left side, for comparison with this earlier work. Since the baselines are all internally sourced it's hard to tell if this paper is achieving state of the art calibration, or only providing a novel approach to doing so. On the topic of baselines not particularly comparable to prior work: the \"N\" and \"LP\" baselines, which in prior work often use neural networks for both the mean and the scales, in this work use RF/XGBOOST for the mean. It would be good to understand whether using a NN for the mean estimator yields changed calibration metrics (thus changing the baseline competitiveness).\n\nOn the whole, I think this is an exciting new contribution and would recommend accepting, but I think the paper would benefit from clearer evidence that the approach provides a value-add relative to existing techniques. If I'm meant to understand that \"N\" and \"LP\" baselines are that evidence, I must have misunderstood, because to me those look like custom baselines built for this work.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A novel method for an important problem",
            "review": "This paper presents an approach to model aleatoric uncertainty for the black-box model, through the combination of Chebyshev polynomial approximation and quantile loss. The method seems novel to the prior work and achieves good results in capturing uncertainty in predictive modeling. My detailed comments are as follows:\n\nStrength:\n1. By constraint the neural network model for the derivative function $\\phi(\\tau, x)$ to be strictly positive, this method solves the quantile crossing issue which is a common problem in simultaneous quantile regression.\n2. This method does not assume any prior knowledge of the model structure, which means one doesn't need to modify the parameters of the original model, and therefore separates the constraint from the model training procedure.\n\nWeakness:\nFrom section 4 and Appendix it looks like the way to compute each coefficient is in a sequential manner, which may not be efficient enough.\n\nAdditional Questions:\n1. If ChePAN is a separate module of the black-box model, is this similar to a post-processing method for pre-trained models to generate user-specified uncertainty intervals?\n2. Following the previous question, if that is the case, does that mean we need to train the black-box model to produce $\\phi(\\tau, x)$ for later use? Or add an additional neural network called uncertainty wrapper for that?\n3. It looks like CCN is not discussed in the experiment section.\n\nUPDATE after author response:\nEstimating arbitrary quantiles to approximate the predictive distribution of a black-box model is a novel problem to look into. In response, the authors have attempted to address my major concern and they are mostly clear. I would suggest the authors add more discussion on the motivation of the problem settings, e.g., whether it arises from an actual business problem, why satisfying constrained black-box uncertainty problem is a must-have, etc.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Easily readable, but with unclear motivation and utility",
            "review": "This paper considers the problem of uncertainty estimation and it proposes to compute quantiles of a black-box predictor using Chebyshev-interpolated quantile regression, where the interpolation parameters are computed with the aid of a neural network. \n\nThe paper is generally well-written, though I am leaning toward rejecting the paper because the ideas are poorly motivated and the text does a poor job of convincing readers there is an open problem being addressed here that prior work has not already done. I've provided a few comments and questions below to support my position. \n\nThe paper’s clarity could be improved by explicitly describing the research question it considers and motivating its solution choices by connecting them to the research question and related work. Can the authors make these details clear: what is the research question you consider and what contributions does this paper offer?\n\nCurrently, it is not clear where this paper sits in relation to prior work. It was mentioned that two starkly different methods -- Dabney et al 2018a and Tagasovska & Lopez-Pax 2018 -- are related to the considered problem but also not applicable, because “the predicted quantiles need to be linked to the black-box prediction in some way.” It seems like such a connection can be established by creating a dataset where the predictions are the targets. Can the authors elaborate on their stance here?\n\nCan the authors please clarify their use of the term “aleatoric uncertainty”? Typically, aleatoric uncertainty describes the inherent variability of a stochastic signal. In contrast, the epistemic uncertainty corresponds to the variability in a stochastic signal’s estimate. This latter type of uncertainty is something that shrinks as more data is collected. The proposed method seems to estimate the uncertainty of a predictor, which would mean it is estimating the epistemic uncertainty of the estimator. However, the paper refers to this as aleatoric. What is the distinction used here?  \n\nThe proposed approach has questionable utility, because estimating the uncertainty of a prediction is arguably a job for Bayesian methods. The current paper makes very little mention of this and takes for granted that a point estimator is provided, but that one wishes to have uncertainty estimates of the predictions. How does the proposed approach compare to simply computing / estimating a posterior over the prediction? The true posterior will of course be difficult to compute in many domains, but the related work and experimental design should acknowledge the existence of alternatives here: e.g. Bayesian neural nets, variatoinal inference. Can the authors describe when it would be more appropriate to use the proposed method over a Bayesian approach?\n\nCan the authors please justify their use of the UMNN architecture and describe why a simpler alternative, such as standard quantile regression or interpolated quantile regression suffice? \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Confusing",
            "review": "## Summary / Weaknesses\n\nI have to confess that I found the paper to be extremely confusing. It is clear that the submission is still several edits away from a version that can be published.\n\nAs far as I can see, the paper lacks a clear, formal description of the problem, and as a result, it is difficult to see precisely where the existing methods fall short (or even which ones are relevant), and how the proposed procedure addresses these shortcomings. Again, as far as I can see, there is little to no theoretical justification for the proposed method in the paper; the proposed method appears to be a heuristic based on approximations that may be reasonable, but requires some justification.\n\n---\n## Recommendation\nI recommend a reject.\n\n---\n## Questions\nPlease give a formal description of the problem the proposed method is trying to address. Also, please give brief but clear descriptions of the existing approaches and their shortcomings.\n\nI am particularly baffled by the sentence \"[the QR models] cannot be be applied to the constrained black-box scenario given that they does (sic) not link their predicted quantiles with a pointwise forecasting system in a constrained way.\" The way I interpret this sentence is that the existing methods do not model the quantiles (or some other functional) of the _output_ of some pointwise forecasting system, but rather they model functionals of Y | X. If this is the correct interpretation, then I do not see why it would be of interest to model the predictions of a black-box forecasting system rather than Y | X.\n\nI am also confused by the experimental setup. Why do N and LP make sense as comparison methods?\n\nAlso, there are several instances of errors of grammar / syntax.\n\n---\n## Disclaimer\nI did not have the time to look at the supplement.\n\n---\n## Update\nI thank the authors for responding to my questions and revising the paper.\n\nAs indicated in the first sentence of my review, the submission's biggest flaw is in poor presentation. I have read the revised version, but I am afraid to say that I remain disappointed. Although I can see that the authors have tried to address some of the common concerns, the changes do not go far enough. Given that the current version is a version in which \"all [...] comments and suggestions have been taken into account,\" I do not see a reason to give the authors a benefit of the doubt, and have decided to keep my score as is. However, because my evaluation appears to be quite different from those of the other reviewers, I think it may be possible that they are seeing something in this paper that I am incapable of. Since I cannot profess to have a complete understanding of the content, I have decided to downgrade my confidence score.\n\nI will give two examples of ambiguous / confusing language. They are both from Section 2 after the paragraph heading **Definition of constrained black-box uncertainty modeling**.\n\n1. (The last sentence of the 1st paragraph) \"Given this context, the pointwise forecasting system mentioned above is a function $\\beta:\\mathbb{R}^D \\to \\mathbb{R}$, which tries to approximate a certain conditional summary statistic (a percentile or moment) or $p(y | x)$.\n\n- My understanding of this sentence is that $\\beta$ is a _statistic_ (i.e., a function of $\\mathcal{D} = (\\mathbf{x}_i,y_i)_{i=1}^{n}$) such that $\\beta \\approx \\beta^*$, where $\\beta^*$ is some functional of interest of the conditional distribution $p(y | \\mathbf{x})$. For example, $\\beta^*$ could be the conditional mean $\\beta^*(\\mathbf{x}) = \\mathbb{E}[Y | X = \\mathbf{x}]$, in which case $\\beta$ is usually obtained by minimizing the MSE, or $\\beta^*$ may be the conditional $\\alpha$-quantile, in which case $\\beta$ is some data approximation of the conditional $\\alpha$-quantile.\n- Now, compare the above sentence to the following sentence from the author response: \"For instance, $\\beta(\\mathbf{x})$ can be the conditional mean of $p(y | \\mathbf{x})$.\"\n\nMy point here is that throughout the paper, $\\beta$ is used to refer to both a functional of the conditional distribution or a data-based approximation for the said functional. I find the lack of distinction puzzling, if not downright confusing.\n\n2. (The 5th paragraph. I think this is supposed to address my objection about the lack of a precise problem statement.) \"The overall goal of the present article is, taking a pre-defined black box $\\beta(x)$ that estimates a certain conditional summary statistic of $p(y | \\mathbf{x})$, to model $q(y | \\mathbf{x})$ under the constraint that if we calculate the summary statistic of this predicted conditional distribution, it will correspond to $\\beta(\\mathbf{x})$.\"\n\n- What is $q(y | \\mathbf{x})$, and what is its precise relationship to $p(y | \\mathbf{x})$? The first occurrence of $q(y | \\mathbf{x})$ is followed by the description that it is \"a conditional density model,\" but this can mean many things. Judging from the remainder of the article, $q(y | \\mathbf{x})$ is either a model defined through a location-scale family or a model defined via a specification of quantiles. The proposed method is exclusively concerned with the latter kind of models. If this is the case, it would help the reader to have this said explicitly when the symbol $q$ is first introduced.\n- The usage of the term \"statistic\" does not appear to be standard. A _statistic_ is a function of the data $\\mathcal{D}$, and is therefore a random quantity. A percentile or a moment of $p(y | \\mathbf{x})$, on the other hand, is a functional of the conditional distribution $p(y | \\mathbf{x})$, and would be non-random.\n- Even ignoring the previous points, the sentence made little sense to me. I will say more on this after the following paragraph.\n\nMore on the subject of clarity, notation-wise, I am bothered by the proliferation of $p$'s. Aside from the occurrence in $p(M | \\mathbf{x})$, which is rare and hence not a cause for concern, $p$ is used to represent the conditional density (distribution) $p(y | \\mathbf{x})$, as well as a generic Chebyshev polynomial approximation $p(\\tau,\\mathbf{x};d)$. It is possible that I am failing to see some deeper connection here, but if none exists, I would prefer a more clear system of notations.\n\nReturning to the problem statement, after re-reading the paper several times and with the help of the author response, I have arrived at the following interpretation:\n\nFind an estimate / model $q(y | \\mathbf{x})$ for the conditional density (distribution) $p(y | \\mathbf{x})$ such that $q$ and $p$ have the same $\\beta$. Here, $q$ is given by specifying the quantiles, and is approximated by a Chebyshev polynomial of degree $d$. The usual QR methods are inadequate, because the model they output will not have the same conditional percentile / moment / etc. as $\\beta$.\n\nHowever, in situations in which $\\beta$ is also being approximated, what is the point in constraining the functional at $\\beta$? As pointed out by the authors, if $\\beta$ is inaccurate, then this error is propagated to the quantiles, and the performance is worse. If this is the case, why is it of practical interest to enforce the constraint? Had the authors given a concrete, illustrative example, this question may not have arisen. However, absent a practical motivation, it is hard to understand why the constraint needs to be enforced at all.\n\nIn any case, suffice it to say that I am still experiencing significant difficulty pinning down the exact goal of the paper.\n\nAt the time of writing my initial review, I had hoped that the issues with clarity would be fixed in the revision, leaving me free to evaluate the paper based on the merits of the proposal. However, this has not been the case. Now that I am more familiar with the paper, I realize that the biggest issue about the clarity has much to do with the organization, ambiguous language, etc. Some of it has been addressed in the revision, but the effort did not go far enough. \n\nEven leaving aside any reservation I have about clarity from the point of view of methodology and/or theory, I have to say that I am deeply dissatisfied about the lack of practical motivation. I believe the authors intended the paragraph after Section 2 to be a response to concerns about poor motivation (which have been raised by other reviewers, not I): \"The present article was motivated by a real-world need that appears in a pointwise regression forecasting system of a large company. Due to the risk nature of the internal problem where it is applied, uncertainty modeling is important.\" It would have been nice if the authors had chosen to respond by giving a _concrete_ example, complete with a real data set and an actual task to which their method is an adequate solution. However, the example given in the added paragraph is far too generic and vague to be useful as an illustrative example.\n\nFinally, when I asked for theoretical justification, I was looking for some actual proofs about e.g., consistency guarantees, approximation quality, etc.\n\n---\n## Minor\nI find the size of the text in the plots to be much too small and hard to read. Also, please label all axes in Figure 3.",
            "rating": "2: Strong rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}