{
    "Decision": "",
    "Reviews": [
        {
            "title": "Interesting investigation combining multimodel, multimodal, and distributed CNNs with implications for GAI ",
            "review": "The authors investigate generalized AI (GAI) by aggregating CNNs. The aggregations can be across different algorithms trained on the same input, same algorithm trained on different input modalities and a combination of the two, with different algorithms trained per input modality and aggregated. The theory seems to corroborate their findings and the authors provide a handful of numerical results that are in line with their theory.  The derivations seem correct as far as I can tell although I may not have spent enough time to evaluate them in detail. The paper is written sufficiently clearly although sometimes the authors refer to previous work without adding enough level of detail about why they are referring to that work in particular. The conclusion section and introduction do not state very clearly why this work matters and what are the immediate applications. The conclusions section is very thin, the authors could expand on the implications of their work. It is not clear to me whether their findings apply only to CNN architectures or can be extended to other types of tasks and deep learning models. I think the paper would be more convincing if the experimental results would include architectures other than CNNs as well as multiple benchmark tasks.\n\n[Update after authors' rebuttal]\n\nAfter reading other reviews together with the authors' rebuttal I would like to downgrade my rating to reject. \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Review",
            "review": "The paper is about a generalized AI in terms of the generalization via transfer learning. The authors describes a collaborative approach such that the proposed framework that is composed of a set of interconnected independent networks (the authors call specialized ai, or SAI), integrated by a component called IAI.\n\n- The paper is hard to follow and it appears to be describing a simple design (aggregating predictions from pre-trained models) in overly complicated terms (e.g. GAI, SAI, IAI).\n- The proposed GAI takes assessments from SAI networks as input, while not utilizing any internal features or parameters from the individual networks. The aggregation effectively is a post processsing step that does not depend on the input data.\n- In the Section 3.1, Table 2, the authors show superior performance of GAI compared with three networks individually. However, the resulting GAI network contains more parameters than the three combined.\n- Regarding aggregating predictions from other networks, the authors could have a baseline using a simple ensemble.\n- The authors only show experiments on DTD. There is lack of theoretical analysis on why the proposed GAI is superior.\n- The authors use DTD dataset as the only dataset for experiments throughout the paper, and individual SAIs are pretrained on ImageNet. It is not clear why it's the correct setup to demonstrate the generalization of GAI and how would GAI compare to alternatives.\n- The authors offered some general context in the \"Introduction\" section, while a more technical discussions of related work is missing and therefore it's hard to put this paper into literature context.\n\nGiven the presentation flaws, insufficient experiments, lack of theoretical analysis, I recommend to reject the submission.\n",
            "rating": "3: Clear rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Light on empirical evaluation, obscurantist language",
            "review": "# Summary of the paper\n\nIn a classification task, aggregating the predictions of various \"weak\" models can give stronger performance than either model alone (\"stacking\"; Wolpert, 1992). This paper proposes a 1-D convolutional architecture for learning how to aggregate predictions from NNs.\n\n## Terminology\n\nEach model that is aggregated is called a SAI (specialized AI), the aggregator network is called an IAI (Integrated by an AI), and the overall predictor is called a GAI (Generalized AI). When there are 2 levels in this aggregation, the result is called DGAI (Distributed Generalized AI).\n\nThe aggregation can be \"multimodel\" (from several models, acting on the same data), or \"multimodal\", from different modalities of data.\n\n# High-level comments\n\nThe architecture proposed for stacking seems fairly useful and simple to implement, and it could be that it works very well for improving performance of any task. However, the paper is very light on empirical evaluation, and on details of it (what training algorithm did you use? SGD, Adam? How many independent trials? What do the things after the ± represent?). It is also very hard to read, using obscure terms that are easy to confuse with each other for no apparent benefit.\n\n## Introduction\n\nI **love** the first 8 lines. \"After a decade of fine-tuning CNN parameters\", \"we have proven, by application objectives, that CNN variants [work]. It's a witty, if slightly too snarky, way to put what the field has been doing.\n\nThe illumination of the 1st letter is not part of the standard ICLR format and needs to be removed.\n\n## Obscurantist language\n\nThe paper uses very obscure, hard to understand language, for concepts that are really simple. The most egregious example is the use of \"multimodal\" and \"multimodel\", two words that differ in 1 letter and at most 3 phonemes, to differentiate between whether or not the various stacked models use different kinds of data as input.\n\nThe paper invents terms that sound fancy and scientific like \"transfer intricacy\" (1st paragraph), \"generalization proof\" (2nd paragraph),  as well as introducing cute names that are only used once, like \"tribunal or wise juror\", or 3-4 times, like \"witness\". The definition of a \"standard classification process\" in the language of stochastic processes is also completely useless, besides making the paper look sophisticated by adding mathsiness.\n\nAlso, in section 2, \"[0, 1]\" is not a measurable space by itself: you also need to specify the sigma-algebra. The Borel sigma-algebra is the most common. Of course, invoking measure theory serves no further purpose in this paper.\n\n## No acknowledging classic prior art\n\nThe \"Generalized AIs\" in this paper are nothing more than stacking ensembles, which have been known for a long time (Wolpert, 1992). I knew that ensembles work better, but I didn't have a reference; I found Stacking on the wikipedia page for \"Ensemble learning\". https://en.wikipedia.org/wiki/Ensemble_learning \n\nWolpert, David H. \"Stacked generalization.\" Neural networks 5.2 (1992): 241-259.\n\n## Light on experimental details and empirical evaluation\n\nThe only contribution of this paper is the architecture for stacking described in section 2, and its empirical evaluation. However, details of the experimental procedure are scant. What dataset is used for Table 2? What training algorithm? How did you update hyperparameters? Where do the numbers after the ± come from, did you run it several times? The intervals of the Xception and GAI models overlap as well, you can't say much from this experiment.\n\nTable 3 is worse: the \"power spectral density\" and \"local standard deviation\" transforms are not explained, and there is no link to another paper that would explain them either.\n\n# Conclusion\n\nThe paper needs to be written in a clear language, cite prior art, and carefully examine the empirical properties of the proposed methods.\n\nIt is my assessment that the paper should be rejected in its current state.",
            "rating": "2: Strong rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}