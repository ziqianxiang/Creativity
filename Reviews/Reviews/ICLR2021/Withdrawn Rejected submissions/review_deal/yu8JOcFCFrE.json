{
    "Decision": {
        "title": "Final Decision",
        "decision": "Reject",
        "comment": "During discussion, the reviewers acknowledge improvement of the revised version of the paper through author rebuttal and agree with that the paper is overall well written.\n\nHowever, the novelty of the paper is not strong, and reviewers share the concern that distinction between self supervised learning and deep clustering is not convincing. Also, the concerns (2) raised by the Reviewer #2 is important, which is about the effectiveness of the proposed two-step procedure: first apply t-SNE to transform into two dimensions, followed by running K-means, while the answer is not well  justified. In my opinion, parameter sensitivity should be studied more carefully. The authors mention that $k$ and $\\kappa$ have little effect on clustering performance, while this could imply that the associated terms do not have impact on the proposed method. This point should be clarified further.\n\nOverall, the paper is still not ready for publication, I will therefore reject the paper."
    },
    "Reviews": [
        {
            "title": "It's all in the title",
            "review": "The authors propose a clustering methods that builds upon DEC and N2D+tSNE with extra loss terms to preserve geometric structures. They provide an extensive analysis but not always fair. In the end, the benefits of \"preserving the geometric structures\" are not clear or well defended.\n\nOverall, the paper is well written and easy to follow.\nThe authors provide arguments to several aspects of their contribution. However it is also scattered with claims.\nThe maths are clear despite some atypical notations (eg. the scale parameter).\n\n1/The introduction raises well the problem of \"learning a representation that favors clustering\" (please use \\emph instead of bold).\nConversely, the paragraph claiming that we need a clustering that also favors representation learning is not clear. From this point of view, it appears to me to be two completely different things.\n\n2/ The second section reviews the most important and related works in the field of deep clustering. \nI would rather describe JULE as a neural extension of hierarchical clustering.\nSince I am not an expert in manifold representation, several abbreviation remains unclear to me: LIS, MMD, MLDL, LLE, SSMM.\n\n3/ Since you wish to learn a representation and clustering, you aim to find the optimal \\theta AND \\mu.\n3.1/ The derivations here are the same as DEC (citation), except that you rightfully name the underlying distribution.\n\"However, we find that the clustering-oriented loss may deteriorate the geometric structure of the latent space\"\nThis claim is not justified. \n\n3.2/ Eq 5. the multiplication dot is unnecessary and disturbing.\nEq 6. The \"scale\" parameter is very disturbing. \nI understand \"rank\" as the number of clusters. This term ensures that the distance between the manifolds centers in the input space and between the centroids in the features space remain the same/proportional. The separation of the clustering centers depends on their initialization. I wonder what happens when C is larger than the number of true clusters. \n\"so L rank is easier to optimize, faster to process, and more accurate.\" Faster to process, yes. However easier and more accurate require more argument. It is not clear relatively to what is it more accurate. Moreover, the conservation of the distances imposed by L_rank  appears to me more difficult to satisfy, especially since the euclidean distance is used in both spaces. \n\nThe alignment loss replaces the update of the \\mu in DEC.\n\n3.3 It is clear and well explained. Although, Fig 2 and its caption could be more informative and self-contained.\n\n4. The experiments involves several baselines and varied data-sets. However, the experimental setting is not clear and weights a lot in my final opinion. \nDo you report best score? Average? What about the baselines? DCLR and N2D reports very similar scores. Are they statistically different? This apply to all the tables.\nIn the same way that (I)DEC is very dependent on the AE initialization, the results (DCLR vs N2D) suggest the same for the propose method. \n\n4.3.1 Table 3: Most of these measure check if neighbors on the input are also neighbors in the feature space.\nIs RMSE relevant since the f is non linear? Note that for LGD, since it stays in the neighborhood, it is not such a big deal.\nWhy is a high CRA desirable? Besides if DCLR did not report a very high value, that would  suggests that L_rank fails.\n\n4.3.2 \"Significantly, the performance of DEC on downstream tasks deteriorates sharply and even shows a large gap with the simplest AEs, which once again shows that the clustering-oriented loss may damage the data geometric structure.\"\nA direct competitor to DCLR is rather IDEC than DEC because of the missing reconstruction loss.\nWithout statistical test, the differences are not interpretable (SVM).\n\n4.4 Here again, and especially for the last three lines of Table 5, the missing statistical test prevent us from drawing any conclusion.\n\nA.7 It should be say more clearly that the rank of j relatively to i is in terms of distance. It is also related to CRA.\nN2D and DCLR report very similar scores on MNIST (Table 1), although the curves on Fig A.3.g are shifted. Hence the argument on the benefit of having a centered curves does not hold.\n\nAs a summary, the paper is well written but includes several claims that are not justified. The experimental section is not reproducible (best score? average? same init for all the baselines?) and miss statistical tests. \nIndeed some geometric aspects are preserved by the projection, but are relevant for clustering? or classification?\nBesides, the benefits over N2D do not appear clear to me. It seams that the method depends on its initialization. I wonder how (I)DEC would perform with the same initialization.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A new deep clustering method that better accounts for the geometric structure of the data, demonstrated by comparison with similar methods.",
            "review": "The main contributions of this work are the inclusion of some new optimization objectives into the standard deep clustering formulations.\nThe cluster orientated loss seems to come from DEC but as the authors point out this causes issues that affect the quality of clusters.\nThus to preserve the manifolds within the embedding the propose new objectives in addition to this. One objective tries to ensure representation clusters are internally coherent with the original manifold Another objective tries to ensure global structure is preserved by optimizing directly the centroids of the learned representation \n\nThere are a number of strengths to this work. \n\nThe idea of including the geometric structure is well founded and their approach appears to account for this well. Unlike the typical work in this area, the authors choose to evaluate their representations on downstream tasks, and not just clustering, included. This really demonstrates the benefits (and limitations) outside of the typical clustering focus. I also liked the inclusion of the ablation study which shows benefit of Weight Graduality (WG) and Alternating Training (AT). They also perform sufficient experimentation to validate their approach.\n\nOne concern w.r.t. there proposed approach is that one of their objective functions only updates the centroids and thus they need another objective to align these. This seems like a rather arbitrary way of going about this. \n\nThe authors also state that \"It is worth noting that all of the above losses coexist rather than independently at different stages\" However, the final stage corresponds to L_LIS corresponds outside of the batching, which is a little misleading. I would not say they are not independent in this case.\n\nI have some questions w.r.t. the evaluation.. \nWhy is tSNE used after pretraining when the work of N2D (which you reference) shows UMAP performs better? This is more of a question about the authors choice, rather that a criticism of the work. \nI also am unclear why they reduce the dimensionality to 2. This is intuitive when you are visualizing the dataset, but not necessarily for clustering. The above paper N2D (which you reference) mentions that the cluster quality lessens with 2 dimensions as opposed to higher.\nAgain, despite these choices, the method outperforms others, thus these are less a direct criticism of the work and more about the lack of justification these choices. \n\nI believe the authors are missing some other relevant work in their comparisons, for e.g. [1], which reports higher performance than the authors on some datasets.\n\nFurther, like much of these works, the method is only tested on smaller datasets. Other approaches are tested on datasets such as ImageNet-10, the inclusion of more larger image datasets would strengthen this work. \n\n[1] Guo, Xifeng, et al. \"Adaptive self-paced deep clustering with data augmentation.\" IEEE Transactions on Knowledge and Data Engineering (2019).",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good work but the main claim needs a more specific illustration",
            "review": "[Summary]\n\nIn this paper, the authors proposes a deep clustering model to enable the clustering and representation learning to favor each other via preserving the geometric structure of data. The proposed DCRL framework integrates an isometric loss for local intra-manifold structure and a ranking loss for global inter-manifold structure. The authors evaluate the proposed framework on five datasets and the experimental results show that the proposed framework brings certain improvements over the baseline approaches. \nGenerally speaking, it is a good work with good results. Considering there are some weaknesses to be solved, I’d like to vote for a rating of 6.\n\n[Pros]\n+ The paper is well organized and easy to follow.\n+ The idea of preserving global and local structure is reasonable and seems to be effective.\n+ The description of experimental setting is sufficient, should be easy to reproduce. The authors also conduct comprehensive experiments with good results achieved.\n\n[Cons]\n- The proposed intra-manifold isometry loss and inter-manifold ranking loss seem to be modifications of $L_{LIS}$ proposed in [1] so the framework is interesting but not surprisingly new to me.\n- Though the authors claim that ‘the clustering-oriented loss may deteriorate the geometric structure of the latent space’ at the very beginning of this paper, this claim is not supported by any proof until it reaches the end of the experiment section. It would be better to illustrate this phenomenon by some figures or case studies in the introduction to help the readers understand this. Moreover, the relationship between geometric structure and the clustering performance is also recommended to be analyzed to show the necessity of preserving the local data structure.\n- In this paper, the meaningfulness of learned representations is tested on downstream classification tasks. However, it seems not very reasonable to adopt such evaluation, since intuitively the representation learning should focus on improving the clustering performance and it seems not very necessary to take the downstream task into account for the clustering models (at least for me it is not very practical to use representations learned by deep clustering models to do some classifications).\n- Experiments are only conducted only with MLP-AE backbones. It is not clear whether the data structure will be preserved for ConvAEs which is also commonly used in real-world applications.\n- There are some minor issues, e.g., 'learining' in page 2 and page 17 should be 'learning'. In Fig.4, ‘AE+K-mean’ should be ‘AE-K-means’.\n[1] Stan Z Li, Zelin Zhang, and Lirong Wu. Markov-lipschitz deep learning. arXiv preprint arXiv:2006.08256, 2020.\n\n[Questions]\n1. Could you please provide some explanation for why the clustering-oriented loss may deteriorate the geometric structure of the latent space and why preserving the structure is necessary for the clustering?\n2. Will the data structure be preserved for ConvAEs backbones?\n3. How do the hyperparameters $k$ and $scale$ affect the performance?\n4. How to set the the range of hyperparameters $\\alpha, \\beta$ in practice?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Ok but not good enough - rejection",
            "review": "This paper proposes a method which can simultaneously perform clustering and represent learning with local and global structure preservation. The method imposes clustering-oriented and structure-oriented in order to optimize the latent space. The experimental results show its effectiveness. However, here are some issues.\n(1) This paper is not innovative enough. From the perspective of the entire clustering process, the proposed clustering method essentially makes the intra-cluster distance as small as possible and the inter-cluster distance as large as possible. There is no significant innovation in the idea of clustering.\n(2) In the initialization of the algorithm, first use t-SNE to transform the latent space Z into two dimensions, and then run K-Means to get the label of each data point. In this step, why do you need to perform dimension conversion first instead of directly performing K-Means clustering on the original data?\n(3) In this method, the author uses K-Means for initialization. However, K-Means is not a stable clustering algorithm. Using it to initialize the label, are the results stable? Has the author analyzed the effect of different label initialization methods on the results?\n(4) The data sets used in the experiment are too single. In the adopted data sets, three are all about MNIST, and there is little difference between MNIST-test and MNIST-full. Moreover, similar to MNIST, USPS is also a handwritten digital image data set. The data sets used by the author are repetitive, and it is difficult to reflect the experimental performance of the method.\n(5) From the quantitative evaluation results of downstream tasks, compared with the classic classification algorithms, the representation learning obtained by the proposed method for classification does not show great advantages in classification accuracy.\nOverall, I think this paper is not ready yet.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}