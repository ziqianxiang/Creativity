{
    "Decision": "",
    "Reviews": [
        {
            "title": "Although the proposed method produces good results, the paper is difficult to understand and needs significant revision.",
            "review": "The authors focus on the problem in generative adversarial networks that fake samples outside the margin with partial unrealistic local patterns are ignored in training. To solve this problem, the authors propose a local gradient amplifier (LGA), which is introduced by extending the generator loss of GANs with hinge adversarial loss. The authors confirm through experiments that applying the proposed method to conventional models (WGAN-GP and SNGAN) results in more stable learning and higher performance than these models.\n\nPros：\n- The proposed method is more stable and performs better than the baseline model.\n\nCons:\n- The main concern is that it is difficult to understand what \"fake samples outside of the margins that partially include unrealistic local patterns are ignored in the training\" means and how important this problem is in improving performance.  The authors should explain clearly what this problem is (using figures, etc.) and argue that it is an important thing to solve to improve performance.\n- The explanation of the proposed method is clearly insufficient. It is understandable to some extent that it is important to see if a particular spatial area contributes to the unrealistic part of the fake image. But I don't know not only how the proposed method accomplishes this, but also the details of the proposed method. For example:\n  - It doesn't explain exactly what function $D_{LGA}$ is. Although it is partially explained in Fig.1 and Eq. 13, it is unclear how these correspond to $D_{LGA}$.\n  - $D_ {i, j}$ is a function that outputs the subscript elements, but I don't know in which part the sum of each element is taken. Also, I don't know why $D_ {LGA}$ has no subscripts ${i,j}$.\n  - I don't know what part of Eq. (12) $\\hat{Y}$ corresponds to. Is this equivalent to the output of $D_{LGA}$?\n  - It is also not clear why the proposed method is an extension of hinge adversarial loss.\n- Other parts of the equations and their explanations are also inappropriate. For example, in Eq.(1), the authors don’t explain what $P_r$ and $P_z$ are, respectively. In Eq. (2), they are denoted as $\\mathbb{P}_r$ and $\\mathbb{P}_g$, which are not consistent.\n- Why are the different names WGAN and wGAN used? If there is no difference between them, then they should be unified.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This work proposes a local gradient amplifier(LGA) to improve the convergence and stability of GAN. Experiments on various data sets show the effective of local gradient amplifier(LGA). However, Local Gradient Amplifier (LGA) is really simple and there is not enough explanation why it is effective. ",
            "review": "Pros:\n+ The paper is easy to read and follow.\n+ FID scores and visual results show the effective of local gradient amplifier(LGA) for improving the convergence and stability of GAN.\nCons:\n-The local gradient amplifier(LGA) is really simple and there is not enough explanation about the reason to  design local gradient amplifier(LGA). For example, why set the values greater than 1 to 1 in the amplification map? Why this design is effective?\n- LGA improves the results of GAN, which could not interpret that LGA is used for spatially decomposition and amplifies the gradient of unrealistic region.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "An extended GAN loss by doing spatial-wise discrimination. Some important comparisons are missing. Writing has to be improved.",
            "review": "The paper propose a new GAN loss which is a modification of loss for generator objective, while the discriminator loss is the typical hinge loss. The authors then further combine it with spatial outputs resulted by convolutions.\n\n1. I have some questions regarding to the motivation of the proposed loss. In the end of Section 2, the authors mentioned  \n\"However, it gives penalties for misclassified samples proportional to the distance from the class boundary. This hinge adversarial\nloss not only makes discriminator more focused on misclassified samples\". By reading until here, I expect the solution is on modifying generator loss, how does it connect with the proposed metric? I may not fully understand because the math notations are confusing (will explain later). More illustrations are needed.   Second, what do you by \"also makes the loss\neasier to control than conventional adversarial loss by setting the decision boundary to 0.\"?\n\n2. The paper is not well written (with some obvious grammar errors), and the math notation are sometimes ill-defined. What are D, D_LGA and D_{ij} in eq (12), they are never explicitly defined.  The authors mentioned D_ij is the \"feature map\" of D, based on the notation above, could we guess D = v^T {D_{ij}}?  If so, how could we use (13)? since v can even change the sign of D_{ij}.  \n\n2. More comparisons are required. There are more GANs using multiple outputs with theoretical groundings. For example, the McGAN mentioned in the paper and its follow up, Sobolev GAN (Mroueh et al., 2018). MMD GANs also leverage multi outputs, and it is known that it can usually (or always) bring you some performance gain. Representative works include \n* MMD GAN: Towards Deeper Understanding of Moment Matching Network\n* On gradient regularizers for MMD GANs\nThe authors should have a more thorough literature review on those works using multivariate outputs and compare some of them with the same architecture to justify why the proposed new loss is better than those. Also, what's the advantage of using the proposed new loss compared with those existing works? given they have nice theory guarantees behind the algorithm design.  I would expect more analysis to justify the proposed loss. \n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Spatial adjustment of generator loss",
            "review": "The paper suggests that when training a generator it’s beneficial to tweak the loss spatially so that less realistic areas receive (even) stronger gradients. This is a somewhat non-obvious statement, and thus interesting to consider.\n\nOverall the writing could be improved a lot, and I would suggest an editing pass from native/professional technical writer if the paper gets accepted. Independent from that, I found sections 1 & 2 lacking motivation. I found myself thinking why on earth am I reading this seemingly random list of citations in the second paragraph of intro. Why not scratch much of that and tell your story instead, providing intuition and getting the reader excited? The same issue can be seen in section 2. The discussion about WGAN, Lipschitz, Hinge are all rather verbose, and yet the authors haven’t even stated that they’re going to be using these techniques as a basis for their work so the reader doesn’t understand why this is being presented. If space is tight, consider removing e.g. the Kantorovich-Rubinstein duality discussion as it has very little to do with your paper.\n\nIn Section 3 you write “current fake images will be updated without any spatial priority and, as a result, regardless of whether particular spatial region in the generator contributed to the unrealistic part of the fake image or not”. This is a key point, and I want to discuss it a bit more. The loss is a scalar, which is computed as an inner product (Eq. 8), preceded by convolutions in many layers. Okay, let’s say the loss is large. We start back propagating through the discriminator, and surely the spatial areas that contributed more to the large loss will receive larger gradients? Or am I missing something here? Unless I’m mistaken, what you claim isn’t entirely true, but instead you wish to make the point that it can be beneficial to make the spatial effect even stronger by explicitly modifying the loss computation.\n\nYou say that Equation amplifies certain gradients, but since A_{i,j} <= 1, I don’t see how anything could get amplified. Don’t you instead attenuate the gradients in the realistic regions? In the end this may be equivalent, but precision is important.\n\nIn Section 4.1 you establish WGAN-GP with lambda = 10 as your baseline, but then inexplicably proceed to change lambda to 1 before running any tests. This makes your baseline invalid! GAN results are often very sensitive to the choice of lambda, and to add credibility to the results section you really need to add “WGAN-GP with lambda = 1”. Maybe it then turns our that Hinge loss for some reason likes a different lambda value, but you need to show this. Currently we see promising results for LGA in several datasets and I’m intrigued. \n\nOn a high-level the reasoning behind LGA resembles Top-K and LOGAN, both of which massage the training to learn *less* from poor generated images. At first it sounds like LGA is aiming for the opposite (!), but I cannot overrule that there might be a similar “snapping towards a realistic mode” happening during the course of training.\n\nAs a summary I find the idea quite thought-provoking and lean towards acceptance in my initial judgement, despite the issues mentioned above.\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}