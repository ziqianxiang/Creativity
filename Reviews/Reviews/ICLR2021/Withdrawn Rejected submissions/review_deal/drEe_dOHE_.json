{
    "Decision": "",
    "Reviews": [
        {
            "title": "An invertible GAN approach to reducing mode collapse. Iterative and not exhaustively compared to state-of-the-art",
            "review": "The authors propose a GAN inversion framework to address mode collapse by reducing the distance between the inverted distribution and the original prior. Empirical comparison to a few baselines show good performance on quality and mode fitting.\n\nStrengths:\n- The proposed approach is simple, and seems to give satisfactory results with respect to a few baselines.\n\nWeaknesses:\n- Contribution is mainly empirical. The theory of section 3 trivial, unless I missed something. Notably, the main insight of this section is very close to what is explained in the paper of a competitive baseline (VEEGAN, although then end up with a different objective). The algorithm is a simple combination of known losses optimization.\n- Several aspects of the approach are unclear in main text: how the three losses are combined (specified in supplemental only, and I would expect this is not completely trivial to balance the magnitude of the loss and find best way to update them iteratively) and why they use a multivariate Gaussian prior (the explanation provides, that components should be dependent/correlates, does not make sense to me.\n- The approach makes a Gaussian approximation when computing distances between reconstructed latent and prior, which is unlikely during training.\n- Given the amount of work on mode collapse, much more baselines should be added to have a convincing empirical demonstration.\n\nQuestions:\nDid you investigate how to balance the magnitude of the loss and find best way to update them iteratively?\nWhy do you use a multivariate Gaussian prior (a simple linear fully connected layer in the generator/encoder can encode this, and there is no reason to expect this makes things easier, in my view).\n",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An interesting concept but it needs many improvements ",
            "review": "In this paper the authors present InvertGAN. Undoubtedly, one of the main problems in the training of GANs is the so-called mode collapse, whereby the generator fails to produce diverse enough data corresponding to all the modes of the ground truth data seen during training. In order to alleviate this, the authors propose a framework in which the main concept is that they do an inverse mapping of the data (i.e., they utilize an additional neural network as the inverse of the generator to project the ground truth or generated data back to the latent space). As they demonstrate in a series of mainly synthetic and limited experiments on real data, invertGAN seems to be outperforming the compared methods both quantitatively and qualitatively.\n\n* Strengths of the paper:\n\nThe concept is intuitive and easy to comprehend. I could see this concept proving to be beneficial in order to avoid mode collapse in certain scenarios but much more rigorous and extensive experimental work should have been carried out in order to corroborate this firmly (see below).\n\n* Weaknesses of the paper:\n\nThe main disadvantage of the paper is that it is very poor experimentally. To begin with, the authors provide comparisons of invertGAN against other methodologies in synthetic data, yet they fail to provide the architecture they used  (they only provide the network architecture for the experiments on real data in the Appendix). Having no knowledge of the exact architecture that was used for the synthetic experiments it is very difficult to understand where the problem potentially lies. It might as well be on the architecture.\n\nMoreover, although they do provide the network architecture for the experiments on real data, it is very hard, in general, to empirically validate the efficacy of GAN methods using only a certain architecture. For example, how can we be certain that this method is not overfitted to the particular architecture?\n\nFurthermore, when the quantitative results are reported about the experiments on real data, I can see that there is not a statistically significant outperformance of invertGAN compared to e.g., Unrolled GAN on Cifar10 or VEEGAN on Cifar100. The same round of experiments should have been run a number of times, and then the average FID/IS etc. scores along with the std should have been reported. Having seen only those results, we cannot be certain about the superiority of the method, even for the particular architecture.\n\nWhat is more, when it comes to carrying out experiments on real data, the authors should have used more challenging datasets of higher image quality (e.g., CelebA-HQ). Validating a methodology on Cifar10 or Cifar100 is good to start with, but more challenging experiments should have been carried out. For example, looking at the generated images in Figures 8 and 9 of the Appendix, I can see some differences qualitatively, but I cannot really tell whether the generated classes are indeed meaningful or not. Moreover, architectures such as the one of Progressive GAN (ICLR'18) have proven to be quite robust to mode collapse yet these have not been explored in the experimental section at all.\n\nFinally, the paper at certain points is a bit difficult to read as there are quite a few syntactic and grammatical errors as well as some sentences are incomplete (e.g., in page 3, in the first paragraph of Sec. 3.2., there is a word “mainly” on its own after the citations). It thus needs polishing. Moreover, the mathematical equations should be more rigorously checked. For example, I understand that the authors present vectors as well as matrices with bold letters. They should be consistent with that throughout the text (e.g., in page 4, the multi-variate Gaussian should have a mean of 0 with bold and a covariance I with bold too). Also, please go through the equations again and check for inconsistencies (e.g., the variables in equation 7 in the KL divergence are wrong).\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Great visualization about the method, but want to see the performance in a more elaborate setting with more recent works.",
            "review": "##### Summary\nThis paper tries to resolve the mode-collapse issue by designing the inverse mapping function. The author well presented the cases when the mode collapse happens and what this paper wants to claim. Although this paper presents their performance on various simple datasets with a set of baseline models, I wonder whether this setting works on a complex generation task or performs better than more recent works.\n\n\n##### Strength\nThis paper is easy to follow, and especially, the Figures helps in understanding how the author approaches this issue. Also, the conceptual explanation about this method was quite clear, and thus readers can easily catch what this method is about. Finally, this paper also compares the performance with a set of baseline models on many simple datasets.\n\n\n##### Weakness\nFirst of all, from the first two pages, it keeps reminding the readers to compare with some most recent diverse mode-capturing techniques, like DSGAN (Yang et al., in ICLR 2019) or MSGAN (Mao et al., in CVPR 2019). Also, because this model is mainly based on learning the inverter, I wonder when it tested on a very complex setting, instead of measuring on a simple dataset, like generating diverse videos or generating images from ImageNet. Along with this, it is also hard to guess how robust this approach would be. Please check the details of each point in the next section.\n\n\n##### Questions\n1. As I mentioned earlier in the weakness section, although this paper mentioned various recent techniques, like (Elfeki et al., 2019), (Meulemeester et al., 2020), and (Ghosh et al., 2018), the latest work that the author used in the experiment was VEEGAN (Srivastava et al., 2017). In this context, I wonder when compared with more recent works. \n\n2. Along with Q1, I think comparing with recent diversity-prompting methods (e.g., Yang et al., in ICLR 2019, Mao et al., in CVPR 2019) would also help the readers to understand the behaviors. Also, because the image-to-noise part can be seen as InfoGAN (Chen et al., in NeurIPS 2016), I think it would be helpful to compare it with InfoGAN as well. \n\n3. Because the InvertGAN relies heavily on the performance of \"inverter\" T^{-1}, I recommend the author to test this method on more complex cases. Generative models usually don't strictly assume that there is a 1:1 mapping between the input and the output, and this model also didn't strictly assume, but because the dataset is simple enough, it is hard to verify that there is no such assumption holds in the data. Thus, to reassure any concerns, I highly recommend the author perform an experiment on a more complex setting like generating diverse videos or generating diverse images in the ImageNet scale. \n\n4. Along with Q3, it is also hard to accept this approach's generality just by reading this paper because there is no mathematical proof for supporting this. Thus, I recommend the author to provide any relaxed derivations for supporting this approach.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting idea with good results on synthetic datasets, but missing real-life validation and polishing",
            "review": "The paper discusses the mode collapse phenomenon in GANs and proposes a new approach to address it via inverse mapping. The authors define mode collapse problem as a combination of two issues: mode missing and mode imbalance. Furthermore, they propose a new architecture called InvertGAN that relies on inverting target sample distribution to a multidimensional mixture of Gaussians.\n\nOverall I like the paper, I think it is fairly well written and the design decisions are well motivated. The mode collapse analysis is done thoroughly and the proposed idea is valid. The argument of using inverse mapping is compelling, although the results do not convince me entirely that this approach  is feasible on real datasets - one usually would expect to see some datasets that are more diverse and frequently used for generative models, such as CelebA. My other concern is that the paper seems rushed with unfinished sentences (sec. 3.2 Previous works (Kingma & Welling, 2014; Srivastava et al., 2017) mainly ?) and spelling errors (Fig. 2 caption: Gassuian). Although this is not critical and can be fixed in camera ready, it shows some lack of maturity of the work. \n\nOverall, I believe that the paper is worth publishing and the idea sounds novel and interesting, however, it still needs some polishing so I won’t argue if it does not get accepted.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}