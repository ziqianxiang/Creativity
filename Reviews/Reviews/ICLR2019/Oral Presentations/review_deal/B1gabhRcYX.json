{
    "Decision": {
        "metareview": "The first reviewer summarizes the contribution well: This paper combines [a CNN that computes both a multi-scale feature pyramid and a depth prediction, which is expressed as a linear combination of \"depth bases\"]. This is used to [define a dense re-projection error over the images, akin to that of dense or semi-dense methods]. [Then, this error is optimized with respect to the camera parameters and depth linear combination coefficients using Levenberg-Marquardt (LM). By unrolling 5 iterations of LM and expressing the dampening parameter lambda as the output of a MLP, the optimization process is made differentiable, allowing back-propagation and thus learning of the networks' parameters.] \n\nStrengths:\nWhile combining deep learning methods with bundle adjustment is not new, reviewers generally agree that the particular way in which that is achieved in this paper is novel and interesting. The authors accounted for reviewer feedback during the review cycle and improved the manuscript leading to an increased rating. \n\nWeaknesses:\nWeaknesses were addressed during the rebuttal including better evaluation of their predicted lambda and comparison with CodeSLAM.\n\nContention:\nThis paper was not particularly contentious, there was a score upgrade due to the efforts of the authors during the rebuttal period.\n\nConsensus:\nThis paper addresses an interesting  area of research at the intersection of geometric computer vision and deep learning and should be of considerable interest to many within the ICLR community. The discussion of the paper highlighted some important nuances of terminology regarding the characterization of different methods. This paper was also rated the highest in my batch. As such, I recommend this paper for an oral presentation. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Oral)",
        "title": "Nice work combining Bundle Adjustment and Deep Learning Methods"
    },
    "Reviews": [
        {
            "title": "Very well written paper on an important subject, with clear technical contribution and convincing results",
            "review": "This paper presents a novel approach to bundle adjustment, where traditional geometric optimization is paired with deep learning.\nSpecifically, a CNN computes both a multi-scale feature pyramid and a depth prediction, expressed as a linear combination of \"depth bases\".\nThese values are used to define a dense re-projection error over the images, akin to that of dense or semi-dense methods.\nThen, this error is optimized with respect to the camera parameters and depth linear combination coefficients using Levenberg-Marquardt (LM).\nBy unrolling 5 iterations of LM and expressing the dampening parameter lambda as the output of a MLP, the optimization process is made differentiable, allowing back-propagation and thus learning of the networks' parameters.\n\nThe paper is clear, well organized, well written and easy to follow.\nEven if the idea of joining BA / SfM and deep learning is not new, the authors propose an interesting novel formulation.\nIn particular, being able to train the CNN with a supervision signal coming directly from the same geometric optimization process that will be used at test time allows it to produce features that  will make the optimization smoother and the convergence easier.\nThe experiments are quite convincing and seem to clearly support the efficacy of the proposed method.\n\nI don't really have any major criticism, but I would like to hear the authors' opinions on the following two points:\n\n1) In page 5, the authors write \"learns to predict a better damping factor lambda, which gaurantees that the optimziation will converged to a better solution within limited iterations\".\nI don't really understand how learning lambda would _guarantee_ that the optimization will converge to a better solution.\nThe word \"guarantee\" usually implies that the effect can be somehow mathematically proved, which is not done in the paper.\n\n2) As far as I can understand, once the networks are learned, possibly on pairs of images due to GPU memory limitations, the proposed approach can be easily applied to sets of images of any size, as the features and depth predictions can be pre-computed and stored in main system memory.\nGiven this, I wonder why all experiments are conducted on sets of two to five images, even for Kitti where standard evaluation protocols would demand predicting entire sequences.",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An interesting work but lacking some details concerning the implementation and experimentations",
            "review": "I believe that the authors have a solid contribution that can be interesting for the ICLR community.\nTherefore, I recommend to accept the paper but after revision because the presentation and explanation of the ideas contain multiple typos and lacking some details (see bellow). \n\nSummary:\nThe authors propose a new method called BA-Net to solve the SfM problem by explicitly incorporating geometry priors into a machine learning task. The authors focus on the Bundle Adjustment process. \n\nGiven several successive frames of a video sequence (2 frames but can be extended up to 5), BA-Net jointly estimates the depth of the first frame and the relative camera motion (between the first frame and the next one).\nThe method is based on a convolutional neural network which extracts the features of the different pyramid levels of the two images and in parallel computes the depth map of the first frame. The proposed network is based on the DRN-54 (Yu et al., 2017) as a feature extractor. \n\nThis is complemented by the linear combination of depth bases obtained from the first image.\nThe features and the initial depth then passed to the optimization layer called BA-layer where the feature re-projection error is minimized by the modified LM algorithm. \n\nThe authors adapt the standard multi-view geometry constraints by a new concept of feature re-projection error in the BA framework (BA-layer) which they made differentiable. \nDifferentiable optimization of camera motion and image depth via LM algorithm is now possible and can be used in various other DL architectures (ex. MVS-Net can probably benefit from BA-layer).\n\nThe authors also propose a novel depth parametrization in the form of linear combination of depth bases which reduces the number of parameters for the learning task, \nenables integration into the same backbone net as used or feature pyramids and makes it possible to jointly train the depth generator and the BA-layer. \n\nOriginally the proposed approach depicts the network operating in the two-view settings. The extensibility to more views is also possible and, as shown by authors, proved to improve performance. It is, however, limited by the GPU capacity. \n\nOverall, the authors came up with an interesting approach to the standard BA problem. They have managed to inject the multi-view geometry priors and BA into the DL architecture. \n\nMajor comments regarding the paper:\n\nIt would be interesting to know the evaluation times for the BA-net and more importantly to have some implementation details to ensure reproducibility.\n\nMinor comments regarding the paper:\n\n-\tThe spacing between sections is not consistent. \n-\tFigures 1 is way too abstract given the complicated set-up of the proposed architecture. It would be nice to see more details on the subnet for depth estimator and output of the net. \nOverall it would be helpful for reproducibility if authors can visualize all the layers of all the different parts of the network as it is commonly done in the DL papers.\n-\tTalking about proposed formulation of BA use either of the following and be consistent across the paper:\nFeaturemetric BA / Feature-metric BA / Featuremetric BA / ‘Feature-metric BA’\n-\tTalking about depth parametrization use ‘basis’ or ‘bases’ not both and clearly defined the meaning of this important notion.\n-\tAttention should be given to the notation in formulas (3) and (4). The projection function there is no longer accepts a 3D point parametrized by 3 variables. Instead only depth is provided. \nIn addition, the subindex ‘1’ of the point ‘q’ is not explained. \n-\tMore attention should be given to the evaluation section. Specifically to the tables (1 and 2) with quantitative results showing the comparison to other methods. \nIt is not clear how the depth error is measured and it would be nicer to have the other errors explained exactly as they referred in the tables (e.g. ATE?).\n-\tHow the first camera pose is initialized?\n-\tIn Figure 2.b I’m surprised by the difference obtained in the feature maps for images which seems very similar (only the lighting seems to be different). Is it three consecutive frames?\n-\tAttention should be given to the grammar, formatting in particular the bibliography. \n\n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "dense SfM with Deep Learning",
            "review": "edit: the authors added several experiments (better evaluation of the predicted lambda, comparison with CodeSLAM), which address my concerns. I think the paper is much more convincing now. I am happy to increase my rating to clear accept.\n\nI also agree with the introduction of the Chi vector, and with the use of the term of \"photometric BA\", since it was used before, even if it is unfortunate in my opinion. I thank the authors to replace reprojection by alignment, which is much clearer.\n\n---------------\n\n\nThis paper presents a method for dense Structure-from-Motion using Deep Learning:\nThe input is a set of images; the output is the camera poses and the depth maps for all the images.\nThe approach is inspired by Levenberg-Marquardt optimization (LM): A pipeline extracting image features computes the Jacobian of an error function. This Jacobian is used to update an estimate of the camera poses. As in LM optimization, this update is done based on a factor lambda, weighting a gradient descent step and a Gauss-Newton step. In LM optimization, this lambda evolves with the improvement of the estimate. Here lambda is also predicted using a network based on the feature difference.\n\nIf I understand correctly, what is learned is how to compute image features that provide good updates, how to predict the depth maps from the features, and how to predict lambda.\n\nThe method is compared against DeMoN and other baselines with good results.\n\nI like the fact that the method is based on LM optimization, which is the standard method in 'geometric bundle adjustment', while related works consider Gauss-Newton-like optimization steps. The key was to include a network to predict lambda as well.\n\nHowever, I have several concerns:\n\n* the ablation study designed to compare with a Gauss-Newton-like approach does not seem correct. The image features learned with the proposed method are re-used in an approach using a fixed lambda. If I understand correctly, there are 2 things wrong with that:\n- for GN optimization, lambda should be set to 0 - not a constant value. Several constant values should also have been tried.\n- the image features should be re-trained for the GN framework:  Since the features are learned for the LM iteration, they are adapted to the use of the predicted lambda, but they are not necessarily suitable to GN optimization.\nThus, the advantage of using a LM optimization scheme is not very convincing.\n\nSince the LM-like approach is the main contribution, and the reported experiments do not show an advantage over GN-like approaches (already taken by previous work), this is my main reason for proposing rejection.\n\n* CodeSLAM (best paper at CVPR'18) is referenced but there is no comparison with it, while a comparison on the EuRoC dataset should be possible.\n\nLess critical concerns that still should be taken into account if the paper is accepted:\n\n- the state vector Chi is not defined for the proposed method, only for the standard bundle adjustment approach. If I understand correctly is made of the camera poses.\n\n- the name 'Bundle Adjustment' is actually not adapted to the proposed method.  'Bundle Adjustment' in 'geometric computer vision' comes from the optimization of several rays to intersect at the same 3D point, which is done by minimizing the reprojection errors. Here the objective function is based on image feature differences. I thus find the name misleading. The end of Section 3 also encourages the reader to think that the proposed method is based on the reprojection error. The proposed method is more about dense alignment for multiple images.\n\n\nMore minor points:\n\n1st paragraph:  Marquet -> Marquardt\ntitle of Section 3: revisitED\n1st paragraph of Section 3: audience -> reader\ncaption of Fig 1: extractS\nEq (2) cannot have Delta Chi on the two sides. Typically, the left side should be \\hat{\\Delta \\Chi}\nbefore Eq (3): the 'photometric ..' -> a 'photometric ..'\n1st paragraph of Section 4.3: difficulties -> reason\ntypo in absolute in caption of Fig 4\nEq (6): Is B the same for all scenes?  It would be interesting to visualize it.\nSection 4.5: applies -> apply\n",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}