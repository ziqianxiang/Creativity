{
    "Decision": {
        "metareview": "The reviewers agree that this is a novel paper with a convincing evaluation.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Oral)",
        "title": "Original paper"
    },
    "Reviews": [
        {
            "title": "Nice and novel idea",
            "review": "This paper proposes the temporal difference variational auto-encoder framework, a sequential general model following the intuition of temporal difference learning in reinforcement learning. The idea is nice and novel, and I vote for acceptance.\n1. The introduction of belief state in the sequential model is smart. How incorporate such technique in such an autoregressive model is not easy.\n2. Fig 1 clearly explained the VAE process.\n3. Four experiments demonstrated the main advantages of the proposed framework, including the effectiveness of proposed belief state construction and ability to jumpy rolling-out, \n\n\nOther Comments and Questions:\n1. Typo, p(s_{t_2}|s_{t_1}) in the caption of Fig 1.\n2. Can this framework partially solve the exposure bias?\n3. The author used uniform distribution for t_2 - t1, and from the ``NOISY HARMONIC OSCILLATOR`` we can indeed see larger interval will result in worse performance. However, the author also mentioned other distortion could be investigated, so I am wondering if the larger probability mass is put on larger dt, what the performance will become.\n4. The code should be released. I think that it is a fundamental framework deserving further development  by other researchers.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Very strong",
            "review": "The authors propose TD-VAE to solve an important problem in agent learning, simulating the future by doing jumpy-rollouts in abstract states with uncertainty. The authors first formulate the sequential TD-VAE and then generalize it for jumpy rollouts. The proposed method is well evaluated for four tasks including high dimensional complex task.\n\nPros.\n- Advancing a significant problem\n- Principled and quite original modeling based on variational inference\n- Rigorous experiments including complex high dimensional experiments\n- Clear and intuitive explanation (but can be improved further)\n\nCons. \n- Some details on the experiments are missing (due to page limit). It would be great to include these in the Appendix. \n- It is a complex model. For reproducibility, detail specification on the hyperparameters and architecture will be helpful.\n\nMinor comments\n- Why q(z_{t-1}|z_t, b_{t-1}, b_t) depends both  b_{t-1}, b_t, not only b_t?\n- The original model does not take the jump interval as input. Then, it is not clear how the jump interval is determined in p(zâ€™|z)?\n",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "TD-VAE",
            "review": "There are several ingredients in this paper that I really liked. For example, (1) the notion that an agent should build a deterministic function of the past which implicitly captures the belief (the uncertainty or probability distribution about the state), by opposition for example to sampling trajectories to capture uncertainty, (2) modelling the world's dynamic in a learned encoded state-space (by opposition to the sensor space), (3) instead of modeling next-step probabilities p(z(t+1)|z(t)), model 'jumpy transitions' p(z(t+delta)|z(t)) to avoid unrolling at the finest time scale.\n\nNow for the weak points:\n(a) the justification for the training loss was not completely clear to me, although I can see that it has a variational flavor\n(b) there is no discussion of the issue that we can't get a straightforward decomposition of the joint probability over the data sequence according to next-step probabilities via the chain rule of probabilities, so we don't have a clear way to compare the TD-VAE models with jumpy predictions against other more traditional models\n(c) none of the experiments make comparisons against previously published models and quantitative results (admittedly because of (b) this may not be easy).\n\nSo I believe that the authors are onto a great direction of investigation, but the execution of the paper could be improved.",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}