{
    "Decision": {
        "metareview": "The reviewers all agree that the idea is interesting, the writing clear and the experiments sufficient. \n\nTo improve the paper, the authors should consider better discussing their meta-objective and some of the algorithmic choices. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Oral)",
        "title": "Well written paper with an interesting idea"
    },
    "Reviews": [
        {
            "title": "an interesting approach to meta-learning, clear accept",
            "review": "This paper introduces a novel meta-learning approach to unsupervised representation learning where an update rule for a base model (i.e., an MLP) is meta-learned using a supervised meta-objective (i.e., a few-shot linear regression from the learned representation to classification GTs). Unlike previous approaches, it meta-learns an update rule by directly optimizing the utility of the unsupervised representation using the meta-objective. In the phase of unsupervised representation learning, the learned update rule is used for optimizing a base model without using any other base model objective. Experimental evaluations on few-shot classification demonstrate its generalization performance over different base architectures, datasets, and even domains.  \n\n+  Novel and interesting formulation of meta-learning by learning an unsupervised update rule for representation learning. \n+  Technically sound, and well organized overall with details documented in appendixes. \n+  Clearly written overall with helpful schematic illustrations and, in particular, a good survey of related work. \n+ Good generalization performance over different (larger and deeper) base models, activation functions, datasets, and even a different modality (text classification).\n\n-  Motivations are not very clear in some parts. E.g., the reason for learning backward weights (V), and the choice of meta-objective.  \n- Experimental evaluation is limited to few-shot classification, which is very close to the meta-learning objective used in this paper. \n- The result of text classification is interesting, but not so informative given no further analysis. E.g., why domain mismatch does not occur in this case?\n\nI enjoyed reading this paper, and happy to recommend it as a clear accept paper. The idea of meta-learning update networks looks a promising direction worth exploring, indeed. \nI hope the authors to clarify the things I mentioned above. Experimental results are enough considering the space limit, but not great. Since the current evaluation task is quite similar to the meta-objective, evaluations on more diverse tasks would strengthen this paper. \n\nFinally, this paper aims at unsupervised representation learning, but it’s not clear from the current title, which is somewhat misleading. I think that's quite an important feature of this paper, so I highly recommend the authors to consider a more informative title, e.g., `Learning Rules for Unsupervised Representation Learning’ or else. ",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Novel idea of learning rules for unsupervised learning, need more theory/evidences on what/why meta objectives are sufficient for learning the unsupervised learning rules",
            "review": "This work brings a novel meta-learning approach that learns unsupervised learning rules for learning representations across different modalities, datasets, input permutation, and neural network architectures. The meta-objectives consist of few shot learning scores from several supervised tasks. The idea of using meta-objectives to learn unsupervised representation learning is a very interesting idea.\n\nAuthors mentioned that the creation of an unsupervised update rule is treated as a transfer learning problem, and this work is focused on learning a learning algorithm as opposed to structures of feature extractors. Can you elaborate on what aspect of learning rules and why they can be transferable among different modalities and datasets? For this type of meta-learning to be successful, can you discuss the requirements on the type of meta-objectives? Besides saving computational cost, does using smaller input dimensions favor your method over reconstruction type of semi-supervised learning, e.g. VAE?\n\nIn the section \"generalizing over datasets and domains\", the accuracy of supervised methods and VAE method are very close. This indicates those datasets may not be ideal to evaluate semi-supervised training.\n\nIn the section \"generalizing over network architectures\", what is the corresponding supervised/VAE learning accuracy?\n\nIn the experimentation section, can you describe in more details how input permutations are conducted? Are they re-sampled for each training session for tasks? If the input permutations are not conducted, will the comparison between this method, supervised and VAE be different?\n\nAfter reviewing the author response, I adjusted the rating up to focus more on novelty and less on polished results.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "substantial step towards good unsupervised and local learning",
            "review": "The paper describes unsupervised learning as a meta-learning problem: the observation is that unsupervised learning rules are effectively supervised by the quality of the representations that they yield relative to subsequent later semi-supervised (or RL) learning. The learning-to-learning algorithm allows for learning network architecture parameters, and also 'network-in-networks' that determine the unsupervised learning signal based on pre and post activations. \n\nQuality \nThe proposed algorithm is well defined, and it is compared against relevant competing algorithms on relevant problems. \nThe results show that the algorithm is competitive with other approaches like VAE (very slightly outperforms).\n\nClarity\nThe paper is well written and clearly structured. The section 5.4 is a bit hard to understand, with very very small images. \n\nOriginality\nThere is an extensive literature on meta-learning, which is expanded upon in Appendix A. The main innovation in this work is the parametric update rule for outer loop updates, which does have some similarity to the old work by Bengio in 1990 and 1992. \n\nSignificance\n- pros clear and seemingly state-of-the-art results, intuitive approach, \n-cons only very modestly better than other methods. I would like to get a feel for why VAE is so good tbh (though the authors show that VAE has a problem with objective function mismatch).\n\nOne comment: the update rule takes as inputs pre and post activity and a backpropagated error; it seems natural to also use the local gradient of the neuron's transfer function here, as many three or four factor learning rules do. ",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}