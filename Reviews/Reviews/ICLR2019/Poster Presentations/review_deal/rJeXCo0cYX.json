{
    "Decision": {
        "metareview": "This paper presents \"BabyAI\", a research platform to support grounded language learning. The platform supports a suite of 19 levels, based on *synthetic* natural language of increasing difficulties. The platform uniquely supports simulated \"human-in-the-loop\" learning, where a human teacher is simulated as a heuristic expert agent speaking in synthetic language.   \n\nPros:\nA new platform to support grounded natural language learning with 19 levels of increasing difficulties. The platform also supports a heuristic expert agent to simulate a human teacher, which aims to mimic \"human-in-the-loop\" learning. The platform seems to be the result of a substantial amount of engineering, thus nontrivial to develop. While not representing the real communication or true natural language, the platform is likely to be useful for DL/RL researchers to perform prototype research on interactive and grounded language learning. \n\nCons:\nEverything in the presented platform is based on synthetic natural language. While the use of synthetic language is not entirely satisfactory, such limit is relatively common among the simulation environments available today, and lifting that limitation is not straightforward. The primary contribution of the paper is a new platform (resource). There are no insights or methods.\n\nVerdict:\nPotential weak accept. The potential impact of this work is that the platform will likely be useful for DL/RL research on interactive and grounded language learning.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "a new platform that supports interactive and grounded language learning"
    },
    "Reviews": [
        {
            "title": "Studies grounded language learning with a human in the loop by removing the human (and natural language)",
            "review": "This paper focuses on grounded language learning with a human in the loop, in the sense where the language is synthetic, the environment is a 2D grid world, and the human is a simulated human teacher implemented using heuristics. This setup is dubbed the BabyAI platform, and includes curriculum learning over 19 levels of increasing difficulty.  \n\nOverall, the BabyAI platform is conceptually similar to numerous previous works that seek to learn grounded language in simulation environments. These efforts differ along various axes, for example visual realism, 2D vs 3D, partially vs. fully observed, different tasks, world-state manipulation or not, etc. The main original aspect of the BabyAI platform is the simulated human-teacher. \n\nStrengths\n- Learning with a human in the loop is an extremely important problem to study, although currently efforts are hampered by cost, lack or reproducibility, and the sample inefficiency of existing learning methods. This paper addresses all three of these issues, albeit by removing the human and natural language. This is simultaneously the greatest weakness of this approach. The contribution of this paper therefore rests on the quality/interestingness/utility of the provided synthetic language and the synthetic teacher.\n- Fortunately, the synthetic language does exhibit interesting compositional properties, it is readily extensible, it has the appealing property that it can be readily interpreted as a subset of english, and it is accompanied by a verifier to check if the specified actions were completed. \n\nWeaknesses\n- If the ultimate goal is learning with a human in the loop, the usefulness of the synthetic teacher is not clear, particularly as it is apparently easier to imitate from an RL trained agent than the teacher. The explanation 'This can explained by the fact that the RL expert has the same neural network architecture as the learner' does no seem obvious to me. \n- Regarding the human in the loop, since this is aspirational and not an aspect of the paper, the title of the paper does not seem reflective of its content (even with the 'First steps' qualifier). \n- If the main unique aspect is the simulated human-teacher, it is not clear why it is necessary to create a new environment, rather than re-using an existing environment. The effect of this is to limit comparisons with recent work and an increasing fragmentation of research across tasks that are related but canâ€™t be compared.\n\nSummary:\nThis paper represents an important direction, in that it provides a testbed for studying the sample efficiency of grounded language learning in a simplified (yet still challenging and compositional) environment. I believe the environment and the provided synthetic language and verifier will prove useful to the community, and despite some reservations about the title and the simulated human-teacher, I recommend acceptance.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "New platfrom for research",
            "review": "Summary:\nThis paper presents a research platform with a simulated human (a.k.a bot) in the loop for learning to execute language instructions in which language has compositional structures. The language introduced in this paper can be used to instruct an agent to go to objects, pick up objects, open doors, and put objects next to other objects. MiniGrid is used to build the environments used for this platform. In addition to introducing the platform, they evaluate the difficulty of each level by training an imitation learning baseline using one million demonstration episodes for each level and report results. Moreover, the reported results contain data efficiencies for imitation learning and reinforcement learning based approaches to solving BabyAI levels. \n\nA platform like this can be very useful to expedite research in language learning, machine learning, etc. In my view, work like this should be highly encouraged by this conference and alike.  \n\nComments:\n1.  There are following papers should be cited as they are very related to this paper:\n    a) Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments\n        https://arxiv.org/abs/1711.07280 \n    b) AI2-THOR: An Interactive 3D Environment for Visual AI\n         https://arxiv.org/abs/1712.05474 \n2. Paper is well-written and easy to follow. The only part which needs an improvement is section 3.4 as the text is a bit confusing.\n3. Heuristic expert, simulated human, human, and bot are exchangeably used in the text. It is better to pick one of these to avoid any confusion in the text. In general, it is not clear to why 'a human in the loop' is chosen, isn't just a program/bot that has is engineered using knowledge of the tasks?\n4. In Table 5, in GoToObjMaze row, data efficiency for \"With Pretraining\" is greater than \"Without Pretraining\", is this a typo? if not, why this is the case?\n5. One useful baseline which can be added to this paper is task-oriented language grounding. This task will be a better measure than current baselines, especially for RL case. Authors can check out the following paper:\nGated-Attention Architectures for Task-Oriented Language Grounding\nhttps://arxiv.org/abs/1706.07230\nThe code is available for this paper. \n\nQuestion:\nWhen this platform will be available for public? ",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting direction and open-source platform, but paper falls short of human evaluation",
            "review": "Summary\n\nThe authors introduce BabyAI, a platform with the aim to study grounded language learning with a human in the loop. The platform includes a *simulated* human expert (bot) that teaches a neural learner. The current domain used in a 2D gridworld and the synthetic instructions require the agent to navigate the world (including unlocking doors) and move objects to specified locations. They also introduce \"Baby Language\" to give instructions to the agent as well as to automatically verify their execution.\n\nThe paper includes a detailed description of the minigrid env with the included tasks and instruction language set. \n\nAuthors trained small and large LSTM models on the tasks on a variety of standard learning approaches, using pure exploration (RL) and imitation from a synthetic bot (IL). They show IL is much more data efficient than RL in this domain as well. Also, a curriculum approach is evaluated (pre-train on task 1-N, then train on task N+1).  \n\nPro\n- Human-in-the-loop research is an exciting direction.\n- The language instruction set is a starting point for high-level human instructions. \n\nCon\n- It is still unclear how to effectively learn with human-in-the-loop. The authors don't actually evaluate \n1) how well the bot imitates a human, or \n2) how an actual human would interact and speed up learning. \nAll experiments are done with standard learning approaches with a synthetic bot. \n- The authors assume that human feedback comes as instructions or demonstrations. These are not the only forms of feedback possible (e.g., preferences). (Does the platform easily support those?)\n\nReproducibility\n- Open-sourcing the platform is a good contribution to the community.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}