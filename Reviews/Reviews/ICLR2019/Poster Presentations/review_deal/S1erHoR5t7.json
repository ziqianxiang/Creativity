{
    "Decision": {
        "metareview": "All authors agree that the relativistic discriminator is an interesting idea, and a useful proposal to improve the stability and sample quality of GANs. In earlier drafts there were some clarity issues and missing details, but those have been fixed to the satisfaction of the reviewers. Both R1 and R3 expressed a desire for a more theoretical justification of why the relativistic discriminator should work better, but the empirical results are strong enough that this can be left for future work.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "A useful improvement for GAN training"
    },
    "Reviews": [
        {
            "title": "Tweak on the Standard GAN",
            "review": "The paper describes an interesting tweak of the standard GAN model (inspired by IPM based GANs) where both the generator and the discriminator optimize relative realness (and fakeness) of the (real, fake) image pairs. The authors give some intuition for this tweak and ran experiments with CIFAR10 and CAT datasets. Different variants of the standard GAN and the new tweak were compared under the FID metric. The experimental setup and details are provided; and the code is made publicly available. \n\nThe results are good and their tweak seems to help in most of the cases. The paper, however, is not very well written and is not of publication quality.  All the insights given in Section 3 are wrong, incomplete and unsatisfying. For example, in Section 3.4, the authors suggest that gradient dynamics of the tweaked model (with some unrealistic and infeasible assumptions) is same as that of an IPM-GAN and contribute to stability. This is wrong. Similar dynamics (even under the unrealistic assumption), does not imply similar performance. In fact, if one is trying to move towards IPM dynamics, then one should try to tweak an IPM model directly. Section 3.2 also seems wrong from my understanding of GAN training. Section 3.3 could also be improved. In fact, any explanations based on minimizing JS divergence is incomplete without answering as to why JS divergence minimizing is the best thing to do. \n\nThe author should have provided more comparison images to rule out the fact that the tweak is not overfitting for the FID metric. The benchmarks are also weak and more experiments need to be done (Eg, CelebA). ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Interesting idea",
            "review": "The paper proposes a “relativistic discriminator” which has the property that the probability of real data being real decreases as the probability of fake data being real increases. \n\nThe paper is very well-written. I particularly liked Section 3 which motivates the key idea through multiple viewpoints. The experiments show that the relativistic discriminator helps in some settings, although it does seem a bit sensitive to hyperparameters, architectures and datasets.\n\nI found the argument about connections to IPM-GANs a bit confusing. In a couple of places in Section 4, the relativistic loss is motivated by showing that the relativistic discriminator makes SGANs more like IPM-GANs. However, not all IPM-GANs are the same, e.g. the experiments show performance gaps between RSGAN, RaSGAN, and WGAN-GP, which suggests there could be other confounding factors. \n\nCould you devise experiments on synthetic datasets where the different hypotheses in Section 3 might lead to different solutions? Would be very interesting to see which hypothesis best explains why relativistic discriminator helps!\n\nSection 4.3: How do you justify the averaging? While the relativistic GAN is well-explained, section 4.3 only briefly mentions the averaging idea. Given that averaging seems to help a lot in some of the experiments, it’d be great to see further discussion of why this helps.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "  Review: The relativistic Discriminator: A key element missing from standard GAN",
            "review": "\nIn this work, the authors considers a variation of GAN by consider simultaneously decrease the probability that real data is real for the generator. To include such a property, the authors propose a relativistic discriminator which estimate the probability that the given real data is more realistic than the fake data. Numerical results are performed to show that the proposed methods are effective, and the resulting GANs are relatively more stable and generate higher quality data samples than their non-relativistic counterparts.\n\nOverall the paper is well written and the rationale behind the proposed modification is clear. In particular, the authors use three different perspective, (the prior knowledge, the divergence minimization, and the gradient expressions), to explain what they thought is missing in the state-of-the-art. By proposing to utilize the information about both real and fake data in the discriminator definition, the authors’ have (to some extent) alleviated the above shortcoming of the state-of-the-art.  Unfortunately, like almost all papers related to the field,  there has been no rigorously justification behind the proposed methods. \n\nThe English of the paper has to be significantly improved. For example, grammar errors like “this mean….”, “didn’t converge, …”\n\nUnfortunately, the codes of the paper is not released, I will encourage the authors to do so. \n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}