{
    "Decision": {
        "metareview": "The paper presents an interesting theoretical analysis by deriving polynomial sample complexity bounds for the training of GANs that depend on the approximator properties of the discriminator.\nEven if it is not clear if the theory will help to pick suitable discriminators in practice, it provides\nnew and interesting theoretical insights on the properties of GAN training.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Interesting theoretical work proving sample complexity bounds for GAN training"
    },
    "Reviews": [
        {
            "title": "Interesting theoretical work on establishing sample complexity bounds for learning certain distributions using GANS",
            "review": "This paper explores how discriminators can be designed against certain generator classes to reduce mode collapse. The strength of the paper is on establishing the sample complexity bounds for learning such distributions to show why they can be effectively learned. The work is important in understanding the behaviour of GANs. The work is original and significant. A few comments that need to be addressed are listed as below:\n\n1. I found the paper is a bit hard to follow in the beginning, due to its structure. In Section 1, it first gives introduction and then talks about the novelty of the paper; it then shows more background work followed by more introduction of the proposed work; after that, Section 1.4 talks more related work. It makes reading confusing in the beginning.\n\n2. The authors wrote that \"In practice, parametric families of functions F such as multi-layer neural networks are used for approximating Lipschitz functions, so that we can empirically optimize this objective eq. (2) via gradient-based algorithms as long as distributions in the family G have parameterized samplers. (See Section 2 for more details.)\" I am not sure how Section 2 gives more details.\n\n3. There are some typos and the references are not very carefully edited. For example, in Theorem 4.5, \"the exists a ...\" -> \"there exists a ...\"; in reference, gan -> GAN.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Proposes the notion of restricted approximability, and provides a sample complexity bound, polynomial in the dimension, for GANs. Whether it proposes use of properly-designed discriminator architecture in GAN learning is not clear enough.",
            "review": "\n[pros]\nThis paper proposes the notion of restricted approximability, and provides a sample complexity bound, polynomial in the dimension, for GANs.\nThe proposal is especially useful in investigating possible cause of the lack of diversity in GANs.\n\n[cons]\nWhether it proposes use of properly-designed discriminator architecture in GAN learning is not clear enough.\nThe claimed ability of the proposed method to avoid mode collapse is not directly addressed in the experiments presented in the appendices.\n\n[quality]\nThe contents of Section 3 may be useful as case studies but are not used in the following sections on neural network generators. It would thus be better to include experimental results into the main part of the paper rather than the current contents in Section 3.\n\n[clarity]\nIn most parts of this paper, the authors seem to propose designing a proper discriminator architecture according to the generator class, and the discriminator architecture is to be used in GAN learning. It seems, however, that a \"properly-designed discriminator architecture\" is not used at all in the experiments in Appendix F. A comparison between a \"properly-designed discriminator architecture\" and a \"vanilla fully-connected distriminator\" is found in Appendix G.4, where the advantage of the former seems marginal. The authors also seem to use the proposal not to improve GAN learning but rather as a tool for evaluation, in order to see whether the lack of diversity in GANs comes either from failure of properly evaluating the Wasserstein distance or from insufficient optimization in learning. These two distinct subjects are discussed in a mixed way, which reduces clarity of the presentation.\nIn the experiments in Appendix G, it is claimed that a discriminator with the architecture specified in Lemma 4.1 is used in GAN learning, but either weight clamping or gradient penalty is used as well. It is unclear how the specifications in Lemma 4.1 for the parameter $\\phi$ are combined with weight clamping or gradient penalty.\nSome statements include forward reference, which obscure readability. For example, in the last paragraph of Section 1.1 \"the statistical properties of GANs\" are mentioned without an explicit statement as to what they mean, which are given later in page 3, lines 6-12. As another example, in the third paragraph of Section 1.3 the authors start discussing the KL-divergence, but at this point it is not evident at all why they do it. It is not until Section 4.1 that the reader can understand the reason by observing that the main theorem (Theorem 4.2) is proved by making use of KL-divergence.\n\n[originality]\nThe idea of introducing the notion of restricted approximability and discussing a sample complexity bound, polynomial in the dimension, for GANs are considered original.\n\n[significance]\nThe whole arguments in this paper are based on the assumption that both $p$ and $q$ are in the class $\\mathcal{G}$. In the context of GAN learning, it poses no problem for the generator since we explicitly parameterize it, for example using a neural network, but in practice there is no guarantee that the target distribution also belongs to the same class, and this point would affect significance of the proposal. One may argue that when one employs a certain neural network architecture for the generator one expects that the target distribution is well expressed by a network with the prescribed architecture. But the question as to what will happen when the target distribution does not belong to the class $\\mathcal{G}$ remains. In any case, no discussion is presented in this paper as for this question.\n\n[minor points]\nPage 3, line 45: for low-dimensional (dimensions -> distributions)\n\nPage 4, line 8: Remove the parentheses enclosing Lopez-Paz & Oquab, 2016.\n\nPage 4, lines 20-21: Duplicate parentheses.\n\nPage 4, line 7: the true and estimated distribution(s) exist.\n\nPage 5, line 33: the lower and upper bound(s) differ\n\nPage 7, line 9: What do \"some assumptions\" refer to?\n\nPage 8, line 44: The(re) exists a discriminator class\n\nPage 19, line 1: there exi(s)ts a coupling",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good paper",
            "review": "This paper analyzes that the Integral Probability Metric (IPM) can be a good approximation of Wasserstein distance under some mild assumptions. They first showed two theorems based on simple cases (Gaussian Distribution and Exponential Families). Then, they proved that, for an invertible generator, a special designed neural network can approximate Wasserstein distance with IPM. The main contribution is that, for a stable generator (i.e., invertible generator), a discriminator can reversely “re-visit” inner status of the generator, then use this information to make a decision. \n\nIn the appendix, several numerical examples are presented to support their theoretical bound. \n\nQ: Assumption 1, \\sigma(t) is twice differentiable. However, Leaky ReLU is not twice differentiable at t=0. Do I misunderstand some part?\n\nQ: The invertible generator assumption is not held in practice. Is that possible to extend the theorem to this case, even with a shallow network (e.g. 2 layers)?\n\nQ: The numerical examples are all based on synthetic data. Did you have any results based on the real dataset?\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}