{
    "Decision": {
        "metareview": "this submission follows on a line of work on online learning of a recurrent net, which is an important problem both in theory and in practice. it would have been better to see even more realistic experiments, but already with the set of experiments the authors have conducted the merit of the proposed approach shines. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "accept"
    },
    "Reviews": [
        {
            "title": "limited empirical evidence",
            "review": "The paper proposes an alternative to backprop through time for\ntraining RNN models.\n\nThe paper is reasonably well written, but somewhat dense and hard\nto follow.  The contribution seems novel.\n\nThe main issue is the empirical evaluation.  All of the tasks\n(masked addition, pixel-by-pixel MNIST, and the AnBn problem)\nare artificial.\n\nIn addition, the results on some of the tasks are mixed if not\nin favor of BPTT.  I am not convinced that these results are enough\nto showcase the practical advantages of KeRL.\n\nI am willing to increase my score, if the authors address this\nissue.\n\nDetailed comments:\n\n- The authors mention that BPTT is not biologically plausible.  Although\n  reasonable, I don't get why this would be an argument against it.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "Interesting evidence that extreme approximations to BPTT can work",
            "review": "This paper proposes a simple method for performing temporal credit assignment in RNN training.  While it seems somewhat naive and unlikely to work (in my opinion), the experimental results surprisingly show reasonable performance on several reasonably challenging artificial tasks.\n\nThe core of the approach is based on equation 7, which approximates the Jacobian between different hidden states at different time-steps as a single adaptively-learned matrix times a decay factor that depends on the time gap.  While this seems like a very severe approximation to make the authors speculate that some kind of feedback alignment-like mechanism might be at play.\n\nThe presentation needs work in several areas, and the experimental results require more explanation, but otherwise this seems like a solid paper.  I would probably increase my rating if the authors could address my issues satisfactorily. \n\n\nSee below for more detailed comments:\n\nAbstract & Section 1: \n\nIs \"sensitivity tensor\" or \"credit assignment tensor\" common term?  Because I've never heard them before.  Consider defining them before you discuss it, and using consistent jargon.  Later in Section 2 you seem to call this the \"RTRL tensor\" (whose meaning I can infer).  \n\nSection 2:\n\nGradient vanishing isn't so much a problem in itself, but a symptom that the sensitivity of the network's output to the action of some neuron in the past is very low. Ths gradient is just relaying this information, so I don't really see vanishing gradients as the problem to overcome, but rather low sensitivity on past activations.\n\nSection 3: \n\nDid you mean to write (W^out h^t + b^out) instead of (W^out h + b^out)^t ?\n\n\"[equation] represents the gradient of the cost with respect to the current hidden state\".  The RHS of this equation makes no sense to me.  Not only does this not depend on the nonlinearity in any way, it doesn't include any consideration of future outputs on which the current h surely depends. \n\nIt would make the paper much more pleasant to read if you gave your derivation of the learning rule before you stated it in gory detail.  It feels almost completely arbitrary reading it first without any justification. This might be fine if it were compact and elegant, but it's not.\n\nConsider using exp(x) instead of e^x since the symbol e already means something else in your notation.\n\nSection 4:\n\nPlease define \"temporal variation\"\n\n\nSection 5:\n\nYou should elaborate on the experimental setup you used.  Especially for the Addition and MNIST problems.  For example, what consistutes a \"step\" in figure 2?  Does KeRL take \"one\" step per time-step?  Or does \"step\" mean a complete gradient computation from running from t = 1 to t= T?  Is the BPTT truncated?  Are you counting one step of BPTT to be one complete forwards and backwards pass?\n\nYou should include some basic description of what an IRNN is.\n\nWhen you say that for MNIST that KeRL \"does not converge to as good of an optimum\" this seems like unjustified inference.  You don't really know that it is converging to a minimum of the original objective at all.  It could be converging to the minimum of some other objective it is implicitly optimizing due to your approximations (if one even exists).  Or it could be simply cycling around and failing to converge.  The fact that the loss plateaus isn't direct evidence of convergence in any sense.  If you wanted to measure this more directly you could look at the (true) gradient magnitude.\n\n\"only requires a few tensor operations at each time step\" -> this is also true of UORO",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An interesting idea of improving BPTT by kernel recurrent learning. Skip in backpropagation is proposed and illustrated.",
            "review": "The proposed kernel recurrent learning (KeRL) provides an alternative way to train recurrent neural network with backpropagation through time (BPTT) where the propagation of gradients can be skipped over different layers. The authors directly assume the sensitivity function between two layers with a distance of tau in a form of Eq. (7). The algorithm of BPTT is then approximated due to this assumption. The model parameters are changed to learn the network dynamics. The optimization problem turns out to estimate beta and gamma of the kernel function. The learned parameters are intuitive. There are a set of timescales to describe the memory of each neuron and a set of sensitivity weights to describe how strongly the neurons interact on average. The purpose of this study is to save the memory cost and to reduce the time complexity for online learning with comparable performance. \n\nPros:\n1. KeRL only needs to compute a few tensor operations at each time step, so online KeRL learns faster than online BPTT for the case with a reasonably long truncation length.\n2. Biologically plausible statements are addressed.\n3. A prior is imposed for the temporal sensitivity kernel. The issue of gradient vanishing is mitigated.\n4. Theoretical illustration for KeRL in Sections 3 and 4 is clear and interesting.\n\nCons:\n1. The proposed method is an approximation to BPTT training. Suppose the system performance is constrained. Some guesses are made. The system performance can be further improved.\n2. The experiment on time cost due to online learning is required so that the reduction of time complexity can be illustrated.\n3. The format of tables 1 and 2 can be improved. Caption is required in Table 1. Overlarge size of Table 2 can be fixed.\n4.  A number of assumptions in Sections 3 and 4 are assumed.  When addressing Section 3, some assumptions in Section 4 are used. The organization of Sections 3 and 4 can be improved.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}