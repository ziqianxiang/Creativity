{
    "Decision": {
        "metareview": "The reviewers all feel that the paper should be accepted to the conference.  The main strengths that they noted were the quality of writing, the wide applicability of the proposed method and the strength of the empirical evaluation.  It's nice to see experiments across a large number of problems (100), with corresponding code, where baselines were hyperparameter tuned as well.  This helps to give some assurance that the method will generalize to new problems and datasets.    Some weaknesses noted by the reviewers were computational cost (the method is significantly slower than the baselines) and they weren't entirely convinced that having more concise representations would directly lead to the claimed interpretability of the approach.  Nevertheless, they found it would make for a solid contribution to the conference.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Well written paper on learning concise representations for regression with strong empirical evaluation"
    },
    "Reviews": [
        {
            "title": "A solid method for learning interpretable networks, though with a large computational cost",
            "review": "# Summary\nThe paper presents a method for learning network architectures for regression tasks. The focus is on learning interpretable representations of networks by enforcing a concise structure made from simple functions and logical operators. The method is evaluated on a very large number of regression tasks (99 problems) and is found to yield very competitive performance.\n\n# Quality\nThe quality of the paper is high. The method is described in detail and differences to previous work are clearly stated. Competing methods have been evaluated in a fair way with reasonable hyperparameter tuning.\n\nIt is very good to see a focus on interpretability. The proposed method is computationally heavy, as can be seen from figure 7 in the appendix, but I see the interpretability as the main benefit of the method. Since many applications, for which interpretability is key, can bear the additional computational cost, I would not consider this a major drawback. However, it would be fair to mention this point in the main paper.\n\n# Clarity\nThe paper reads well and is nicely structured. The figures and illustrations are easy to read and understand.\n\n# Originality\nThe paper builds on a large corpus of previous research, but the novelties are clearly outlined in section 3. However, the presented method is very far from my own field of research, so I find it difficult to judge exactly how novel it is.\n\n# Significance\nThe proposed method should be interesting to a wide cross-disciplinary audience and the paper is clearly solid work. The focus on interpretability fits well with the current trends in machine learning. However, the method is far from my area of expertise, so I find it difficult to judge the significance.\n",
            "rating": "7: Good paper, accept",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "This paper lacks technical novelty and experimental result is incomplete.",
            "review": "This paper introduces a genetic algorithm that maintains an archive of representations that are iteratively evolved and selected by comparing validation error. Each representation is constructed as a syntax tree consists of elements that are common in neural network architectures. The experimental results showed that their algorithm is competitive to the state-of-the-art while achieving much smaller model size.\n\nComments:\n1. I think this paper lacks technical novelty. I'm going to focus on experimental result in the following two questions.\n2. FEAT is a typical genetic algorithm that converges slowly. In the appendix, one can verify that FEAT converges at least 10x slower than XGBoost. Can FEAT achieve lower error than XGBoost when they use the same amount of time? \nCan the authors provide a convergence plot of their algorithm (i.e. real time vs test error)?\n3. From Figure 3 it seems that the proposed algorithm is competitive to XGBoost, and the model size is much smaller than XGBoost. Have the authors tried to post-processing the model generated by XGBoost? How's the performance compare?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting method with very promising results.",
            "review": "The paper proposes a method for learning regression models through evolutionary\nalgorithms that promise to be more interpretable than other models while\nachieving similar or higher performance. The authors evaluate their approach on\n99 datasets from OpenML, demonstrating very promising performance.\n\nThe authors take a very interesting approach to modeling regression problems by\nconstructing complex algebraic expressions from simple building blocks with\ngenetic programming. In particular, they aim to keep the constructed expression\nas small as possible to be able to interpret it easier. The evaluation is\nthorough and convincing, demonstrating very good results.\n\nThe presented results show that the new method beats the performance of existing\nmethods; however, as only very limited hyperparameter tuning for the other\nmethods was performed, it is unclear to what extent this will hold true in\ngeneral. As the main focus of the paper is on the increased interpretability of\nthe learned models, this is only a minor flaw though.\n\nThe interpretability of the final models is measured in terms of their size.\nWhile this is a reasonable proxy that is easy to measure, the question remains\nto what extent the models are really interpretable by humans. This is definitely\nsomething that should be explored in future work, as a small-size model does not\nnecessarily imply that humans can understand it easily, especially as the\ngenerated algebraic expressions can be complex even for small trees.\n\nThe description of the proposed method could be improved; in particular it was\nunclear to this reviewer why the features needed to be differentiable and what\nthe benefit of this was (i.e. why was this the most appropriate way of adjusting\nweights).\n\nIn summary, the paper should be accepted.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}