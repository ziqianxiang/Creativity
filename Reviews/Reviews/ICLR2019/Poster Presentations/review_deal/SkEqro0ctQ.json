{
    "Decision": {
        "metareview": "The paper receives a unanimous accept over reviewers, though some concerns on novelty exist. So it is suggested to be a probable accept. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Unanimous accept. "
    },
    "Reviews": [
        {
            "title": "Interesting hierarchical approach to explainability",
            "review": "This paper proposes a hierarchical extension of contextual decomposition. The approach is validated in qualitative examples and a small scale usability study\n\nQuality, \nThe paper is well motivated. Contextual decomposition is briefly described but detailed enough to self-contained. The experimental evaluation produces usability evidence. Uncertainty could have been better explained, \n\nClarity, \nThe main methodological contribution (hierarchical CD) is well motivated but only  provided in the form of an algorithm. Could have been more precisely described and optimality discussed. \n\nOriginality & significance\nThe work builds heavily on CD but has the hierarchical extension is original and significant. \nUncertainty estimates could have improved the significance of the usability study\n\npros and cons\n+ interesting problem\n+ well-motivated algorithmic extension of CD\n- uncertainty of usability experiment?\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Contextual decomposition for general DNNs",
            "review": "**Summary**\n\nIn this paper, the authors extend an existing feature interpretation method for LSTMs to more generic DNNs. They introduce a hierarchical clustering of the input features and the contributions of each cluster to the final prediction. \n\n**Strength**\n\n1. Splitting information into binary groups at each layer is a neat approach to segregate interpretations.\n2. Experiments are elaborate and cover the breadth of the proposed method well.\n3. The paper is well presented and fairly easy to follow. \n\n\n**Weakness**\n\n1. Limited contributions in terms of novelty. This approach for RNNs is presented fairly well in the previous paper [Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs](https://arxiv.org/abs/1801.05453).\n2. It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting idea. Potentially convincing experiments. Limited methodological novelty",
            "review": "This paper proposes a novel approach to explain neural network predictions by learning hierarchical representations of groups of input features and their contribution to the final prediction. The proposed method is a straightforward extension of the contextual decomposition work by (Murdoch et. al. 2018) which estimates feature interpretability for LSTMs. This work extends (Murdoch et. al. '18) to more general NN architectures and further employs agglomerative clustering to identify groups of features-- as opposed to individual features--that are predictive of the output. \n\nResults are shown using a LSTM trained on the standard Stanford sentiment task and a VCG DNN trained on ImageNet which show the superior performance of the proposed approach. In addition, the paper also provides some survey results where \"humans\" were asked to pick more interpretable models. \n\nThe paper is nicely written and puts itself nicely in context of the previous work. Though, I have several concerns:\n\n1). Biggest concern: Conditioning on the (Murdoch et. al. 18) paper, the methodological novelty of the proposed approach is minimal. Though, the experimental gains on the vision and NLP tasks are nice.\n\n2). It was unclear to me how the agglomerative algorithm (Algorithm 1) was run. That is, was it run as part of the LSTM estimation for instance for the sentiment task OR was it run post-hoc after getting the model estimates from LSTM? If it was run post-hoc then I am unsure if we can assume that the \"agglomeratively grouped CD scores of individual features\" are the same as the \"CD scores for the groups/interactions of features\" in terms of their contribution to the final prediction.\n\n3). Though, the paper mentions several times regarding generalizing (Murdoch et. al. 18) to architectures other than LSTMs but still the experimental results on the sentiment task uses an LSTM as the model. It would have been nice to show the comparative strength of the proposed approach on a different architecture even for the sentiment task. (I understand that the paper uses a different DNN architecture for the vision task).\n\n4). The paper talks several times about diagnosing why a model went wrong e.g. the \"negation\" in the case of the LSTM model in Figure 2, but never discusses the bigger and more interesting problem. How can we build an improved LSTM model for the sentiment task which classifies that incorrect prediction correctly? \n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}