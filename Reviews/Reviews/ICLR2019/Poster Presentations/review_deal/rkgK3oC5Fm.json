{
    "Decision": {
        "metareview": "This paper proposes a method to encourage diversity of Bayesian dropout method. A discriminator is used to facilitate diversity, which the method deal with multi-modality. Empirical results show good improvement over existing methods. This is a good paper and should be accepted.\n",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "A good paper to improve diversity of existing Bayesian deep learning methods"
    },
    "Reviews": [
        {
            "title": "Some interesting ideas, clarifications needed",
            "review": "The work proposes a Bayesian neural network model that is a hybrid between autoencoders and GANs, although it is not presented like that. Specifically, the paper starts from a Bayesian Neural Network model, as presented in Gal and Ghahramani, 2016 and makes two modifications.\n\nFirst, it proposes to define one Bernoulli variational distribution per weight kernel, instead  of per patch (in the original work there was one Bernoulli distribution per patch kernel). As the paper claims, this reduces the complexity to be exponential to the number of weights, instead of the number of patches, which leads to a much smaller number of possible models. Also, because of this modification the same variational distributions are shared between locations, being closer to the convolutional nature of the model.\n\nThe second modification is the introduction of synthetic likelihoods. Specifically, in the original network the variational distributions are designed such that the KL-divergence of the true posterior p(ω|X, y) and the approximate posterior q(ω) is minimiezd. This leads to the optimizer encouraging the final model to be close to the mean, thus resulting in less diversity. By re-formulating the KL-divergence, the final objective can be written such that it depends on the likelihood ratio between generated/\"fake\" samples and \"true\" data samples. This ratio can then be approximated by a GAN-like discriminator. As the optimizer now is forced to care about the ratio instead of individual samples, the model is more diverse.\n\nBoth modifications present some interesting ideas. Specifically, the number of variational parameters is reduced, thus the final models could be much better scaleable. Also, using synthetic likelihoods in a Bayesian context is novel, to the best of my knowledge, and does seem to be somewhat empirically justified. \n\nThe negative points of the paper are the following.\n\n- The precise novelty of the first modification is not clearly explained. Indeed, the number of possible models with the proposed approach is reduced. However, what is the degree to which it is reduced. With some rough calculations, for an input image of resolution 224x224, with a kernel size of 3x3 and stride 1, there should be about 90x90 patches. That is roughly a complexity of O(N^2) ~ 8K (N is the number of patches). Consider the proposed variational distributions with 512 outputting channels, this amount to 3x3x512 ~ 4.5K. So, is the advantage mostly when the spatial resolution of the image is very high? What about intermediate layers, where the resolution is typically smaller?\n\n- Although seemingly ok, the experimental validation has some unclarities.\n  + First, it is not clear whether it is fair in the MNIST experiment to report results only from the best sampled model, especially considering that the difference from the CVAE baseline is only 0.5%. The standard deviation should also be reported.\n  + In Table 2 it is not clear what is compared against what. There are three different variants of the proposed model. The WD-SL does exactly on par with the Bayes-Standard (although for some reason the boldface font is used only for the proposed method. The improvement appears to come from the synthetic likelihoods. Then, there is another \"fine-tuned\" variant for which only a single time step is reported, namely +0.54 sec. Why not report numbers for all three future time steps? Then, the fine-tuned version (WD-SL-ft) is clearly better than the best baselines of Luc et al., however, the segmentation networks are also quite different (about 7% difference in mIoU), so it is not clear if the improvement really comes from the synhetic likelihoods or from the better segmentation network. In short, the only configuration that appears to be convincing as is is for the 0.06 sec. I would ask the authors to fill in the blank X spots and repeat fair experiments with the baseline.\n\n- Generally, although the paper is ok written, there are several unclarities.\n  + Z_K in eq. (4) is not defined, although I guess it's the matrix of the z^{i, j}_{k, k'}\n  + In eq (6) is the z x σ a matrix or a scalar operation? Is z a matrix or a scalar?\n  + The whole section 3.4 is confusing and it feels as if it is there to fill up space. There is a rather intricate architecture, but it is not clear where it is used. In the first experment a simple fully connected network is used. In the second experiment a ResNet is used. So, where the section 3.4 model used?\n  + In the first experiment a fully connected network is used, although the first novelty is about convolutions. I suppose the convolutions are not used here? If not, is that a fair experiment to outline the contributions of the method?\n  + It is not clear why considering the mean of the best 5% predictions helps with evaluating the predicted uncertainty? I understand that this follows by the citation, but still an explanation is needed.\n\nAll in all, there are some interesting ideas, however, clarifications are required before considering acceptance.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting improvement to dropout based Bayesian inference",
            "review": "The submission considers a disadvantage of a standard dropout-based Bayesian inference approach, namely the pessimization of model uncertainty by means of maximizing the average likelihood for every data sample. The formulation by Gal & Ghahramani is improved upon two-fold: via simplified modeling of the approximating variational distribution (on kernel/bias instead of on patch level), and by using a discriminator (i.e. classifier) for providing a \"synthetic\" likelihood estimate. The latter relaxes the assumptions such that not every data sample needs to be explained equally well by the models.\nResults are demonstrated on a variety of tasks, most prominently street scene forecasting, but also digit completion and precipitation forecasting. The proposed method improves upon the state of the art, while more strongly capturing multi-modality than previous methods.\n\nTo the best of my knowledge, this is the first work w.r.t. future prediction with a principled treatment of uncertainty. I find the contributions significant, well described, and the intuition behind them is conveyed convincingly. The experiments in Section 4 (and appendix) yield convincing results on a range of problems.\nClarity of the submission is overall good; Sections 3.1-3.3 treat the contributions in sufficient detail. Descriptions of both generator and discriminator for street scenes (Section 3.4) are sufficiently clear, although I would like to see a more detailed description of the training process (how many iterations for each, learning rate, etc?) for better reproducability.\nIn Section 3.4, it is not completely clear to me why the future vehicle odometry is provided as an input, in addition to past odometry and past segmentation confidences. I assume this would not be present in a real-world scenario? I also have to admit that I fail to understand Figure 4; at least I cannot see any truly significant differences, unless I heavily zoom in on screen.\n\nSmall notes:\n- Is the 'y' on the right side of Equation (5) a typo? (should this be 'x'?)\n- The second to last sentence at the bottom of page 6 (\"Always the comparison...\") suffers from weird grammar",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "a nice applied work",
            "review": "The paper presents an application of Bayesian neural networks in predicting \nfuture street scenes. The inference is done by using variational approximation \nto the posterior. Moreover, the authors propose to using a synthetic (approximate)\nlikelihood and the optimization step in variational approxiation is based on a regularization.\nThese modifications are claimed by the authors that it yields a better results in practice \n(more stable, capture the multi-modal nature). Numerical parts in the paper support\nthe authors' claims: their method outperforms some other state-of-the-art methods.\n\nThe presentation is not too hard to follow.\nI think this is a nice applied piece, although I have never worked on this applied side.\n\nMinor comment:\nIn the second sentence, in Section 3.1, page 3, \n$f: x \\mapsto y$    NOT $f: x \\rightarrow y$. \nWe use the \"\\rightarrow\" for spaces X,Y not for variables.  \n\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}