{
    "Decision": {
        "metareview": "This paper investigates a new approach to machine reading for procedural text, where the task of reading comprehension is formulated as dynamic construction of a procedural knowledge graph. The proposed model constructs a recurrent knowledge graph (as a bipartite graph between entities and location nodes) and tracks the entity states for two domains: scientific processes and recipes.\n\nPros:\nThe idea of formulating reading comprehension as dynamic construction of a knowledge graph is novel and interesting. The proposed model is tested on two different domains: scientific processes (ProPara) and cooking recipes.\n\nCons:\nThe initial submission didn't have the experimental results on the full recipe dataset and also had several clarity issues, all of which have been resolved through the rebuttal. \n\nVerdict:\nAccept. An interesting task & models with solid empirical results.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "An interesting task & models with solid empirical results."
    },
    "Reviews": [
        {
            "title": "Good ideas and results, could use some work with explanation",
            "review": "* Summary\nThis paper addresses machine reading tasks involving tracking the states of entities over text. To this end, it proposes constructing a knowledge graph using recurrent updates over the sentences of the text, and using the graph representation to condition a reading comprehension module. The paper reports positive evaluations on three different tasks.\n\n* Review\n\nThis is an interesting paper. The key technical component in the proposed approach is the idea that keeping track of entity states requires (soft) coreference between newly read entities and locations and the ones existing in the knowledge graph constructed so far.\n\nThe proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says. This is especially the case in a few places involving coreference:\n1. The paper says at the top of page 6 that the result of Eq 1 is a disambiguated intermediate node representation.\n2. The self attention in Eq 2 performs coreference disamguation which prevents different instances of the same location from being predicted for multiple entities.\n\nWhile these may indeed be working as advertised, it would be good to see some evaluation that verifies that after learning, what is actually happening is coreference.\n\nWhy does the graph update require coreference pooling again?  Don't the updates in Eq 1 and 2 take care of this? The ablation does not test this, right?\n\nAnother modeling choice that is not clear is regarding how the model processes the text -- reading prefixes of the paragraph, rather than one sentence at a time. What happens if the model is changed to be read one sentence at a time?\n\nThat the model implicitly learns constraints from data is interesting!\n   \nBottomline: The paper presents interesting ideas and good results, but would be better if the modeling choices were better explored/motivated.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Meaningful contribution, but hard to read",
            "review": "The paper proposes a recurrent knowledge graph (bipartite graph between entities and location nodes) construction & updating mechanism for entity state tracking datasets such as (two) ProPara tasks and Recipes. The model goes through the following three steps: 1) it reads a sentence at each time step t and identifies the location of each entity via machine reading comprehension model such as DrQA (entities are predefined). 2) Co-reference module adjusts relationship scores (soft adjacency matrix) among nodes, including possibly new nodes introduced by the MRC model. 3) to propagate the relational information across all the nodes, the model performs L layers of LSTM for each entity that attend on other nodes via attention (where the weights come from the adjacency matrix). The model repeats the three steps for each sentence. The model is trained by directly supervising for the correct span by the MRC model at each time step, which is possible because the data provides strong supervision for each sentence (not just the answer at the end).\n The model achieves the state of the art in the two tasks of ProPara and Recipes dataset.\n\nStrengths: The paper provides an elegant solution for tracking relationship between entities as time (sentence) progresses. I also agree with the authors that this line of work (dynamic KG construction and modification) is an important area of research. While the model shares a similar spirit to EntNet, I think the model has enough distinctions / contributions, especially given that it outperforms EntNet by a large margin. The model also obtains non-trivial improvement over previous SOTA models.\n\nWeaknesses: Paper could have been written better. I had hard time understanding it. The notations are overall confusing and not explained well. Also there are a few unclear parts which I discuss in questions below.\n\nQuestions: \n1. Are e_{i,t} and lambda_{i,t} vectors? Scalars? Abstract node notations? It is not clear in the model section. Also, it took me a long time to figure out that ‘i’ is used to index each entity (it is mentioned later).\n2. The paper says v_i (initial representation of each entity) is obtained by looking at the contextualized representations (LSTM outputs) of entity mention in the context. What happens if there are multiple mentions in the text? Which one does it look at?\n3. For the LSTM in the graph update, why does it have only one input? Shouldn’t it have two inputs, one for previous hidden state and the other for input?\n4. Regarding Recipe experiments, the paper says it reaches a better performance than the baseline using just 10k examples out of 60k. This is great, but could you also report the number when the full dataset is used?\n5. What does it mean that in training time the model “updates” the location node representation with the encoding of correct span. Do you mean you use the encoding instead?\n6. For ProPara task 2, what threshold did you choose to obtain the P/R/F1 score? Is it the threshold that maximizes F1?\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Contributions are novel and convinced about significance",
            "review": "The paper addresses a challenging problem of predicting the states of entities over the description of a process. The paper is very well written, and easily understandable. The authors propose a graph structure for entity states, which is updated at each step using the outputs of a machine comprehension system. The approach is novel and well motivated. I will suggest a few improvements: \n\n1. the NPN model seems a good alternative, will be good to have a discussion about why your model is better than NPN. Also, NPN can probably be modified to output spans of a sentence. I will be curious to know how it performs.\n\n2. A more detailed illustration of the system / network is needed. Would have made it much easier to understand the paper. \n\n3. What are the results when using the whole training set of Recipes ?\n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}