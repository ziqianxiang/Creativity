{
    "Decision": {
        "metareview": "The paper presents a simple and effective convolution kernel for CNNs on spherical data (convolution by a linear combination of differential operators). The proposed method is efficient in the number of parameters and achieves strong classification and segmentation performance in several benchmarks. The paper is generally well written but the authors should clarify the details and address reviewer comments (for example, clarity/notations of equations) in the revision. \n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "decision"
    },
    "Reviews": [
        {
            "title": "Simple and effective idea. ",
            "review": "Summary:\nThe paper proposes a novel convolutional kernel for CNN on the unstructured grids (mesh). Contrary to previous works, the proposed method formulates the convolution by a linear combination of differential operators, which is parameterized by kernel weights. Such kernel is then applied on the spherical mesh representation of features, which is appropriate to handle spherical data and makes the computation of differential operators efficient. The proposed method is evaluated on multiple recognition tasks on spherical data (e.g. 3d object classification and omnidirectional semantic segmentation) and demonstrates its advantages over existing methods.\n\nComments/suggestions:\nI think the paper is generally well-written and clearly delivers its key idea/advantages. However, I hope the authors can elaborate the followings:\n\n1) Analysis of computational cost\nIt would be helpful to elaborate more analysis on computational cost. The proposed formulation seems to involve the second-order derivatives in the backpropagation process (due to the first-order derivatives in Eq.(4)), which can be a computational bottleneck. It will be very useful to provide analysis on computational cost together with parameter efficiency study (Figure 3 and 4).\n\n2) Intuitive justification\nIt would be great if the authors provide more intuitive descriptions on Eq.(4) (and possibly elaborate captions of Figure 1); what is the intuition of using differential operators? Why is it useful to deal with unstructured grids? How does it lead to improvement over the existing techniques?\n\nConclusion: \nOverall, I think this paper has solid contributions; the proposed MeshConv operator is simple but effective to handle spherical data; the experiment results demonstrate its advantages over existing methods on broad applications, which are convincing. I think conveying more intuitions on the proposed formulation and providing additional performance analysis will help readers to understand paper better. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Simple and efficient model on spherical data, large scale experiments need more benchmarks",
            "review": "This article introduces a simple yet efficient method that enables deep learning on spherical data (or 3D mesh projected onto a spherical surface), with much less parameters than the popular approaches, and also a good alternative to the regular correlation based models.\n\nInstead of running patches of spherical filters, the authors takes a weighted linear combination of differential operators applied on the data. The method is shown to be effective on Spherical MNIST, ModelNet, Stanford 2D-3D-S and a climate prediction dataset, reaching competitive/state-of-the-art numbers with much less parameters..\n\nLess parameters is nice, but the argument could be strengthened if the authors could also show impressive results in terms of runtime. Typically number of parameters is not a huge issue for today’s deep networks, but for real-time robotics to be equipped with 3D perception, runtime is a much bigger factor.\n\nI also think that the Stanford 2D-3D-S experiments have some issues:\n\nUNet and FCN-8s are good baselines, but other prior work based on spherical convolution are omitted here. E.g. S2CNN and SphereNet. S2CNN has released their code so it should be benchmarked.\n\nAdditionally, comparison to PointNet++ could be a little unfair. \n\ni) What is the number of points used in PointNet++? The author reported 1000 points for ModelNet which is ok for that dataset but definitely too small for indoor scenes. The original paper used 8192 points for ScanNet indoor scenes.\n\nii) Point-based can have data-augmentation by taking subregions of the panoramic scene, where as sphere-based method can only take a single panoramic image. The state-of-the-art method (PointSIFT) achieves ~70 mIOU on this dataset. PointNet(++) can also achieve 40-50 mIOU. Maybe the difference is at using regular image or panoramic images, but the panoramic image is just a combination of regular images so I wouldn’t expect such a large difference.\n\nIn conclusion, this paper proposes a novel deep learning algorithm to handle spherical data based on differential operators. It uses much less parameters and gets impressive results. However, the large scale experiments has some weaknesses. Therefore I recommend weak accept.\n\n----\nSmall issues / questions:\n\n- Notation lacks clarity. What are x, y in Eqn. 1? The formulation of convolution is not very clear to me, but maybe due to my lack of familiarity in this literature.\n\n- In Figure 1, the terminology of “MeshConv” is first introduced, which should come earlier in the text to improve clarity.\n\n- In the article, the author distinguished their method with S2CNN that their method is not rotation invariant. I don’t understand this part. In the architecture diagram, if average pool is applied across all spherical locations, then why is it not rotation invariant?\n\n===\nAfter rebuttal: \nI thank the authors for addressing the comments in my review. It clarifies the questions I had about on the 2D3DS dataset (panorama vs. 3D points). Overall I feel this is a good model and have solid experiments. Therefore, I raise the score to 7.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "The paper presents a new convolution-like operation for parameterized manifolds, and demonstrates its effectiveness on learning problems involving spherical signals. The basic idea is to define the MeshConvolution as a linear combination (with learnable coefficients) of differential operators (identity, gradient, and Laplacian). These operators can be efficiently approximated using the 1-hop neighbourhood of a vertex in the mesh.\n\nIn general I think this is a strong paper, because it presents a simple and intuitive idea, and shows that it works well on a range of different problems. The paper is well written and mostly easy to follow. The appendix contains a wealth of detail on network architectures and training procedures.\n\nWhat is not clear to me is how exactly the differential operators are computed, and how the MeshConvolution layer is implemented. The authors write that \"differential operators can be efficiently computed using Finite Element basis, or derived by Discrete Exterior Calculus\", but no references or further detail is provided. The explanation of the derivative computation is:\n\"The first derivative can be obtained by first computing the per-face gradients, and then using area-weighted average to obtain per-vertex gradients. The dot product between the per-vertex gradient value and the corresponding x and y vector fields are then computed to acquire grad_x F and grad_y F.\"\nWhat are per-face gradients and how are they computed? Is the signal sampled on vertices or on faces? What area is used for weighting? What is the exact formula? What vector fields are you referring to? (I presume these are the coordinate vector fields). In eq. 5, what are F_i and F_j? What is the intuition behind the cotangent formula (eq. 5), and where can I read more? etc.\n\nPlease provide a lot more detail here, delegating parts to an appendix if necessary. Providing code would be very helpful as well.\n\nA second (minor) concern I have is to do with the coordinate-dependence of the method. Because the MeshConvolution is defined in terms of (lat / lon) coordinates in a non-invariant manner, and the sphere does not admit a global chart, the method will have a singularity at the poles. This is confirmed by the fact that in the MNIST experiment, digits are rotated to the equator \"to prevent coordinate singularity at the poles\". I think that for many applications, this is not a serious problem, but it would still be nice to be transparent and mention this as a limitation of the method when comparing to related work.\n\nIn \"Steerable CNNs\", Cohen & Welling also used a linear combination of basis kernels, so this could be mentioned in the related work under \"Reparameterized Convolutional Kernel\".\n\nTo get a feel for the differential operators, it may be helpful to show the impulse response (at different positions on the sphere if it matters).\n\nIn experiment 4.1 as well as in the introduction, it is claimed that invariant/equivariant models cannot distinguish rotated versions of the same input, such as a 6 and a 9. Although indeed an invariant model cannot, equivariant layers do preserve the ability to discriminate transformed versions of the same input, by e.g. representing a 9 as an upside-down 6. So by replacing the final invariant pooling layer and instead using a fully connected one, it should be possible to deal with this issue in such a network. This should be mentioned in the text, and could be evaluated experimentally.\n\nIn my review I have listed several areas for improvement, but as mentioned, overall I think this is a solid paper.",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}