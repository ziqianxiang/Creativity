{
    "Decision": {
        "metareview": "The proposed method suggests a way to do robust conditional image generation with GANs. The premise is to make the image to image translation model resilient to noise by leveraging structure in the output space, with an unsupervised \"pathway\".\n\nIn general, the qualitative results seem reasonable on a a number of datasets, including those suggested by reviewers. The method appears simple, novel and easy to try.  The main concerns seem to be that the idea is maybe too simple, but I'm not particularly bothered by that. The authors showed it working well on a variety of tasks (synthetic and natural), provide SSIM numbers that look compelling (despite SSIM's short-comings) and otherwise give compelling arguments for the technical soundness of the approach.\n\nThus, I recommend acceptance.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "metareview"
    },
    "Reviews": [
        {
            "title": "Simple but effective method, methodological novelties are limited though!",
            "review": "This manuscript proposes a robust version of conditional GAN (named RoC-GAN) that leverage the intrinsic structure in the output space. To achieve robustness, the authors replace the single pathway in the generator with two different pathways that partially share weights. The authors study the theoretical properties of RoC-GAN and prove that it shares the same properties as the vanilla GAN. For quantitative evaluations, the authors use two datasets of natural scenes and faces and evaluate denoising and sparse inpainting using the SSIM metric.\n-\tThe idea is simple and seems to be working. The methodological novelties seem more-or-less limited, but the theoretical analysis and the intuitive (and well-motivated) modification over CGANs add merits to the paper. \n-\tThe theoretical analysis of the method relates RoC-GAN to the original GAN, rather than CGAN! What is the connection here? If RoC-GAN is very similar to CGAN from a theoretical point of view (which it seems to be), then all the analysis to relate it to traditional GAN seem useless.\n-\tThe extensive experiments in the supplementary material are appreciated. But the authors only compare their method with one single previous work (i.e., Rick Chang et al. (2017)), while there are several similar related works (either based on adversarial training strategies or simple denoising AEs).\n-\tAlso, ablation studies can further show how each component of the model contributes to the final results. What if we were to only use the two-path generator without adversarial training? Different components of the final loss function can be removed and analyzed one at a time!\n-\tWhat are the conditions for mode-collapse for the proposed GAN? There are no discussions on this.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Well-written paper but the novelty and significance might be a weakness",
            "review": "General:\nIn general, this is a well-written paper. This work focuses on the robustness of conditional GAN(RoC-GAN) when facing the noise. The authors claim the generator of RoC-Gan will span the target manifold, even in the presence of large amounts of noise. The main contribution of the paper is to introduce a two-pathway model, where one of them is used to perform regression as ordinary GAN while the other one helps the whole model span the target domain.\n\nStrength:\n1. The idea is simple and straightforward. The authors provide necessary theoretical analysis and empirical validation for their model. \n2. The proposed method seems technically correct to me. i.e. Although I am not very sure how well it works in practice, the idea is fine.\n\nPossible Improvements:\n1. I agree adding another auto-encoder as a helper may give better generation results by spanning the whole target space, but I don't think this constraint is strong enough in practice. \n2. In section 3.3, the time complexity of computing 'L_deconv' seems extremely large. From the perspective of numerical optimization, optimizing such a matrix will cause trouble if the dimension of weight matrices are large. i.e. optimizing the high-dimensional covariance matrix seems a problem to me.\n3. The experiments looks good. The experiments could be more convincing if using more complex data sets(e.g. CIFAR10, ImageNet) besides CelebA. My concern for using such data sets(the resolution of images is low and the distribution is simple)  is that: although the noise seems to corrupt most of the image, the distribution of the image is not complex, so the generative model can recover it easily. Since this is a more empirical paper, the experiments should be more convincing.\n\nConclusion:\nThe author(s) are thoughtful and they put lots of work on this paper. The proposed method is simple. For novelty and significance, I think the idea is not very fancy to me. I am not very convinced by the method proposed in the paper. Although the paper demonstrates the robustness of their model with different experiments, most of them were not performed on deep neural networks and complicated data sets. As a conclusion, I vote for weak rejection.\n\nMinor suggestion:\nIncrease the resolution of the figures.\n\n------------------------------- After Rebuttal ---------------------------------\nI am very satisfied with the authors' response, so I will change my vote from rejection to acceptance.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Explanation is not clear and experiments are weak",
            "review": "Authors propose to augment a conditional GAN model with an unsupervised branch for spanning target manifold and show better performance than the conditional GAN in natural scene generation and face generation.\n\nHowever the novelty is limited and not well explained.\n1.Similar idea of using an autoencoder as another branch to help image generation has been proposed in Ma et al.â€™s work. \nLiqian Ma, Qianru Sun, Stamatios Georgoulis, Luc Van Gool, Bernt Schiele, Mario Fritz. Disentangled Person Image Generation, CVPR 2018.\n\n2. In the paper authors claim that skip connection makes it harder to train the longer path, which is kind of contradictory to what is commonly done in tasks of image classification, semantic segmentation and depth estimation. Can authors explain this claim?\nIn addition, it is not clear why maximizing the variance can address the challenge of training longer path.\n\n3. In Table 1, the improvement over baselines is small in case of sparse inpaint setting.\n\n4. In Figure 4, the fourth row is more blurry than the third row although with less artifacts like black dots.\n\n\n%%%%%%%% After rebuttal %%%%%%%%\n\nI appreciate authors' efforts to address my comments and am satisfied with their response. I will change decision from rejection to acceptance.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}