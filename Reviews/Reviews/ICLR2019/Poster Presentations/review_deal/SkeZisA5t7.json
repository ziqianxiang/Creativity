{
    "Decision": {
        "metareview": "This paper suggests that noise-regularized estimators of mutual information in deep neural networks should be adaptive, in the sense that the variance of the regularization noise should be proportional to the range of the hidden activity. Two adaptive estimators are proposed: (1) an entropy-based adaptive binning (EBAB) estimator that chooses the bin boundaries such that each bin contains the same number of unique observed activation levels, and (2) an adaptive kernel density estimator (aKDE) that adds isotropic Gaussian noise, where the variance of the noise is proportional to the maximum activity value in a given layer. These estimators are then used to show that (1) ReLU networks can compress, but that compression may or may not occur depending on the specific weight initialization; (2) different nonsaturating noninearities exhibit different information plane behaviors over the course of training; and (3) L2 regularization in ReLU networks encourages compression. The paper also finds that only compression in the last (softmax) layer correlates with generalization performance. The reviewers liked the range of experiments and found the observations in the paper interesting, but had reservations about the lack of rigor in the paper (no theoretical analysis of the convergence of the proposed estimator), were worried that post-hoc addition of noise distorts the function of the network, and felt that there wasn't much insight provided on the cause of compression in deep neural networks. The AC shares these concerns, and considers them to be more significant than the reviewers do, but doesn't wish to override the reviewers' recommendation that the paper be accepted.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "Interesting visualizations, but more rigor and analysis would help"
    },
    "Reviews": [
        {
            "title": "Interesting observations!",
            "review": "The authors of this paper studied the popular belief that deep neural networks do information compression for supervised tasks. They studied this compression behavior with tanh and ReLU (and it's variants) activation functions which are saturating and non saturating in nature respectively. \n\nThe compression score is computed using Mutual Information Estimation which when computed are usually infinite. For finite mutual information values, noise can be added to hidden activations. For this purpose, two approaches namely Entropy Based Binning(EBAB) and adaptive Kernel Density Estimation(aKDE) were explored. EBAB adds noise to the hidden activations by binning and aKDE by Gaussian noise. Their results show that both EBAB and aKDE exhibit compression in case of ReLU, although this behavior is the strongest in tanh. \n\nFinally, When compression score was plotted against accuracy, higher rates of compression did not show significant correlation with generalization. Hence showing evidence that generalization(or good performance) can be achieved even without information bottleneck(information compression).\n\nQualms:\n1. Figure 7's description that ELU, Swish and centered softplus functions doing compression is not very apparent. \n2. Figure 9b: Regression line between compression score and accuracy shows a positive correlation between them. This seems contradictory to the inference.\n3. The experiments were done on a 5-layer network with 10-7-5-4-3 nodes respectively on a toy data of 12-bit binary vectors. The study could have included bigger networks with popular datasets which would give substantial support to the trend observed on toy data.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper uses information to show compression of DNN with unbounded activation function, but it gives no questions to what form the compression.",
            "review": "This paper proposes a method for the estimation of mutual information for networks with unbounded activation functions and the use of L2 regularization to induce more compression.  The use of information planes to study the training behavior of networks is not new.  This paper addresses the issue of unbounded  hidden state activities.  As the differential mutual information in DNN is ill-defined, the authors proposed to add noise to the hidden activity by using the binning process.   It is not clear in the paper that if the binning is applied just for visualizing the information plane or for computing the activities of hidden units in upper layers.   If it is the latter one, it creates unnecessary distortions to the DNN.  As the authors pointed out, different initializations can lead to different behaviour on the information plane.  It would be difficult to draw conclusions based on the experimental results, even they come from the average of 50 individual networks.  Also, the experiences are performed using a particular task, it is not sure if similar behavior is observed in other tasks.   It is, however, more important to understand what makes the compression.   For the L2 regularization, the compression is expected as the regularization tends to limit the values of the  weights. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "This paper has 3 principal contributions: it proposes a different way of measuring mutual information in a neural network, proposes a compression score to compare different models, then empirically analyses different activation functions and L2 weights.\n\nThis work seems like a welcome addition to the IB thread. To me the most interesting result is simply that activation functions aren't simply about gradient flow, and that they may each have properties that are more or less desirable depending on the domain they might be used on. The authors are careful in the wording of their conclusions, I think with reason; while these results are useful in that there seem to be consistently different behaviors coming from different hyperparameters, information planes show a relatively qualitative part of the picture.\n\nQuantitatively, the proposed compression score is interesting, but as the authors say, simplistic. It seems to me that we care more about the converged models than the whole training trajectory; how does this score evolve with time?\n\nI think an important part of discussion that lacks in this paper is a more in-depth take as to how these findings relate to the Zhang et al [1] memorization vs generalization paper and its follow ups. There seem to be many links to be drawn.\n\nThis work is overall a good contribution, but I'll have to agree with the authors' conclusion that more principled analysis methods are required to have a solid grasp of the training dynamics of DNNs. The writing of the paper is good, but the writing of the captions could be improved. (the hard page limit of ICLR is 10 pages and your paper has a lot of captions, so I think investing into a bit more text would be good)\n\n\nComments:\n- It might be worth to re-explain what the information plane plots are in a figure caption, not just in the text (the text also doesn't really explain that each point is a moment in training, and each thread a different layer, this paper should be readable by someone who has never seen these plots before). \n- It's not clear what is going on in figure 5, I can guess but, again, this paper should be readable by anyone in the field. You mention different initializations, but which exactly? What makes you say that 5c has no compression but that 5a does compression first? It should be explained explicitly.\n- I believe what you say about Figure 8, but the plots are so similar that it is hard to compare them visually. Maybe a different kind of superposition into a single plot would better illustrate the compression effect of L2?\n- Typo in the x axis caption of figures 9.\n- Figure 9a is not readable in greyscale (or by a colorblind person), consider using a different symbol for the softmax scatter (and adding this symbol to the legend).\n- The first Schmidhuber citation of the paper seems a bit out of place. I think he himself would say that deep learning has been going on for much longer than since 2015. (in fact I think you could just remove the entire first paragraph, it is just unnecessary boilerplate)\n- Why should there be a direct correlation between compression and generalization? For example, it is known that training DNNs with soft targets improves test accuracy in classification, or even forcing softness in both targets and representations [2] also improves test accuracy.\n- I'm still personally not sold on binning as a strategy to evaluate MI. Did you perform experiments that show that the observed difference is consistent if more computation is done to approximate MI, and not just an artefact of max-entropy binning?\n\n[1] Zhang et al (2016) https://arxiv.org/abs/1611.03530\n[2] Verma et al (2018) https://arxiv.org/abs/1806.05236\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}