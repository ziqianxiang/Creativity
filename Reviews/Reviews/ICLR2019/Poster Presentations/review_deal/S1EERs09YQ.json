{
    "Decision": {
        "metareview": "Important problem (making NN more transparent); reasonable approach for identifying which linguistic concepts different neurons are sensitive to; rigorous experiments. Paper was reviewed by three experts. Initially there were some concerns but after the author response and reviewer discussion, all three unanimously recommend acceptance.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Meta-review"
    },
    "Reviews": [
        {
            "title": "Solid paper with interesting insights - left with some questions",
            "review": "This paper describes a method for identifying linguistic components (\"concepts\") to which individual units of convolutional networks are sensitive, by selecting the sentences that most activate the given unit and then quantifying the activation of those units in response to subparts of those sentences that have been isolated and repeated. The paper reports analyses of the sensitivities of different units as well as the evolution of sensitivity across network layers, finding interesting patterns of sensitivity to specific words as well as higher-level categories.\n\nI think this paper provides some useful insights into the specialization of hidden layer units in these networks.  There are some places where I think the analysis could go deeper / some questions that I'm left with (see comments below), but on the whole I think that the paper sheds useful light on the finer-grained picture of what these models learn internally. I like the fact that the analysis is able to identify a lack of substantial change between middle and deeper layers of the translation model, which inspires a prediction - subsequently borne out - that decreasing the number of layers will not substantially reduce task performance.\n\nThe paper is overall written pretty clearly (though some of the questions below could likely be attributed to sub-optimal clarity), and to my knowledge the analyses and insights that it contributes are original. Overall, I think this is a solid paper with some interesting contributions to neural network interpretability.\n\nComments/questions:\n\n-I'm wondering about the importance of repeating the “concepts” to reach the average sentence length. Do the units not respond adequately with just one instance of the concept (eg \"the ball\" rather than \"the ball the ball the ball\")? What is the contribution of repetition alone?\n\n-Did you experiment with any other values for M (number of aligned candidate concepts per unit)? It seems that this is a non-trivial modeling decision, as it has bearing on the interesting question of how broadly selective a unit is.\n\n-You give examples of units that have interpretable sensitivity patterns - can you give a sense of what proportion of units do *not* respond in an interpretable way, based on your analysis?\n\n-What exactly is plotted on the y-axis of Figure 5? Is it number of units, or number of concepts? How does it pool over different instances of a category (different morphemes, different words, etc)? What is the relationship between that measure and the number of distinct words/morphemes etc that produce sensitivity?\n\n-I'm interested in the units that cluster members of certain syntactic and semantic categories, and it would be nice to be able to get a broader sense of the scope of these sensitivities. What examples of these categories are captured? Is it clear why certain categories are selected over others? Are they obviously the most optimal categories for task performance?\n\n-p7 typo: \"morhpeme\"",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting results on an important problem, but insufficient analysis and evaluation ",
            "review": "========== Edit following authors' response  ==========\n\nThank you for your detailed response and updated version. I think the new revision is significantly improved, mainly in more quantitative analyses and details in several places. I have updated my evaluation accordingly. \n\nSee a few more points below.\n\n1. Thank you for clarifying your definition of concepts. I still think that the word \"concept\" has a strong semantic connotation, while the linguistic elements your analyses capture may do other things. The results in appendix E do show that some semantic clusters arise. It's especially interesting to see the blocks in some of the heat maps, where similar \"concepts\" are clustered together (like the sports terms in AG); consider commenting on this. \n\n2. The new quantitative analyses are helpful. One other suggestion that I mentioned before is to connect detected concepts to external resources like WordNet or ConceptNet. That would help show that \"concepts\" are indeed semantic objects. \n \n3. The motivation for replicating as normalizing for length does make sense, although the input would still be unnatural. The comparison to \"one instance\" is helpful, but it's interesting that the differences between it and replication in figure 2 are not large. It would be good to show results that substantiate your assumption that without replication there will be a bias towards lengthy concepts. Does \"one instance\" detect more lengthy concepts than replication? \n\n4. The results on frequency and loss difference in 4.5 are very interesting. There is another angle to consider frequency: words that appear frequently often carry less semantic content (e.g. function words), so one might conjecture that they would require less units. It may be interesting to look at which concepts are detected at each frequency bin.\n\n5. Minor points: section 2.2 still mentions \"regression\" where it should be \"classification\".  \n\n6. A few remaining grammar issues:\n- \"one concept has a less activation value..\" - rephrase \n- end of section 3.3: \"this experiments\" -> \"these experiments\"\n\n\n========== Original review follows ==========\n\nSummary:\n=======\nThis paper analyzes individual units in CNN models for text classification and translation tasks. It defines a measure of sensitivity for a unit and evaluates how sensitive each unit is to \"concepts\" in the input text, where concepts are morphemes, words, and phrases. The analysis shows that some units seem to learn semantic concepts, while others capture linguistic elements that are frequent or relevant for the end task. Layer-wise results show some correspondence between layer depth and linguistic element size.  \n\nThe paper studies an important question that is relatively under-studies in NLP compared to the computer vision community. The motivation for the work is quite convincing.  \nI found some of the results and analysis interesting, but overall felt that the work can be made much stronger by more quantitative evaluations. I am also worried that the notion of \"concept\" is misleading here. See below for this and other comments. I am willing to reconsider my evaluation pending response to the below issues. \n\nMain comments:\n=============\n1. Concepts: \n- morphemes, words, and phrases - are these \"concepts\"? They are indeed \"fundamental building blocks of natural language\" (2.2), but \"concepts\" has a more semantic connotation that I'm not sure these units target at. \n- Some of the results do suggest that units learn concepts, as the analysis in 4.2 shows a \"unit detecting the meaning of certainty in knowledge\" and later units that have similar sentiments. It would be informative to quantify this in some way, for example by matching detected concepts to WordNet synsets, sentiment lexicons, etc., or else tagging and classifying them with various NLP tools. This could also reveal if units learn more syntactic or semantic concepts, and so on. \n2. Generally, many of the analyses in the paper are qualitative and on a small scale. The results will be more convincing with more automatic aggregate measures. \n3. The structure of the paper is confusing. Section3 starts with the approach but then mentions datasets and tasks (3.1). Section 4 is titled experiments, but section 4.1 starts with defining the concept selectivity. I would suggest reorganizing sections 3 and 4, such that section 3 describes all the methods and metrics, while dataset-specific parts are moved to section 4. \n4. section 3.2 should provide more details on the sentence representation and how its obtained in the CNN models. A mathematical derivation and/or figure could be helpful. It is also not clear to me what's the motivation for mean-pooling over the l entries of the vector. \n5. section 3.3: the use of replicated text for \"concept alignment\" is puzzling. This is not a natural input to the model, and I think more justification and motivation åre needed for this issue, as well as perhaps comparison with other approaches. \n6. I found section 4.4 very interesting. It shows some intuitive results of larger linguistic elements learned at higher layers, but then some results that do not show such a trend. Then, hypothesizing that the middle layers are sufficient AND validating the hypothesis by retraining the model is excellent. It's a very nice demonstration that the analysis can lead to model improvements.  \n7. Figure 2 seems to be almost caused by construction of the different options for S_+. Is it surprising that the replicate set has the highest sensitivity? Is there a better control setup than comparing with a random set? \n8. One concern that I have is the effect of confounding factors like frequency on the results. The papers occasionally attributes importance to concepts (e.g. in 4.2), but I wonder if instead we may be seeing more frequent words. Controlling for the effect of frequency would be useful.   \n\n\nMinor comments:\n==============\n- Section 2.2, first paragraph: regression should be changed to classification\n- The related work is generally relevant, although one could mention a few other papers that analyzed individual neurons in NLP tasks [1, 2]\n- section 4.1: the random set may perhaps be denoted by something more neutral, not S_+ as the replicate and inclusion sets. \n- section 4.3, last paragraph: listing examples showing that units in Europarl focus on key words would be good. \n- Figure 5, y axis label: should this be number of units instead of concepts? \n- Appendix A has several interesting points but there is no reference to them from the main paper. \n\n\nWriting, grammar, etc.:\n======================\n- Introduction: among them - who is them? \n- 2.1: motivated from -> motivated by; In computer vision community -> In the computer vision community\n- 2.1: quantifying characteristics of representations in layer-wise -> rephrase\n- 3.2: dimension of sentence -> dimension of the/a sentence \n- 4.1: to which -> remove \"which\" \n- 4.2: in the several encoding layer -> in several encoding layers \n- 4.3: aliged -> aligned \n- Capitalize titles in references \n- A.2: with following -> with the following; how much candidate -> how much a candidate; consider following -> consider the following \n- A.3: induces similar bias -> induces a bias; such phrase -> such a phrase; on very -> on a very \n- C: where model -> where the model; In consistent -> Consistent; where model -> where the model \n\n\nReferences\n==========\n[1] Qian et al., Analyzing linguistic knowledge in sequential model of sentence\n[2] Shi et al., Why Neural Translations are the Right Length",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper proposes an interpretation to the activation values of hidden layer units of convolutional neural networks trained on language tasks, aligning those units with natural language concepts. The work is novel and interesting to the NLP community.",
            "review": "The paper is well written and structured, presenting the problem clearly and accurately. It contains considerable relevant references and enough background knowledge. It nicely motivates the proposed approach, locates the contributions in the state-of-the-art and reviews related work. It is also very honest in terms of how it differs on the technical level from existing approaches. \nThe paper presents interesting and novel findings to further state-of-the-art’s understanding on how language concepts are represented in the intermediate layers of deep convolutional neural networks, showing that channels in convolutional representations are selectively sensitive to specific natural language concepts. It also nicely discusses how concepts granularity evolves with layers’ deepness in the case of natural language tasks.\nWhat I am missing, however, is an empirical study of concepts coverage over multiple layers, studying the multiple occurrences of single concepts at different layers, and a deeper dive on the rather noisy elements of natural language and the layers’ activation dynamics towards such elements.\nOverall, however, the ideas presented in the paper are interesting and original, and the experimental section is convincing. My recommendation is to accept this submission.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}