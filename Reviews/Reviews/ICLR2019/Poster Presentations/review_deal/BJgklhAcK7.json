{
    "Decision": {
        "metareview": "This work builds on MAML by (1) switching from a single underlying set of parameters to a distribution in a latent lower-dimensional space, and (2) conditioning the initial parameter of each subproblem on the input data.\nAll reviewers agree that the solid experimental results are impressive, with careful ablation studies to show how conditional parameter generation and optimization in the lower-dimensional space both contribute to the performance. While there were some initial concerns on clarity and experimental details, we feel the revised version has addressed those in a satisfying way.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Good contribution on meta-learning"
    },
    "Reviews": [
        {
            "title": "More intuitions and insights are required to understand the proposed method",
            "review": "This paper presents a new meta-learning framework that learns data-dependent latent space and performs fast adaptation in the latent space. To this end, an encoder that maps data to latent codes and a decoder that maps latent codes to parameters are also learned. Experimental results demonstrate its effectiveness for few-shot learning.\n\nInterestingly, the initialization for adaptation is task-dependent, which is different from conventional MAML-like methods. Furthermore, the results on multimodal few-shot regression seems to show that it works well for multimodal task distribution, which is important for generalization of meta-learning. However, there are quite a few questions that are less clear and require more discussions and insights. \n\n1. Since this work relies heavily on an encoding process and a decoding process, more details and discussions on the design and requirement of the encoder and decoder are necessary. Particularly, the inclusion of a relation network in the encoding process seems ad hoc. More explanations may be helpful. \n\n2. It is less clear why this method can deal with multimodal task distribution as shown in the regression experiment. Is it related to the data-dependent model initialization?\n\n3. It applies meta-learning in a learned latent space, which seems quite related to a recent work, Deep Meta-Learning: Learning to Learn in the Concept Space, Arxiv 2018, where meta-learning is performed in a learned concept space. A discussion on its difference to this prior work seems necessary. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "lack of details",
            "review": "This paper proposes a latent embedding optimization (LEO) method for meta-learning, in particular, few-shot learning.  The proposed model has three meta components, an encoding network, a relation network, and a decoding network. It claims the contribution is to decouple the optimization-based meta-learning techniques from high-dimensional space of model parameters. \n\nThe proposed work focuses on the standard few-shot learning scenario. The notable merit of this work is that it presented the so-far best empirical results. On miniImageNet, it produced 61.76% (1-shot) and 77.59(5-shot) accuracy results. This is quite amazing. \n\nThe presentation of the work however lacks sufficient details and motivations, which makes it difficult to judge the proposed model. (1) It is not clear what are the specific architectures and model parameter settings for the encoding, decoding and relation networks.  (2) In Eq.(4), it defines \\mu_n^d,\\sigma_n^d as the output of the decoding network which takes the single z_n as input. I doubt a single z_n input can provide information on both \\mu_n^d,\\sigma_n^d. (3) How to use the developed model in the testing phase?\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Impressive paper that naturally and effectively extends MAML",
            "review": "This work presents an extension of the MAML framework for \"learning to learn.\" This extension changes the space in which \"inner-loop\" gradient steps are taken to adapt the model to a new task, and also introduces stochasticity. The authors validate their proposed method with regression experiments in a toy setting and few-shot classification experiments on mini- and tiered-Imagenet. The latter are well known and competitive benchmarks in few-shot learning.\n\nThe primary innovations that distinguish this work from previous gradient-based approaches to meta-learning (namely MAML) are that (i) the initial set of parameters is data-dependent and drawn from a generative distribution; and (ii) the adaptation of model parameters proceeds in a lower-dimensional latent space rather than in the higher-dimensional parameter space. Specifically, model parameters are generated from a distribution parameterized by an adapted latent code at each adaptation step. I find both of these innovations novel.\n\nThe experimental results, in which LEO outperforms the state of the art on two benchmarks derived from ImageNet by \"comfortable margins,\" and the ablation study demonstrate convincingly that these innovations are also significant. I also found the curvature analysis and embedding visualization illuminating of the model's function. My one suggestion would be to test the model on realistic data from beyond the image domain, perhaps on something sequential like language (consider the few-shot PTB setting from Vinyals et al. (2016)). I'm aware anecdotally that MAML struggles with adapting RNNs and I wonder if LEO overcomes that weakness.\n\nThe paper is clearly written and I had little difficulty in following the algorithmic details, although I'm sure it helped to be familiar with the convoluted meta-learning and inner-/outer- loop frameworks. I recommend it for publication.\n\nPros:\n- Natural, novel extension to gradient-based meta-learning\n- state of the art results on two competitive few-shot benchmarks\n- good analysis\n- clear writing\n\nCons:\n- realistic, high-dim data is only from the image domain\n\nMinor questions for the authors:\n- Relation Networks are computationally intensive, although in few-shot learning the sets encoded are fairly small. Can you discuss the computational cost and training time of the full framework?\n- What happens empirically when you generate parameters for more than just the output layer in, eg, your convolutional networks?\n- What happens if you try to learn networks from scratch through the meta-learning process rather than pre-training and fine-tuning them? Some of the methods you compare against do so, to my understanding.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}