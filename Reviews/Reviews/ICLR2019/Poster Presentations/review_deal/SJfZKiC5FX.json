{
    "Decision": {
        "metareview": "1. Describe the strengths of the paper.  As pointed out by the reviewers and based on your expert opinion.\n \n- The approach is novel\n- The experimental results are convincing.\n\n2. Describe the weaknesses of the paper. As pointed out by the reviewers and based on your expert opinion. Be sure to indicate which weaknesses are seen as salient for the decision (i.e., potential critical flaws), as opposed to weaknesses that the authors can likely fix in a revision.\n\n- The authors didn't show results with non-Gaussian noise\n- Some details that could help the understanding of the method are missing. \n\n3. Discuss any major points of contention. As raised by the authors or reviewers in the discussion, and how these might have influenced the decision. If the authors provide a rebuttal to a potential reviewer concern, itâ€™s a good idea to acknowledge this and note whether it influenced the final decision or not. This makes sure that author responses are addressed adequately.\n\nNo major points of contention.\n \n4. If consensus was reached, say so. Otherwise, explain what the source of reviewer disagreement was and why the decision on the paper aligns with one set of reviewers or another.\n\nThe reviewers reached a consensus that the paper should be accepted.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "novel approach with convincing results"
    },
    "Reviews": [
        {
            "title": "An improvement to the SoA of the domain, more explanations and analysis welcomed",
            "review": "The paper proposes a restoration method based on deep reinforcement learning. It is the idea of trainable unfolding that motivates the use of Reinforcement learning, the restoration unit is a SoA U-Net. \n\nRemarks\n\n* The author seems to make strong assumptions on the nature of the noise and made no attempt to understand the nature of the learning beyond a limited set of qualitative example and PSNR. \n\n* Even if the experimental protocol has been taken from prior work, it would have been appreciated to make it explicit in the paper, especially as ICLR is not a conference of image processing. Indeed, It would have made the paper more self-sufficient. \n\n* Second 2 describing the method is particularly hard to understand and would require more details. \n\n* In the experimental section, the authors claim that \"These results indicate that the restoration unit has the potential to generalize on unseen degradation levels when trained with good policies\". It would have been important to mention that such generalization capability seems to occur for the given noise type used in the experiments. I didn't see any explicit attempt to variate the shape of the noise to evaluate the generalization capability of the model.\n\nIn conclusion, the paper proposes an interesting method of image denoising through state of the art deep learning model and reinforcement learning algorithm. The main difference with the SoA on the domain is the use of a diffusion dynamics. IMHO, the paper would need more analysis and details on the mentioned section.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A useful method for blind image restoration problems",
            "review": "Summary:\n\nThe authors proposes a new image restoration method that becomes particularly useful for blind restoration setting, e.g., the unknown noise variance setting for denoising. They utilized the moving endpoint control methodology, which essentially is applying reinforcement learning to the image restoration, and devised a method that adaptively decides the unfolding steps for given noisy image. The experimental results show encouraging results. \n\nPros:\nIn the experimental result, the proposed DURR outperforms DnCNN-B, a current state-of-the-art. Particularly, while DnCNN-B suffers for the noise level that it was not trained for, DURR can still denoise much better. (Table 2) A similar result is obtained for the JPEG deblocking problem as well. \n\nCons:\n- Since the Deep Q-learning is used to train the policy unit, I suspect the training time could be quite long. How does the reward curve look like while training? How stable is the training? Showing such details should make the paper stronger. \n- It will be interesting to see more details on the model. For example, what is the mean/std for the number of folds that model applies for BSD68? What is the distribution (histogram?) of the folds for BSD68? Currently, the paper just simply shows the results and seems to hide many details. \n- What was the choice for \\lambda in Eq. (3),(4)? How do you choose it?\n- How does the result look like on other benchmark datasets other than BSD68? It seems like the specific number of looks for each noise level is important for training. Do the choices of (25,4),(35,6),(45,9),(55,12) generalize well to other datasets as well?\n\nOverall, I think the paper should add more details mentioned above to make the paper stronger. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Simple and effective restoration approach ",
            "review": "Summary\n\nThis paper decomposes the image restoration task in two part: the restoration part handled by a restoration RNN, and the number of steps to apply the RNN is determined using a policy unit. \nState of the art results are achieved on blind grey level Gaussian noise denoising on the BSD68 dataset.\n\nThe approach is novel to my knowledge, the paper is well written, the results are good and well illustrated.\n\nQuestions:\n-It would be nice to present results on color images, and on datasets that contains natural noises.  \n-Lowering the learning rate on plateaus during training is done by hand or is there an automatic criterion to define the plateaus?\n\nMinor:\npage 1: extra \")\" after ref to Bredies et al 2010\ncould cite Chen, Zu, Koltun ICCV17 in deep models for restoration\nSeveral \"L\" have been replaced by \"_' e.g. under review at IC_R, R_-based, etc in the whole paper\np.4: rain-> train\ngreatly influence -> greatly influences\np5: typo performace\nmake a uniform bib: whole first name or abbr. , no URL, etc.\np6: the weight -> the set of weights \nadd the specification that the noise is Gaussian\nthe sentence \"the training set and testing set of ...\" is used twice, remove one.\np7 Table 1: the perf of DnCNN-B is 29.16 and not 29.15 for sigma 25, right?",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}