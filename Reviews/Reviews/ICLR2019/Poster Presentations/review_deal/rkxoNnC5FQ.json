{
    "Decision": {
        "metareview": "The paper proposes an unsupervised domain adaptation solution applied for semantic segmentation from simulated to real world driving scenes. The main contribution consists of introducing an auxiliary loss based on depth information from the simulator. All reviewers agree that the solution offers a new idea and contribution to the adaptation literature. The ablations provided effectively address the concern that the privileged information does in fact aid in transfer. The additional ablation on the perceptual loss done during rebuttal is also valuable and should be included in the final version. \n\nThe work would benefit from application of the method across other sim2real dataset tasks so as to be compared to the recent approaches mentioned by the reviewers, but the current evaluation is sufficient to demonstrate the effectiveness of the approach over baseline solutions. ",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "A new approach to learning from simulated data with privileged information"
    },
    "Reviews": [
        {
            "title": "interesting use of depth information from simulators as priviledged information for unsupervised domain adaptive segmentation",
            "review": "The paper focuses on the problem of semantic segmentation across domains. The most standard setting for this task involves real world street images as target and synthetic domains as sources with images produced by simulators of photo-realistic hurban scenes.  This work proposes to leverage further depth information which is actually produced by the simulator together with the source images but which is in general not taken into consideration.\nThe used deep architecture is a GAN where the generator learning is guided by three components: (1) the standard discriminator loss (2) the cross entropy loss for image segmentation that evaluates the correct label assignment to each image pixel (3) an  l1-based loss which evaluates the correct prediction of the depth values in the original and generated image. A further perceptual regularizer is introduced to support the learning.\n\n+ overall the paper is well organized and easy to read\n+ the proposed idea is smart: when starting from a synthetic domain there may be several hidden extra information that are generally neglected but that can instead support the learning task\n+ the experimental results seem promising \n\nStill, I have some concerns\n\n- if the main advantage of the proposed approach is in the introduction of the priviledged information, I would expect that disactivating the related PI loss we should get back to results analogous of those obtained by other competing methods. However from Table 2 it seems that SPIGAN-no-PI is already much better than the  FCN Source baseline in the Cityscape case and much worse in the Vistas case. This should be better clarified -- are the basic structure of SPIGAN and FCN analogous?  \n\n- the ablation does not cover an analysis on the role of the perceptual regularizer. This is also related to the point above: the use of a perceptual loss may introduce a basic difference with respect to competing methods. It should be better discussed.\n\n- section 4.1 mentions the use of a validation set. More details should be provided about it and on how the hyperparameters were chosen.\nA possible analysis on the robustness of the method to those parameters could provide some further intuition about the network stability.\nIt might be also interesting to check if the  the loss weights provide some intuition  about the relative importance of the losses in the learning process.\n\n- the negative transfer rate is another way to measure the advantage of using the PI with respect to not using it. However, since it is not evaluated for the competing methods its value does not add much information and indeed it is only quickly mentioned in the text. It should be better discussed.\n\n- some recent papers have shown better results than those considered here as baseline:\n[Learning to Adapt Structured Output Space for Semantic Segmentation, CVPR 2018]\n[Unsupervised Domain Adaptation for Semantic Segmentation via Class-Balanced Self-Training, ECCV 2018]\nthey should be included as related work and considered as reference for the experimental results.\n\nOverall I think that the proposed idea is valuable but the paper should better clarify the points mentioned above.\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "[REVISED REVIEW] Interesting way of using depth data from a simulator as Privileged Information. ",
            "review": "This papers presents an unsupervised domain adaptation algorithm for semantic segmentation. A generative adversarial network is envisaged to carry out synthetic-to-real image translation. In doing so, depth information extracted from a simulator is used as privileged information (PI) to boost the transfer on the target domain, regularizing the model and ensuring a better generalization. \n\n*Quality*\nThe paper addresses a relevant problem, which is the adaptation of methods from simulated data to real ones. The authors devise a convincing method which takes advantage of state-of-the art generative adversarial architectures and privileged information. \n\n*Clarity*\nThe paper is sufficiently well written. In general, the main idea and proposed method are clear and easy to follow. The only problem is that some background concepts (such as privileged information or unsupervised domain adaptation) are given for granted, compromising the readability for someone not familiar with those topics. \nOn a more technical side, for reproducibility purposes, the following aspects have to be clarified:\n1.\tDetails about the validation set used for grid search. Is the validation set extracted from the target domain? (In principled labels from the target domain should not be used during learning).\n2.\tNumber of iterations before convergence: is the training of the network numerically stable? Are there issues in convergence of some of the sub-modules? Which one is leading the learning?\n3.\tComments about the relative magnitudes of losses. This will maybe give some intuitions about the values used for the hyper-parameters (e.g., the L_PI is only weighted by 0.1).\n\n*Originality*\nThe way authors take advantage of depth information extracted from a simulator as privileged information is novel in the sense that, with respect to the original student-teacher paradigm of the paper by Vapnik & Vashist, here the idea of privileged information is interpreted as a regularizer to boost the training stage. \n\n*Significance*\nThe application of semantic segmentation in urban scenes for navigation tasks is relevant. The scored results are on pair with/ superior to state-of-the-art in unsupervised domain adaptation. \nHowever, the ablation study could be more extensive in order to understand the contribution of the several components, besides the PI network. In fact, it would be interesting to analyze the contribution of the perceptual loss (and others). Also, one could include the target-only result (as done in original LSD paper) to provide an upper bound on the best accuracy that is achievable.\n\n*Pros*\n1. The applicative setting of semantic segmentation in urban scenes for navigation is relevant. \n2. Using privileged information from simulators seems novel and well presented in this paper.\n3. Strong experimental results achieved in challenging benchmarks.\n\n*Cons*\n1. The regularization effect of the PI network could be supported by a more extensive ablation study of the model, for example by ablating the several losses used (in particular, the perceptual loss).\n2. A quite relevant amount of hyper-parameters need to be cross-validated. Is the method robust against different parameters’ configuration?\n3. Missing citations [1, 2]: there are works in the literature that can hallucinate a missing modality during testing. Although such works approach a different problem, authors should cite them.\n\n[1] Judy Hoffman, Saurabh Gupta, Trevor Darrell - Learning with Side Information through Modality Hallucination – CVPR 2016\n[2] Nuno Garcia, Pietro Morerio, Vittorio Murino - Modality Distillation with Multiple Stream Networks for Action Recognition – ECCV 2018\n\n*Final Evaluation*\nThe authors face the challenging synthetic-to-real adaptation setup, with an interesting usage of z-buffer from a simulator as privileged information. Overall, the work is fine, apart from the following points.\n1.\tIn addition to a few missing citations [1, 2], an ablation study on the perceptual loss is necessary to dissect the impact of each component of the pipeline. \n2.\tThe clarity of the paper can be improved by adding some background material on unsupervised domain adaptation and learning with privileged information (PI), as to better highlight the technical novelty of using PI within a L1 regularizer. \n3.\tThe training stage of all submodules could have better investigated, for instance, by providing some convergence plots of the loss functions across iterations.\n4.\tHow to do grid search for parameters in a domain adaptation setting is always a delicate aspect and authors seem elusive on that respect. \n5.\tAgain about hyper-parameters. Due to their high number, some sensitivity analysis should have provided.\nAs it is, the paper’s strengths slightly outperform the weaknesses, leading to an overall borderline-accept. If authors implement the suggested modification, a full acceptance will be feasible.\n\n[COMMENTS AFTER AUTHORS' RESPONSE]\nAfter the rebuttal provided by authors, all raised questions and criticisms have been fully solved. Therefore, I recommend for a full acceptance.",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Privileged information for domain adaptation",
            "review": "This article addresses the problem of domain adaptation of semantic segmentation methods from autonomous vehicle simulators to the real world. The key contribution of this paper is the use of privileged information for performing the adaptation. The method is of those called unsupervised domain adaptation as no labels from the target domain are used for the adaptation. The method is based on a GAN with: a) A generator that transforms the simulation images to real appearance; b) A discriminator that distinguish between real and fake images;  c) a privileged network that learns to perform depth estimation; and d) the task networks that learns to perform semantic segmentation. Privileged information is very few exploited in simulations and I consider it an important way of further exploit these simulators.\n\nThe article is clear, short, well written and very easy to understand. The method is effective as it is able to perform domain adaptation and improve over the compared methods. There is also an ablation study to evaluate the contribution of each module. This ablation study shows that the privileged information used helps to better perform the adaptation. The state of the art is comprehensive and the formulation seams correct.  The datasets used for the experiments (Synthia, Cityscapes and Vistas) is very adequate as they are the standard ones.\n\nSome minor concerns:\n - The use of 360x640 as resolution\n - The use of FCN8 instead of something based on Resnet or densenet\n\nI would like some more details on what is happening with Vistas dataset. SPIGAN-no-PI underperforms the source model. By looking at Figure 4 we can observe that the transformation of the images is not working properly as many artifacts appear. In SPIGAN those artifacts does not appear and then the adaptation works better. Could it be a problem in the training?\n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}