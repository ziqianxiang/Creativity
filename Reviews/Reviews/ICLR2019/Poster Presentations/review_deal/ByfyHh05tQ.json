{
    "Decision": {
        "metareview": "After a healthy discussion between reviewers and authors, the reviewers' consensus is to recommend acceptance to ICLR. The authors thoroughly addressed reviewer concerns, and all reviewers noted the quality of the paper, methodological innovations and SotA results.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Consensus is accept"
    },
    "Reviews": [
        {
            "title": "Interesting application of RL to DNA, new SotA perf, some theoretical novelty",
            "review": "I'm happy with the revisions the authors have made, as I find that they call out the novel contributions a bit more explicitly. Specifically I see some novel work in the area of simultaneous multi-task/meta-RL and black box optimization of the policy net architectures. I don't think calling this NAS is justified; calling it bayesopt or black box opt is fair. NAS uses a neural net to propose experiments over structured graphs of computation nodes. This work appears to be simpler hyperparameter optimization.\n\n====\n\nQuality:\nThe work is well done, and the experiments are reasonable/competitive, showcasing other recent work and outperforming. \n\nClarity:\nI thought the presentation was tolerable. I was a bit confused by Table 1 until reading the prose at the bottom of page 7 indicated Table 1 is presenting percentages, not integer quantities. The local improvement step is not very clearly explained. Are all combos tried across all mismatched positions, or do we try each mismatched position independently holding the others to their predicted values? What value of zeta did you end up using? It seems like this is essential to getting good performance. It is completely unclear to me what the 'restart option' does.\n\nOriginality:\nUsing RL in this specific application setting seems relatively new (though also explored by RL-LS in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6029810/). On the other hand, the approach used doesn't seem to be substantially different than anything else typically used for policy gradient RL. The meta-learning approach is interesting, though again not too different from multi-task approaches (though these are perhaps less common in RL than in general deep learning).\n\nSignificance:\nLikely to be of practical utility in the inverse design space, specifically therapeutics, CRISPR guide RNA design, etc. Interesting to ICLR as an application area but probably not much theory/methods interest.\n\n\nOn balance I lean slightly against accepting and think this is a better fit to either a workshop or a more domain-specific venue (MLHC http://mucmd.org/ for example).",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "RNA sequence design with deep reinforcement learning",
            "review": "This work tackles the difficult RNA design problem, i.e. that of finding a RNA primary sequence that is going to fold into a secondary/tertiary structure able to perform a desired biological function. More specifically, it used Reinforcement Learning (RL) to find the best sequence that will fold into a target secondary structure, using the Zuker algorithm and designing a new primary sequence 'from scratch'. A new benchmark data set is also introduced in the paper along .\n\nQuestions/remarks:\n - I struggle with your notations as soon as section 2.1. What is the star (*) superscript for? Was expecting the length of the RNA sequence instead. Same on p4, when introducing the notation of your decision process $ D_w $, explicitly introduce all the ingredients.\n - in Equation (2) on p4, maybe clarify the notation with '.', '(' and ')' for example as the reader could really struggle.\n - I didn't really understand the message in Section 4, not being an expert in the field. Could you clarify your contribution here?\n - your 'Ablation study' in Section 5.2; does it correspond to true uncertainty/noise that could be observed in real data?\n - why a new benchmark data set, when there exist good ones to compare your method to, e.g. in competitions like CASP for proteins?\n - do you make your implementation available?\n - quite like the clarification of the relationship of your work to that of Eastman et al. 2018. Could you also include discussions to other papers, e.g. Chuai et al. 2018 Genome Biol and Shi et al. 2018 SentRNA on arXiv?\n\nAltogether the paper reads well, seems to have adequate references, motivates and proposes 3 variations of a new algorithm for a difficult learning problem. Not being an expert in the field, I just can't judge about the novelty of the appraoch.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "Partially unclear and minor methodological contributions, but good application paper overall",
            "review": "General comment\n==============\nThe authors used policy gradient optimization for generating RNA sequences that fold into a target secondary structure, reporting clear accuracy and runtime improvements over the previous state-of-the-art. The authors used BOHR for optimizing hyper-parameters and present a new dataset for evaluating RNA design methods. The paper is well motivated and mostly clearly written. However, the methodological contributions are limited and I have some important concerns about their evaluation. Overall, I feel it’s a good paper for an ICLR workshop or biological journal if the authors address the outstanding comments.\n\nMajor comments\n=============\n1. The methodological contributions are limited. The authors used existing approaches (policy gradient optimization and BOHR for hyperparameter optimization) but do not report new methods, e.g. for sequence modeling. Performing hyper-parameter optimization is in my eyes not novel, but common practice in the field. It would me more informative if the authors compared reinforcement learning to other approaches for (conditional) sequence generations, e.g. RNNs, autoregressive models, VAEs, or GANs, which have been previously reported for biological sequence generation (e.g. http://arxiv.org/abs/1804.01694).\n\n2. Did the authors split all three datasets (Eterna, Rfam-Taneda, Rfam-learn-test) into train, eval, and test set, trained their method on the training set, optimized hyper-parameters on the eval set, and measured generalization and runtime on the test set? This is not described clearly enough in section 5. I suggest to summarize the number of sequences for each dataset and split in a table.\n\n3. Did the authors also optimize the most important hyperparameters of RL-LS and other methods? Otherwise it is unclear if the performance gain is due to hyperparameter optimization or the method itself.\n\n4. The time measurement (x-axis figure 3) is unclear. Is it the time that methods were given to solve a particular target structure and does figure 3 show the average number of solved structures in the test for a the time shown on the x-axis? \n\n5. Were all methods compared on the same hardware (section 5; 20 cores; Broadwell E5-2630v4 2.2 GHz CPUs) and can they be parallelized over multiple CPU or GPU cores? This is essential for a fair runtime comparison.\n\n6. The term ‘run’ (“unreliable outcomes in single runs”, section 4) is unclear. Is it a single sample from the model (one rollout), a particular hyperparameter configuration, or training the model once for a single target structure? This must be clarified for understanding the evaluation.\n\n7. How does the accuracy and runtime or LEARNA scale depending on the sequence (structure) length?\n\n8. How sensitive is the model performance depending on the context size k for representing the current state? Did the authors try to encode the entire target structure with, e.g. recurrent models, instead of using a window centered on the current position?\n\n9. The authors should more clearly describe the local optimization step (section 3.1; reward). Were all nucleotides that differ mutated independently, or enumerated exhaustively? The latter would have a high runtime of O(3^d), where d is the number of nucleotides that differ. When do the authors start with the local optimization? \n\nMinor comments\n=============\n10. The authors should replace ‘450x’ faster in the abstract by ‘clearly’ faster since the evaluation does not show that LEARNA is 450x faster than all other methods.\n\n11. Does “At its most basic form” (introduction) mean that alternative RNA nucleotides exist? If so, this should be cited.\n\n12. The authors should more clearly motive in the introduction why they created a new dataset.\n\n13. The authors should mention in section 2.1 that the dot-bracket notation is not the only notation for representing RNA structures (https://www.tbi.univie.ac.at/RNA/ViennaRNA/doc/html/rna_structure_notations.html).\n\n14. The authors should define the hamming distance (section 2.1). Do other distance metrics exist?\n\n15. For the Traveling Salesman Problem (section 2.2) should the reward be the *negative* tour length?\n\n16. The authors should more clearly describe the embedding layer (section 4). Are nucleotides one-hot encoded or represented as integers (0, 1  for ‘(‘ and ‘.’)?",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}