{
    "Decision": {
        "metareview": "The reviewers have reached a consensus that this paper is very interesting and add insights into interpolation in autoencoders.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Strong paper"
    },
    "Reviews": [
        {
            "title": "Regularize interpolation or regularize manifold?",
            "review": "Main idea:\nThis paper investigates the desiderata for a successful interpolation:\n1) Interpolation looks realistic;\n2) The interpolation path is semantically smooth. \nAn adversarial regularizer is proposed to achieve 1), and in practice 2) may also satisfied.  \nTo evaluate the method, they introduce a synthetic dataset with line images and compare with different autoencoder methods without the interpolation regularization.\nFor real data, they show that the interpolation regularized autoencoder (i.e. ACAI) leads to a better unsupervised representation.\n\nQuestions:\n1. Do we really need every interpolated point to be realistic (i.e. similar to a data point in the train-set)? I believe that there exists an interpolation between two totally different objects can never be observed.  \n2. Do we need interpolation points to form a semantically smooth morphing? I guess this is a desired property for continuous generators, but it seems not necessary in general.\n3. The gamma in the 2nd term in (1) is confusing. If gamma = 1, I understand it forces to predict alpha = 0 since x is real. But if gamma < 1, the average in data space may be very blurry thus not realistic at all. How does gamma affect the optimization?\n4. ACAI looks very similar to LSGAN: by giving \"0\" label to real data and \"alpha\" label to fake data; in LSGAN, alpha = 1.\nHave you tested a LSGAN like regularizer? \n5. The baselines are not representative: since ACAI introduces an adversarial regularizer, you should compare with other GAN techniques induced regularizers, such as WGAN regularized autoencoder. \n\nAfter rebuttal:\nSee the long discussion below. I tend to believe that a good interpolation is not only a way to do sanity check but also a nice property to explicitly control in representation learning.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review for \"Understanding and Improving Interpolation in AE via an Adversarial Regularizer - Interesting Paper with good results.",
            "review": "Summary: The authors propose a new approach to encourage valid interpolation in Auto-Encoders (AE). It is based on a regularization procedure involving a critic network judging the realistic nature of reconstructed data point from its mixed latent representations by recovering the mixing coefficient. The authors show that this approach does indeed improve the quality of interpolated samples on few tasks. A synthetic tasks of lines interpolation (proposing new Mean Distance and Smoothness metric for this task), classification task (with a single-layer classifier) from the latent space representation and finally a clustering accuracy on the latent space. On the proposed regularization method seems to help significantly compared to commonly used AE architectures (Basic AE, Denoising AE, Variational AE, Adversarial AE and VQ-VAE).\n\nThis paper was a very interesting read, and the work seems to be of significance for the unsupervised learning community.\nIt was clearly written and conveys the contributions clearly and the experimental results and their interpretations seem valid.\n\nThe proposed approach of a critic based regularizer is a simple but seemingly important addition that contributes to improving interpolation in AE significantly and even show impact \"downstream tasks\" as the authors put it.\n\nFew comments/questions come to mind:\n\n- For the critic Loss L_d in equation (1) , the authors mention that the \\gamma based second term (that should ensure that the critic outputs 0 for non-interpolated inputs and expose the critic to realistic data even if the AE reconstruction is poor)  does not seem to be crucial in your approach but stabilized the adversarial training. Could you somehow quantify this. It seems like stability of the adversarial training should be paramount to your method to make sure the AE learns a better latent representation. This comment, even though I assume it well-founded, seems a bit of a contradiction.\n\n- For the Lines synthetic data. It was chosen to use a 32x32 image size with 16 points length lines. This configuration does quantize directly the angles your measures can distinguish. Below a certain angle differences (or delta), 2 angles must have the same pixel representation, i.e. exact overlapping lines. My question is simple: What is the smallest angle you can use/distinguish or, how many exact unique lines can you have? \n\nOverall this is a good paper that deserves publications.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An interesting regularized AE algorithm that improves interpolation in latent space",
            "review": "This paper proposed an adversarially regularized AE algorithm that improve interpolation in latent space. Specifically, a critic is used to predict the interpolation weight \\alpha and encourage the interpolated images to be more realistic. The paper verified the method on a newly proposed synthetic line benchmark and on downstream classification and clustering tasks.\n\nPros:\n1.\tA novel algorithm that promotes the interpolation ability of AE\n2.\tA new synthesized line benchmark to verify the interpolation ability of different AE variants\n3.\tStrong results on downstream classification and clustering tasks\n\nCons: \n1.\tThe interplay of the adversarial network (between AE and critic) isn’t very clear and can be improved\n2.\tEq. 1, should x be x_1 or a new data other than x1 and x2?\n3.\tThe paper states that the 2nd term of Eq. 1 isn’t crucial. If x is a new data (other than x1 or x2), how can the critic infer \\alpha without a reference to x1 or x2?\n4.\tThe paper states that “encouraging this behavior also produce semantically smooth interpolation …”. Besides the empirical evidences from data, it would be better to any some theoretical justifications.\n",
            "rating": "9: Top 15% of accepted papers, strong accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}