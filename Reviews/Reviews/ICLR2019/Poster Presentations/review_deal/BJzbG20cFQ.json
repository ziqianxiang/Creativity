{
    "Decision": {
        "metareview": "1. Describe the strengths of the paper.  As pointed out by the reviewers and based on your expert opinion.\n\n- The problem is well-motivated and related work is thoroughly discussed\n- The evaluation is compelling and extensive.\n\n2. Describe the weaknesses of the paper. As pointed out by the reviewers and based on your expert opinion. Be sure to indicate which weaknesses are seen as salient for the decision (i.e., potential critical flaws), as opposed to weaknesses that the authors can likely fix in a revision.\n\n- Very dense. Clarity could be improved in some sections.\n\n3. Discuss any major points of contention. As raised by the authors or reviewers in the discussion, and how these might have influenced the decision. If the authors provide a rebuttal to a potential reviewer concern, it’s a good idea to acknowledge this and note whether it influenced the final decision or not. This makes sure that author responses are addressed adequately.\n\nNo major points of contention.\n\n4. If consensus was reached, say so. Otherwise, explain what the source of reviewer disagreement was and why the decision on the paper aligns with one set of reviewers or another.\n\nThe reviewers reached a consensus that the paper should be accepted.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "novel high-performing model; thorough experimental analysis and discussion; clarity could be improved"
    },
    "Reviews": [
        {
            "title": "Towards Metamerism via Foveated Style Transfer",
            "review": "Summary\nThis paper proposes a NeuroFovea (NF) model for generation of point-of-fixation metamers. As opposed to previous algorithms which use gradient descent to match the local texture and image statistics, NF proposed to use a style transfer approach via an Encoder-Decoder style architecture, which allows it to produce metamers in a single forward pass, allowing it to achieve a significant speed-up as compared to early approaches.\n\nPros\n-The paper tackles a very intriguing topic.\n-The paper is very well written using concise and clear language allowing it to present a large -amount of information in the 10 pages + appendix.\n-The paper provides a thorough discussion of both the problem, related work and the model itself.\n-A single forward pass nature of the model allows it to achieve a 1000x speed-up in generating metamers as opposed to previous GD based approaches.\n-The authors provide enough details to allow for reproducibility.\n\nCons\n-(Not necessarily a negative) Requires a very careful reading as the paper provides a lot of information (though as mentioned it is very well written)\n-The quantitative evaluation is somewhat lacking in that there are no quantitative psychophysical experiments to compare this model to competing ones across different observers. For example, it would have been interesting to compare the ability of observers to distinguish between original images and metamers generated by different models. \n\nAdditional comments\nOn page 10., you show Fig. 13 however you mention at the end of the first paragraph you further elaborate on Fig 13. in the Supplementary Materials. I think it would be better to either provide more discussion in the text and refer to the figure, or just move it fully to Supplementary materials.\n\nAlso, in the qualitative comparison of various models you mention that SideEye runs in milliseconds whereas NF runs in seconds. It would be interesting to discuss the potential trade-off between speed and the quality of generated metamers between the models.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review of Towards Metamerism via Foveated Style Transfer",
            "review": "This paper presents an interesting analysis of metamerism and a model capable of rapidly producing metamers of value for experimental psychophysics and other domains.\n\nOverall I found this work to be well written and executed and the experiments thorough. Specific points on positives and negatives of the work follow:\n\nPositives:\n- The paper shows a solid understanding of the literature in this domain and presents a strong motivation\n- The problem itself is addressed at a deep level with many nuanced (but important) considerations discussed\n- Ultimately the results of the model seem convincing in particular with the accompanying psychophysical experiments\n\nNegatives:\n- (Maybe not a negative, but a question) At the extreme tradeoff between intrinsic structure and texture, the notion of a metamer seems somewhat obscured. At what point is a metamer no longer a metamer?\n- (Also not necessarily a negative) Exercising SSIM is a valid decision given it's widespread use. I am curious if MS-SSIM, IW-SSIM or other metrics make any significant difference. ",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Somewhat obscure writing, but reasonable contribution",
            "review": "Summary:\nThe paper proposes a fast method for generating visual metamers – physically different images that cannot be told apart from an original – via foveated, fast, arbitrary style transfer. The method achieves the same goal as an earlier approach (Freeman & Simoncelli 2011): locally texturizing images in pooling regions that increase with eccentricity, but is orders of magnitude faster. The authors perform a psychophysical evaluation to test how (in)discriminable their synthesized images are amongst each other and compared with originals. Their experiment replicates the result of Freeman & Simoncelli of a V2-like critical scaling in the synth vs. synth condition, but shows that V1-like or smaller scaling is necessary for the original vs. synth condition.\n\nI reviewed an earlier version of this paper for a different venue, where I recommended rejection. The authors have since addressed some of my concerns, which is why I am more positive about the paper now.\n\nStrengths:\n+ The motivation for the work is clear and the implementation straightforward, combining existing tools from style transfer in a novel way.\n+ It's fast. Rendering speed is indeed a bottleneck in existing methods, so a fast method is useful.\n+ The perceptual quality of the rendered images is quantified by psychophysical testing.\n+ The role of the scaling factor for the pooling regions is investigated and the key result of Freeman & Simoncelli (pooling regions scale with 0.5*eccentricity) is replicated with the new method. In addition, the result of Wallis et al. (2018) that lower scale factors are required for original vs. synth is replicated as well.\n\n\nWeaknesses:\n- Compared with earlier work, an additional fudge parameter (alpha) is introduced. It is not clear why it is necessary and it complicates interpretation.\n- The paper contains a number of sections with obscure mathiness and figures that I can't follow and whose significance is unclear.\n\n\nConclusion:\nThe work is well motivated, the method holds up to its promise of being fast and is empirically validated. However, it feels quite ad-hoc and the writing of the paper is very obscure at various places, which leaves room for improvement.\n\n\nDetails:\n\n- The motivation for introducing alpha not clear to me. Wasn't the idea of F&S that you can reduce the image to its summary statistics within a pooling region whose size scales with eccentricity? Why do you need to retain some content information in the first place? How do images with alpha=1 (i.e. keep only texture) look?\n\n- Related to above, why does alpha need to change with eccentricity? Experiment 1 seems to suggest that changing alpha leads to similar SSIM differences between synths and originals as F&S does, but what's the evidence that SSIM is a useful/important metric here?\n\n- Again related to above, why do you not use the same approach of blending pooling regions like F&S did instead of introducing alpha?\n\n- I would like to know some details about the inference of the critical scaling. It seems surprisingly spot on 0.5 as in F&S for synth vs. synth, but looking at the data in Fig. 12 (rightmost panel), I find the value 0.5 highly surprising given that all the blue points lie more or less on a straight line and the point at a scaling factor of 0.5 is clearly above chance level. Similarly, the fit for original vs. synth does not seem to fit the data all that well and a substantially shallower slope seems equally plausible given the data. How reliable are these estimates, what are the confidence intervals, and was a lapse rate included in the fits (see Wichmann & Hill 2001)?\n\n- I don't get the point of Figs. 4, 13 and 14. I think they could as well be removed without the paper losing anything. Similarly, I don't think sections 2.1 and the lengthy discussion (section 5) are useful at all. Moreover, section 3 seems bogus. I don't understand the arguments made here, especially because the obvious options (alpha=1 or overlapping pooling regions; see above) are not even mentioned.\n\n- How is the model trained? Do the authors use the pre-trained model of Huang & Belongie or is the training different in the context of the proposed method? I could only find the statement that the decoder is trained to invert the encoder, but that doesn't seem to be what Huang & Belongie's model does and the paper does not say anything about how it's trained to invert. Please clarify.\n\n- At various places the writing is somewhat sloppy (missing words, commas, broken sentences), which could have been avoided by carefully proof-reading the paper.",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}