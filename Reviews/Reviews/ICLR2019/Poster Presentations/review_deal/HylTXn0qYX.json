{
    "Decision": {
        "metareview": "This paper proposes a new method for verifying whether a given point of a two layer ReLU network is a local minima or a second order stationary point and checks for descent directions. All reviewers agree that the algorithm is based on number of new techniques involving both convex and non-convex QPs, and is novel. The method proposed in the paper has significant limitations as the method is not robust to handle approximate stationary points. Given these limitations, there is a disagreement between reviewers about the significance of the result . While I share the same concerns as R4, I agree with R3 and believe that the new ideas in the paper will inspire future work to extend the proposed method towards addressing these limitations. Hence I suggest acceptance. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "ICLR 2019 decision"
    },
    "Reviews": [
        {
            "title": "Review",
            "review": "Updates:\nAuthor(s) acknowledged that they cannot get a robust analysis. Furthermore, the optimality test also requires a robust analysis. Therefore, I believe the current version is still incomplete so I changed my score. I encourage author(s) to add the robust analysis and submit to the next top machine learning conference.\n\n-------------------------------------------\nPaper Summary:\nThis paper gives a new algorithm to check whether a given point is a (generalized) second-order stationary point if not, it can return a strict descent direction even at this point the objective function (empirical risks of two-layer ReLU or Leaky-ReLU networks) is not differentiable.\nThe main challenge comes from the non-differentiability of ReLU. While testing a second-order stationary point is easy, because of the non-differentiability, one needs to test 2^M regions in the ReLU case. This paper exploits the special structure of two-layer ReLU network and shows it suffices to check only the extreme rays of the polyhedral cones which are the feasible sets of these 2^M linear programs. \n\nComments:\n1. About Motivation. While checking the optimality on a non-differentiable point is a  mathematically interesting problem, it has little use in deep learning.  In practice, SGD often finds a global minimum easily of ReLU-activated deep neural networks [1].\n2. This algorithm can only test if a point is a real SOSP. In practice, we can only hope to get an approximate SOSP. I expect a robust analysis, i.e., can we check whether it is a (\\epsilon,\\delta) SOSP?\n3. About writing: g(z,\\eta) and H(z,\\eta) appear in Section 1 and Section 2, and they are used to define generalized SOSP. However, their formal definitions are in Lemma 2. I suggest give the formal definitions in Section 1 or Section 2 and give more intuitions on their formulas.\n\nMinor Comments:\n1. Many typos in references, e.g., cnn -> CNN.\n2. Page 4: Big-Oh -> Big O.\n\n\n\nOverall I think this paper presents some interesting ideas but I am unsatisfied with the issues above. I am happy to see the authorsâ€™ response, and I may modify my score. \n\n\n[1] Zhang, C., Bengio, S., Hardt, M., Recht, B., & Vinyals, O. (2016). Understanding deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "review",
            "review": "This paper proposes an efficient method to test whether a point is a local minimum in a 1-hidden-layer ReLU network. If the point is not a local minimum, the algorithm also returns a direction for descending the value of the loss function. \n\nThe tests include a first-order stationary point test (FOSP), and a second-order stationary point test (SOSP). As these test can be written as QPs, the core challenge is that if there are M boundary points in the dataset, i.e.,  data points on a non-differentiable region of the ReLU function, then the FOSP test requires 2^M tests of extreme rays -- each boundary partition the whole space into at least two parts. This paper observes that since the feasible sets are pointed polyhedral cones. Therefore checking only these extreme rays suffices. This results in an efficient test with only 2M tests. \n\nLastly, the paper performs experiments on synthetic data. It turns out there are surprisingly many boundary points.\n\nComments:\nThis paper proposes an interesting method of testing whether a given point is a local minimum or not in a ReLU network. The technique is non-trivial and requires some key observation to make it computationally efficient. However, I have the following concerns:\n1) such a test may need very high numeric precision. For instance, you cannot make sure whether a floating point number is strictly greater than 0 or not. The small error may critically affect the property of a point. \n2) boundary points of a ReLU network should have measure 0 (correct me if not). The finding in the experiment shows surprisingly many boundary points. This is counter-intuitive. Is it because of numeric issues? You might misclassify non-boundary points.\n3) Usefulness. \n    a. The paper claims that such a test would be very useful in practice. However, they cannot even perform an experiment on real datasets. \n    b. Such a method only works for one-hidden layer network. It is not clear deeper network admit similar structure. \n    c. Practical training of neural-network usually trains the network using SGD, which always obtain a solution with a non-zero gradient. In this sense, there is no need for such a testing. \n    d. It seems like it is much easier to perform a test with different activation function, e.g., sigmoid.\n    \nIf the authors can address these concerns convincingly, I would be happy to change the rating.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Algorithm for testing local optimality in ReLU networks",
            "review": "Summary:\nThis work proposes a theoretical algorithm for checking local optimality and escaping saddles when training two-layer ReLU networks. The proposed \"checking algorithm\" involves solving convex and non-convex quadratic programs (QP) which can be done in polynomial time. The paper is well organized and technically correct with detailed proofs.\n\nComments:\n1) Applicability issue: the conditions required by the proposed checking algorithm are too ideal, making it difficult to apply in practical applications. For example, the first step of the proposed algorithm is to check whether 0 belongs to the subdifferential. In practice, the iterates may get very close to a stationary point, but arriving to a stationary point might be too time-consuming and unrealistic. If the problem is smooth, then the gradient is expected to be small so that one can easily relax this first order optimality condition by allowing a small gradient. However, since here the problem is nonsmooth, in general the subgradient could be still very large even when the iterate is very close to a stationary point.  Therefore, one would need to relax the ideal conditions in the proposed algorithm to make it more applicable.\n\n2) Another concern is that the efficiency of the proposed method relies too much on the empirical result that the number of flat extreme ray is small. The computational complexities for the test of the local optimality is exponentially depending on the number of flat extreme rays. Thus to guarantee a high efficiency of the proposed test algorithm and to make the main theory sound, it is important to provide a theoretical bound on this number. Without appropriate theoretical guarantees on the upper-bound of this number, it is not persuasive to claim that the proposed theoretical algorithm is of high efficiency.\n \n3) The computational complexity is proportional to the number of training data points which could be huge. Is it possible to have a stochastic version?\n\nTypos:\n1) On page 2, under Section 2, ``$h(t):=$\" should be ``$h(x):=$\"\n\n2) In section 2.1, at the end of the paragraph \"Bisection by boundary data points\": change $b_1$ by $\\delta_1$ in ``$\\Delta_1x_i+b_1$\".\n\n3) On page 4, when defining B_k, change x by x_i. \n\n4) On page 5, above Lemma 1, when defining C_k, N(x_i) is not well defined.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Refreshing ideas, clever algorithm, unclear impact",
            "review": "The paper proposes a method to check if a given point is a stationary point or not (if not, it provides a descent direction), and then classify stationary points as either local min or second-order stationary. The method works for a specific non-differentiable loss.  In the worst case, there can be exponentially many flat directions to check (2^L), but usually this is no the case.\n\nOverall, I'm impressed. The analysis seems solid, and a lot of clever ideas are used to get around issues (such as exponential number of regions, and non-convex QPs that cannot be solved by the S-procedure or simple tricks). A wide-variety of techniques are used: non-smooth analysis, recent analysis of non-convex QPs, copositive optimization.\n\nThe writing is clear and makes most arguments easy to follow.\n\nThere are some limitations:\n\n(1) the technical details are hard to follow, and most are in a lengthy appendix, which I did not check\n\n(2) there was no discussion of robustness. If I find a direction eta for which the directional derivative is zero, what do you mean by \"zero\"? This is implemented on a computer, so we don't really expect to find a directional derivative that is exactly zero.  I would have liked to see some discussions with epsilons, and give me a guarantee of an epsilon-SOSP or some kind of notion.  In the experiments, this isn't discussed (though another issue is touched on a little bit: you wanted to find real stationary points to test, but you don't have exactly stationary points, but rather can get arbitrarily close).  To make this practical, I think you need a robust theory.\n\n(3) The numerical simulations mainly provided some evidence that there are usually not too many flat directions, but don't convince us that this is a useful technique on a real problem.  The discussion about possible loss functions at the end was a bit opaque.  Furthermore, if you can't find a dataset/loss, then why is this technique useful?\n\nThe paper is interesting and novel enough that despite the limitations, I am supportive of publishing it. It introduces new ideas that I find refreshing. The technique many not ever make it into the state-of-the-art algorithms, but I think the paper has intellectual value regardless of practical value.\n\nIn short, quality = high, clarity=high, originality=very high, and significance=hard-to-predict",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}