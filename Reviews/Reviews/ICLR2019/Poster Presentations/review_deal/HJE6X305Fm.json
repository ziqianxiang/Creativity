{
    "Decision": {
        "metareview": "The paper provides a simple method for regularising and robustifying GAN training. Always appreciated contribution to GANs. :-)",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Good practical approach to stabilise GAN training"
    },
    "Reviews": [
        {
            "title": "robustness regularization improves GANs training",
            "review": "The paper proposed a systematic way of training GANs with robustness regularization terms. Using the proposed method, training GANs is smoother and  \n\npros\n- The paper is solving an important problem of training GANs in a robust manner. The idea of designing regularization terms is also explored in other domains of computer vision research, and it's nice to see the its power in training GANs.\n- The paper provides detailed proofs and analysis of the approach, and visualizations of the regularization term help people to understand the ideas.\n- The presentation of the approach makes sense, and experimental results using several different GANs methods and competing regularization methods are extensive and good in general\n\ncons\n- I didn't find major issues of the paper. I think code in the paper should be made public as it could potentially be very useful for training GANs in general.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good paper with good results",
            "review": "The main idea that this paper presents is that making a discriminator robust to adversarial perturbations the GAN objective can be made smooth which results in better results both visually and in terms of FID. In addition to the  proposed adversarial regularisation the authors also propose a much stronger regularisation called robust feature matching which uses the features of the second last layer of the discriminator. I find the ideas presented in this paper interesting and novel.\nThe authors' claims are supported with sufficient theory and several experiments that prove their claims. The presented results show consistent improvements in terms of FID and actually some of the improvements reported are impressive",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A novel idea, but lack of motivation and intuition",
            "review": "## Overview\n\nThis paper proposes a new way to stabilize the training process of GAN by regularizing the Discriminator to be robust to adversarial examples. Specifically, this paper proves that a discriminator which is robust to adversarial attacks also leads to a robust minimax objects. Authors provide theoretical analysis about the how the robustness of the Discriminator affects the properties of the objective function, and the proposed regularization term provides an efficient and effective way to regularize the discriminator to be robust. However, it does not build connection between the robustness of the Discriminator and why it can provide meaningful gradient to the Generator. Experimental results demonstrate the effectiveness of the proposed method. This paper is easy to understand.\n\n\n## Drawbacks\nThere are some problems in this paper. First, this paper is not highly motivated and lacks of intuition. I can hardly understand why the robustness can stabilize the training of GAN. Will it solve the problem of gradient vanishing problem or speed up the convergence of GAN? The toy example in Sec. 4.2 shows that it can regularize the Discriminator to provide a meaningful gradient to Generator, but no theoretical analysis is provided. The main gap between them is that the smoothness of D around the generated data points does not imply the effectiveness of gradients. Second, the theoretical analysis is inconsistent with the experimental settings. Theorem 4.3 holds true when f is non-positive, but WGANâ€™s loss function can be positive and this paper does not give any details about this part. Third, in Sec. 4.2, I can hardly distinguish the difference between robust loss, robust discriminator and regularized objectives.\n\nBesides, there are lots of typos in this paper. In Sec 3, Generative Adversarial Networks part, the notations of x and z are quiet confusing. In Definition 3.2, d which measures the distance between network outputs is not appeared above.\n\n## Summarization\nGenerally, this paper provides a novel way to stabilize the training of GAN. However, it does not illustrate its motivation clearly and no insight is provided.\n\n## After rebuttal\nSome of the issues are addressed. So I change my rating to 6.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}