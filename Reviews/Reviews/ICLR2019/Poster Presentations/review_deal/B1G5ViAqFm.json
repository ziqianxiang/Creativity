{
    "Decision": {
        "metareview": "1. Describe the strengths of the paper.  As pointed out by the reviewers and based on your expert opinion.\n \n- The paper tackles an interesting and challenging problem with a novel approach.\n- The method gives improves improved performance for the surface reconstruction task.\n\n2. Describe the weaknesses of the paper. As pointed out by the reviewers and based on your expert opinion. Be sure to indicate which weaknesses are seen as salient for the decision (i.e., potential critical flaws), as opposed to weaknesses that the authors can likely fix in a revision.\n\nThe paper\n- lacks clarity in some areas\n- doesn't sufficiently explain the trade-offs between performing all computations in the spectral domain vs the spatial domain. \n\n3. Discuss any major points of contention. As raised by the authors or reviewers in the discussion, and how these might have influenced the decision. If the authors provide a rebuttal to a potential reviewer concern, it’s a good idea to acknowledge this and note whether it influenced the final decision or not. This makes sure that author responses are addressed adequately.\n\nReviewers had a divergent set of concerns. After the rebuttal, the remaining concerns were:\n- the significance of the performance improvements. The AC believes that the quantitative and qualitative results in Table 3 and Figures 5 and 6 show significant improvements with respect to two recent methods.\n- a feeling that the proposed method could have been more efficient if more computations were done in the spectral domain. This is a fair point but should be considered as suggestions for improvement and future work rather than grounds for rejection in the AC's view.\n\n4. If consensus was reached, say so. Otherwise, explain what the source of reviewer disagreement was and why the decision on the paper aligns with one set of reviewers or another.\n\nThe reviewers did not reach a consensus. The final decision is aligned with the more positive reviewer, AR1, because AR1 was more confident in his/her review and because of the additional reasons stated in the previous section.\n",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "novel approach to interesting and challenging problem with promising results"
    },
    "Reviews": [
        {
            "title": "This paper concerns the application of standard CNN methods to input from geometric domains where information is not necessarily provided pre-sampled on a Euclidean grid.",
            "review": "Overall Thoughts:\n\nI think this paper addresses an interesting topic and that the community as a whole are interested on the application of learning algorithms to non-Euclidean domains. It is nice to see the application of Fourier sampling to geometric primitives in a sensible manner and I am positive about that part of the paper. However, in its current form, I have quite a few questions about the approach and the empirical studies - I would need to here more information from the authors on the points below.\n\nSpecific Comments/Questions:\n\nSec1: The authors make a number of assertions about the representational errors that occur in other approaches - I feel that these claims should be supported by specific references.\n\nContributions: It is not clear to me that the experiments show that the method “preserves maximal information content” - in my understanding, information content has a formal definition and I don’t see where this is presented in the results?\n\nSec2: Before CNNs there has been a substantial analysis of Fourier methods applied to shape models, e.g. elliptical Fourier series for shape contours (and signed distance representations) by Prisacariu et al.\n\nSec2: It is also worth noting that there is substantial literature on non-uniform Fourier methods including the non-uniform Fourier transform and a number of accelerations (e.g. NUFFT) as well as consideration of the implications of band-limiting the sampled spectra.\n\nSec3: The mathematical derivation all makes sense to me and makes use of results for piecewise uniform signals. Please could the authors provide more details on how the spectra are represented? These discontinuous signals (esp. delta functions) will have infinite bandwidth in the spectral domain so how they are stored would seem very important to me. Are the signals band limited at some point? If so, how does this affect the approximation and should filtering/windowing be used? Otherwise is there not a difficult storage problem? The final paragraph suggests all the analytic signals might be stored but this has a big impact on how efficient the algorithm is and really is far too important a point to just have a single sentence - please can the authors expand on how this is actually implemented and what the computational considerations are (and resulting impacts on performance)?\n\nSec4: Please can the authors add error bars (at the least) to all the tables/plots in the results. It is entirely unreasonable to make any statements about how significant the results may be without even the most basic of analysis. Ideally we should see histograms of the results for the retrieval and shape reconstruction results. \n\nSec4: How is the downsampling performed in the MNIST experiment? It would seem very important to take care with this for the purpose of comparison. A significant disparity between the signed distance function and the NUFT would seem slightly surprising to me? Again, without error bars we really cannot say very much about the results on the right of Fig3(b).\n\nSec4: Could the Fig4 results not be provided as histograms? We also need many more details about how the results were obtained and procedures to ensure that the results are meaningful and robust (e.g. repeated tests and partitions of the data, etc..)\n\nArch and Training Details: How are we to know that these choices provide fair comparisons to previous approaches?\n\nSec3/4: All the results seem to require the input to be reconstructed back into a dense sampling domain (via inverse FT) - is this the case? Would it not be more efficient to perform the convolutions in the spectral domain where the signal is sparse?\n\nSec4: It seems pretty unfair to train and test on a single category of shapes in the shape test since the data is known not to be very diverse? Particularly when, unless I’ve misunderstood, the baselines on the shape recovery test to not involve learning and so (while helpful to have) they are not really fair baselines compared to other learning approaches? Also, please can the authors provide much more information about the extra processing applied (e.g. the part starting with the “extra mesh thickness”) since there seem to be some extra steps that are nothing to do with the rest of the method and may impact the results significantly. \n\nSec4: It is interesting that Table 3 (again difficult to say without error bars) indicates that there are times when the method performs better with the additional of noise - this seems counter-intuitive - please could the authors comment on this?\n\nOther Points:\n\nI’m afraid that there are quite a few grammatical errors in the text (too many to list here) so I would recommend another round of proof-reading.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "positive solution to learn across varied graph topologies",
            "review": "Convolutiuonnal Neural Networks on Non-uniform Geometrical Signals using Euclidean Spectral Transformation\n\nThe paper tackles the challenging problem of learning across mixed graph topologies, which is today a real challenge. It is highly original due to the unified general framework for handling differing graph topologies. The method is highly generalizable to other learning techniques since it proposes a transformation of varied topologies into a cartesian grid-like embedding, via the new non-uniform Fourier transform. The method is evaluated on MNIST, Shape Retrieval, and point to surface reconstruction. The paper is dense and uses non-trivial mathematical formulations, but reads well and remains easy to follow. The experiments supports well, and greatly adds clarity to understand the proposed methodology. Overall, recommendation towards acceptance. \n\nPositive\n+ Develop a method to analyze signal on mixed topologies with a new non-uniform Fourier transform.\n+ The proposed approach has advantages on -reducing sampling error, -unified framework for mixed topology, -reducing heuristics in designing can architecture, -local weights in mesh structures.\n+ Improved performance in surface reconstruction task.\n\nSpecific Comments\n- In the inverse Fourier Transformation, a voxel-like grid structure is used, however - how to control the size of this volume? If the size is large, or explodes, the complexity of the cnn architecture would explode as well - How is this size issue tackled?\n- In this same inverse Fourier Transformation, the whole infinite space would be obviously hard to sample - Spectral information would be lost - How bad is this and how does this impact results?  How would this compare to direct graph-based methods, for instance, in a fixed graph structure?\n- Ovsjanikov’s Functional maps, siggraph 2012, have been proposed to find maps between differing graph spectrum, partly solving the problem of handling graphs of multiple topologies. One way would be to find spectral correspondences between embeddings. How helpful would this be to find similarities between embeddings in this new proposed unified framework?\n\nTypos - geometris",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Hard to Understand, insufficient results.",
            "review": "This paper introduces a method for handing input data that is defined on irregular mesh-type domains. If I understand it correctly, the core technique is  to perform Fourier analysis to transform the input data to the frequency domain, which is then transformed back to a regular domain before applying a standard neural network. The claimed result is that this is better than standard linear interpolations. The key technical contribution is to define FT on points, edges, and meshes (This reviewer appreciates these efforts). Explicit formula are given. However, the paper does not perform convolutions on the input irregular domain directly, which is quite disappointing. The experimental results are preliminary. It is expected to perform evaluation on more applications such as semantic segmentation. \n\n\nThe major issue of the paper is that the goal was not stated clearly. Does it target for a neural network that is defined on irregular domains or simply a technique to handling irregular domains? Given the Fourier transform, it is possible to define convolutions directly as multiplications in the Fourier domain....the paper can be more interesting, if it follows this line.\n\nOverall, it is hard to champion the paper based on the current technical approach and the experimental results. \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}