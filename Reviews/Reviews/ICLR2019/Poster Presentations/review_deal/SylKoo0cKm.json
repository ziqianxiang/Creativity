{
    "Decision": {
        "metareview": "This paper proposes a new measure to quantify the contribution of an individual neuron within a deep neural network. Interpretability and better understanding of the inner workings of neural networks are important questions, and all reviewers agree that this work is contributing an interesting approach and results.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Interesting work on how to measure the importance of an individual neuron in a network"
    },
    "Reviews": [
        {
            "title": "An important measure of Neuron Importance",
            "review": "This paper presents a new method to measure the importance of hidden neurons in deep neural networks. The method integrates notions of activation value, input influence to a neuron and neuron influence to the network's output. They provide results confirming that this measure is able to identify neurons that are important for specific tasks.\n\nQuality\n\nThe experiments are well designed to verify their hypothesis, although there could be more to make sure those results are not particular to the few selected problems. Nevertheless, the results are consistent across those experiments.\n\nClarity\n\nThe text is well written in general, but the structure could be improved. The introduction contains too much related work, which should be divided in another section. Section 2 contains mostly high level explanations of the work, which should be integrated in the introduction, and thus before the related work section, to improve readability. See minor comments for more specific suggestions.\n\nIt is difficult to understand the goal of Section 4.2. Section 2 states that section 4.2 proves that a \"path method\" must be used in order to satisfy the axioms, but why such axioms are important is not stressed enough. Also, it is not clear why those are called axioms since they are not use to build anything else. It seems to me that those are rather \"desirable properties\" than axioms.\n\nOriginality\n\nA important number of related works are cited and compared with the current work. Although the proposed measure is close to what is proposed by Datta et al., this paper makes the distinction clear and benchmarks its results properly against it.\n\nSignificance\n\nThere is an increasing need to interpretability of deep neural networks as they get more and more applied to real-world problems. Measures as the one proposed in this paper are a very important building block towards this.\n\nConclusion\n\nFor its original importance measure and the proper experiment benchmarks, I believe this paper should be accepted. There is however many minor issues that should be fixed for the camera-ready version. Although the recommended length is 8 pages, the strict limit is 10, so I would recommended to use a bit of the remaining extra space to conclude the paper properly with a discussion on the results and their consequences, as well as a conclusion to wrap up the paper.\n\n***\n\nMinor Comments\n\nIntroduction:\n- The term flow is never defined precisely, we need to infer it based on the definition of conductance and attribution.\n- First paragraph would be more clear with simple word explanation rather than maths. Also, second sentence is not a complete sentence\n- Work on image indicators of importance could be compared better with current work. Indicators can be seen as a measure of importance.\n- This sentence is not clear: \"[...]; the nature of correlations in the two models may differ\".\n\nSection 2:\n- Last paragraph of section 2 can be true for any well-performing importance measure. The statements should be put in perspective with others.\n\nSection 3:\n- Section 3 should be introduced by explaining the goal of the section otherwise it breaks the flow of reading.\n- The role of the baseline x' should be better explained when it is presented (first paragraph of section 3).\n- The interchangeable use of the term \"conductance of neuron j\" for equations 2 and 3 is confusing. Different terms should be use, even if the context makes it possible to infer which one is being referred to.\n- Remark 1 seems trivial, but the selection of baseline x' seems less trivial. Some explanations should be devoted to it.\n- Second paragraph of remark 1 is not clear. Why couldn't we take another layer's neuron as the neuron of interest, bounding the conductance measure on one layer as the input and the output of the model? If we make the input to be a neuron y rather than the true input x, we could take another neuron z in a subsequent layer to be the neuron of interest, resulting in conductance measure Cond^z_i(y).\n\nSection 4:\n- List of importance measure at beginning of Section 4 should probably have citations.\n- Backward reference to section 3 seems to be a mistake, should it be subsection 4.2?\n- Each of the justifications to get around the issue of distinguishing strange model behavior from bad feature importance technique should be explained briefly in paragraph before section 4.1.\n\nSubsection 4.1:\n- I do not understand the problem explained in fourth paragraph of section 4.1. g(f(1 - epsilon)) = 0, why would it be 1- epsilon?\n- Problem explained in fifth Paragraph of section is not clear unless what the influence of the unit is clearly stated. Is it simply dg/df? \n- A short explanation of what is tested in section 6 should be given at last paragraph of section 4.1. Although the results are favorable to the conductance metric, it is not clear how they precisely confirm the problem of incorrect signs presented in the caricature examples.\n\nSubsection 4.2:\n- As said in the my main comments, I am not convinced by the use of the term Axiom. They are not use as building blocks, and are rather used as desirable properties for which the authors prove that only \"path methods\" can satisfy.\n- Footnote 2 on page 5 it difficult to read.\n- Although the proof does not seem to use the axioms as a building block, which is fortunate since it would make it a circular argument otherwise, the text suggests so: \"Given these three axioms, we can show that:\".\n- The importance of section 4.2 should be clarified. More emphasis on the importance of the axioms (desirable properties) should be made.\n\nSection 5:\n- Choices for experiments should be explained. Why choosing layers mixed** rather than others? Why choosing filters?\n- Figures 1-4 are difficult to interpreted on a printed version. Since this is qualitative, I suggest to change the saturation of the images to make them easier to interpret. The absolute values are not important for a qualitative interpretation\n- Figure 4 could be more interesting if compared with other classes, like other animal faces. Anyhow, I understand that those were chosen based on the subset of classes used for the experiments.\n- Space should be added between figures to better divide the captions\n\nSection 6:\n- The difference between experiments of Figure 5 and 6 should be made more clear.\n\nSection 7-8:\n- Where are they? No discussion? No conclusion?",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Requested minor clarifications.",
            "review": "The authors propose a notion of conductance to attribute the deep neural network’s prediction to its hidden units. The conductance is the flow of attribution via the hidden unit(s) in consideration. The paper proposes using conductance to not only evaluate importance of hidden unit to the prediction for a specific input but also over a set of inputs. The strongest part of the analysis of conductance is that conductance naturally couples  the path at the base features with that of the hidden layer.\n\nThe authors position their work well within the existing approaches in the community and generalizes the efficient use of measuring hidden activation wrt to specific input or set of inputs.\n\nThe analysis makes efficient use of mean value theorem in the context of  parametrization of the loss function.\n\nConductance seems to satisfy the completeness of hidden features. Further, it also satisfies the layer-wise conservation principle with the outputs completely redistributed  to the inputs.\n\nIt would be good to see more analysis on the axioms 1 through to 4 for the sake of completeness in the light of partial axiomatization of conductance.\n\nThe authors provide empirical evaluation of conductance over a variety of tasks. It would be good to see some more insight in order to relate to interpretability of the importance of neurons, although there has been no claims made on it as its hard to measure importance without interpretability.\n",
            "rating": "7: Good paper, accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Could use more motivation but it is a good concept.",
            "review": "The idea is nice. It is well aligned with tools that are needed to understand neural networks. However, the experiments feel like they are missing motivation as to why this method is being used. The paper does not provide very significant evidence that this method is useful. The negation example is nice but this doesn't seem to display the potential power of the method to understand a neural network.\n\nMore motivation for experimental section is needed. If the authors don't discuss a motivation then how will a reader know how to apply the tool? It seems there is no conclusion to take away from the experiments in section 5 (convolutions). \n\nThe authors should rethink the structure of the experimental section from the standpoint of convincing someone to use this method. In section 4.1 the authors have a good discussion on what is wrong with other methods in order to motivate their approach but then they don't deliver significant evidence in the later part of the section.\n\nThe paper needs more discussion and experiments to explain how and why to use this approach. \n\nWhile the authors say \"attributing a deep network’s prediction to its input is well-studied\" they don't compare directly against these methods. \n\nThere are many typos and grammar errors\n\nWhile I think the paper could be much more impactful if the experimental section was greatly reworked; I believe the first 5 pages of the paper are a very good contribution and it should be accepted.\n",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}