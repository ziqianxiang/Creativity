{
    "Decision": {
        "metareview": "This paper proposes verification algorithms for a class of convex-relaxable specifications to evaluate the robustness of neural networks under adversarial examples.\n\nThe reviewers were unanimous in their vote to accept the paper. Note: the remaining score of 5 belongs to a reviewer who agreed to acceptance in the discussion.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "Interesting contribution to understanding NNs"
    },
    "Reviews": [
        {
            "title": "good paper, with minor issues",
            "review": "This paper uses convex relaxation to verify a larger class of specifications\nfor neural network's properties. Many previous papers use convex relaxations on\nthe ReLU activation function and solve a relaxed convex problem to give\nverification bounds.  However, most papers consider the verification\nspecification simply as an affine transformation of neural network's output.\nThis paper extends the verification specifications to a larger family of\nfunctions that can be efficiently relaxed.\n\nThe author demonstrates three use cases for non-linear specifications,\nincluding verifying specifications involving label semantics, physic laws and\ndown-stream tasks, and show some experiments that the proposed verification\nmethod can find non-vacuous bound for these problems. Additionally, this paper\nshows some interesting experiments on the value of verification - a more\nverifiable model seems to provide more interpretable results.\n\nOverall, the proposed method seems to be a straightforward extension to\nexisting works like [2]. However the demonstrated applications of non-linear\nspecifications are indeed interesting, and the proposed method works well on \nthese tasks.\n\nI have some minor questions regarding this paper:\n\n1) For some non-linear specifications, we can convert these non-linear elements\ninto activation functions, and build an equivalent network for verification\nsuch that the final verification specification becomes linear. For example, for\nverifying the quadratic specification in physics we can add a \"quadratic\nactivation function\" to the network and deal with it using techniques in [1] or\n[2].  The authors should distinguish the proposed technique with these existing\ntechniques. My understanding is that the proposed method is more general, but\nthe authors should better discussing more on the differences in this paper.\n\n2) The authors should report the details on how they solve the relaxed convex\nproblem, and report verification time. Are there any tricks used to improve\nsolving time? What is the largest scale of network that the algorithm can\nhandle within a reasonable time?\n\n3) The detailed network architecture (Model A, Model B) is not shown. How many\nlayers and neurons are there in these networks? This is important to show the\nscalability of the proposed method.\n\n4) For the Mujoco experiment, I am not sure how to interpret the delta values\nin Figure 1. For CIFAR I know it is the delta of pixel values but it is not\nclear about the delta in Mujoco model. What is the normal range of predicted\nnumbers in this model?  How does the delta compare to it? Is the delta very\nsmall or trivial?\n\n5) Is it possible to show how loose the convex relaxation is for a small toy\nexample? For example, the specification involving quadratic function is a\ngood candidate.\n\nThere are some small glitches in equations:\n\n* In (4), k is undefined\n* In (20), I am not sure if it is equivalent to the four inequalities after (22).\nThere are 4 inequalities after (22) but only 3 in (20).\n\n\nMany papers uses convex relaxations for neural network verification. However\nvery few of them can deal with general non-linear units in neural networks.\nReLU activation is usually the only non-linear element than we can handle in\nmost neural network verification works. Currently the only works that can\nhandle other general non-linear elements are [1][2]. This paper uses more\ngeneral convex relaxations than these previous approaches, and it can handle\nnon-separable non-linear specifications. This is a unique contribution to this\nfield. I recommend accepting this paper as long as the minor issues mentioned\nabove can be fixed.\n\n[1] \"Efficient Neural Network Robustness Certification with General Activation\nFunctions\" by Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, Luca Daniel.\nNIPS 2018\n\n[2] \"A dual approach to scalable verification of deep networks.\" by\nKrishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, and\nPushmeet Kohli. UAI 2018.\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting proposal to craft non-linear, convex relaxable specifications for more complicated networks",
            "review": "This paper considers more general non-linear verifications, which can be convexified, for neural networks, and demonstrate that the proposed methodology is capable of modeling several important properties, including the conversation law, semantic consistency, and bounding errors.\n\nA few other comments\n\n*) Is it critical that the non-linear verifications need to be convex relaxable. Recently, people have observed that a lot of nonconvex optimization problems also have good local solutions. Is it true that the convex relaxable condition is only required for provable algorithm? As the neural network itself is nonconvex, constraining the specification to be convex is a little awkward to me.\n\n*) The paper contains the example specification functions derived for three specific purpose, I'm wondering how broad the proposed technique could be. Say if I need my neural network to satisfy other additional properties, is there a general recipe or guideline. If not, what's the difficulty intuitively speaking?\n\nThe paper needs to be carefully proofread, and a lot of commas are missing.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Some new ideas to generalize verifications for adversarial robustness but limited investigation and experimental results.",
            "review": "- Summary: This paper proposes verification algorithms for a class of convex-relaxable specifications to evaluate the robustness of the network under adversarial examples. Experimental results are shown for semantic specifications for CIFAR, errors in predicting sum of two digits and conservation of energy in a simple pendulum. \n\n- Clarity and correctness: It is a well-written and well-organized paper. Notations and expressions are clear. The math seems to be correct. \n\n- Significance: The paper claims to have introduced a class of convex-relaxable specifications which constitute specifications that can be verified using a convex relaxation. However, as described later in the paper, it is limited to feed-forward neural networks with ReLU and softmax activation functions and quadratic parts (it would be better to tone down the claims in the abstract and introduction parts.)\n\n- Novelty: The idea of accounting for label semantics and quadratic expressions when training a robust neural network is important and very practical. This paper introduces some nice ideas to generalize linear verification functions to a larger class of convex-relaxable functions, however, it seems to be more limited in practice than it claims and falls short in presenting justifying experimental results.\n\n** More detailed comments:\n\n** The idea of generalizing verifications to a convex-relaxable set is interesting, however, applying it in general is not very clear -- as the authors worked on a case by case basis in section 3.1. \n\n** One of my main concerns is regarding the relaxation step. There is no discussion on the effects of the tightness of the relaxation on the actual results of the models; when in reality, there is an infinite pool of candidates for 'convexifying' the verification functions. It would be nice to see that analysis as well as a discussion on how much are we willing to lose w.r.t. to the tightness of the bounds -- especially when there is a trade-off between better approximation to the verification function and tightness of the bound. \n\n** I barely found the experimental results satisfying. To find \"reasonable\" inputs to the model, authors considered perturbing points in the test set. However, I am not sure if this is a reasonable assumption when there would be no access to test data points when training a neural network with robustness to adversarial examples. And if bounding them is a very hard task, I am wondering if that is a reasonable assumption to begin with.\n\n** It is hard to have a sense of how good the results are in Figure 1 due to lack of benchmark results (I could not find them in the Appendix either.)\n\n** The experimental results in section 4.4 are very limited. I suggest that the authors consider running more experiments on more data sets and re-running them with more settings (N=2 for digit sums looks very limited, and if increasing N has some effects, it would be nice to see them or discuss those effects.)\n\n** Page 2, \"if they do a find a proof\" should be --> \"if they do find a proof\" \n** Page 5, \"(as described in Section (Bunel et al., 2017; Dvijotham et al., 2018)\", \"Section\" should be omitted.\n\n******************************************************\nAfter reading authors' responses, I decided to change the score to accept. It got clear to me that this paper covers broader models than I originally understood from the paper. Changing the expression to general forms was a useful adjustment in understanding of its framework. Comparing to other relaxation technique was also an interesting argument (added by the authors in section H in the appendix). Adding the experimental results for N=3 and 4 are reassuring.\nOne quick note: I think there should be less referring to papers on arxiv. I understand that this is a rapidly changing area, but it should not become the trend or the norm to refer to unpublished/unverified papers to justify an argument.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}