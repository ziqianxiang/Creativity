{
    "Decision": {
        "metareview": "1. Describe the strengths of the paper.  As pointed out by the reviewers and based on your expert opinion.\n\nThe proposed method performed well on 3 visual content transfer problems.\n \n2. Describe the weaknesses of the paper. As pointed out by the reviewers and based on your expert opinion. Be sure to indicate which weaknesses are seen as salient for the decision (i.e., potential critical flaws), as opposed to weaknesses that the authors can likely fix in a revision.\n\n- The paper is hard to follow at times\n- The problem being addressed is technically interesting but not well-motivated. That is, the question \"why is this of interest to the ICLR community\" was not well-answered.\n\n3. Discuss any major points of contention. As raised by the authors or reviewers in the discussion, and how these might have influenced the decision. If the authors provide a rebuttal to a potential reviewer concern, it’s a good idea to acknowledge this and note whether it influenced the final decision or not. This makes sure that author responses are addressed adequately.\n\nThere were no major points of contention.\n\n4. If consensus was reached, say so. Otherwise, explain what the source of reviewer disagreement was and why the decision on the paper aligns with one set of reviewers or another.\n\nThe reviewers reached a consensus that the paper should be accepted.\n",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Accept (Poster)",
        "title": "good performance on proposed task; task not well-motivated"
    },
    "Reviews": [
        {
            "title": "interesting approach for a very specific task",
            "review": "This paper tackles the task of content transfer. For a given type of images (frontal face shots), the goal is to transfer a particular localized property (e.g. glasses or facial hair) extracted from one image to another image of the same type (difference face). This is also known as the problem of guided image-to-image translation. \nThe problem is formalized as the one of learning to map two different domains, one domain being composed of images with the property/attribute of interest, the other one containing images without it. The problem is said to be ‘unsupervised’, i.e. there is no pairwise correspondences between images of the two domains (with/without attributes).\nThe novelty of the approach lies on\n-\tthe loss, which is composed of three terms: two reconstruction losses and a domain confusion loss\n-\tthe overall architecture and in particular the fact that images are represented as a combination of the output of two encoders: one encodes the face and the other encodes the property (e.g. glasses).\n\nOverall comments:\n+ a theoretical part discusses generalization bounds and the emergence of disentangled representations\n+ visual results are appealing showing the suitability of the method to the considered task\n- the discussion of the advantages of the proposed method could be improved\n- the motivation for some of the experimental results is unclear (choice of experimental protocol and baselines). \n- the scope of the method seems limited\n\nDetailed comments:\n\nI personally like the described model. The disentanglement mechanism is intuitive to understand, and seems well suited for this particular task, as qualitative evidence suggests. I am not sure if this approach would be applicable beyond the very specific scenario considered in the paper. \n\nThe paper emphasizes that the strength of the method lies on its simplicity w.r.t. competitors, and its better results. These two aspects could be better discussed. \n\nSimplicity: \nIn several places the paper claims that the proposed approach is considerably simpler. Some parts hint to criteria for the ‘complexity’ comparison, such as Table 1 or a few sentences (e.g. “this allows us to train with many less parameters and without the need to applying excessive tuning”). It would be more convincing to have a dedicated discussion of the practical advantages of the simplicity claimed by this method, discussing e.g. training/testing time, memory footprint of the models, convergence properties, stability, etc. \n\nComparison: \nThe chosen baselines, i.e. MUNIT and DRIT are experimentally shown to perform poorly on the considered task. Yet although these methods were also developed for guided image translation, they were designed for a rather different application: style transfer. I am not sure these comparisons bring much insight on the performance of the method.\nExperiments are conducted for a very specific task, on a single dataset. Would the method have broader application?\n\nExperimental protocol:\nI understand that such an approach is difficult to evaluate quantitatively but I am not sure what there is to learn from experiments reported in Table 3, as there is no point of comparison on this task. This could be clarified. \n\nAdditional comments:\n-\tThe paper relies on the assumption that the distribution of persons with sunglasses and that of persons without them is the same, except for the sunglasses. This sounds like a strong requirement for the data used to train the network; it would be interesting to discuss the practical impact of this assumption, especially on the data requirement for the method to perform well\n-\tI found Figure 1 quite useful. A visual representation of the architecture and its associated description help follow the technical part. \n-\tI got confused with some of the claims in section 4.2. More generally, I found the technical part hard to follow.\n-\tThe user study seems small: only 10 pairs of images are considered. How were those pair chosen? Is the set representative?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Unsupervised disentanglement approach for content transfer",
            "review": "The paper proposes an unsupervised approach for mapping two sets of objects, A and B, such that set B contains all the information that is in set A and some additional information. The paper learns a latent space which encodes: (a) information which is shared in both sets, and (b) the additional content present in B. This is done by employing a two-pathway encoder and a decoder for both the sets. Experiments on problems such as adding glasses or facial hair to faces shows that the proposed method performs better than existing disentanglement approaches. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "1: The reviewer's evaluation is an educated guess"
        },
        {
            "title": "Interesting Formulation/Results, Writing Can be Improved",
            "review": "This paper proposes an unsupervised style transfer method uses two-pathway encoder and a decoder for both domains. The loss function can be written using reconstruction losses and the confusion term. Experimental results are very promising comparing to state of the art methods. \n\nThe methodology presented in this paper is simple yet powerful according to the experimental results. However I do have a few concerns:   \n\n1. The writing can certainly be improved.  I had a difficult time understanding Section 2. For example the function Q is upper cased but later the f and g are all lower cased. Why domains A and B are defined using the space and the probability measure? \"our framework assumes that the distribution of persons with sunglasses and that of persons without them is the same,\" The \"distribution of persons\" is not a rigorous definition and is hard to infer what does it actually mean. \"f\" does not appear in the loss terms although it appears under \"min\". \n\n2. I like the simplicity of the objective function, but it is hard for me to understand that why the algorithm does not pick up spurious differences between A and B. For example, what if there are lighting differences and glasses/no-glasses differences between A and B? See 3rd row of figure 2 for an example. \n\n3. Given the huge differences in performance between the proposed method and MUNIT and DRIT, some analysis/discussion on the reason of success/failure should be given.\n\n--------------------------------------------------------\n\nI have read authors' response. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}