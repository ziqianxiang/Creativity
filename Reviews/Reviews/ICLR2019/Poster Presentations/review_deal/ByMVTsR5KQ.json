{
    "Decision": {
        "metareview": "This paper proposes a GAN model to synthesize raw-waveform audio by adapting the popular DC-GAN architecture to handle audio signals. Experimental results are reported on several datasets, including speech and instruments. \n\nUnfortunately this paper received two low-quality reviews, with little signal. The only substantial review was mildly positive, highlighting the clarity, accessibility and reproducibility of the work, and expressing concerns about the relative lack of novelty. The AC shares this assessment. The paper claims to be the first successful GAN application operating directly on wave-forms. Whereas this is certainly an important contribution, it is less clear to the AC whether this contribution belongs to a venue such as ICLR, as opposed to ICASSP or Ismir.  This is a borderline paper, and the decision is ultimately relative to other submissions with similar scores. In this context, given the mainstream popularity of GANs for image modeling, the AC feels this paper can help spark significant further research in adversarial training for audio modeling, and therefore recommends acceptance. I also encourage the authors to address the issues raised by R1.  ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Accept (Poster)",
        "title": "interesting application of GANs to audio, may spark further research."
    },
    "Reviews": [
        {
            "title": "Interesting application, limited algorithmic contribution",
            "review": "This paper applies GANs for unsupervised audio generation. Particularly, DCGAN-like models are applied for generating audio. This application is interesting, but the algorithmic contribution is limited.\n \nQualitative ratings are poor. The important problem of generating variable-length audio is untouched.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "This paper proposes WaveGAN for unsupervised synthesis of raw-wave-form audio",
            "review": "This paper proposes WaveGAN for unsupervised synthesis of raw-wave-form audio and SpecGAN that based on spectrogram. Experimental results look promising.\n\nI still believe the goal should be developing a text-to-speech synthesizer, at least one aspect.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review - Adversarial Audio Synthesis ",
            "review": "\n\n*Pros:*\n-\tEasily accessible paper with good illustrations and a mostly fair presentation of the results (see suggestions below).\n-\tIt is a first attempt to generate audio with GANs which results in an efficient scheme for generating short, fixed-length audio segments of reasonable (but not high) quality.\n-\tHuman evaluations (using crowdsourcing) provides empirical evidence that the approach has merit.\n-\tThe paper appears reproducible and comes with data and code.\n\n*Cons*:\n-\tPotentially a missing comparison with existing generative methods (e.g. WaveNet). See comments/questions below ** \n-\tThe underlying idea is relatively straightforward in that the proposed methods is a non-trivial application of already known techniques from ML and audio signal processing.\n\n*Significance*: The proposed GAN-based audio generator is an interesting step in the development of more efficient audio generation and it is of interest to a subcommunity of ICLR as it provides a number of concrete techniques for applying GANs to audio.\n\n*Further comments/ questions:*\n-\tAbstract/introduction: I’d suggest being more explicit about the limitations of the method, i.e. you are currently able to generate short and fixed-length audio.\n-\tSpecGAN (p 4): I’d suggest including some justification of the chosen pre-processing of spectrograms (p. 4, last paragraph). \n-\t** Evaluation:  The paper dismisses existing generative methods early in the evaluation phase but the justification for doing so is not entirely clear to me: Firstly, if the inception score is used as an objective criterion it would seem reasonable to include the values in the paper. Secondly, as inception scores are based on spectrograms it could potentially favour methods using spectrograms directly (SpecGAN) or indirectly (WaveGAN, via early stopping) thus putting the purely sample based methods (e.g. WaveNet) at a disadvantage. It would seem fair to pre-screen the audio before dismissing competitors instead of solely relying on potentially biased inception scores (which was probably also done in this work, but not clearly stated…)? Finally, while not the aim of the paper, it would have been beneficial to discuss and understand the failures of existing methods in more detail to convince the reader that a fair attempt has been made to getting competitors to work before leaving them out entirely. \n-\tResults/analysis: It is unclear to me how many people annotated the individual samples? What is the standard deviation over the human responses (perhaps include in tab 1)? Consider including a reflection on (or perhaps even test statistically) the alignment between the qualitative diversity/quality scores and the subjective ratings to justify the use of the objective scores in the training/selection process.\n-\tRelated work: I think it would provide a better narrative if the existing techniques are outlined earlier on in the paper.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}