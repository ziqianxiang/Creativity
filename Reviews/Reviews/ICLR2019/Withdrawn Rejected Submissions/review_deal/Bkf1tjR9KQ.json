{
    "Decision": {
        "metareview": "The paper describes an architecture search method which optimises multiple objectives using a genetic algorithm. All reviewers agree on rejection due to limited novelty compared to the prior art; while the results are solid, they are not ground-breaking to justify acceptance based on results alone.\n",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "limited novelty"
    },
    "Reviews": [
        {
            "title": "Good results but limited novelty. Experimental comparison could be improved.",
            "review": "The paper proposes a multi-objective search algorithm that designs resource-efficient convolutional architectures. The key idea is to maintain a population of networks and to iteratively approach the Pareto front through evolution. The normal & reduction cells are searched on CIFAR-10 and then transferred to ImageNet. The resulting architectures empirically lead to better trade-offs than other baselines.\n\nPros:\nThe paper is well-written and easy to comprehend.\nResults are competitive against strong baselines such as NASNet.\nResource budgets are handled in a principled manner with multi-objective optimization. \n\nCons:\n\nMy main concerns are on the technical novelty and experimental comparison.\n\nTechnical novelty:\n\nThe proposed algorithm seems highly similar to the existing multi-objective NAS algorithms, especially the ones based on Pareto optimality [1,2,3]. In Sect 2, the authors state that the main difference from prior works such as [2] and [3] is the usage of a different and larger search space and large-scale experiments. However, both aspects are of limited technical novelty.\n\nExperimental comparison:\n\nIn sect 3.3, the authors say “we noticed that the original NASNet search space can greatly benefit from extra connections from any given block”. If the proposed algorithm was investigated in an enhanced version of the NASNet space, it would be unclear whether we should attribute the reported performance to the proposed multi-objective evolution or this additional search space engineering. It would be better to report the results using the original space as well for fair comparison. \n\nThe main claimed contribution is a multi-objective evolutionary algorithm. To demonstrate its effectiveness, it would be necessary to compare against existent multi-objective NAS strategies in the literature. Most of those strategies (e.g., scalarization, weighted product method) should be straightforward to implement on top of the current search space. The current results are less convincing since the authors only compared their method against single-objective baselines (e.g. NASNet, PNAS, AmoebaNet) which are completely unaware of additional dimensions of the desired objectives. \n\nThe networks are searched on CIFAR-10 and then transferred to ImageNet. Unlike most prior works (including the ones focusing on resource-constrained NAS), the authors did not the final performance of their architecture on CIFAR-10. It would be informative to report the CIFAR-10 results as well.\n\nOther suggestions & questions:\nThe authors did not report their training setup for ImageNet. It would be good to include those details to ensure the readers are informed should there are any additional augmentations.\n\n“uniform mutation and a crossover probability of 0.1” (sect 4.1)\nIt would be better to included more details on these evolution forces for reproducibility. These are also important component of the proposed algorithm.\n\n“We manually select 3 architectures that we will be fully train on ImageNet in Section 4.2” (sect 4.1)\nI believe this part needs more clarifications since there can be a large number of architectures on the Pareto front. What’s the criteria for manual selection?\n\n[1] Elsken, Thomas, Jan Hendrik Metzen, and Frank Hutter. \"Multi-objective architecture search for cnns.\" arXiv preprint arXiv:1804.09081 (2018).\n[2] Kim Ye-Hoon, Reddy Bhargava, Yun Sojung, and Seo Chanwon. NEMO: Neuro-Evolution with Multiobjective Optimization of Deep Neural Network for Speed and Accuracy. ICML’17 AutoML Workshop, 2017.\n[3] Dong, Jin-Dong, et al. \"DPP-Net: Device-aware Progressive Search for Pareto-optimal Neural Architectures.\" arXiv preprint arXiv:1806.08198 (2018).",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The results are competitive, but not too much innovation",
            "review": "The paper is easy to read. The authors did a job in describing the problem, concepts, and the proposed multi-objective optimization method. The computational results are on par with NASNet-A mobile. \n\nIt is good to know that we can use standard multi-objective method for neural architecture search. The implementation seems to be straightforward. The paper mainly uses existing ideas, but with some incremental improvements. It lacks novelty.  \n\nThe time reduction of this method on ImageNet comes from transfer learning by training on CIFAR-10 first. As the paper admits this is not going to generalizing well. How good the method is if just using a single dateset? For CIFAR-10, is this method comparable with ENAS(https://arxiv.org/pdf/1802.03268.pdf)?\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting but incremental work",
            "review": "The authors propose a multi-objective neural architecture search based on an evolutionary algorithm. The contradicting objective functions are optimized by ranking the candidates by Pareto-dominance, replace the bottom 50% with new candidates generated by the top 50% candidates through random mutations. The multi-objective function considers classification accuracy and an approximation of the inference speed. The method is compared to MobileNet and Mobile NASNet on ImageNet indicating an improvement with respect to search time.\n\nThe authors admit that their work is incremental and a combination of existing work. Furthermore, they admit that Dong et al. (2018) is the closest related work, however, they do not compare to them in the experimental section. The method by Dong et al. requires only 8 GPU days (Dvolver requires 50) yielding very similar results. Why this has been ignored remains unclear.\n\nThe paper is not self-contained, important methodological aspects of the method are insufficiently described. I recommend at least to formally define the crowding distance. It would be also reasonable to define your objective functions already in Section 3 instead of mentioning them in the caption of Figure 3 and its axis labels.\n\nI think it's fair to call your approach evolutionary but you might want to discuss its relationship to beam search and in this scope discuss [A].\n\nThe comparison in Table 2 is not fair. You use the swift activation function and do not report the corresponding numbers for MobileNet or Mobile NASNet. Ramachandran et al. (2017) report these (75% and 74.2% for NASNet and MobileNet).\nComparing the Dvolver architecture with ReLU activations to MobileNet does not indicate any improvements.\n\nYou mention that most previous approaches are only keeping track of the best solution while you evolve over a population. Maybe this sentence is not well written and something else is meant but now this statement is wrong.\n\n[A] Thomas Elsken, Jan Hendrik Metzen, Frank Hutter: Simple And Efficient Architecture Search for Convolutional Neural Networks. CoRR abs/1711.04528 (2017)",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}