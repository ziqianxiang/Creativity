{
    "Decision": "",
    "Reviews": [
        {
            "title": "not a careful consideration of causality, causal operation on graphical model, or conditional independence, etc....",
            "review": "\n\nThe objective of the paper is not clear. Which of these are the objective:\n\n- You want to build a classifier that is not influenced by the aging \nor \n- You want to *measure* the effect of disease by removing the age effect\n\n- On page 3, in the v structure A->X-<D, the mutual information between A and D is shown. In this structure, because A and D are independent of each other, the mutual information is zero. Do they mean conditional mutual information?\n\n- In this problem, D is a cause for X. Controlling for the effect (X) does not make sense here. P(D|do(X)) is simply P(D) because of the causal principle. Do(X) will cut the arrow from D to X but will not affect the distribution of D.\n\n- There is also a subtle difference between disease and diagnosis. The disease is the real status of the patient that we do not get to observe or expensive/unethical to measure while the diagnosis is kind of label given by a doctor. In this problem, it is not clear if D is decided based on A and X by the doctor or it is done differently. \n\n- The authors need to show the effectiveness of their method on simulated data.\n\n- For such a small sample size, I am not convinced the NN is necessary. In a small sample size regime, the proposed metric results in high variance estimation because there will be a very small number of subjects in each bucket. \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Theoretical and algorithmic novelty is not enough. Exhaustive domain/empirical evidence is expected. Needs work.",
            "review": "Following the summary comment, the main issue is -- the idea makes sense in terms of using fair representation learning for confounding variable analysis. However, several aspects needs to be improved. \n\n1) Evidence for linguistic feature predicting age seems not enough i.e., the error reported in page 8 is approx. 40% of the overall range of the age in the two datasets considered; Hence the confounder SNR might not be strong to show significant changes/patterns in disentanglement scores (of Hardt et al) -- which is why all the deltas in Tables 1, 2 are very close. \n\n2) There is an implicit influence of the good-ness of input/linguistic features? How to account for that in the performance summaries? Also, any specific reason for choosing 2 and 5 groups/bins for age? \n\n3) The models in Table 2 should 'not' have significant differences in the ideal case -- is this correct? i.e., the disentanglement scores are doing reasonable job for all settings? Also, the authors suggest the improvements are mostly significant -- this should be more precise (back to exhaustive evaluations thing). \n\n4) The scale of disentanglement is difficult to interpret. Shouldn't the score be normalized by the group size to fix the range across all comparisons? \n\n5) What is the basis for presenting the four models? And it seems the simplest model is working best because, for the size of the dataset (small, unlike standard CV data), the non-simple models are over-parameterized and more non-linear (for the lack of a better phrase) to train?  \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Important problem. Some convincing results. Some missing baselines. Some missing previous work. Limited novelty.",
            "review": "This paper proposes an approach to disentangle the impact of \"age\" while quantifying the impact of narrative transcripts on predicting dementia. \"Age\" is a confounder as it impacts both the narrative transcripts (due to change in cognitive abilities with age) and dementia (as one gets older they're more likely to get dementia). \n\nThe paper proposes an adversarial approach which essentially learns to correctly predict dementia classification using narrative text but adversarially predicts \"age\" to deconfound the impact of \"age\". The paper also contributes by extending the fairness metric proposed by (Madras et. al. 18) to continuous attributes. The experimental results are shown on dementia datasets based on DementiaBank and FamousPeople to highlight the efficacy of the proposed approach.\n\nThe paper is well written and nicely describes the motivation for the problem being solved. That said, the paper has several weaknesses:\n\n1). There is a rich literature these days on adversarially protecting sensitive attributes OR relatedly text understanding in confound-controlled settings. Some of the papers that the authors missed and should cite are: \"Deconfounded Lexicon Induction for Interpretable Social Science\"; \"Interpretable Neural Architectures for Attributing an Adâ€™s Performance to its Writing Style\" (both Pryzant et. al. '18); \"Towards robust and privacy-preserving text representations.\" (Li et. al. 18) etc. \n\nConditioning on that work, the methodological novelty of the proposed approach is little. I consider the extension of the metric proposed by (Madras et al. 18) to continuous sensitive attributes-- as touted by authors-- as straightforward. The only novel contribution in my eyes is the use of adversarial techniques for the important problem of dementia prediction-- a very important problem.\n\n2). The paper discusses the weaknesses of the conventional approaches to the confound-controlled problem e.g. \"Controlling A\", \"Controlling X\", \"Pre-adjusting X\". However, it does not mention or compare against another set of popular approaches in statistics and social sciences for such problems-- matching-based approaches such as propensity-score matching which match dementia patient with a control who is most similar to them on attributes such as age.\n\n3). Also, how would a conventional \"residualization\" approach fare relative to the proposed approach? That is, first regress (potentially non-linearly) narrative transcripts on age and compute the residual i.e. part of variance in text not explained by age. Finally, regress this residual on dementia. \n\n4). In the experiments section, the authors mention that they did not directly optimize the fairness metric i.e. FP/FN rates as it is non-differentiable. That is true, but they definitely need to provide that baseline as it will provide an upper-bound on the most fair solution that could be achieved and would help put the results in perspective. (There are methods out there for non-differentiable objective functions, though of course they might lack theoretical guarantees.  I believe that having any such baseline numbers is more important than having none at all.)\n\n5). It's surprising that the simplest of the methods i.e. age-indep-simple and age-indep-autoencoder have the best fairness scores in Table 2. Why is that? Why don't more complex approaches based on consensus and entropy fare better? ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}