{
    "Decision": {
        "metareview": "AR1 is concerned about the novelty and what are exact novel elements of the proposed approach. AR2 is worried about the novelty (combination of existing blocks) and lack of insights. AR3 is also concerned about the novelty, complexity and poor  evaluations/lack of thorough comparisons with other baselines. After rebuttal, the reviewers remained unconvinced e.g. AR3 still would like to see why the proposed method would be any better than GAN-based approaches.\n\nWith regret, at this point, the AC cannot accept this paper but AC encourages the authors to take all reviews into consideration and improve their manuscript accordingly. Matters such as complexity (perhaps scattering networks aren't the most friendly here), clear insights and strong comparisons to generative approaches are needed.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Some merit."
    },
    "Reviews": [
        {
            "title": "Simple combination of existing works",
            "review": "The paper used the graph scattering network as the encoder, and MLP as the decoder to generate links/graph signals/graphs.\n\nPros:\n1.\tClearly written. Easy to follow.\n2.\tNo need to train the encoder\n3.\tGood results on link prediction tasks\n\nCons:\n1.\tLack of novelty. It is a simple combination of existing encoders and decoders. For example, compared to VGAE, the only difference in the link prediction task is using a different encoder. Even if the performance is very good, it can only demonstrate the effectiveness of others’ encoder work and this paper’s correct selection of a good encoder. \n2.\tLack of insights. As a combination of existing works, if the paper can deeply explain the why this encoder is effective for the generation, it is also beneficial. But we also do not see this part. In particular, in the graph generation task, the more important component may be the decoder to regulate the validness of the generated graphs (e.g. “Constrained Generation of Semantically Valid Graphs via Regularizing Variational Autoencoders. In NIPS 2018” which used the similar decoder but adding strong regularizations in VAE). \n3.\t Results on QM9 not good enough and lack of references. Some recent works (e.g. “Junction Tree Variational Autoencoder for Molecular Graph Generation, ICML 2018”) could already achieve 100% valid. \n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting topic, but the paper does not contain enough novel content.",
            "review": "## Summary ##\n\nThe authors apply the wavelet scattering transform to construct an autoencoder for graphs. They apply this architecture to reconstructing citation graphs, images, and generating molecules.\n\n## Assessment ##\n\nIt was difficult to discern what parts of this paper were new work. The graph scattering transform seems to have appeared first in Hammond et al. or Zhou and Lerman. The proposed decoder in 3.2.1 is attributed to Kipf and Welling. The molecule generation portion was interesting, but I don't think there was enough novel content in this paper to justify acceptance to ICLR. I could be convinced otherwise if the authors' contribution is clarified in rebuttal.\n\n## Questions and Concerns ##\n\n* I found the definition of $S[p]f$ (page 5) a little confusing. In particular, what constitutes a 'path' $p$ in this setting?\n* Can you motivate the whitening operation $A$ that is applied to the encoding? It seems like this is eliminating a lot of the information encoded in $\\bar{X}$.\n* I'm confused by the choice of loss function at the top of page 6. Since $D(z) = \\sigma(...)$, it seems like $D(i, j)$ is meant to represent the probability of a link between $i$ and $j$. In that case, the loss is a sum of negative probabilities, which is unusual. Was this meant to be a sum of log probabilities? Also, this loss doesn't seem to account for including edges where there are none. Can you explain why this is the case?\n* In section 4.2, the encoded dimension is 256 IIUC. Considering that the data was restricted to the \"boots\" class, the reduction from 784-->256 dimensions does not seem significant. The authors concede that some high-frequency information is lost, so I wonder how their approach compares to e.g. a low-pass filter or simple compression algorithm.\n* Section 4.3 states that the molecules considered are constructed from atoms C, H, O, N and F. Later, there are multiple references to only 4 atom types, one-hot vectors in $R^4$ etc. Clarify please!",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting paper, may lack novelty and clarity, seems to have problems in experimental evaluation.",
            "review": "Summary:\nThe paper presents a generative model for graphs which is a VAE-like architecture where the encoder is a scattering transform with fixed parameters (rather than a trainable neural net)\n\nPros:\n+ The problem of graph generative models is very important, and a lot of the existing methods are not very scalable.\n+ Using spectral methods in place of standard \"neural net operations\" makes a lot of sense. \n+ Numerical results for the \"link prediction\" task seem to be significantly better than those of baselines.\n\nCons: \n- The paper contains various imprecisions (see the non-exhaustive list below), and significant amount of statements which are hard to understand.\n- I am not sure if the work can be considered particularly novel: in particular, it is not really emphasised what is the difference with [Angles & Mallat '2018].\n- The motivation for the work is not entirely clear: it is true that GANS and VAEs have their issues, but in my view it is not really explained / argued why the proposed method would solve them.\n- I find the argument about the efficiency not very convincing, especially after looking at the members (bottom of p. 7): the scattering transform alone takes several orders of magnitude longer than the baseline. Authors also mention that their method does not require training \fof the encoder, but I do not see any comparisons with respect to number of parameters.\n- The experimental evaluation for \"signal generation\" and \"graph generation\" is not very convincing. For the former there is no real comparison to existing models. And for the latter, the experimental setup seems a bit strange: it appears that the models were trained on different subsets of the dataset, making the comparison not very meaningful. Also, I would expect to see the same methods to be compared to a cross all the tasks (unless it is impossible for some reason).\n\nVarious typos / imprecisions / unclear statements:\np.1, \"are complex as well as difficult to train and fine-tune.\": not at all clear what this means.\np.1, \"Their development is based on fruitful methods of deep learning in the Euclidean domain, such as convolutional and recurrent neural networks.\": Recurrent and convolution neural network are not necessarily restricted to Euclidean domains. \np.1, \"Using a prescribed graph representation, it is possible to avoid training\nthe two components at the same time, but the quality of the prescribed representation is important\nin order to generate promising results.\": not clear what this sentence means.\np.2, \"Unlike GAN or VAE, the model in this paper does not require training two components either iteratively or at the same time.\": I do not see why that would necessarily be a bad thing, especially in the case of VAE where traditional training in practice corresponds to training a single neural net.\np.3, \"GAN-type graph networks use a discriminator in order to compete with the generator and make its training more powerful.\": I am not sure this statement is strictly correct.\np.9: \"We remark that the number of molecules in the training sets are not identical to that in ...\": does this mean that the models are effectively trained on different data? In that case, the comparison is not very meaningful.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}