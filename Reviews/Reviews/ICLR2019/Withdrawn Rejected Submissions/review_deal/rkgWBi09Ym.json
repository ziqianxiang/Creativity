{
    "Decision": "",
    "Reviews": [
        {
            "title": "Official review",
            "review": "Summary:\nThe paper proposes a variant of GAN, called Gaussian Mixture GAN (GM-GAN), which essentially replaces the simple, unimodal prior over latent spaces of standard GAN with a mixture of Gaussians, motivated by the goal of increasing diversity of samples. The number of mixture components is fixed, but parameters of each component can be learned. Experiments show that, given the right number of mixture components, GM-GAN can produce better results than standard GAN. In addition, the paper proposes to score GANs based on two separate measures: 1) quality score, which reports the Euclidean distance in feature space (of some pretrained classifier) between a given generated image and its nearest-neighbor in training set (again, nearest neighbor according to same feature space), and 2) diversity score, which combines intra-class diversity using MS-SSIM metric and inter-class diversity using entropy of a pre-trained classifier’s predictions. Finally, the paper proposes applying the GM-GAN model as a clustering method, and shows that it can achieve competitive results on 3 image datasets.\n\nStrengths:\n-\tThe problem of lack of diversity/mode dropping is an important problem in GANs and the proposed approach seems like an intuitive way to address it.\n-\tThe lack of a proper metric for evaluating generative models is indeed a very important research problem. Decomposing desired qualities of generated data into separate metrics seems like a sensible approach.\n-\tProposed approach achieves state-of-the-art results on clustering in MNIST.\n\nWeaknesses:\n-\tThe novelty of the proposed approach is questionable, especially given a published work which propose exactly the same idea of using a Gaussian Mixture as prior for GANs in CVPR 2017 [1]. \n-\tThe paper does not address an important limitation of this approach: how to decide the number of mixture components. A more recent paper [2] (accepted at NIPS 2018 – possibly was not available at the time of this submission) addresses this issue.\n-\tThe proposed evaluation metrics do not seem to be quite different from current metrics, e.g. Inception score and FID, except that it explicitly tries to disentangle diversity vs. quality aspects\n\nOverall recommendation: \nGiven the aforementioned weaknesses, especially the lack of novelty, I do not recommend acceptance of this paper.\n\nReferences:\n[1] Gurumurthy, Swaminathan, Ravi Kiran Sarvadevabhatla, and R. Venkatesh Babu. \"DeLiGAN: Generative Adversarial Networks for Diverse and Limited Data.\" CVPR. 2017.\n[2] Khayatkhoei, Mahyar, Maneesh Singh, and Ahmed Elgammal. \"Disconnected Manifold Learning for Generative Adversarial Networks.\" NIPS (2018).\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "a natural idea (combine GAN and Mixture of Gaussian)",
            "review": "To improve the synthetic image quality of GAN, the paper presents a method by combining GAN and Mixture of Gaussian (MOG), termed GM-GAN. In addition, a new scoring measurement is proposed by considering the diversity vs. quality of the generated samples. \n\nProbs:\n1.\tIt is a promising topic to improve the synthetic image quality \n2.\tIt is also promising to combine MOG and GAN.\n\nCons.\n1.\tMaybe the most ``tough’’ question is that how about the advantages of the proposed method over the recent BigGAN in terms of the generated data. \n2.\tthe difference should be further highlighted with VAE-GAN and its variants, as well as , Probabilistic Generative Adversarial Networks; \n3.\tCould the proposed method be verified on a higher resolution image dataset? The current used images are too small considering recent developments. \n4.\tBesides generated mnist (fig.4), the illustration on some more challenging data sets should be given, as well as some failed examples. \n5.\tAs you use the label to train the GM-GAN (alg 1), is it fair to compare the method with other unsupervised clustering approaches? i.e. the label has been implicitly/explicitly used for clustering. Moreover, pls also clarify step 7-8 in alg 2.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}