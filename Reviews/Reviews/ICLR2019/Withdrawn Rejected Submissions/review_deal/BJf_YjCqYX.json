{
    "Decision": {
        "title": "Important problem, interesting solution, however stronger results may be needed",
        "metareview": " The paper addresses an important problem of detecting biases in classifiers (e.g. in face detection), using simulation tools with Bayesian parameter search. While the direction of research and the presented approach seem to be practically useful, there were several concerns raised by the reviewers regarding strengthening the results (e.g., beyond single avatar, etc), and suggestions on possibly a more applied conference as a better venue.  While thourough rebuttals by the authors addressed some of these concerns, which increased some ratings, overall, the paper was still in the borderline range. We hope the suggestions and comments of the reviewers can help to improve the paper.\n\n \n ",
        "recommendation": "Reject",
        "confidence": "3: The area chair is somewhat confident"
    },
    "Reviews": [
        {
            "title": "The paper uses computer graphics simulation for determining bias in commercial Face detection systems.  Specifically, skin type, age, head pose, expression parameters are varied to generate the data. Efficient exploration of simulation parameter space is done by using Bayesopt. ",
            "review": "Quality and Clarity:  The paper is clear and has comprehensive references to the recent literature and past literature on face detection, bias in computer vision data and systems.  \nOriginality:   Since the main claim of the paper is about the use of graphics simulation for performance characterization, we recommend that the authors review past work on use of simulations for systems performance characterization.  The idea of using simulations to perform performance assessment of vision goes back to the 90's (see for instance: haralick et al (haralick.org, performance characterization papers). The idea of using computer graphics simulations for transfer learning and performance assessment has been revisited recently (see for instance: veerasavarappu et al, 2015-17, arxiv papers, cvpr 2017, wacv 2017). \n\nSignificance:  While the paper demonstrates the utility of the main idea, the results are not comprehensive and can be strengthened.  For instance, the authors state that simulations can be used to combat bias via training with augmented data.   My opinion is that the paper may be more well suited in a applied workshop/conference such as WACV. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Important application area but findings are preliminary",
            "review": "\nSummary:\n=========\nThe paper uses a proof-of-concept Bayesian parameter search-based simulation in virtual environment to probe biases of an already trained model towards specific categories that may have been sparsely represented in the training set. Understanding bias in trained models, especially in models involving end-to-end deep neural networks learners, is of high importance in machine learning. More specifically, probing the source of unintentional bias introduced as a result of skewed distribution in the training set and dissecting the biased performance is important for many applications such as surveillance, criminal profiling, medical diagnosis and predicting creditworthiness of a person. \n\nThe authors used four commercial face recognition APIs (by Microsoft, Google, IBM, and Face++) as test bed for this investigation.\n\nStrength:\n========\n- The paper reads well and is easy to follow.\n\n- The application of face detection and recognition is a good choice as it is precursor to detailed analysis in surveillance and criminal profiling.\n\n- The choice of the controlled Bayesian parameter search enables one to control the amount of variation with respect to the expected uncertainty in performance of the classifier on the generated input from the simulator.\n\n- The use of standardized measures such as Fitzpatrick’s skin tone and FACS intensity help in replication and consistency in the evaluation.\n\nWeakness:\n=========\n\n- Although evaluating commercial APIs is good enough in demonstrating the existence of the bias, access to the trained model with possibility to retrain the model in such a way to mitigate a bias in particular parameter could have helped to further tie the drop in performance to the parameter variation.\n\n- This work is preliminary and only involves a single person face manipulated in the parameter space. It lacks diversity of in samples and as such limits the analysis to draw strong conclusions. As such a generative network (such as a GAN trained to generate diverse samples while controlling for the parameters under investigation could have helped to draw more generalized conclusion.\n\n- The age parameter variation is not convincingly different across the values considered. It would have been interesting to use models trained for age progression such as [1] for a more diverse variation in the age parameter space.\n\nMinor comments:\n===============\n- Figures 4 and 5 could have used better captions describing the ranges for instance for age 1 is older and for skin tone 1 is darker (although indicated in Fig. 3). Captions should be self contained. Fig. 5 caption should describe the chance performance in each case.\n\n- The manuscript should be revised to make in text citation formats consistent (some places it uses authors (year) and other places it uses (authors, year)). Also, minor punctuation and syntactic errors should be fixed.\n\n[1] Yang, H., Huang, D., Wang, Y. and Jain, A.K., 2017. Learning face age progression: A pyramid architecture of gans. arXiv preprint arXiv:1711.10352.",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Decent paper but I have several concerns.",
            "review": "This paper identifies bias of commercial Face detection API (Microsoft, Google, Face++, IBM) by sending face images generated from AirSim, in which different face attributes (e.g., skin color, age, face orientation, lighting conditions, etc) can be controlled and explored. The paper shows that for darker skin color and old age, the classifier tends to have a higher false negative rate (miss the face more). This is in particular more apparent if Bayesian Optimization is used to explore the parameter space based on the previous detection results to find the failure cases. \n\nThere are several concerns:\n\n1. Bayesian Optimization might itself create a bias in the input data distribution, since it selectively pick some parameter configuration over the others.   \n\n2.  Using simulator might create additional biases. Maybe the faces generated by the simulator using the parameters of skin color of the minority / old age are less realistic than other faces, which lead to higher misclassification rate. In the paper there is no analysis in that aspect. \n\nOverall I feel this is an interesting paper and it may identify important problems in the existing commercial AI system. However,  I am not an expert in this field so I am less confident about the thoroughness of experiments, as well as the fairness of approaches. \n\nMinor issue:\n\nFig. 4 “Age”, skin detection => age. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}