{
    "Decision": "",
    "Reviews": [
        {
            "title": "A paper with some problems",
            "review": "This paper proposes to combine the gradients of source domains to help the learning in the target domain.\n\nAccording to Eq. (1), it seems that the proposed model is not so flexible as claimed in the introduction since an implicit assumption behind Eq. (1) is that different tasks share the same network architecture. If the source and target tasks are from different domains, how to adjust the weights associated with the input layers since different tasks have different feature representations with different dimensionalities. Similar situation happens to the output layer for different types of tasks as the label spaces are different.\n\nAuthors claim that problem (5) is a constrained non-linear optimization problem. However, in my opinion, this is a linear programming problem with an analytical and trivial solution. I don't know where the nonlinearity comes.\n\nThe use of pseudo labels is very common in semi-supervised learning. I cannot see any significant contribution of the proposed methods compared with existing approaches.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good Idea but major issues with formulation and experimental setup.",
            "review": "The paper is proposing a method which is aimed for multi-source domain adaptation with weak supervision. In addition to the classical setup, paper also consider the case in which some of the source domains have a possibly non-overlapping label space with the target task. Proposed idea is rather simple and effective. The paper consider a model in which shared parameters are updated with convex combination of gradients, computed for available sources. The mixture weights for the convex combination is chosen such that the resulting update decreases the loss function of the few labelled examples from the target domain. This defines a bilevel optimization problem and paper uses a simple proxy which is minimising the cosine distance between the mixture and the gradient for the few labelled examples.\n\nThe biggest strength of the paper is its effectiveness in large set of experiments. Considering that it is also very easy to implement, I would expect the idea to be useful for the deep learning community. Idea of using adaptive weights for each batch and using different mixture weights for different layers are interesting and novel. Having said that, the paper is not ready to be published yet in my honest opinion as I summarize the issues below.\n\nMAJOR ISSUES:\n- Experimental Setup: Although the method is largely compared with domain adaptation methods, the setup is almost identical to few shot learning. In few shot learning, the test(target) and train(source) distributions typically have different label distribution. Hence, all few-shot learning methods are valid baselines for this paper. I think recent ones should be included in the experimental study. I would also suggest to use few-shot datasets like OmniGlot and CARS for the experiments since the performance of few-shot learning algorithms on them is already widely presented in the literature.\n\n- Related Work: Although the paper does a good job comparing with related work in domain adaptation, it misses two recent work which poses a bilevel optimization problem for meta-learning in order to solve a similar problem. These references are: [Bilevel Programming for Hyperparameter Optimization and Meta-Learning, ICML 2018] and [Deep Bilevel Learning, ECCV 2018]. Although these papers addresses slightly different problems with different optimization methods, fundamental idea is closely related. Authors should discuss these works.\n\n- Correctness: I think the way the optimization problem (defined in Equation 5) is solved is NOT correct. First of all, the inner product is a linear operator; hence the problem is a linear program in terms of w_{s_i}^l. Hence, the statement that it is a non-linear optimization problem is not correct. Second of all, as long as any of the inner-products is positive, the optimal value is infinity as the w is not bounded. Even if it was bounded, it would be a one hot vector such that the weight corresponding to largest inner product is 1 and others are zero. I do not think the paper solves (eq 5) correctly. Please correct me if I misunderstood some part.\n\nMINOR ISSUES\n-Implementation Details: Paper is missing majority of implementation details. For example, how the parameters are shared between different domains and tasks? This is rather crucial and should be discussed in details.\n\nSUMMARY: I think the fundamental idea in the paper is interesting although a similar ideas have been used for similar problems already. I think the paper would still be useful to the community even after considering the limited novelty. However, I do not think the paper is correct. Moreover, I think it needs a stronger empirical study comparing with few-shot learning methods. Hence, I suggest authors to fix the correctness issue. extend the experiments with few-shot learning setup, and re-submit.\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Incremental over previous literature. Contributions not thoroughly validated by experiments",
            "review": "This paper is essentially a combination of a modified meta-learning reweighting framework plus self-training. The proposed reweighting framework is largely similar to Ren et al. ICML18, with certain changes including cosine similarity based meta-learning objective, layer-wise weighting, and adaptive learning rate. \n\nClarity:\n- The paper is well-written with good clarity.\n\nConcerns:\n- There are several significant weaknesses in the paper that points to a clear rejection of this work:\n\n1) The proposed methods seems incremental, given the existence of Ren et al. ICML18. The idea of self-training is not new either. The authors also failed to cite several highly related works that used pseudo-label/self-training for domain adaptation:\nZou et al., Domain Adaptation for Semantic Segmentation via Class-Balanced Self-Training, ECCV18\nInoue et al., Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation, CVPR18\nLee, Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks, ICML13 Workshop\n\n2) With all proposed modifications on top of Ren et al. ICML18, there is not any theoretical or empirical justification to support these modifications except the ablation study on adaptive learning rate. The proposed method is not even compared with Ren et al. ICML18, or other meta-learning methods. \n\n3) The proposed GradMix module doesn't seem to outperform many previous literature in the experiment. The only part that gives a very clear gain happens to be the pseudo-label module, which has been investigated widely by many previous works and is not a major contribution of this work.\n\nSummary:\n- Overall, it is hard to see substantial contributions of this work given the incremental improvements, limited justifications, and the limited performance gain from the main technical method.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}