{
    "Decision": {
        "metareview": "This paper proposes novel recurrent models for polyphonic music composition and demonstrates the approach with qualitative and quantitative evaluations as well as samples. The technical parts in the original write-up were not very clear, as noted by multiple reviewers. During the review period, the presentation was improved. Unfortunately the reviewer scores are mixed, and are on the lower side, mainly because of the lack of clarity and quality of the results.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "recurrent models for polyphonic music composition, quality seems to be the issue"
    },
    "Reviews": [
        {
            "title": "well-written paper",
            "review": "The paper is well written and presented, giving a good literature review and clearly explaining the design decisions and trade-offs. The paper proposes a novel factorisation approach and uses recurrent networks. \n\nThe evaluation is both quantitative and qualitative. The qualitative experiment is interesting, but there is no information given about the level of musical training the participants had. You would expect very different results from music students compared to the general public. How did you control for musical ability/ understanding?\n\nThe paper has a refreshing honesty in its critical evaluation of the results, highlighting fundamental problems in this field.\n\nOverall, while I am not an expert in musical composition and machine learning, the paper is clear, and appears to be advancing the art in a reliable fashion.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Contains a good overview and extensive simulations. Unfortunately poor technical writing.",
            "review": "\nComposing polyphonic music is a hard computational problem. \nThis paper views the problem as modelling a probability distribution \nover musical scores that is parametrized using convolutional and recurrent \nnetworks. Emphasis is given to careful evaluation, both quantitatively and qualitatively. The technical parts are quite poorly written.\n\nThe introduction is quite well written and it is easy to follow. It provides a good review that is nicely balanced between older and recent literature. \n\nUnfortunately, at the technical parts, the paper starts to suffer due to sloppy notation. The cross entropy definition is missing important details. What does S exactly denote? Are you referring to a binary piano roll or some abstract vector valued process? This leaves a lot of guess work to the reader. \nEven the footnote makes it evident that the authors may have a different mental picture -- I would argue that a piano roll does not need two bits. Take a binary matrix: Roll(note=n, time=t) = 1 (=0) when note n is present (absent) at time t. \n\nI also think the term factorization is sometimes used freely as a synonym for representation in last paragraphs of 4 and first two paragraphs of 5 -- I find this misleading without proper definitions.\n\nThe models, which are central to the message of the paper, are not described clearly. Please\ndefine function a(\\cdot) in (2), (3), (4), : this maybe possibly a typesetting issue (and a is highly likely a sigmoid) but what does x_p W_hp x x_pt etc stand for? Various contractions? You have only defined the tensor as x_tpn. Even there, the proposed encoding is difficult to follow -- using different names for different ranges of the same index (n and d) seems to be avoiding important details and calling for trouble. Why not just introduce an order 4 tensor and represent everything in the product space as every note must have a duration? \n\nWhile the paper includes some interesting ideas about representation of relative pitch, the poor technical writing makes it not suitable to ICLR and hard to judge/interpret the extensive simulation results.\n\nMinor:\n\nFor tensors, 'rank-3' is not correct use, please use order-3 here if you are referring to the number of dimensions of the multiway array. \n\nWhat is a non-linear sampling scheme? Please be more precise.\n\nThe Allan-Williams citation and year is broken:\nMoray Allan and Christopher K. I. Williams. Harmonising Chorales by Probabilistic Inference. Advances in Neural Information Processing Systems 17, 2005.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "sections almost made sense, output almost sounded good, ... (\"4: Ok but not good enough\")",
            "review": "PROs\n-seemingly reasonable approach to polyphonic music generation: figuring out a way to splitting the parts, share parameters appropriately, measuring entropy per time, all make sense\n-the resulting outputs tend to have very short-term harmonic coherence (e.g. often a ‘standard chord’ with some resolving suspensions, etc), with individual parts often making very small stepwise motion (i.e. reasonable local voice leading)\n-extensive comparison of architectural variations\n-positive results from listening experiments\n\nCONs\n-musical outputs are *not* clearly better than some of the polyphonic systems described; despite the often small melodic steps, the individual lines are quite random sounding; this is perhaps a direct result of the short history\n-I do not hear the rhythmic complexity that is described in the introduction\n-the work by Johnson (2015) (ref. provided below) should be looked at and listened to; it too uses coupled networks, albeit in a different way but with a related motivation, and has rhythmic and polyphonic complexity and sounds quite good (better, in my opinion) \n-some unclear sections (fixable, especially with an appendix; more detail below)\n-despite the extensive architectural comparisons, I was not always clear about rationale behind certain choices, eg. if using recurrent nets, why not try LSTM or GRU? (more questions below)\n-would like to have heard the listening tests; or at least read more about how samples were selected (again, perhaps in an appendix and additional sample files)\n\n quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).\n\nQuality -- In this work, various good/reasonable choices are made. The quality of the actual output is fine. It is comparable to-- and to my ears not better than-- existing polyphonic systems such as the ones below (links to sample audio are provided here):\n\n-Bachbot - https://soundcloud.com/bachbot (Liang et al 2017)\n- tied parallel nets - http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/ (Johnson 2015, ref below)\n-performanceRNN - https://magenta.tensorflow.org/performance-rnn - (Simon & Oore 2017)\n..others as well..\n\n\nClarity -- Some of the writing is \"locally\" clear, but one large, poorly-organized section makes the whole thing confusing (details below). It is very helpful that the authors subsequently added a comment with a link to some sample scores; without that, it had been utterly impossible to evaluate the quality. There are a few points that could be better clarified:\n\t-p5”a multi-hot vector of notes N”. It sounds like N will be used to denote note-numbers, but in fact it seems like N is the total number of notes, i.e. the length of the vector, right? What value of N is used?\n-p5 “a one-hot vector of durations D”. It sounds like D will be used to denote durations, but actually I think D is the length of the 1-hot vector encoding durations right? What value of D is used, and what durations do the elements of this vector represent?\n-similarly, does T represent the size of the history? This should really be clarified.\n\t-p5 Polyphonic models.\n\t\t-Eq (2), (3), (4): Presumably the h’s are the hidden activations layers?\n\t\t-the networks here correspond to the blue circles in Fig 1, right? If so, make the relationship clear and explicit \n\t\t-Note that most variables in most equations are left undefined       \n\t\t-actually defining the W’s in Eq(2-4)  would allow the authors to refer to the W’s later (e.g. in Section 5.2) when describing weight-sharing ideas. Otherwise, it’s all rather confusing. For example, the authors could write, “Thus, we can set W_p1 = W_p2 = W_p3 = W_p4” (or whatever is appropriate). \n\t-Generally, I found that pages 5-7 describe many ideas, and some of them are individually fairly clearly described, but it is not always clear when one idea is beginning, and one idea is ending, and which ideas can be combined or not. On my first readings, I thought that I was basically following it, until I got to Table 5, which then convinced me that I was in fact *not* quite following it. For example, I had been certain that all the networks described are recurrent (perhaps due to Fig1?), but then it turned out that many are in fact *not* recurrent, which made a lot more sense given the continual reference to the history and the length of the model’s Markov window etc. But the reader should not have had to deduce this. For example, one could write, \n\t“We will consider 3 types of architectures: convolutional, recurrent, .... In each architecture, we will have [...] modules, and we will try a variety of combinations of these modules. The modules/components are as follows:”. It’s a bit prosaic, but it can really help the reader. \n-Appendices, presented well, could be immensely helpful in clarifying the exact architectures; obviously not all 22 architectures from Table 5 need to be shown, but at least a few of them shown explicitly would help clarify. For example, in Fig1, the purple boxes seem to represent notes (according to the caption), but do they actually represent networks? If they really do represent notes, then how can “notes” receive inputs from both the part-networks and the global network? Also, I was not entirely clear on the relationship of the architecture of the individual nets (for the parts) to that of the global integrating network. E.g. for experiment #20, the part-net is an RNN (with how many layers?? with regular or LSTM cells?) followed by a log-linear predictor (with one hidden layer of 300 units right? or are there multiple layers sometimes?), but then what is the global network? Why does the longest part-history vector appear to have length 10 based on Table 5, but according to Table 3 the best-performing history length was 20? Though, I am not sure the meaning of the “bottom/top” column was explained anywhere, so maybe I am completely misunderstanding that aspect of the table? Etc.\n-Many piano scores do not easily deconstruct into clean 4-part polyphony; the example in Appendix A is an exception. It was not clear to me how piano scores were handled during training. \n-Terminology: it is not entirely clear to me why one section is entitled “homophonic models”, instead of just “monophonic models”. Homophonic music usually involves a melody line that is supported by other voices, i.e. a sort of asymmetry in the part-wise structure. Here, the outputs are quite the opposite of that: the voices are independent, they generally function well together harmonically, and there is usually no sense of one voice containing a melody. If there’s some reason to call it homophonic, that would be fine, but otherwise it doesn’t really serve to clarify anything. However, the authors do say that the homophonic composition tasks are a “minor generalization of classic monophonic composition tasks”, so this suggests to me that there is something here that I am not quite understanding.\n\nThe last sentence of Section 5.3 is very confusing-- I don’t understand what lin_n is, or 1_n is, or how to read the corresponding entries of the table. The first part of the paragraph is fairly clear. \n\nTable 4: “The first row” actually seems like it is referring to the second row. I know what the authors mean, but it is unnecessarily confusing to refer to it in this way. One might as well refer to “the zeroth row” as listing the duration of the clip :)\n\nThe experimental evaluation: I would like to hear some of the paired samples that were played for subjects. Were classical score excerpts chosen starting at random locations in the score, or at the beginning of the score? It is known that listening to a 10-second excerpt without context can sometimes not make sense. I would be curious to see the false positives versus the false negatives. Nevertheless, I certainly appreciate the authors’ warning to interpret the listening results with caution.\n\n\n\n\nOriginality & Significance -- So far, based both on the techniques and the output, I am not entirely convinced of the originality or significance of this particular system. The authors refer to “rhythmically simple polyphonic scores” such as Bachbot, but I cannot see what is rhythmically fundamentally more sophisticated about the scores being generated by the present system. One nice characteristic of the present system is the true and audible independence of the voices.\n\nOne of the contributions appears to be the construction of models that explicitly leverage with shared weights some of the patterns that occur in different “places” (pitch-wise and temporally) in music. This is both very reasonable, and also not an entirely novel idea; see for example the excellent work by Daniel Johnson, “Generating Polyphonic Music Using Tied Parallel Networks” (paper published 2017, first shared online, as far as I know, in 2015: links to all materials available at http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/  )\nAnother now common (and non exclusive) way to handle some of this is by augmenting the data with transposition. It seems that the authors are not doing this here. Why not? It usually helps. \n\nAnother contribution appears to be the use of a per-time measure of loss. This is reasonable, and I believe others have done this as well. I certainly appreciated the explicit justification for it, however.\n\nNote that the idea of using a vector to indicate metric subdivision was also used in (Johnson 2015).\n\nPlaying through some of the scores, it is clear that melodies themselves are often quite unusual (check user studies), but the voices do stay closely connected harmonically, which is what gives the system a certain aural coherence. I would be interested to hear (and look at) what is generated in two-part harmony, and even what is generated-- as a sort of baseline-- with just a single part. \n\nI encourage the authors to look at and listen to the work by Johnson:\n-listening samples: http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/\n-associated publication: http://www.hexahedria.com/files/2017generatingpolyphonic.pdf\n\nOverall, I think that the problem of generating rhythmically and polyphonically complex music is a good one, the approaches seem to generally be reasonable, although they do not appear to be particularly novel, and the musical results are not particularly impressive. The architectural choices are not always clearly presented.\n\t\t\t\n\t\t\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}