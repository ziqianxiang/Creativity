{
    "Decision": "",
    "Reviews": [
        {
            "title": "interesting idea",
            "review": "multi-objective learning is known to regularize estimation and improve optimization. the authors excellently bring this idea to causal inference, in particular learning conditional average treatment effect. I see the main contribution of the paper experimental: the authors demonstrate that their methods achieve good results on different tasks.\n\nthe causal setting it operates under is the classical one: under strong ignorability and overlap. the contribution is in causal estimation, rather than causal identification.\n\nwhile the authors claim the results are all state-of-the art, in several cases, it seems the S-learner is a very competitive and seemingly favorable competitor; in simulation 4,5,6 of fig 3 for example. and fig 6.\n\ncould the authors please clarify in their understanding of the empirical performance? in what scenario/data patterns will the Y-learner often outperform? when does it perform the best compared to its competitors. it could help to give intuitions of why and when the proposal work. it could help future users decide when to use it.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "More experimental evaluations can improve the paper",
            "review": "Summary\nThis paper proposed to estimate the conditional average treatment effect (CATE) in counterfactual inference by modifying an existing approach, called X-learner, in the following ways. First, both the treatment response function and the control response function were modeled as neural networks, denoted as f_theta, rather than random forest. The imputed treatment effect can be computed. Second, the mapping from the imputed treatment effect to the CATE were also modeled as neural networks, denoted as f_tau. Therefore, f_theta and f_tau can be jointly optimized through backpropagation. Experimental results on a simulated dataset showed that the co-training of f_tau and f_theta contributed most to the improvement of Y-learner compared to the X-learner. Experimental results on six simulated datasets, the VOTE dataset, and MNIST dataset showed the proposed Y-learner can outperform its competing alternatives, including T-leaner, S-learner, R-learner, X-learner, on a subset of all datasets.\n\nComments\nThis work aimed to estimate the conditional average treatment effect. The related work section contains relevant work from the statistics and economics community. Did the author try to implement and compare against some strong baselines commonly used in the machine learning community, such as the Bayesian additive regression trees (BART, Hill 2011), the counterfactual regression with integral probability metrics (Shalit et al. ICML 2017), counterfactual multiple-task Gaussian process (Alaa et al. NIPS 2017)?\n\nWhy didn't the MSE of X-learner (Figure3: Simulation 3) and T-learner (Figure 3: Simulation 1, Figure 5) monotonically decrease w.r.t. the number of samples?\n\nWere the confidence intervals shown in Figure 2,3 generated by simulating those synthetic datasets multiple times? Could the authors explain why the confidence interval of the Y-learner is very small when the number of samples used is quite small?\n\nWhat were the network architectures and detailed hyper-parameter settings used for f_theta and f_tau? Were the results sensitive to the choice of those parameters? For the competing baselines (T-leaner, S-learner, R-learner, X-learner), which model were used as the function approximator, neural network or random forest?",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting idea, but both writing and experiments need further improvement",
            "review": "In this submission, the authors propose the Y-learner to estimate conditional average treatment effect(CATE), which simultaneously updates the parameters of the outcome functions and the CATE estimator. The co-learning strategy idea is interesting, but the details of the method are not well explained and the experiment results seem not convincing. The detailed comments are as follows:\n\nFirst, the motivation of Y-learner is not well presented. As mentioned in the paper, Y-learner is an improvement of X-learner, so the authors need to clearly illustrate the deficiency of X-learner. Also, whether the Y-learner can keep the advantages of X-learners and overcome its disadvantages?\n\nSecond, in section 3, the authors mention the importance of the learning rate in the training of GAN as an analogy to explain why co-learning can achieve better performance. However, it doesn’t convince me well, and the reasons are as follows: in GAN, the generator and discriminator have the adversarial relationship, but this relationship is no longer exist in Y-learner as the outcome prediction networks (f_{\\theta_0}, f_{\\theta_1}) and CATE estimation network (f_{\\tau}) are complementary. Whether the phenomenon observed in the GAN training can be an analogy to explain the superiority of co-learning is still doubtful. The authors should give more detailed explanations.\n\nThird, I have some questions about the results (figure 2) of the experiment which aims to test the importance of co-learning in the Y-learner. (1) Which category (method with co-learning or without co-learning) the method Y-learner with no backpropagation belongs to? Is the method Y-learner with no backpropagation the same as Algorithm 1 excluding the line 3 and 7? (2) In figure 2, the method Y-learner with no backpropagation achieves similar performance with the full Y-learner. Why does this happen? Whether the method Y-learner with no backpropagation can replace the Y-learner? Why the authors design the full backpropagation through f_{\\theta_0}, f_{\\theta_1} when training f_{\\tau} in the Y-learner?\n\nForth, whether the machine learning methods adopted in R, S, T, X-learners are all neural networks when conducting the experiment on the simulated data as well as the GET-OUT-THE-VOTE dataset? \n\nFifth, the experiment results are not convincing. In the introduction, the authors claim that Y-learner can achieve state of the art performance with only a fraction of the data on several CATE estimation tasks. However, the results on six simulated datasets and the MNIST task don’t support this claim: (1) In the simulated datasets, only in dataset 2 (complex linear case), the Y-learner has better performance with fewer training samples, and in the other five datasets, there always exits some baselines that perform better than Y-learner. (2) In the MNIST task, the baseline method S-learner performs much better than the proposed method, and also S-learner requires much less training sample to learn good CATE estimator compared with Y-learner. \n\nSixth, the analysis of the experiment results are missing. For example, the authors should explain why the proposed method doesn’t perform as well as S-learners in MNIST task. \n\nMinor question: the notations \\pi_{\\theta_0}, \\pi_{\\theta_1}, and \\pi_{\\tau} in Figure 1 are not explained. Are they typos? Or they should be f_{\\theta_0}, f_{\\theta_1} and f_{\\tau} instead of \\pi?\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}