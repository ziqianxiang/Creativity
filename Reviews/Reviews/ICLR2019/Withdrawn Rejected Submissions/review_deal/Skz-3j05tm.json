{
    "Decision": {
        "metareview": "This paper describes a graph convolutional network (GCN) approach to capture relational information in natural language as well as knowledge sources for goal-oriented dialogue systems. Relational information is captured by dependency parses, and when there is code switching in the input language, word co-occurrence information is used instead. Experiments on the modified DSTC2 dataset show significant improvements over baselines.\nThe original version of the paper lacked comparison to some SOTA baselines as also raised by the reviewers, these are included in the revised version.\nAlthough the results show improvements over other approaches, it is arguable BLEU and ROUGE scores are not good enough for this task. Inclusion of human evaluation in the results would be very useful.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Good performance but not much novelty"
    },
    "Reviews": [
        {
            "title": "Interesting topic, requires a somewhat better analysis",
            "review": "The current paper proposes using Graph Convolutional Networks (GCN) to explicitly represent and use relational data in dialog modeling, as well an attention mechanism for combining information from multiple sources (dialog history, knowledge base, current utterance). The work assumes that the knowledge base associated with the dialog task has en entity-to-entity-relationship format and can be naturally expressed as a graph. The dependency tree of dialog utterances can also be expressed as a graph, and the dialog history as a set of graphs. To utilize this structure, the proposed method uses GCNs whose lowest layer embeddings are initialized with the entity embeddings or via outputs of standard RNN-like models. The main claim is that the proposed model outperforms the current state-of-the-art on a goal-oriented dialog task.\n\nThe idea of explicitly modeling the relational structure via GCNs is interesting. However, the use of GCNs independently per sentence and per knowledge-base is a bit disappointing, since it does not couple these sources of information in a structured way. Instead, from my current understanding, the approach merely obtains better representations for each of these sources of information, in the same way it is done in the related language tasks. For instance, have you considered passing information across the trees in the history as well? Or aligning the parsed query elements with the KB elements?\n\nThe results are very good. That said, a source of concern is that the model is only evaluated as a whole, without showing which modification brought the improvements. The comparison between using/not using RNNs to initiate the first GCN layer is promising, but why not compare to using only RNN also? Why not compare the various encoders within an established framework (e.g. without the newly introduced attention mechanism)? Finally, the attention mechanism, stated as a contribution, is not motivated well.\n\nClarity:\nThe notation is described well, but it's not terribly intuitive (the query embedding is denoted by c, the history embedding by a, etc.), making section 4.4. hard to follow. A figure would have made things easier to follow, esp. due to the complexity of the model. A clearer parallel with previous methods would also improve the paper: is the proposed approach adding GCN on top of an established pipeline? Why not?\n\nMore discussion on code-mixed language, e.g. in section 4.6, would also improve clarity a bit (make the paper more self-contained). While the concept is clear from the context, it would be helpful to describe the level of structure in the mixed language. For instance, can dependency trees not be obtained code-mixed languages? Is there any research in this direction? (or is the concept very new?) Maybe I am just missing the background here, but it seems helpful in order to asses how appropriate the selected heuristic (based on the co-occurence matrix) is.\n\nRelevant Reference:\nLearning Graphical State Transitions, Johnson, ICLR 2017 also uses graph representations in question answering, though in a somewhat different setting.\n\nTypos:\nSection 4: \"a model with following components\"\nSection 5: \"the various hyperparameters that we conisdered\"",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good performance but less clear novelty",
            "review": "The paper proposes a Graph Convolutional Network-based encoder-decoder model with sequential attention for goal-oriented dialogue systems, with the purpose of exploiting the graph structures in KB and sentences in conversation. The model consists of three encoders for a query, dialogue history, and KB, respectively, and a decoder with a sequential attention mechanism. The proposed model attains state-of-the-art performance on the modified DSTC2 dataset of (Bordes et al., 2017). For the experiments with graphs constructed from word co-occurrence matrix, code-mixed versions of modified DSTC2 released by (Banerjee et al., 2018) are used.\n\nPros and Cons\n(+) SOTA performance on the DSTC2 dataset.\n(+) Without dependency parser when it is not possible\n(-) Limited novelty\n(-) Limited convincing the advantage of GCN itself\n\nDetailed comments\nThe paper incorporates the graph structures in sentences and KB to make richer representations of conversation and achieves a state-of-the-art performance on the DSTC2 dataset. The paper is clearly written, and the results seem promising. However, as the paper combines existing mechanisms to design a model for dialog, the novelty seems to be relatively weak.\nIn particular, I felt that some experimental results are required to verify some of the arguments put forward by the authors. We listed two issues as below.\n\n1. Effects of GCN\nThe authors show that RNN-GCN-SeA can make state-of-the-art performance, but not how much GCN makes effects on improving the performance on the dialog task. \nI think the authors need to compare the results of RNN-GCN-SeA with a model without GCN (i.e. RNN-SeA) in order to show that exploiting the structural information of dependency and contextual graphs do play an important role.\nThe random graph experiments (Table 3) show the effect of good structure in GCN, but I felt that it is not enough to demonstrate an improvement by GCNs. \n\n2. Comparative Experiments\nI think that some experiments, which is reported in the previous papers (including Mem2Seq), would make the authorâ€™s experimental argument strong.\n- Entity F1 score for the modified DSTC2 dataset\n- Results on bAbI dialog dataset (task1~5 and its OOV variants) and In-Car Assistant dataset\n\nMinor issues\n1. Authors described that Mem2Seq is one of the state-of-the-art models in this field, including in the abstract. However, Mem2Seq does not outperform seq2seq model in all experiments. From what point of view is this model state-of-the-art? \n2. Recent studies have focused on copy mechanism in task-oriented dialog systems. Could you explain how the copy mechanism could be incorporated into the proposed model? I am also interested in the comparative results between seq2seq + attn + copy (per-resp-acc of 47.3) and its entity F1 measure (Eric and Manning, 2017; Madotto et al. 2018).\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A dialogue system that is novel in using graph convolutional networks as part of an encoder-decoder dialogue system with attention",
            "review": "This is a well-written paper (especially the introduction) with fairly extensive experimentation section. It'a very possitive for me that you resort to more than one set of figures of merit.\n\nMy concerns are: \n\nYou mention that GCNs have been used for question-anwering already. It would be infomative to furhter describe this work and clearly state how you handle things differenclty, since a Q&A system is quite close to a dialogue one.\n\nThere are some parts that could be made more clear. For example, when you mention that you collectively represent all trees as a single graph. How do you do that?\n\nThe model has a great number of parameters. It is not clear to me how you concluded to the specific parameter values. \n\nIt would be nice to add the complexity of the model and also be more specific about how you choose the parameter values.\n\nMy proposals are:\n\nI think that the paper would greatly benefit if you additionally to the equations you also presented the model in a graphical way as well. Additionally, although the paper is very well mathematically defined, is not so easy to follow from a practical perspective. For example, regarding section 5.3 I would prefer to see the 3 models you present in a graphical way as well.\n\nMaybe add the links to the datasets you are using? On a related subject, would your models be transferable accross datasets?\n\nMinor issues\nPPMI abreviation is first used and then defined.\nThere are also some typos, like conisdered (that I suppose was meant to be considered, for example)",
            "rating": "7: Good paper, accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}