{
    "Decision": "",
    "Reviews": [
        {
            "title": "A GAN-inspired way to watermark (embed special identification code) into deep neural networks.",
            "review": "The paper considers watermarking neural networks - making them react to a special, hidden to observers patterns in input images.\n\nIn the proposed approach an Encoder E takes an input image, and modifies it to embed the watermark. Then a decoder, D is tasked to find images with the added watermark. The magnitude of the modification is constrained by limiting the distance between the activations of a VGG19 network. The method proposed in the paper seems to be simple and effective on some benchmark datasets.\n\nThe paper is poorly written: the concept of watermaking is only explained on page 2, and the description given refers to a more general use than the one facilitated by the methods in this paper (watermarking is defined to embed a user-defined signal s into a sample whereas the proposed technique can only transmit one bit - the sample has been watermarked or not).  Then. the technique is presented from a GAN perspective, even though the Encoder and Decoder networks cooperate and need a third network to ensure that the watermarking is hard to detect (this third, VGG19 net is revealed only on page 5). This third network seems to be more important than the exact fatty-skinny architecture of the encoder decoder, but its properties are not evaluated in the paper. In fact, without this third network, the proposed approach could just learn to change a single pixel of the image for watermarking purposes, a trivial operation.\n\nFurthermore, the paper lacks proper design goals for the watermarking procedure. This makes it impossible to judge the value of the proposed architectural choices. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "This paper proposes a GAN-based technique to generate watermarked images. In the presented setup, a high-capacity generator generates watermarked samples that should be decodable by a low-capacity detector. The idea is that the decoder can then be used within other neural networks for protection or to attack them. Different to a vanilla GAN setup, the decoder and encoder work together. The watermark, in the proposed setup, is added by combining residual blocks and an attention mechanism. Experiments are presented for a couple of publicly available datasets.\n\nFrom a technical point of view, I think this is a valid strategy to follow, however, the motivation is unclear to me. If the goal is to create watermarked images that can be detected later on, many methods in the information security literature exist. The authors argue two particular points: (1) the detector needs to be lightweight and (2)  they do not want to implant a predefined signal into the images, but rather let the encoder decide what needs to be implanted. Regarding point (1), as\nmentioned, many methods exist that are (non neural-network based) fast in detection (AND fast in embedding), as they essentially only require correlation with a watermark signal in a transform domain (DWT, DCT, etc.), see, e.g.,\n\nJ. R. Hernandez, M. Amado, and F. Perez-Gonzalez. \nDCT-domain watermarking techniques for still images: Detector performance analysis and a new structure.\nIEEE Transactions on Image Processing, 9(1):55–68, Jan. 2000.\n\nA. Nikolaidis and I. Pitas. \nAsymptotically optimal detection for additive watermarking in the DCT and DWT domains. \nIEEE Transactions on Image Processing, 12(5):563–571, May 2003.\n\nA. Briassouli, P. Tsakalides, and A. Stouraitis. \nHidden Messages in Heavy-Tails: DCT-Domain Watermark Detection Using Alpha-Stable Models. \nIEEE Transactions on Multimedia, 7(4):700–714, Aug. 2005.\n\nR. Kwitt, P. Meerwald and A. Uhl\nA Lightweight Rao-cauchy Detector for Additive Watermarking in the Dwt-domain.\nACM Workshop on Multimedia and Security, 2008.\n\n...\n\nThese methods further provide optimality guarantees for detection (under certain assumptions) and allow\nto directly control the embedding strengths which affects the PSNR for instance.  \n\nRegarding issue (2), it's unclear to me why implanting a signal is not desirable. Typically this is just a sequence of random numbers generated by a specific seed.\n\nAdditionally, the authors claim that their method produces \"robust\" watermarks, however, this is not evaluated. Typically, one would try to attack the watermarking scheme to address this question. Also, the produced watermarks (e.g., Fig. 2) are not imperceptible. This is also not directly controllable, as it depends on the optimization procedure. My suggestion for the authors is to perform a more fine-grained comparison to existing techniques and assess robustness as well as the impact of existing schemes on classification performance (as done for their method). Maybe, the authors can also comment on the achieved PSNR values  which are rather low, compared to SWM for instance. Modifying images in such a way might be undesirable in practical applications. Typically, it is also important to assess how the embedding strength affects the detection success in a more fine-grained manner (similar to Table 1). \n\n\n\n\n\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting paper, confusing at times, needs more work.",
            "review": "This paper starts by discussing the usage of watermarking for Deep-NN's. Then changes topic and focuses on using DNN's for image watermarking. This is perhaps the most confusing point of this paper, since it's foundational to the paper structure.\n\nIf my understanding is correct, and let me be clear I am not 100% sure it is, but if this this paper is about \"using a DNN's to embed watermarking in images\", the authors should state it clearly at the beginning, including in the abstract and in the introduction, and resubmit. The discussion about using adversarial examples to watermark DNN's (so that the networks themselves are not stolen) is a departure from the core message, and a very confusing one indeed.\n\nBased on this current understanding, my review follows.\n\nThis paper proposes a encoder-decoder method, based on CNN's to embed a watermark into images (and audio).\n\nTo be clear, this is watermarking by detection, which means the decoder will output 1 if an image is watermarked, 0 otherwise. Effectively this watermarking is adding 1-bit of information to the content. I say this because usually (classic) watermarking methods can add codewords of more than one bit to content, thus allowing to embed the copyright owner private key(s) for future retrieval and proof of ownership; more on the implications of this later, at the end of the paper.\n\nThe network architecture(s) proposed are asymmetrical, in the sense that the encoder is high capacity and decoder is small. This makes sense, given that one want to perform decoding quickly, but adding the watermark can tolerate more computation/delay. The encoder is based on attention/convolutions and residual connections.\n\nThe decoder is based on a small DCGAN discriminator. The authors then state \"is very hard to identity the decoder after being implanted into a neural network model because it is tiny and uses only very standard neural operators.\". This again is confusing - under my understanding that this method is about image watermarking, why would we add this decoder into another network, covertly? Can the authors please clarify this?\n\nThe authors then proceed by discussing about GAN and GAN related loss functions in section 3.3, but then in section 4.3 they show a loss function that in their own words is not GAN related, because there is no \"Adversarial\" game. \nConfusing again: why to talk about GAN when there is no \"A\" - this is clearly NOT an adversarial game, there is an encoder and a recognizer which looks at a image and tells if it's watermarked or not. A better way to write this loss function would be a simple softmax cross-entropy of the output of the recognizer (D) to the image class of 1=watermarked ~ 0=not-watermarked. When I look at eq.3, I am not 100% sure it achieves that.\n\nThe authors correctly point out that for the watermark to not be detectable, it has to be small in some sense. To achieve that the authors  penalize the detection loss (eq.3) with a VGG hinge-loss on the watermarked vs non-watermarked image. The authors simply state that this works better than pixel-wise features.  \nThis makes sense, but only to some extent; it would have been better to show comparisons of watermarks between L1/L2 and VGG losses, because VGG loss will tend to prefer visually appealing distortions which might still be rather large distortions in term of PSNR. In some applications this is OK, for in some other applications this is not OK. You can imagine some content owners now wanting their images distorted more than a certain margin in a \"euclidean\" sense, in which case VGG loss might not work.\n\nThe paper then provides results for image and also speech recognition. Results show distortions levels as well changes in recognition accuracy due to the added watermarking noise, as well as watermarking detection rate. The results are good, with low distortion, negligible loss in accuracy, and almost perfect detection rate. \n\nThe experimental results are clearly the strong point of this paper. However, and this is a big however, the authors do not provide public source code to reproduce the results. I strongly encourage authors to submit publicly available code and data.\n\nFinally, to conclude, I would like to elaborate on the validity of the embed 1-bit / detect approach to watermarking.\nThis is very important, since this method does not add one code-word but only 1-bit, then the question is how can we really evaluate this system?\n\nPicture the following scenario: Let's assume I am owner-A ~ I train my network, I embed my one 1-bit into my images. Let's say that the esteemed member of our program committee is owner-B. S/He does the same, trains her network embeds the watermark into her images. We both test our detection result, based on the protocol proposed on this paper -  we both separately feed our images and our watermarked images into our detectors, and get 100% accuracy! We are very happy, watermarks look unnoticeable to the human eye and are detected by our networks!\n\nNow the BIG QUESTION IS ~ we both own 1-bit of information only right? Then what would happen if I feed the watermarked images of the esteemed-member of our program committee - owner-B into my network? Will my detection network say it's watermaked or not? Because if it says it's watermarked, now I could claim I own the content of owner-B ... same issue the other way around, owner-A watermarked data into owner-B network. What would happen? I am not saying this issue will arise, but given we only embed 1-bit of information, who owns that 1-bit? This should at least be tested. \n\nBased on all these comments I feel this is an interesting paper, which requires more work, more experiments, a more clear focus and more clarifications.\n\nThank you!",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}