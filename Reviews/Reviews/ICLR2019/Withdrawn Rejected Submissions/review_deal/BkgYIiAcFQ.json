{
    "Decision": {
        "metareview": "there is a disagreement among the reviewers, and i am siding with the two reviewers (r1 and r3) and agree with r3 that it is rather unconventional to pick learning-to-learn to experiment with modelling variable-length sequences (it's not like there's no other task that has this characteristics, e.g., language modelling, translation, ...) ",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "further work needed"
    },
    "Reviews": [
        {
            "title": "Theoretical Analysis of the forget gate behaviour leading to a nice novel contribution",
            "review": "This paper performs an analysis of the cell-state updating scheme of LSTM and realizes that it is mainly controlled by the forget gate. Based on these outcomes they reformulate the functions (interpreted as differential equations) to add a decay-behaviour in the forget gates, finally called DecayNet-LSTM.\n\n\nThe theoretical analysis in this paper is very welcome and goes beyond observations which we made in the past, i.e., we often saw similar behavior in our experiments and as the authors also state in Section 5, there have been previous observations and approaches. In 2016, I have seen an idea called Random Activation Preservation (RAP) (https://ieeexplore.ieee.org/abstract/document/7487778 ) which just randomly \"resets\" the gates. However, they only show empirical outcomes, not a sophisticated analysis as in this paper.\n\nIn the experiments it is shown, that the DecayNet-LSTM performs similarly, or sometimes better than simple LSTM on standard tasks. On more difficult tasks, such as Perm-SeqMNIST, a state-of-the-art performance is achieved.\n\nMinor comments:\nPlease note, it should be Long Short-Term Memory (with hyphen between short and term)\nYou call the contribution DecayNet; And in the paper sometimes refer to it as DecayNet-LSTM; Maybe there could also be a DecayNet-GRU, ... If you, instead of \"reformulation\", would clearly write that DecayNet is an addition to the LSTM architecture, it might be more clear.",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Unclear general utility, insufficiently explained experiments.",
            "review": "This paper analyses the internal dynamics of an LSTM, focusing on the cell state as being the most important component, and analyses what directly influences the contents of the cell state using difference equations. The authors note that at any timestep, the output cell state is the sum of (previous cell state * forget) and (input gate * input). The former can only shrink or maintain the cell value, which the authors label 'catch' and the latter can increase the magnitude, labelled 'release'.\n\nThe authors show that for a single neuron, with chosen values for the forget gate and inputs, consistent growth or consistent shrinking of the cell state can be observed. When the forget is large, say 0.9, the input gate can be anywhere in the range 0.5, 1.0] and still produce growth in the cell value. For forget gate = 0.25, an even larger range of input gate values all produce a shrinking cell value.\n\nDue to the forget gate seemingly having a stronger effect than the (input gate * input) component, the authors propose to hard wire the forget gate to produce a continuous and monotonic decrease, producing the DecayNet. The rate of this decay is controlled by a learned function of the input and previous hidden state, with some shifting in order to maintain a monotonic decrease. Each forget neuron will decrease at a different rate through the processing of a sequence, leading to sections of the cell state which will decay slowly and sections which will decay quickly.\n\nThe authors perform two sets of experiments. The second is sequence classification with the standard 'pixel by pixel' permuted sequential MNIST, in which they show a new SOTA with using Recurrent Batch Norm combined with DecayNet. They also demonstrate a DecayNet with fewer parameters producing roughy the same median performance as a normal LSTM but with lower variance.\n\nThe first experiment is described as \"image classification\", with MNIST and Fashion-MNIST. This section is unclear to me, I had initally assumed that the data would be fed in one pixel at a time, but due to the presence of the other experiments I presume this is not the case. It is not clear what the 'time' dimension is in how the RNNs are applied here, if not through some ordering of pixels. If the entire image is presented as a flattened input, and the time dimension is iterating through the dataset, then there is no reason to use an RNN here. More detail must be added here to make it clear exactly how these RNNs are being applied to images - the text says the softmax layer is produced from the final hidden state, but without the information about how the different hidden states are produced for a given training example this not meaningful. I can imagine that both tasks are pixel by pixel, and the only difference is whether to apply the permutation.. but that is my guesswork.\n\nIn general I find this paper an interesting idea, reasonably well communicated but some parts are not clear. All the experiments (as far as I can tell) work on fixed length sequences. One advantage of an LSTM is that can run onnline on arbitrary length data, for example when used in a RL Agent. In those circumstances, does learning a fixed monotonic delay on the forget gate make sense? I would guess not, and therefore I think the paper could be more explicit in indicating when a DecayNet is a good idea.\n\nThere are definitely tasks in which you want to have the forget gate drop to zero, to reset the state, and then go back up to 1 in subsequent timesteps to remember some new information. Presumably the monotonic delay would perform poorly.\n\nIs DecayNet appropriate only when you have fixed length sequences, where the distribution of 'when does relevant information appear in the input' is fixed? These questions make me doubt the generality of this approach, whereas \"this reformulation increases LSTM modelling power ... and also yields more consistent results\" from the abstract reads like this is a strictly better LSTM. A much wider variety of experiments would be required to justify this sentence. \n\nIt would be interesting to see some diagrams of forget gate / cell state changes throughout a real task, ie a graph with `k` on the x axis. The presentation of the new forget gate in \"System 2\" is clear in terms of being able to implement it, but it's not intuitive to me what this actually looks like. The graphs I suggest might go a long way to providing intuition for readers.\n\n\n\nOverall while I like the spirit of trying to understand and manipulate LSTM learning dynamics I am recommending reject. I do not think the paper sufficiently motivates why a monotonic decay should be good, and while the new SOTA on permuted MNIST is great, I'm concerned that the first experiments are not reproducable, as detailed previously in this review. All hyperparameters appear to be present, so this paper would be reproducable, except for the NIST experiments.\n\n\nGeneral recommendations for a future resubmission:\n\n* Clarify description of first MNIST experiments, and how they are different from permuted MNIST.\n* Experiments on a wider variety of canonical RNN tasks - Penn Treebank is an obvious contender.\n* Some mention of in what situations this is obviously not a good model to use (RL?)\n* More intuition / visualisations as to what the internal dynamics inside DecayNet look like, vs normal LSTM.\n* Devote less space to the initial dynamics analysis, or modify to be representative of a real task. This part was interesting on first read, but the only thing I think it really proves is 'when we artificially choose the input values things get bigger or smaller'. The important thing is, what actually happens when training on a task that we care about - if the same catch and release dynamics are observable, then that makes the idea more compelling.\n\n\nNotes and suggestions:\nI feel the notation would be clearer if instead of k = 1 .. D, this index was t = 1 ... T. This makes it cleare that s_k is not the k'th item in the array, but rather than whole activation array at a specific time. The notation \\sigma_t could then be replace with \\tanh.\n\n\"We replace \\sigma_t with sin for an ergodic delay over time\": as this is a new gate for the forget gate, should this be \\sigma_s?\n\nOne DL rule of thumb heard relatively often is to simply initialise LSTM forget gate biases to 1, to \"remember more by default\". As this is a (much simpler) way of trying to influence the behaviour of the gate, and it anecdotally improves data efficiency, it is worth mentioning in the paper.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "motivation and experiment are not convincing enough",
            "review": "This paper provide a modification on the classical LSTM structure. Specifically, it reformulate the forget gate with a monotonically decreasing manner, using sinusoidal function as the activation function. \n\nHowever, both the motivation and experimental results on such modification are not convincing enough. \n\n1. While there are many heuristic guesses in sec3, important supports of these guesses are missed. For example, Figure 2 is designed to provide supports for the claim that we need controlled forget gates.  However, all the values of forget gates and input gates in Figure 2 are manually set as *conceptual observations*, which provides limited insight on what will happen in the real cases. While the reformulation in sec4 is based on the observations in Figure 2, it is important to plot the real cell propagation after the reformulation, and see whether the real observation meets the conceptual observations in Figure 2.\nBTW, Plots in Figure 2 only account for LSTMs' propagation within 3 steps, but in real cases there are way more steps. \n\n2. The authors claim monotonic propagation in the constant forget gates is more interpretable than those of the vanilla-LSTM, as no abrupt shrinkage and sudden growth are observed. But it isn't straightforward to get the relations between abrupt shrinkage and sudden growth on forget gates and the expressive power of the vanilla-LSTM. Also, it's hard to say the monotonic propagation is more interpretable because we don't know what's the meaning of such propagation on the behaviors of LSTMs in applications. \n\n3. The reformulation in sec 4, especially the formula for the forget-polar input p_k, looks heavily hand-crafted, without experimental supports but statements such as \"we ran numerous simulations\", which is not convincing enough. \n\n4. Experiments are applied on MNIST and Fashion-MNIST. While both datasets are not designed in nature for sequential models like LSTMs. There are better datasets and tasks for testing the proposed reformulation.   e.g. sentence classification, text generation, etc.  No explanation on the choice of datasets.  In addition, the difference between vanilla-LSTM and DecayNet-LSTM is small and it's hard to say it isn't marginal. Maybe larger-scale datasets are needed. \n\n5. Lacking of explanation on specific experimental settings. E.g. training all methods for *only one epoch*, which is very different from the standard practice.  \n\n6. More qualitative interpretations for real cell states in both vanilla LSTM  and DecayNet-LSTM are needed. Only conceptual demonstration is included in Figure 2. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}