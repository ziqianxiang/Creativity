{
    "Decision": {
        "metareview": "The paper proposes an interesting neural architecture for traffic flow forecasting, which is tested on a number of datasets. Unfortunately, the lack of clarity as well as  precision  in writing appears to be a big issue for this paper, which prevents it from being accepted for publication in its current form. However, the reviewers did provide valuable feedback regarding writing, explanation, presentation and structure,  that the paper would benefit from.\n",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "lack of clarity and precision in writing"
    },
    "Reviews": [
        {
            "title": "Confused...",
            "review": "I am sorry but I am super confused with this paper. There is no clarity and about half of the sentences are written with broken english. \n\nThe model (as far as I can understand from the partial explanations and Figure 2) looks like a kitchen sink -- a combination of pieces from previously explored methods in the context of traffic flow estimation. This might be fine, but there is no motivation provided for this. \n\nRather than spending the method section with repeating well known Loss equations, KL-divergence, convolution, etc... Please focus on the architecture provided in the paper and the motivations behind it. More importantly, how it differs from previous approaches and why these choices have been made. \n\nThis paper is not ready for publication. It needs a re-write at least, preferably working out the original motivations behind architectural choices. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "significant clarification needed",
            "review": "This paper has potential, but I do not think it is ready for publication. I will ask some questions / make some suggestions:\n\n1) Your first sentence makes a claim about there being a large body of research on traffic flow forecasting. I don't doubt this, but you should cite some papers, please.\n\n2) Your contributions raise the following questions for me: \n\n- Contribution 1 is that you use a very large dataset (for training? you don't say.) and a small dataset (for testing), thus proving that your method works and generalizes. Your method may be effective, but compared to what? Your method may generalize, but how do we know that if you've only tested it on one small dataset?\n\n- Contribution 2 says that you creatively used lagged data in a time series model. This is probably a good idea, but it does not sound all that creative to me, compare with, e.g. an AR model.\n\n- Contribution 3 says that you use driving distance to model spatial correlation. Again, this is probably a good idea, and when we get further we learn that you applied a Graph Convolution Network. Were these the choices that you claim are novel? Are they novel? What other choices might be reasonable and how would they compare?\n\n3) Section 3 immediately jumps into the use of autoencoders. But I think you need to justify why we care about using autoencoders in the first place. If the problem is traffic forecasting, why don't you tackle that problem head on?\n\n4) Section 3 mentions sparsity without justifying why I care about sparsity. This might be an important tool for regularization in a deep neural network. Or it might not be--given enough data and other regularization techniques (weight decay, early stopping, dropout).\n\n5) Is the spatial dependency that you end up learning qualitatively different than the spatial dependency you would get by instead assuming a particular parametric form as is done in kernel methods / Gaussian processes, e.g. the Gaussian kernel or the Matern kernel parameterizes the covariance between observations at two spatial locations?\n\n6) In your experiment I believe you randomly split 15 minute blocks into train/test/validate. I think this evaluation will be over-optimistic insofar as if 10:30-10:45 and 11:00-11:15 are in the train set, but 10:45-11:00 is in the test set, it will be relatively easy to predict 10:45-11:00. I would suggest considering train/test/validate splits based on larger chunks, e.g. leave the data in 15 minute blocks, but randomly select hours (4 blocks) to put in train/test/validate.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Potentially interesting, though large omissions make this difficult to follow",
            "review": "The paper uses a number of deep learning approaches to analyse sets of Traffic data. However, as these sets of traffic data are never explained it is difficult to follow or understand what is going on here.\n\nSome major comments:\n1) Many of the key concepts in the paper are not discussed. The primary one would be that of what the two data sets contain. Without knowledge of this it is difficult to ascertain what is going on. \n\n2) Many of the processes used are not described in enough detail to either understand what is going on or to re-produce the work. Without this it is difficult to make headway wit the work.\n\n3) It is not clearly articulated what the experiments performed are doing. For example, how have you applied the other techniques to this data?\n\n4) Key terms are not defined. Such as Traffic Flow.\n\n5) The English structure of the paper is poor with many mistakes. A thorough proof-reading is essential.\n\nSome more specific points:\n- \"with the larger road network, the difficulty of flow forecasting grows.\" - This seems to be a consequence of the other ones not a challenge in it's own right.\n\n- What is \"superiority\"?\n\n- \"Spatiotemporal traffic flow forecasting task is currently under a heated discussion and has attracted a large research population.\" - evidence to back up this statement.\n\n- Your contributions aren't contributions, but rather a list of what you have done.\n\n- How does your related work relate to what you have done?\n\n- Hard to parse \"To extract temporal relationships within the history traffic flows, we model this process as a layering structure with autoencoder as cell\"\n\n- Appendices B and C should be in the main paper.\n\n- What is in x^{(1)}?\n\n- \"When take the sparsity constrains into consideration\" - what are the sparsity constraints?\n\n- How do you obtain the weights?\n\n- Figure 2 should come much sooner as it relates a lot of the concepts together.\n\n- \"On both datasets, we slice traffic flow information into 15 minutes windows, where 70% of data is for training, 10% for validation and remaining 20% for testing.\" - Is that each 15 mins is split 70:10:20?\n\n- Proof by example is not a proof.\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}