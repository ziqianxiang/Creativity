{
    "Decision": "",
    "Reviews": [
        {
            "title": "Limited novelty and not fully convince by the improvement in empirical evaluation",
            "review": "As I was asked for an emergency reviewer for this paper rather late, I refrain myself from reading at other reviewers comment when writing this review for an unbiased judgment. Please forgive me if the concerns or issues I raise here already been asked by other reviewers.\n\n- summary\nThis paper proposes to improve semi-supervised learning with two manifold regularizations: the tangent adversarial regularization (TAR) and normal adversarial regularization (NAR), hence naming their method Tangent-Normal Adversarial Regularization (TNAR). The author implements the TAR and NAR by applying virtual adversarial training (VAT) techniques on the manifold space, which is trained separately by either variational autoencoder (VAE) or localized GAN (LGAN) to obtain the encoder and decoder mapping between data space and manifold space. The proposed TNAR shows improvement on the controlled synthetic dataset; demonstrates the effectiveness of both TAR and NAR via the ablation study on the FashionMNIST dataset; claims to outperform state-of-the-art SSL methods on both SVHN and CIFAR-10 datasets. \n\nEvaluation\n- The writing of the paper is in general ok, but reading the introduction that categorizes the SSL by three streams seem somehow unnatural to me. Perhaps it would be more clear to directly start from manifold space assumption and add more details or connection to other manifold space regularization related works.  \n\n-The technical derivation in section 3 is sound as far as I can tell because it mainly involves existing techniques that have been studied in VAT [7]. This also makes me feel the contribution in terms of novelty is rather limited, since the tangent space regularization is not new [4]. The only novel part seems to add an additional normal adversarial regularization that is perpendicular to the tangent noise.\n\n- My biggest concern is in the empirical evaluation. The experiment setup closely follows [7], using the model architecture Conv-small appeared in [1,3,4,5,6,7] and Conv-large appeared in [2,6,7], while not applying ZCA whitening as data preprocessing. This possibly leads to an inconsistency between the results in Table 3 of this paper and table 4 of [7] for both Conv-small and Conv-large setting. Also, it would also be an unfair comparison that only TNAR and VAT include entropy regularization while other SOTA methods [1,3,4,5,6] did not. As shown in Table 4 of [7], entropy-regularization significantly improve accuracy. I suggest the author include results of TNAR w/o entropy-regularization;  results of ZCA preprocessed data;  setting alpha_2 and alpha_3 as zero to see the difference between TNAR and FM-GAN [5].\n\nMinor questions:\n- What is the difference between TNAR and [5]? Is it that TNAR finding the tangent vector r where TNAR applies power methods as like VAT while [5] find the tangent vector r differently?\n\n- How important is the GAN/VAE training for good semi-supervised learning task? Do you also find the bad generator leading to better SSL task as shown in [8]? I am also curious that how different encoder/decoding mapping would affect the SSL downstream task, as different prior works adopt different settings.\n\n- TNAR is claimed to be computational efficient compared other manifold regularization based on tangent propagation or manifold Laplacian norm. Do you have empirical evidence?\n\n- I also suggest reporting the mean/std of the experiment results by running like five different random seed, as most of the works did.\n\n[1] T. Salimans et al., Improved techniques for training gans. NIPS 2016\n[2] S. Laine and T. Aila. Temporal Ensembling for Semi-supervised Learning. ICLR 2017\n[3] V. Dumoulin et al., Adversarial Learned Inference. ICLR 2017\n[4] A. Kumar et al, Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference, NIPS 2017\n[5] B. Lecouat et al., Semi-supervised Learning with GANs: Revisiting Manifold Regularization. ICLR 2018 Workshop\n[6] Guo-Jun Qi et al, Global versus Localized Generative Adversarial Nets. CVPR 2018\n[7] T. Miyato et al., Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning, PAMI 2018\n[8] Z. Dai etal ., Good Semi-supervised Learning That Requires a Bad GAN, NIPS 2017\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Poor novelty, clarity and significance",
            "review": "This paper proposed a new regularization for semi-supervised learning called tangent-normal adversarial regularization. It can be decomposed into two parts, namely the tangent adversarial regularization and the normal adversarial regularization. Both of them are related to the smoothness assumption in a more general form.\n\nThe novelty seems really incremental as a combination of two existing concepts and thus there is no clear conceptual improvement. The two parts as the building blocks are even already included in the deep learning book.\n\nThe clarity is OK but not so good. The introduction is very long but not so informative. In fact, the description and discussion are even misleading. The first paragraph gives the background information of SSL in 12 lines without a single citation. I think a minimal background is necessary, while this paragraph is too much in such a way that it gives something every body knows and is a waste of the most precious space.\n\nThe 3 streams of SSL are misleading: the 1st and 3rd are traditional generative methods and GANs which overlap a lot, and some important streams such as co-training are completely ignored. Even though the paper is claimed to focus on the 2nd stream, i.e., regularization, it focused only on the geometric regularization and ignored any other regularization for instance entropy regularization (by Prof. Bengio!) and expectation regularization (by Prof. McCallum!) that belong to information-theoretic regularization.\n\nThe 3 assumptions are also strange. To me, there is 1 assumption and 2 implementations of that assumption. As far as I know, the basic assumptions in SSL are all based on 3 concepts of consistency originated from LGC and VAT. Since SSL has a long history and is/was a very hot topic, the authors should survey the literature more carefully.\n\nThe significance is even not OK. As claimed in the paper it focuses on the 2nd stream, the proposed method should mainly be compared with similar regularization approaches. VAT is the origin of perturbation consistency but no longer SOTA. There are many following methods, temporal ensembling from ICLR 2017, mean teacher from NIPS 2017, smooth neighbor teacher graph from CVPR 2018, and compact clustering via label propagation from ICML 2018, just to name a few. Again, the authors should survey the literature more carefully and then consider how to revise their paper.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "review",
            "review": "The paper proposes to extend VAT by decomposing the regularization term into two spaces, the tangent space and the normal space. The tangent space is spanned over the columns of the Jacobian matrix of a function that maps latent (manifold) variables to data, and the normal space is defined as orthogonal to the tangent space. Power iteration was employed to optimize the inner-loop function.\n\nPros\n1. Positive signals have been shown on multiple datasets.\n2. The proposed regularization terms seem to be novel and technically sound.\n\nCons and questions\n1. How did you obtain the results of VAT in the experiments? It seems the results in Table 3 could not be found in Miyato et al. It is important to obtain a proper baseline to substantiate the main claim of the paper. Moreover, it might not be appropriate to claim the proposed method is state-of-the-art (SoTA) on SVHN and CIFAR-10 given that the numbers in Table 3 are different from Miyato et al. To claim SoTA, you would need to at least implement your model in a setting that is comparable to the numbers in Miyato et al (e.g. using ZCA), rather than running your model in a setting that was not considered in Miyato et al (e.g. removing ZCA).\n2. It seems that the proposed method introduces a bunch of additional hyper-parameters, including lambda, two epsilons, and the alphas that weigh different terms. Is it difficult to tune these hyper-parameters in practice? What values did you actually use for these hyper-parameters?\n3. The paper would be further improved if an ablation study could be performed on SVHN and/or CIFAR-10, since these are more popular datasets for semi-supervised learning. It would become clearer how the proposed method is better than the previous ones.\n4. The paper claimed that \"TAR inherits the computational efficiency from VAT\". Does power iteration bring additional computation costs? What is the actual computational time, compared to VAT?",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}