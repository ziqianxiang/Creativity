{
    "Decision": {
        "metareview": "+ experiments on an interesting task: inferring relations which are not necessarily explicitly mentioned in a sentence but need to be induced relying on other relations\n+ the idea to frame the relation prediction task as an inference task on a graph is interesting \n\n- the paper is not very well written, and it is hard to understand what exactly the contribution is. E.g., the authors contrast with previous work saying that previous work was relying on pre-defined graphs rather than inducing them. However, here they actually rely on predefined full graphs as well (i.e. full graphs connecting all entities).   (See questions from R1)\n\n- the idea of predicting edge embeddings from the sentence is an interesting one. However, I do not see results studying alternative architectures (e.g., fixed transition matrices + gates / attention), or careful ablation studies. It is hard to say if this modification is indeed necessary / beneficial.  (See also R3, agreeing that experiments look preliminary)\n\n- Extra baselines? E.g., what about layers of multi-head self-attention across entities? (as in Transformer). What about the number of parameters for the proposed model? Is there chance that it works better simply because it is a larger model? (See also R3)\n\n- evaluation only one dataset (not clear if any other datasets of this kind exist though)\n\nOverall, though I find the direction and certain aspects of the model quite interesting, the paper is not ready for publication.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "an interesting direction but not ready for publication yet"
    },
    "Reviews": [
        {
            "title": "Review",
            "review": "\nThis paper proposes a new model based on graph neural networks for relation extraction and evaluates it on multiple benchmarks and demonstrates its ability to do some level of “multi-hop relational reasoning”.\n\nAlthough the empirical results look good and the paper might present some interesting and effective ideas, I find the paper very difficult to follow and many concepts are confusing (and even misleading).\n\nSection 3-4:\n\n- “l” is not defined -- I assume it denotes the number of tokens in the sentence but |s| is used in other places.\n- Are “entires” and “entities” the same?\n- a series of tokens => a sequence of tokens.\n- Equation (5): “n” is not defined on the right of equation. Does this mean that different layers have LSTMs/MLPs with separate sets of parameters? If it is the case, why do you need the word embeddings at all the layers to construct the transition matrices? Please clarify. \n- Does BiLSTM return one vector or a sequence of l vectors? Even MLP needs to be defined.\n\nIn general I find the concept of “generated parameters” even confusing. How would traditional GNNs work in this context? Isn’t the novelty that parameterizing word/positional information in the transition matrix which enables a graph-based neural network working?\n\nIt would be very important to explain the intuition of this model and make the presentation clear and understandable. I don’t recommend this paper to be accepted in the current format.\n\nThe empirical results also make me wonder whether this model outperforms other models because the other models work on a single pair of entities while this model attempts to work on all pairs of entities at the same time so that it enables some level of reasoning at the entity level (e.g., language + cast member -> language spoken in Figure 1). If this is the real contribution, the paper has to make it clear enough. \n\nAnother related paper that needs to be cited:\n\n- Zhang et al, 2018: Graph Convolution over Pruned Dependency Trees Improves Relation Extraction. EMNLP.\n\n\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper describes a Graph NN method for information extraction from sentences. Some interesting innovations in the paper. The evaluation analysis and the comparison with other models are still preliminary.",
            "review": "The paper describes a Graph NN method for information extraction from sentences. The objective is to label couples of entities (token or multiple tokens)  according to a given set of relations. The GNN processes token representations through one or more layers and a final classification layer scores the relations between entity couples in the sentence. Parameters of GNN – transition matrices between layers operating on node representations – are learned from the data.  Experiments are performed on different variants of an extraction corpus, for the task consisting in extracting all the relations between identified token couples in a sentence. \n\nThe description is clear. The main original contribution is the scheme used for learning the transition matrices between layers from the text input.  Overall, the proposed system is a new mechanism for classifying relations between items in a sentence using GNN. Note that the current title is misleading w.r.t. this goal.\nThe authors claim that the model allows relational reasoning on text. This is somewhat exaggerated, the model performs relation classification and that’s it. There is nothing indicating any form of reasoning and this argument could be removed without reducing the value of the paper.\n\nThe experiments show that the proposed model outperforms, on this classification task baselines, including a recent model. The analysis here should be developed and improved: as it is, it does not provide much information.\nBelow are some questions concerning this evaluation.\nWhy not using mono sentence evaluation on the two distantly labeled datasets? \nThe performance of the two CNN baselines on the hand labeled dataset are extremely low, what is the reason for that?\nThe improved performance of the proposed model w.r.t. the baselines is attributed to the “reasoning” potential of the model, but this explanation falls short. There is no fact in the paper to support this idea, and the Context-aware RE model making use of sentence attention has also the potential of exploiting contextual information and thus might also infer more complex relations. The reason for the improvement has to be found somewhere else.\nOverall, there is some interesting innovation in the paper. The evaluation analysis and the comparison with other models are still preliminary.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good results, some questions",
            "review": "This work proposes a method for parametrising relation matrices in graph neural networks (GNNs) using text. The model is applied in a relation extraction task, and specific dataset subsections are identified to test and analyse “hopping” behaviour: a model’s ability to combine multiple relations for inferring a new one.\n\nStrengths\n- strong results\n- testing on both bag-level / single-level relation extraction\n- Insights via multiple ablations — variation of the number of layers, exploring densely connected data subsections with cycles to identify examples for multi-hop inference\n- evaluation on new, human-annotated test set\n\n\nIssues\n- evaluation only on one task, and one dataset (although, with more detail).\n- unclear how/why the specific result metrics and their particular range of precision are chosen. Why is F1/Acc only reported for the human-labelled part, but not for the distantly labelled part? Why is precision cut off at ~25% recall? A comprehensive aggregate measure across all levels of recall would be more informative, e.g. PR-AUC., and consistently applied in all experiments.\n- task varies from previous versions of the task, posing a potential problem with comparability. What is the motivation behind augmenting the dataset with “NA” labels? Why is the task from previous work altered to predicting relationships between _every_ entity pair? Also unclear: is predicting “NA” actually part of the training loss, and of the evaluation? Is training of the previous “baseline” models adapted accordingly?\n- some claims appear too bold and vague — see below.\n- comparatively small modelling innovation\n- There is similar prior work to this, most prominently Schlichtkrull et al. 2017 [https://arxiv.org/pdf/1703.06103.pdf] who evaluate on Fb15k-237, but also De Cao et al. 2018 [https://arxiv.org/pdf/1808.09920.pdf, published within 1 month before ICLR submission deadline] who evaluate on Wikihop. These previous methods in fact do the following: “Most existing GNNs only process multi-hop relational reasoning on pre-defined graphs and cannot be directly applied in natural language relational reasoning.” It would be good to work out differences to these previous models in more detail, especially to Schlichtkrull et al. 2017.\n- unclear how big the specific contribution of the language-generated matrices is. I would normally not obsess about such a baseline, but it seems that the “generate using NL” aspect is a core to the paper (even in the title), and this isn’t worked out clearly.\n\n\nMore comments / questions:\n- “multi-hop relational reasoning is indispensable in many natural language processing tasks such as relation extraction”. This isn’t clear to me, “indispensable” is a very strong wording.\n- “state-of-the-art baselines”. SOTA defines the best previous work. How can there be several baselines (plural) which are all best? What does SOTA mean when a slight redefinition of the task is proposed, as in this work?\n- “Relation extraction from text is a classic natural language relational reasoning task” — reference would be useful. \n- not a big issue, though this does sound somewhat contradictory: 1) “the number of layers K is chosen to be of the order of the graph diameter”. 2) “We treat K as a hyperparameter”\n- not clear: is LSTM indeed exactly the same as GP-GNN with K=1? I assume there is a difference, as the LSTM encodes the entire sentence at once, conditioning entity representations on their local context, whereas in GP-GNN this would not be the case.\n- The distinction to Context-Aware RE (CARE) is not clear. The authors argue that CARE models co-occurrence of multiple relations, but is this not what a multi-hop relation extraction _should_ learn? It is also not clear how GP-GNN differs in this respect.\n- It would be interesting to compare with a model which does not use language to define relation matrices (A), but learns them directly as parameters (independently from the text). \n- It would be interesting to see an analysis of the matrices A_{i,j}. What does the text generate, and how can one find this out? ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}