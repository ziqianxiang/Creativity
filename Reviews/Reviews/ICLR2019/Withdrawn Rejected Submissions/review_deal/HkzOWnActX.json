{
    "Decision": {
        "metareview": "This paper proposes a meta-learning algorithm that extends MAML, particularly focusing on multimodal task distributions. The paper is generally well-written, especially with the latest revisions, and the qualitative experiments show some interesting structure recovered. The primary weakness of the paper is that the experiments are largely on relatively simple benchmarks, such as Omniglot and low-dimensional regression problems. Meta-learning papers with convincing results have shown results on MiniImagenet, CIFAR, CelebA, and/or other natural image datasets. Hence, the paper would be more compelling with more difficult experimental settings. In the paper's current form, the reviewers and the AC agree that it does not meet the bar for ICLR.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "meta review"
    },
    "Reviews": [
        {
            "title": "Layer-wise conditioning via task-embedding for meta-learning",
            "review": "Strengths:\n+ The paper identifies a valid limitation of the MAML algorithm: With a limited number of gradient descent steps from a single initialization, there is a limit to the ability of a fixed-size neural network to adapt to tasks sampled from a diverse dataset.\n+ The tSNE plots show some preliminary interesting structure for the simple regression and RL tasks, but not for the classification task.\n\nWeaknesses:\n- The motivation of uncovering latent modes of a task distribution does not align with the proposed method. The algorithm computes a continuous representation of the data from a task (which is fixed during gradient-based fast adaptation). The mode identity, on the other hand, should be a discrete variable.  Such a discrete variable is never explicitly computed in the proposed method.\n- The technical writing is unclear and jargon is often used without definition. Importantly, one of the central motivators of the paper, \"task modulation\", is never given a precise definition.\n- The standard few-shot classification task (Omniglot) does not clearly consist of a task distribution that is multimodal, so the method is not well-motivated in this setting.\n- Experimental conclusions are weak.\n\nMajor comments:\n- The paper neglects to discuss how the proposed method could be used in the context of other methods for \"gradient-based meta-learning\" such as Ravi & Larochelle (2016). I believe the attention-based modulation and the FiLM modulation could be easily adapted to that setting. Why was this not discussed or evaluated?\n- Conditioning has been used in the context of few-shot learning before, but this is not discussed (https://arxiv.org/abs/1805.10123, https://arxiv.org/abs/1806.07528).\n- The paper often confounds task representation with neural network parameter values. For example, Figure 1 depicts the adaptation of parameter values with gradients (\\nabla L), yet the caption describes \"task modes.\" More careful writing would disentangle these two components.\n- The motivation for the particular form of the task embedding computation is not given. What were the other options? Why not, for example, an order-invariant function instead of a bidirectional GRU?\n- In all of the experiments, there is no appropriate baseline that keeps the parameter dimensionality constant, so it is unclear whether the (marginal) improvement in performance is due to added expressivity by adding more parameters rather than an algorithmic improvement. I suggest an ensembling baseline with an appropriate number of ensemble members.\n- There is no evaluation on a standard benchmark for few-shot classification (miniImageNet), and the Omniglot improvement is small.\n- The reinforcement learning comparison at some point compares MUMOMAML with modulation applied (therefore with access to task-specific data) to MAML with no adaptation (and therefore no access to task-specific data). This is not entirely fair.\n- tSNE results can be misleading (e.g., see https://distill.pub/2016/misread-tsne/), and the task delineation is not extremely clean. I would be more convinced if a clustering algorithm were applied.\n\nMinor comments:\n- The paper needs to be checked over for English grammar and style.\n- everywhere: The \"prior\" referred to in this paper is not a prior in the Bayesian sense. I suggest a more careful use of terminology.\n- abstract: \"augment existing gradient-based meta-learners\" You augment a specific variant of gradient-based meta-learning, MAML.\n- pg. 1: \"carve on a snowboard\" don't know what this means\n- The terminology of \"task distribution\" and \"modes\" thereof is used without introduction in the introduction section. The terminology \"model-based meta-learning/adaptation\" and \"gradient-based meta-learning/adaptation\" is also used without introduction here. This makes the introduction unnecessarily opaque. Consider the reader who is not familiar with meta-learning papers; they would have a very hard time parsing, for example, the phrase \"...this not only requires additional identity information about the modes, which is not always available or is ambiguous when the modes are not clearly disjoint...\" (pg. 1).\n- Further, the terminology \"model-based\" seems non-standard, and is aliased with the term model-based reinforcement learning (which specifically refers to the set of RL algorithms that make use of a \"model\" of transition dynamics). Since the paper tackles a reinforcement learning benchmark, this may lead to some confusion.\n- pg. 3; \"our model does not maintain an internal state\" Is the task representation/embedding not an internal state?\n- pg. 3: \"relevant but vaguely related skills\" this is imprecise\n- pg. 3: The episodic training setup, which is standard to meta-learning setups, could be much better described. The MAML algorithm could be given better intuition.\n- everywhere: \"task specific\" -> task-specific\n- Algorithm 1: \"infer\" is a misuse of terminology that usually refers to an operation in latent variable probabilistic modelling. Since the computation of \\tau is purely feedforward, I recommend writing \"compute.\"\n- \\tau should be used in some places where v is used instead",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Why modulation works for meta-learning",
            "review": "This paper presents an interesting meta-learning algorithm that can learn from multimodal task distributions, by combining model-based and gradient-based meta-learning. It first represents a task with a latent feature vector produced by a recurrent network, and then modulates the meta-learned prior with this task-specific latent feature vector before applying gradient-based adaptation. Experimental results are shown to validate the proposed algorithm. While the idea appears to be quite novel for meta-learning, further efforts are needed to improve this work.\n\n1. The experiment on few-shot image classification is less convincing, with results only on the Omniglot dataset, which are only comparable to those of existing methods that are designed for a single task distribution. Why not show results on MiniImageNet or other more realistic datasets which are more likely to be multimodal?  \n\n2. It is not clear how the idea of modulation works for multimodal meta-learning. More discussions and insights can be helpful.\n\n3. The encoding of a task relies on the order of examples, which seems undesirable for a classification or regression problem. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Official review",
            "review": "\nMuMoMAML: Model-Agnostic Meta-Learning for Multimodal Task Distributions\n\nThis paper proposed multi-modal MAML, which alleviates the single initialization limitation of MAML by modulating task prior with MAML. Below are some comments.\n\nPros:\n1. Overall, the paper is clear written. \n2. By using modulation, there is no need to explicitly control/know the number of modes in advance.\n3. The multi-MAML baseline is good for an ablation study, though it is only on a synthetic regression task.\n4. MUMOMAML combines the strength of both gradient-based and model-based meta-learners.\n\nCons.\n1. The novelty of the paper seems to be the combinations of MAML and FiLM, which seems a bit limited.\n2. I wonder whether the proposed method is mostly useful when there is a clear mode difference as in the synthetic regression/RL tasks of the paper. Moreover, the paper only shows tasks with only two-three modes, what happen when there is a large number of modes?\n3. What's the results on the mini-Imagenet? The Omniglot seems to be saturated already.\n4. Why tau is not updated in the inner loop of Algorithm 1?\n\nMinor:\n1. page 4, 'in to' -> 'into'\n2. In page 5, in 'based on the input data samples and then\ninfers the parameter to modulate the prior model', what does the `input data samples' refers to? Is it the training data of a meta-learning task?\n3. Do you stop gradient to the learner in MUMOMAML?",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}