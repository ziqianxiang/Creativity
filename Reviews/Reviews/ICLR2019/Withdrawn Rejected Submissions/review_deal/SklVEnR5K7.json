{
    "Decision": {
        "metareview": "The reviewers are reasonably positive about this submission although two of them feel the paper is below acceptance threshold. AR1 advocates large scale experiments on ILSVRC2012/Cifar10/Cifar100 and so on. AR3 would like to see more comparisons to similar works and feels that the idea is not that significant. AR2 finds evaluations flawed. On balance, the reviewers find numerous flaws in experimentation that need to be improved. \n\nAdditionally, AC is aware that approaches such as 'Convolutional Kernel Networks' by J. Mairal et al. derive a pooling layer which, by its motivation and design, obeys the sampling theorem to attain anti-aliasing. Essentially, for pooling, they obtain a convolution of feature maps with an appropriate Gaussian prior to sampling. Thus, on balance, the idea proposed in this ICLR submission may sound novel but it is not. Ideas such as 'blurring before downsampling' or 'low-pass filter kernels' applied here are simply special cases of anti-aliasing. The authors may also want to read about aliasing in 'Invariance, Stability, and Complexity of Deep Convolutional Representations' to see how to prevent aliasing. On balance, the theory behind this problem is mostly solved even if standard networks overlook this mechanism. Note also that there exist a fundamental trade-off between shift-invariance plus anti-aliasing (stability) and performance; this being a reason why max-pooling is still preferred over anti-aliasing (better performance versus stability). Though, this is nothing new for those who delve into more theoretical papers on CNNs: this is an invite for the authors to go thoroughly first through the relevant literature/numerous prior works on this topic.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Anti-aliasing has been explored before."
    },
    "Reviews": [
        {
            "title": "Making CNNs translation equivariant again, potentially important line of work with multiple loose ends",
            "review": "\nSummary\n\nFrom a theoretical point of view, one might be tempted to believe that deep CNNs are translation equivariant and their predictions are translation invariant. In practice, this is not necessarily true. The authors propose to augment standard deep CNNs with low-pass filters to reduce this problem. The results seem promising for an older VGG architecture.\n\nQuality\n\nThe paper is very verbose, the figures and captions are tedious to read, the mathematical notation seems strange as well, making the writing more concise is highly encouraged. The main ideas are easy to follow and the choice of experiments seems fine. \n\nSignificance\n\nThis is the first empirical work trying to fix the issue of non-translation equivariance in convolutional neural networks. The conclusions of this work are potentially relevant for a wide audience of CNN practitioners.\n\nMain Concerns\n\nTo show that all claims of the paper do indeed hold, the authors should attack their augmented network with the translation attack of [1]. As robustness to this type of transformations is one of the main goals, it should be tested if it was achieved. The attack can be found in some open source frameworks [2] and should be easy to apply.\n\nWall-clock times need to be reported for the various blurring kernels and compared to the baselines.\n\nExtend results to a cutting-edge architecture, e.g. DenseNets or Wide ResNets. If this result is not provided the significance of the work is not clear.\n\nDespite being more expensive, do dilations fix the issue of missing translation equivariance provably and not just approximately like the low-pass filtering approach proposed here? This should be discussed and a comparison in terms of wall-clock time would be great as well.\n\nMinor\n\n- Strange notation e.g. in equation 1. Why not write: x+\\delta x in the argument of the function instead of \"Shift\". The current notation seems unnecessarily informal.\n- Figure 4: show scale and color bar.\n\n[1] Engstrom et al., \"A rotation and a translation suffice: Fooling cnns with simple transformations.\"\n[2] https://foolbox.readthedocs.io/en/latest/modules/attacks/decision.html#foolbox.attacks.SpatialAttack",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A paper with technical details and analysis, but the problem addressed does not seems to be interesting and significant",
            "review": "This paper analyzed on the core factor that make CNNs fail to hold shift-invariance, the naive downsampling in pooling. And based on that the paper proposed the modified pooling operation by introducing a low-pass filter which endows a shift-equivariance in the convolution features and consequently the shift-invariance of CNNs.\n\nPros:\n1.\tThe paper proposed a simple but novel approach to make CNNs shift-invariant following the traditional signal processing principle.\n2.\tThis work gave convincing analysis (from both theoretical illustrations and experimental visualizations) on the problem of original pooling and the effectiveness of the proposed blur kernels.\n3.\tThe experiment gave some promising results. Without augmentation, the proposed method shows higher consistency to the random shifts.\n\nCons:\n1.\tWhen cooperating with augmentation, the test accuracy on random shifted images of proposed method did not exceed the baseline. Although the consistency is higher, it is secondary to the test accuracy of random shifted data. And it is confused to do average on consistency and test accuracy, which are in different scales, and then compare the overall performance on the averages. \n2.\tIt seems to be more convincing if the ‘random’ test accuracy is acquired by averaging several random shifts on a single image and then do average among images, as well as to show how accuracy various on shifting distance.\n3.\tSome other spatial transforming/shifting adaptive approaches should be taken into consideration to compare the performance.\n4.\tThere are some minor typos, such as line 3 in Section 3.1 and line 15 in Section 3.2\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting approach in its simplicity with flaws in evaluation",
            "review": "This work shows that adding a simple blurring into max pooling layers can address issues of image classification instability under small image shifts. In general this work presents a simple and easy to implement solution to a common problem of CNNs and even though it lacks more thorough theoretical analysis of this problem from the signal processing perspective (such as minimal size of the blurring kernel for fulfilling the Nyquist-Shannon sampling theorem), it seems to provide ample empirical evidence.\n\nPros:\n+ The introduction and motivation is really well written and Figure 3 provides a clear visualisation main max pooling operator issues.\n+ The proposed method is really simple and shows promising results on the CIFAR dataset. With random shifts, authors had to tackle cropping with circular shifts. As it can cause artifacts in the data, authors also provide baseline performances on the original data (used for both training and testing).\n+ Authors provide a thorough evaluation, ranging from comparing hidden representations to defining consistency metrics of the classified classes.\n\nThis work is lacking in the experimental section due to some missing details and few inconsistencies. I believe the most of my concerns can be relatively easily fixed/clarified in an update of this submission.\n\nMajor issues, which if fixed would improve the rating:\n- It is not correct to average test accuracy and test consistency as both measures are different quantities, especially when using them for ranking. The difference between accuracy of different methods are considerably smaller than differences in the classification consistency. \n- It is not clear how many shifts are used for computing the \"Random Test Accuracy\" and the \"Classification Accuracy\". Also whether the random shifts are kept constant between evaluated networks and evaluation metrics.\n- Authors do not address the question what is the correct order of operations for the blurring. E.g. would the method empirically work if blurring was applied before max pooling? Do the operations commute?\n- The selection of the filters is rather arbitrary, especially regarding the 1D FIR filters. The separability of these filters should be discussed.\n- I believe authors should address how this work differs to [1], as it also tests different windowing functions for pooling operators, even though in different tasks.\n\nMinor issues, which would be nice to fix however which do not influence my rating:\n* Section 3.1 - And L-Layer deep *CNN*, H_l x W x C_l -> H_l x W_l x C_l\n* Section 3.1. Last paragraph - I would not agree with the statement that in CNNs the shift invariance must necessarily emerge upon shift equivariance. If anything, this may hold only for the last layer of a network without fully connected layers and with average pooling of the classifier output (ResNet/GoogleNet like networks).\n* Explicitly provide the network architecture as [Simonyan14] does not test on CIFAR and cannot use Batch normalisation.\n* It would be useful to add citation for the selected FIR filters.\n* The flow of section 4.2. can be improved to help readability. The three metrics should be first motivated before their introduction. Metric 2. paragraph - the metric is defined below, not above. \n* It would be interesting to see what would be the performance if the blurring filters were trained as well (given some sensible initialisation).\n* One future direction would be to verify that this approach generalises to larger networks as well. It might be worth to discuss this in the conclusions.\n\n[1] Scherer, Dominik, Andreas Müller, and Sven Behnke. \"Evaluation of pooling operations in convolutional architectures for object recognition.\" Artificial Neural Networks–ICANN 2010. Springer, Berlin, Heidelberg, 2010. 92-101.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}