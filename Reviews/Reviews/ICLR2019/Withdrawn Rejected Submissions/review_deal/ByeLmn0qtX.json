{
    "Decision": {
        "metareview": "This paper proposes using conditional VAEs for multi-domain transfer and presents results on CelebA and SCUT. As mentioned by reviewers, the presentation and clarity of the work could be improved. It is quite difficult to determine the new/proposed aspects of the work from a first read through. Though we recognize and appreciate that the authors updated their manuscript to improve its clarity, another edit pass with particular focus on clarifying prior work on conditional VAEs and their proposed new application to domain transfer would be beneficial. \n\nIn addition, as DIS is the main metric for comparison to prior work and for evaluation of the final approach, the conclusions about the effectiveness of this method would be easier to see if a more detailed description of the metric and analysis of the results were provided. \n\nGiven the limited technical novelty and discussion amongst reviewers of the desire for more experimental evidence, this work is not quite ready for publication.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Additional discussion and experiments appreciated, more improvements needed"
    },
    "Reviews": [
        {
            "title": "Unclear contribution",
            "review": "- To this reviewerâ€™s understanding, the proposed method is very similar or equal to the conditional VAE. The only difference comes from the way of involving the condition information during training.\u0000 This should be clarified and further, it is necessary to compare with the conditional VAE in the experiments, rather than the vanilla VAE.\n\n- The proposed method uses a predefined and fixed value of the variance $\\sigma^{2}$, which is very informative and should be estimated from data in inference. Basically, there is no specification on this value in their experiments.\n\n- In a similar perspective, how the results changes according to the variation of the value $\\sigma$.\n\n- It is not intuitive how significant the improvement of 5% in PIS. It would be good to provide the intuitive understanding of the improvement.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A preference learning generative model (in deep setting), with somewhat unintuitive setting and weak experimental evaluation",
            "review": "1) Summary of the paper:\n\nThe paper brings up a relatively new problem of learning a generative model for multiple domains. The domains, D1,...,Dn, may refer to person-specific preferred images, for instance, and they focus on how to build generative models P(x|Di), which represents a set of images preferred by subject i.\n\nThey assumed a specific setup where one can access domain classifiers P(Di|x), but not the samples from P(x|Di). It is a bit odd: actually they worked mostly on a special (relatively new) dataset named \"SCUT-FBP-5500\", which seems to contain labeled samples, (x,D1,...,Dn) -- then, obviously we can access x|Di as well as Di|x. Of course, this type of fully labeled dataset is small-sized.\n\nTheir approach is basically to partition the latent space by the domains D1,...,Dn. They utilize the standard VAE model which is shared across the domains, and introduce domain-specific latent priors P(z|D_i) which are Gaussians. The learning is essentially a combination of the VAE learning and the latent prior learning, where the latter is done by enforcing the generated samples x from each Di to be consistent with the domain classifier P(Di|x). This strategy sounds reasonable enough.\n\nOne issue lies in the latent prior learning (ie, optimization of (3)). Since they need to evaluate P(Di|x), x is limited to the labeled samples, namely those from the (small-sized) SCUT-FBP-5500 dataset only. So although they wrote expectation wrt p(x) in (3), the p(x) cannot be a large dataset like the CelebA dataset as they intended, but p(x) is limited to a small dataset like SCUT-FBP. The large samples from p(x) are only exploited in the VAE learning part.\n\nThe experimental evaluation is weak: evaluated on only one dataset, compared with just standard VAE and StarGAN which are not aimed for the particular problem setup the authors are considering.\n\nAt least, they may be able to compare it with a baseline approach, e.g., using the samples from p(x|D_i) available from the SCUT dataset (small though), one can learn encoder/decoder models for each D_i.\n\n2) Strengths:\n\nRelatively unique problem (but unusual and unintuitive setup) and a reasonable approach.\n\n3) Weak points:\n\n-The writing is sloppy. It doesn't read very well, and difficult to follow. Contains many typos.\n\n-Weak in experimental evaluation and comparison with other (baseline) approaches.\n\n-There appears to exist identity change in many of face image preference examples.  This is unexpected.  I would be more inclined to believe that personal preferences are about appearance (style) features rather than identify.  Yet most examples in Fig.6 indicate the opposite.\n\n- Writing would benefit from laying out intuition beyond both the model and the experimental results.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review",
            "review": "In this paper, the authors propose a variational domain adaptation framework for learning multiple distributions through variational inference. The proposed framework assumes a prior, and models each domain as a posterior. A multi-domain variational auto-encoder is then proposed to implement the concept of multi-domain semi-supervision. Experimental studies are done to show the effectiveness of the proposed framework.\n\nThis paper does not deal with the conventional domain adaptation problem as many existing domain adaptation works do. It focuses on the adaptation task of data generation. Here are some comments:\n(1)\tIt would be better to clarify the adaptation task by giving a concrete real-word example in the introduction. Specifically, you may want to specify what the source and target tasks are, and what the assumption you have made on the source and target tasks is.\n(2)\tIn the abstract and introduction, you state that a source domain is regarded as a prior, and target domain is regarded as posterior. From the Method section, I am not sure whether this is a valid statement. In my understanding, equation (1) is the KL summation of all the domains. The following derivation assumes that the data of all the domains draw a distribution p(x) (which is the prior), and the data of each domain has a specific distribution p^(i)(x) (which is the posterior).  Do you assume that all the domains from D_i to D_n are target domains? Then, what are the source domains?\n(3)\tFrom eq.(2) to eq.(3), why p(D_i) = \\lamda_i is assumed? Is p(D_i) related to the number of the instance in D_i?\n(4)\tIn the prior part of eq.(3), it should have a p(D_i|x) before log p_\\theta(x), right? Where is f(\\hat_{D}|x), in the first line of page 4, used? What are the optimizers: g and g_e?\n(5)\tRegarding the experimental studies, what do you want to conclude from the visualization of the domain embeddings? It would be better to give more discussion, analyses or observation for the visualization. For the comparison result with StarGAN, could you elaborate the experimental settings for each method? Could you give more explanation on why MD-VAE outperforms StarGAN. Furthermore, are there any other state-of-the-art baselines that can be compared?  \n\nOverall, I think this is an interesting paper. However, there are some unclear parts need to be further clarified. The experimental studies are a litter weak in the sense that (1) it needs more discussion and analyses on the results; and (2) more baselines need to be compared. \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}