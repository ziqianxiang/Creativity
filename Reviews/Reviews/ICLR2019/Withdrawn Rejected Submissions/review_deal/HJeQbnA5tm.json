{
    "Decision": {
        "metareview": "The paper proposes a regularization method that introduces an information bottleneck between parameters and predictions.\n\nThe reviewers agree that the paper proposes some interesting ideas, but those idea need to be clarified. The paper lacks in clarity. The reviewers also doubt whether the paper is expected to have significant impact in the field.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Interesting ideas, lacking in clarity."
    },
    "Reviews": [
        {
            "title": "Interesting to read but might lack depth",
            "review": "I read the paper and understand it, for the most part. The idea is to interpret some regularization technics as a from of noisy bottleneck, where the mutual information b tween learned parameters and the data is limited through the injection of noise. \n\nWhile, the paper is a plaisant read, I find difficult to access its importance and the applicability of the ideas presented beyond the analogy with the capacity computation. Perhaps other referee will have a clearer opinion.\n\nI'd be interested to hear if the authors see a connection between their formalism and the one of Reference prior in Bayesian inference (Bernardo et al https://arxiv.org/pdf/0904.0156)\n\nPro: nicely written, clear interpretation of regularization as a noise injection technics, explicit link with information theoery and Shanon capacity.\n\nCon: not clear to me how strong and wide the implications are, beyond the analogies and the reinterpretation",
            "rating": "7: Good paper, accept",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Interesting ideas, but unclear how to interpret",
            "review": "This paper studies \"Noisy Information Bottlenecks\". The overall idea is that, if the mutual information between learned parameters and the data is limited, then this prevents overfitting. It proposes to create a \"bottleneck\" to limit the mutual information. Specifically, the bottleneck is created by having the data depend on a noisy version of the parameters, rather than the true parameters and invoking the information processing inequality. The paper gives an example of Gaussian mean field inference. Ultimately, the analysis boils down to looking at a signal-to-noise ratio of the algorithm, which looks very much like regularization.\n\nI think this is a very interesting direction, but the present paper is somewhat unclear. In particular, the example in section 3.1 says that a noisy information bottleneck is introduced, but then says that the modified and unmodified models have \"training algorithms that are exactly equivalent.\" I think this example needs to be clarified. Many of the parameters here are also unclear and not properly defined/introduced. What is the relationship between $\\theta$ and $\\tilde\\theta$ exactly? In this simple model, can we not calculate the mutual information directly (i.e., without the bottleneck)?\n\nThe connection between mutual information and generalization has been studied in several contexts [see, e.g., the references in this paper and https://arxiv.org/abs/1511.05219 https://arxiv.org/abs/1705.07809 https://arxiv.org/abs/1712.07196 https://arxiv.org/pdf/1605.02277.pdf https://arxiv.org/abs/1710.05233 https://arxiv.org/pdf/1706.00820.pdf ] and further exploration is desirable. This paper is giving an information-theoretic perspective on existing variational inference methods. Such a perspective is interesting, but needs to be further developed and explained. Specifically, how can mutual information in this context be formally linked to generalization/overfitting? Also, the definition of mutual information used in this paper uses the inferred distribution q (e.g., in eq. 2), which is somewhat unusual. As a result, constraining the model will alter the mutual information and I think the effect of this should be remarked on.\n\nOverall, I think this paper has some interesting ideas, but those need to be fleshed out and clearly explained in a future revision.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "this paper uses DPI in a wrong way",
            "review": "This paper proposes a justification to one observation on VAE: \"restricting the family of variational approximations can, in fact, have a positive regularizing effect, leading to better generalization\". The explanation given in this work is based on Gaussian mean-field approximation.\n\nI had trouble to understand some parts of this paper, since some of the sentences do not make sense to me. For example\n\n- the sentence under eq. (2)\n- the sentence \"Bacause the identity of the datapoint can never be learned by ...\" What is the identity of a dat point?\n\nIt looks like section 2.1 wants to show the connections between eq. (2) and other popularly used inference methods. Somehow, those connections are not clear to me.\n\nBesides some issues in the technical details, the major problem of this paper is that it uses the data processing inequality (DPI) in a **wrong** way.\n\nAs in (Cover and Thomas, 2012), which is also cited in this paper, DPI is defined on a Markov chain X -> Y -> Z and we have I(X,Y) >= I(X,Z). \n\nHowever, based on the definition of \\theta and \\tilde{\\theta} given in the first sentence of section 2.3, the relation between \\theta, \\tilde{\\theta} and D should be: D <- \\theta -> \\tilde{\\theta} (if it is a generative model) or D -> \\theta -> \\tilde{\\theta} (if a discriminative model). Either case, I don't think we can have the inequality in eq. (5).  ",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}