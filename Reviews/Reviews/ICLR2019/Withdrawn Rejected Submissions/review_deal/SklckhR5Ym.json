{
    "Decision": {
        "metareview": "The paper proposes an additional module to train language models, adding\na new loss that tries to predict the previous token given the next one, thus\nenforcing the model to remember the past. Two out of 3 reviewers recommend to\naccept the paper; the third one said it was misleading to claim SOTA since\nauthors didn't try the mixture-of-softmax model that is actually currently SOTA.\nThe authors acknowledged and modified the paper accordingly, and added a few\nmore experiments. The reviewer still thinks the improvements are\nnot important enough to claim significant novelty. Overall, I think the idea is simple and\nadds some structure to language modeling, but I also concur with the reviewer about\nlimited improvements, which makes it a borderline paper. When\ncalibrating with other area chairs, I decided to recommend to reject the paper.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "meta-review"
    },
    "Reviews": [
        {
            "title": "Weak accept",
            "review": "This paper proposes an additional loss term to use when training an LSTM LM.  The authors argue that, intuitively, we want the output distribution to retain some information about the context, or \"past\".  Given this, they use the output distribution as input to a one layer network that must predict the current token.  The loss for this network is incorporated as an additional term used when training the LM.  The authors show that by adding this loss term they can achieve SOTA (for single softmax model) perplexity on a number of LM benchmarks.\n\nThe technical contribution is proposing a new loss term to use when training a language model.  The idea is clear, simple, and well explained, and it seems to be effective in practice.  One drawback is that it is highly specific to language models.  Other recent works which have demonstrated effective regularization of LSTM LMs have proposed methods that can be used in any LSTM model, but that is not the case here.  In addition, there is not much theoretical justification for it, it seems like a one-off trick.  The loss term is motivated by the idea that we want the output distribution to retain some information about the context, but why should that be the case?\n\nAlthough it is specific to language models, there are a few reasons it might be of broader significance:\n- It falls in the recent line of work in incorporating auxiliary losses for various tasks.  This idea has touched many problems and seen success in practice.\n- Perhaps it can be applied to other sequence models.  For example in encoder-decoder models, the decoder can be thought of as a conditional LM.\n\nExperiments are comprehensive and rigorous.  They might be more convincing if there were results on a very large corpus such as 1 billion word corpus.\n\nPros:\n- New SOTA for single softmax model on LM benchmarks.\n- Simple, clearly explained idea.\n- Demonstrates effectiveness of auxiliary losses.\n- Rigorous experiments.\n\nCons\n- Trick is specific to LM.\n- No large corpus results.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A useful regularization for RNN language models",
            "review": "The paper suggests a new regularization technique which can be added on top of those used in AWD-LSTM of Merity et al. (2017) with little overhead.\n\nThis is a well-written paper with a clear structure. The experiments are presented in a clear and understandable fashion, and the evaluation seems thorough. The methodology seems sound, and the authors present the reader with all the information needed to replicate the experiments.\n\nI would only suggest evaluating this technique on AWD-LSTM-MoS of Yang et al. (2017) to get a more complete picture.\n\nReferences\n- Merity, S., Keskar, N.S. and Socher, R., 2017. Regularizing and optimizing LSTM language models. arXiv preprint arXiv:1708.02182.\n- Yang, Z., Dai, Z., Salakhutdinov, R. and Cohen, W.W., 2017. Breaking the softmax bottleneck: A high-rank RNN language model. arXiv preprint arXiv:1711.03953.",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "At best misleading notion of state-of-the-art, optimistic evaluation",
            "review": "In their abstract, the authors claim to provide state-of-the-art perplexity on Penn Treebank, which is not true. As the authors state, their notion of \"state-of-the-art\" excludes exactly that earlier work, which does provide state-of-the-art perplexity on Penn Treebank (Yang et al. 2017), as stated in Sec. 4.1. The question is, why one would exlude the mixture-of-softmax approach here? This is clearly misleading.\n\nThe authors introduce the idea of past decoding for the purpose of regularization. It remains somewhat unclear, why this bigram-centered regularization would strongly contribute for prediction in general.\n\nThe results obtained show moderate improvements of approx. 1 point in perplexity on top of their best current result on Penn Treebank. Considering the small size of the corpus for the evaluation of a regularization method, the results even seem optimistic - it remains unclear, if this approach would readily scale to larger datasets. The mode of language modeling evaluation presented here, without considering an actual language or speech processing task, provides limited insight w.r.t. its utility in actual applications. Moreover, the very limited size of the language modeling tasks chosen here is highly advantageous for smoothing/regularization approaches. It remains totally unclear, how the presented approaches would perform on more realistically sized tasks and within actual applications.\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}