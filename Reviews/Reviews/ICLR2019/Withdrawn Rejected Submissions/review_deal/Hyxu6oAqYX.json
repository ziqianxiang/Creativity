{
    "Decision": {
        "metareview": "The authors present an algorithm for label noise correction when the label error is a function of the input features.\n\nStrengths\n- Well motivated problem and a well written paper.\n\nWeaknesses\n- The reviewers raised concerns about theoretical guarantees on generalization; it is not clear why energy based auto-encoder / contrastive divergence would be a good measure of label accuracy especially when the feature distribution has high variance, and when there are not enough clean examples to model this distribution correctly.\n- Evaluations are all on toy-like tasks with small training sets, which makes it harder to gauge how well the techniques work for real-world tasks.\n- Itâ€™s not clear how well the algorithm can be extended to multi-class problems. The authors suggested 1-vs-all, but have no experiments or results to support the claim.\n\nThe authors tried to address some of the concerns raised by the reviewers in the rebuttal, e.g., how to address unavailability of correctly labeled data to train an auto-encoder. But other concerns remain. Therefore, the recommendation is to reject the paper.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "not enough theoretical guarantees, evaluations are insufficient"
    },
    "Reviews": [
        {
            "title": "Need more theoretical guarantee",
            "review": "This paper addresses Type III label noise correction problem in which the labeling noise depends on the features. They assume that we can obtain a small amount of cleanly labeled data, and use an energy-based semi-supervised learning approach to bootstrap the relabeling process. \n\nPros:\n- Problem is well-motivated with a reasonably good overview of this research area. \n- Paper is generally well-written with enough details to follow and good experimental result discussion.\n\nCons:\n- The energy-based approach based on contrastive divergence is pretty straightforwardly defined, but it will make the paper much stronger if the authors can have more analysis on this approach and/or provide theoretical guarantee on generalization. \n- It is not obvious to me how to extend the proposed approach to multi-class problems. \n- It will be beneficial to test the approach on more real-world problems on top of the toy-data-alike binary classification problems. \n\nMinor clarification questions: \n- What amount of cleanly labeled data is sufficiently required for the proposed approach to work? The authors have some pre-selected percentage in experiments but it is non-trivial to establish that for different applications.\n- Related to the previous comment, how much clean data were used in AE (known) columns in all experiments? \n- In Fig 2 between the two subgraphs, why is the left one showing positive thetas while the right one showing negative thetas?\n- Were the hyperparameters a & b chosen from cross-validation or from std of E terms in all experiment results? \n- In Table 1, for Breast Cancer dataset, how can AE (known) be better than the upper-bound LR-C? \n- It would be good to vary the noise parameters and show how robust the proposed approach is in dealing with different levels of noise. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Need improvements",
            "review": "Need improvements\n\n[Summary]\n\nThis paper addresses the problem of correcting noisy labels for binary classification. It assumes the exists of fully clean data, trains an energy-based autoencoder using contrastive learning objective, and use the estimated energy to determine if a training label is corrupted or not. \n\n[Pros]\n\n1.\tThe paper summarizes different types of label noise in a sensible way. And, it is reasonable to bootstrap the learning process with a small fully clean dataset.\n2.\tThe proposed method shows encouraging results under controlled noise.\n\n[Cons]\n\n1.\tIt is not well-motivated why a contrastive objective or an energy-based autoencoder can be a good solution for label correction. In particular, the connections are not established between the discriminative feature learned by an energy-based model and the label correctness. The proposed method looks more like a binary classifier with a better-regularized structure, but still, it is unclear why an energy-based autoencoder is a good choice. \n2.\tThe proposed method is limited to binary classification, and there is no obvious way to extend it to multiple classes. \n3.\tThe experiments are on toy/small-scale datasets with controlled label noise (but the way to control the noise is not clear). To show the effectiveness of the proposed methods, experiments need to be done on larger-scale datasets with truly realistic unknown noise, Establishing state-of-the-art classification accuracy using a large-scale dataset with noisy labels can serve as strong support for this paper.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Good intuition with weak theoretical supports",
            "review": "This submission proposes an energy-based method to correct mislabelled examples. Intuitively, the authors claim that contradictions between energy and noisy labels can be used to identify label noise. To make the idea reliable, the authors propose to compute the energy by using learned (commonly shared) features. Experiment results look good. The presentation is also clear. My concerns are as follows:\n\n(1) By learning discriminative features and then correcting the label noise, the authors have implicitly assumed that the label noise strongly dependent on the discriminative features. This assumption may be strong as most labels are provided according to the original instance (features). In the experiment section, it is very unclear about how the noise is generated, e.g., how to select x_i according to variance? How to set the threshold? What is \"col\" in Tables 1 and 2? What are the overall label noise rates? Note that if the threshold for the variance is large. It means that the noise is only added to the discriminative features, making the experiment too ad-hoc. \n\n(2) The theory of why the residual energy can be used to identify label noise is elusive. How to set the threshold for identifying label noise with a theoretical guarantee is also unclear. Two recent papers on learning with instance-dependent label noise are surprisingly missed, e.g., Menon, Aditya Krishna, Brendan Van Rooyen, and Nagarajan Natarajan. \"Learning from binary labels with instance-dependent corruption.\" arXiv preprint arXiv:1605.00751 (2016). and Cheng, Jiacheng, et al. \"Learning with Bounded Instance-and Label-dependent Label Noise.\" arXiv preprint arXiv:1709.03768 (2017). The latter one proposes algorithms to identify label noise with theoretical guarantees. The authors should compare the proposed method with them.\n\n(3) There are methods provided for choose the values of hyperparameters. Most of them are empirically set, which is not convincing.\n\n(4) The authors reported that with discriminative features learned by employing noisy data, the proposed method also provide good performance. It would be interesting to see how corrected labels will recursively help better learn the discriminative features. Illustrating figures are preferred.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}