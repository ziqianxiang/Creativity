{
    "Decision": {
        "metareview": "The paper uses a multimodal prior in GANs and reconstructs the latents back from images in two stages to match the generated data modes to the latent space modes. It is empirically shown that this can prevent mode collapse to some extent (including intra-class collapse). However the paper lacks a comparison with state of the art GANs that have been shown to get better FID scores (~21 for SN-GAN [1] vs ~28 in the paper) so the benefit here is unclear, particularly in cases when the mode prior is unknown. Similarly for other applications used in the paper such as inference and attribute discovery, it falls short of demonstrating quantitative improvements with the approach. For example, there is a growing body of work on unsupervised disentanglement in generative models with several metrics to measure it, which could be used to evaluate the attribute discovery performance. R1 has brought up the point of lack of comparisons which the AC agrees with. Authors have made revisions in the paper including some comparisons but these feel insufficient to establish the benefits of the method over state of the art in preventing mode collapse. \n\nA borderline paper as reflected in the reviewer scores but can be made stronger with experiments showing convincing improvements over state of the art in at least one of the applications considered in the paper. \n\n\n[1] Miyato, T., Kataoka, T., Koyama, M., & Yoshida, Y. (2018). Spectral normalization for generative adversarial networks. ArXiv Preprint ArXiv:1802.05957.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Use of multimodal prior for mode conditional generation but lacks convincing experiments to demonstrate its use/benefits "
    },
    "Reviews": [
        {
            "title": "Modification to GAN construction which induces bias to encourage mode matching between latent and data space.",
            "review": "This paper presents a GAN construction which encourages the latent space to mode-match the data distribution.  This allows for unsupervised class-label inference (experimentally verified for two tasks).\n\nI think the paper is of low significance, but the approach outlined is interesting.\n\nUnfortunately, I think the work is slightly let down by the presentation (there are many typos, and the first couple of sections could do with a rewrite), as well as a lack of rigorous experimentation.  I believe that the paper is also missing references to the conditional VAE literature, which shares many similarities (at least in application) with the described approach.\n\nPros:\n- Some theoretical justification for the approach taken.\n- Early evidence that the method allows for latent space class separation, given a prior on number of classes.\n\nCons:\n- A little more experimental evidence would be welcome.  E.g. why is the result for CIFAR 10 not shown---hard to understand how helpful the inductive bias is for a general problem.\n- No discussion of conditional VAEs (which were designed with a very similar goal in mind).\n- No discussion of why decomposing h in the manner in which they did was appropriate.\n- Would be nice to see a more detailed study of how adding supervision + varying the strength of the inductive bias affects performance.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "A well-written paper; would be appreciated if the motivation were clearer and the method more principle",
            "review": "This paper is concerned with the so-called conditional generation, which was descried as the task of sampling from an unknown distribution conditioned on semantics of the data. This proposed method aims at achieving this by using a latent distribution engineered according to a certain data prior. Experimental results showed that the proposed method seems to produce good results.\n\nI have several questions about the motivation and the method in the paper. First, it is not clear to me how the \"semantics\" of the data was defined. Is it given by visual inspection? Is it possible to find it with some automated method? Second, the authors seem to advocate the idea that data of a k-mode distribution should be generated from a k-mode latent distribution. It might be useful in certain scenarios; however, it is not clear why the transformation from the latent to the observed does not change the number of modes or why keeping the same number of modes would endow the latent distribution a \"semantics\" meaning. We know that a k-mode distribution can be obtained by applying a smooth nonlinear transformation to a Gaussian or uniform distribution and, similarly, a k-mode distribution can be transformed to a single-mode distribution with a smooth mapping. So I am not sure why engineering the latent distribution this way can give it a \"semantics\" meaning. Should we try to enforce a kind of smoothness of the transformation, by, say, penalizing high derivative values? Third, the experimental results seem nice, but the lack of comparisons blurs the advantage of the proposed method. How is the result produced by GAN compared to the reported one? How did the original GAN with the engineering latent distribution work? It would be appreciated if the authors could address these issues more clearly.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "The paper proposes simple modifications to GAN architecture for unsupervised conditional image generation. The authors achieve this by making the distribution of noise z dependent on variable y that can depend on the label distribution when available. This involves learning to predict the input noise z as well as y from the generated image. The qualitative results shown for unsupervised conditional image generations using the approach are convincing. \n\nPros:\n\t- The paper is well written and easy to follow.\n\t- The simple modification to the noise distribution leads to good results on unsupervised conditional image generation.\n\t- Minimizes loss terms exactly instead of lower bound as is commonly done in other similar unsupervised approaches.\n\t- Theoretical justifications for the approach are convincing.\n\nCons:\n\t- The paper can be strengthened by including ablation studies on the loss term for the z reconstruction.\n\t- How will InfoGAN and VEEGAN compare with similar loss terms for the z reconstruction added to their objective?\n\t- It will be useful to show FID and other similar scores to better evaluate the learned generative model. Including mode counting, experiments will strengthen the paper.\n\t- ACGAN can suffer from the issue of generating images where it is easy to infer y [1]. This leads to mode collapse within each category/class. Will the proposed approach suffer from similar issues?\n\n[1] Shu, Rui, Hung Bui, and Stefano Ermon. \"AC-GAN Learns a Biased Distribution.\"",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}