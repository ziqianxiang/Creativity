{
    "Decision": {
        "metareview": "This paper studies the really hard problem of zero-shot learning in acoustic modeling for languages with limited resources, using data from English. Using a novel universal phonetic model, the authors show improvements compared to using an English model for 20 other languages in phone recognition quality.\n\nStrengths\n- Reviewers agree that the problem is an important one, and the presented ideas are novel.\n- Universal phonetic model to represent phones in any language is interesting.\n\nWeaknesses\n- The results are really weak, to the point that it is unclear how effective or general the techniques are. The work is an interesting first step, but is not developed enough to be accepted at this point.\n- The universal phonetic model being trained only in English might affect generalizability to languages that do not share phonetic characteristics. The authors agree partly, and argue that the method already addresses some issues since the model can already represent unseen phones. But, coupled with the high phone error rates, it is still unclear how appropriate the technique will be in addressing this issue.\n- Novelty: Although the idea of mapping phones to attributes, and using those for ASR is not novel (e.g., using articulatory features), application for zero-shot learning is. The work assumes availability of a small text corpus to learn phone-sequence distribution, so is similar to other zero-resource approaches that assume some data (audio, as opposed to text) is available in the new language.\n\nThis paper presents interesting first steps, but lacks sufficient experimental validation at this point. Therefore, AE recommendation is to reject the paper. I encourage the authors to improve and resubmit in the future.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Good first step, but error rates are too high"
    },
    "Reviews": [
        {
            "title": "Review",
            "review": "This paper presents an approach to address the task on zero-shot learning for speech recognition, which consist of learning an acoustic model without any resources for a given language. The universal phonetic model is proposed, which learns phone attributes (instead of phone label), which allows to do prediction on any phone set, i.e. on any language. The model is evaluated on 20 languages and is shown to improve over a baseline trained only on English.\n\nThe proposed UPM approach is novel and significant: being able to learn a more abstract representation for phones which is language-independent is a very promising lead to handle the problem of ASR on languages with low or no resources available. \n\nHowever, the results are the weak point of the paper. While the results demonstrate the viability of the approach, the gain between the baseline performance and the UPM model is quite small, and it's still far from being usable in practice. \n\nTo improve the paper, the authors should discuss the future work, i.e. what are the next steps to improve the model.\n\nOverall, the paper is significant and can pave the way for a new category of approaches to tackle zero-shot learning for speech recognition. Even if the results are not great, as a first step they are completely acceptable, so I recommend to accept the paper.\n\nRevision:\nThe approach of using robust features is interesting and promising, as well as the idea of training on multiple languages. Overall, the authors response addressed most of the issues, therefore I am not changing my rating.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting but not good enough!",
            "review": "This paper proposes to train a Universal Phonetic Model for building speech recognition for new languages without any training data. It suggests to use X-SAMPA to map phones from all the languages into a single phonetic space. The prediction models are designed to first predict the phonetic features and then the phones depending on the target language.\nOverall , the paper is quite clear written. \n- Strengthens:\n+ It observed overall improvements for all the target languages.\n\n- Weaknesses:\n+ The idea and the proposed model are not novel. \n+ All the baseline systems have relative high phone error rates.\n+ The authors claimed to have a universal phonetic model but actually the model was trained only with English data. Therefore, experimental setup could be improved. In my opinion, it makes more sense to define a bunch of resource-rich languages as source and then train a real universal phonetic model. \n+ Overall, this paper lacks an analysis what are exactly improved and why the improvements for some target languages are larger than for the others.\n ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Claims of being first not completely justified",
            "review": "Overview:\n\nThis paper proposed an approach for zero-shot phoneme recognition, where it is possible to recognise phonemes in a target language which has never been seen before. Rather than just training a phoneme recogniser directly on background data and then applying it to unseen data, phonetic features are first predicted, allowing phonemes not in the source language set to be predicted.\n\nMain strengths:\n\nThe paper's main strength lies in that this is a very unexplored area that could assist in the development of speech technology where it is currently not possible. The proposed model (Section 2) has also not been considered in prior work.\n\nMain weaknesses:\n\nThe paper's main weakness is in some of its claims and that it misses some very relevant literature. Detailed comments together with a minimal list of references are given below (but I would encourage the authors to also read a bit more broadly). But in short I do not think it is that easy to claim that this is the first paper to do zero-shot learning on speech; many of the zero-resource studies where unlabelled audio is used could be seen as doing some for of zero-shot matching. Specifically [5] is able to predict unseen phoneme targets.  Multilingual bottleneck features can be applied to languages that have never been seen before [2], and the output of phoneme recognisers trained on one language have long been applied to get output on another unseen language. The first one-shot learning speech paper [4] (to my knowledge) is also not mentioned at all. The approach in the paper also still relies on some text data from the target language; if this then can be described as \"zero-shot\" learning, then I think many of these previous studies c also make this claim.\n\nOverall feedback:\n\nThere is definitely value in this work, but it should be much better situated within the broader literature. Below I give some editorial suggestions and also outline some suggestions for further experiments.\n\nDetailed comments, suggestions and questions:\n\n- Abstract: It would be useful to have some details of the \"baseline model\" here already, especially since it is such a new task.\n- Introduction: \"... but they can hardly predict phones or words directly due to their unsupervised nature.\" This is a strong statement that maybe requires more justification. On the one hand, the statement is true, and the high word error rates in e.g. [3] can be cited. On the other hand, it has been shown that at the phone-distinction level, these models perform quite well and sometimes outperform supervised models [1]. Since this paper also considers phone error rate as a metric, I think care should be taken with such statements.\n- Introduction: \"While zero-shot learning has attracted a lot of attention in *the* computer vision community, this setup has hardly been studied in speech recognition research especially in acoustic modeling.\" Definitely look at some of the studies mentioned below, and also [4] specifically.\n- \"However, we note that our model can be combined with a well-resourced language model to recognize words.\" How would this be done, since I think this is actually quite a challenging task.\n- Section 2: \"... useful the original ESZSL architecture ...\" -> \"... useful in the original ESZSL architecture ...\"\n- Section 2.2: I assume the small text corpus is at the phone level (and not characters directly)? This should be clarified, and it could raise the question of whether this approach is truly \"zero-shot\".\n- Section 3.2: \"We used EESEN framework ...\" -> \"We used the EESEN framework ...\"\n- Section 4: You could look at the recent work in [2], which uses multilingual bottleneck features trained on 10 languages and applied to multiple unseen languages. It would be interesting to also train your approach on multiple languages instead of only English.\n\nMissing references:\n\n1. M. Heck, S. Sakti, and S. Nakamura, \"Feature Optimized DPGMM Clustering for Unsupervised Subword Modeling: A Contribution to Zerospeech 2017,\" in Proc. ASRU, 2017.\n2. E. Hermann and S. J. Goldwater, \"Multilingual bottleneck features for subword modeling in zero-resource languages,\" in Proc. Interspeech, 2018.\n3. H. Kamper, K. Livescu, and S. Goldwater, An embedded segmental k-means model for unsupervised segmentation and clustering of speech,\" in Proc. ASRU, 2017.\n4. B. M. Lake, C.-Y. Lee, J. R. Glass, and J. B. Tenenbaum, \"One-shot learning of generative speech concepts,\" in Proc. CogSci, 2014.\n5. O. Scharenborg, F. Ciannella, S. Palaskar, A. Black, F. Metze, L. Ondel, and M. Hasegawa-Johnson, \"Building an ASR system for a low-resource language through the adaptation of a high-resource language asr system: Preliminary results,\"in Proc. ICNLSSP, 2017.\n\nEdit: Based on the rebuttal I've changed my rating from 4 to 5.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}