{
    "Decision": {
        "metareview": "All three reviewers expressed concerns about the writing of the paper. The AC thus recommends \"revise and resubmit\".",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Needs rewriting"
    },
    "Reviews": [
        {
            "title": "Adversarial learning framework for energy-based structured prediction ",
            "review": "Building on the work of (Gygli et al., 2017), this paper introduces a training algorithm for energy-based models for structured prediction. Similar to Gygli et al. (2017), they train an energy-based discriminator, which matches the energy value of structured outputs with their target values assigned by a value function.\nThe authors present the learning algorithm in an adversarial learning framework by describing a structured prediction model G and a discriminator D. However, it is very confusing for me to understand the proposed formulation as an adversarial framework. In an adversarial framework, at the equilibrium, G could be used as a final prediction model, however, the predicted output of G are still low quality. For example, considering Table 1, the performance of G is exactly the same as NN baseline, which suggests that only the first term of Eq. 6  participates in the training of G (because L_g(G, y*) is the exact objective of the NN baseline).\nWhat that I can easily relate to, however, is that this training algorithm is similar to Gygli et al. (2017), but uses G to get an initial point for gradient-based inference. We want this initial point to be close to the target value Eq. 6. We use the initial value (prediction of G) and the ground truth as the matching constraints (Eq. 5) (as well as the other samples that construct Eq. 10). This actually describes why D can refine the output of G (because it looks at it as an initial point that needs refinement), but the discriminators in the other adversarial frameworks can't refine that much (since they have reached the equilibrium). I would love to hear authors comments on my concern regarding the proposed adversarial framework.\n\nOther comments:\n1) Lg is a surrogate loss, not the task-loss. Task-loss could be F1, IOU, BLEU, etc, which is the ultimate performance measure on a task. \n2) The authors refer to G as a structured prediction model but starting from Section 4, they have switched to call it a classifier, which is confusing.\n3) \"Gygli et al. (2017) found that the key to learning energy-based models is generating proper training data.\":  Is this a general statement for every energy-based model? I understand its effect when matching values, but is it still true for other training algorithms such as structural SVM training (Belanger and McCallum, 2016)? Do you have evidence to support it?\n4) \"In the experiment, we adopt the fully convolutional network (FCN) (Long et al., 2015) baseline model proposed in (Gygli et al., 2017) as our segmentation network. It consists of three 5 × 5 convolutional layers and two deconvolution layer.\": The text from Gygli et al. (2017) says three convolutional layers and two fully connected layers. Are you using the same architecture? If not, can you describe the architecture in more details? \n5) The qualitative results for Gygli et al. (2017) appear in https://gyglim.github.io/deep-value-net/. The reported output for DVN row is significantly worse than the segmentation results of the same horses specifically for columns 4 and 8, while the overall reported IOU in Table 2 is exactly the same. Can you describe the source of this disagreement?\n6) Is having a continuous domain for value function v essential for the proposed training algorithm? \n\n=== After rebuttal ===\nI am not convinced that the improved performance is because of the adversarial training. I trained a simple MLP and with the right amount of regularization it gets 42.0% f1 score on Bibtex, so I am not sure that the adversarial training is very essential here.\n \n\n ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Useful but incremental improvement over previous work; Clarity of writing needs improvement",
            "review": "- The writing and structure of the paper can be improved. It is difficult to read without first reading Gygli et al. 2017, and this paper should be more self-contained. There are also many parts that are not clear: \n  1. What is the model structure of G? Is it another neural network, or other structured prediction approaches such as graphical models? \n  2. The GAN-based approaches listed in the experiments section are originally designed for learning generative models. What are the adaptations required to turn them into structured prediction models? This is not clear at all. \n\n- The convergence of GAN training is an ongoing research problem and in practice also affects the quality of results. Yet in this paper I don't see any details on how these adversarial networks are trained jointly (e.g., heuristics to balance the progress on G and D). The authors should give more details on these.   \n\n- The main difference of this paper compared to Gygli et al. 2017 seems to be the joint learning of a prediction model G. Instead of relying only on the valuation network D and starts iterative gradient ascent on the initial prediction of a vector y^(0) of all zeros, the authors start the iterative gradient ascent with the prediction from G (equation 7). Otherwise the paper looks very similar to Gygli et al. 2017, including the training sample generation methods. So to me the main message of this paper is that you can improve deep value networks by providing a better starting point in inference with G. The improvement is somewhat small though, between 1-2% on the datasets shown in the experiments section. \n\n- Overall this paper gives a useful but incremental improvement over the deep value network proposed by Gygli et al. 2017. However, the writing should be substantially improved to make the paper more self-contained and to include missing experiment details. \n\n=== after rebuttal ===\n\nThe authors explain some of their model choices in the rebuttal, but I am still not convinced about the difference with Gygli et al. 2017 is significant enough. \n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting ideas, but needs a few more justifications for certain modeling choices over others",
            "review": "Summary:\nThis paper effectively learns a variant of a Deep Value Network (Gygli et al 2017), a model consisting of an energy network that assigns scores to input-output tuples that is trained to mimic a task-specific loss. The primary differences between the model presented in this work (titled LDRSP) and DVNs are twofold: first, the initial label prediction used at test time for inference is the output of a model rather than being initialized to all zeros. Second, a GAN-inspired loss is used to train both the scoring function and the initial prediction estimator. This new setup is compared against a variety of recent structured prediction methods on the tasks of multilabel classification, semantic segmentation, and 3-class face segmentation.\n\nComments:\nI think the ideas presented in this paper are interesting, but I think their presentation could be a bit clearer. As mentioned in the summary, what you’re presenting is still more or less a deep-value network with some additions - however, you don’t refer to it as such in the body of the paper anywhere I saw. The first addition is the use of a learned model to produce the initial prediction; this is a natural extension to Deep Value Networks, and on its own is somewhat incremental in nature. I do not think you adequately explained why you chose to use a GAN-like loss to learn these models. Another baseline that would have helped justify its use would be to train your G model to predict structured outputs in the standard way (max-margin or cross-entropy loss) and then train your energy function in the DVN way. \n\nThe experimental settings are somewhat small in scope but follow the precedent set by previous structured prediction papers, which is fine. You make appropriate comparisons against previous structured prediction models as well as against different types of GAN-like losses. But, as I mentioned before, I think you needed to have more comparisons against different ways of training these networks that do not follow a GAN-inspired framework. \n\nOverall, I like the new ideas in this paper but I think a few more experimental settings are required before they should be published.\n\n=== after rebuttal ===\n\nI appreciate the response, but I still think further analysis of the model is needed to understand where the gains in performance are coming from. The claim is that this is due to the adversarial loss used, but without further ablations I feel this is too strong a claim to be making given the current evidence.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}