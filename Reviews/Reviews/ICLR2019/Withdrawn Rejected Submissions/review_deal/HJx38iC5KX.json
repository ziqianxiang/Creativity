{
    "Decision": {
        "metareview": "This paper proposes a new solution to the problem of domain generalization where the label distribution may differ across domains. The authors argue that prior work which ignores this observation suffers from an accuracy-vs-invariance trade-off while their work does not. \n\nThe main contribution of the work is to 1) consider the case of different label distributions across domains and 2) to propose a regularizer extension to Xie 2017 to handle this. \n\nThere was disagreement between the reviewers on whether or not this contribution is significant enough to warrant publication. Two reviewers expressed concern of whether 1) naturally occurring data sources suffer substantially from this label distribution mismatch and 2) whether label distribution mismatch in practice results in significant performance loss for existing domain generalization techniques. Based on the experiments and discussions available now the answer to the above two points remains unclear. These key questions should be clarified and further justified before publication.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Potentially interesting new problem setup, but lacking sufficient evidence to showcase problem relevance"
    },
    "Reviews": [
        {
            "title": "This paper lacks sufficient novelty",
            "review": "In this paper, the author(s) propose a method, invariant feature learning under optimal classifier constrains (IFLOC), which maintains accuracy while improving domain-invariance. Here is a list of suggestions that will help the author(s) to improve this paper.\n1.The paper explains the necessity and effectiveness of the method from the theoretical and experimental aspects, but the paper does not support the innovation point enough, and the explanation is too simple.\n2.In this paper, Figure3-(b) shows that the classification accuracy of IFLOC-abl method decreases a lot when γ is taken to 0. Figure3-(c) shows that the domain invariance of IFLOC-abl method becomes significantly worse when γ is 10. The author(s) should explain the reasons in detail.\n3. The lack of analysis on domain-class dependency of each dataset makes the analysis of experimental results weak.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Simple and effective idea, good experiment design",
            "review": "This paper proposed to address domain generalization under inter-dependence of domains and classes. It motivates a new regularization term by analyzing an existing work, DAN. It shows that this term can improve the generalization performance when the classes and domains are not independent. Experiments are extensive and supportive. \n\nI do not have many comments about this paper. It was a joy to read. The proposed idea is well motivated. It is simple and seems like effective. Experiments are extensive. \n\nWhile the regularization term is motivated by analyzing DAN, it would be nice to discuss its application to other domain adaptation/generalization methods. What is even better is to show its effectiveness on another method in the experiments.",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "The proposed problem seems similar to traditional conditional distribution matching problem. ",
            "review": "The paper proposed a problem that most prior methods overlooked the underlying dependency of classes on domains, namely p (y|d) \\= p(y).   Figure 1 is used to illustrate this issue. \n\nIf the conditional probability of source domain and target domain is not equal (i.e., p(y|x_S) \\= p(y|x_T)  ), the optimal invariance can lead the same generalization problem.   Unfortunately, a lot of works has been done [1,2] in matching domain classifier or conditional probability.  It is desirable to discuss the difference between these two problems and compared with the missing references in experiments. \n\nIt is also suggested to conduct the analysis of why the datasets satisfy the assumption of the dependence of class and domains. \n\nReference:\n[1] Flexible Transfer Learning under Support and Model Shift, NIPS 2014.\n[2]Conditional Adversarial Domain Adaptation, NIPS 2018",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}