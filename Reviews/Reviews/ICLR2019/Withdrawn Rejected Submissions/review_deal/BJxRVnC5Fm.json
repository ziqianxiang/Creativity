{
    "Decision": {
        "metareview": "This paper proposes an approach to pruning units in a deep neural network while training is in progress. The idea is to (1) use a specific \"scoring function\" (the absolute-valued Taylor expansion of the loss) to identify the best units to prune, (2) computing the mean activations of the units to be pruned on a small sample of training data, (3) adding the mean activations multiplied by the outgoing weights into the biases of the next layer's units, and (4) removing the pruned units from the network. Extensive experiments show that this approach to pruning does less immediate damage than the more common zero-replacement approach, that this advantage remains (but is much smaller) after fine-tuning, and that the importance of units tends not to change much during training. The reviewers liked the quality of the writing and the extensive experimentation, but even after discussion and revision had concerns about the limited novelty of the approach, the fact that the proposed approach is incompatible with batch normalization (which severely limits the range of architectures to which the method may be applied), and were concerned that the proposed method has limited impact after fine-tuning.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Good writing and experiments, but limited novelty and applicability"
    },
    "Reviews": [
        {
            "title": "Some clarity issues",
            "review": "This paper presents a mean-replacement pruning strategy and utilizes the absolute-valued Taylor expansion as the scoring function for the pruning. Some computer vision problems are used as test beds to empirically show the effect of the employment of bias-propagation and different scoring functions. The empirical results validates the effectiveness of bias-propagation and absolute-valued Taylor expansion scoring functions.\n\nThe work is generally well-written and the results are promising, and the theoretical explanation in 3.3 is intriguing. However, I think the following issues need some further clarifications:\n1. What's the exact difference and connection between the mean-replacement pruning technique, and the bias-propagation technique in Ye et al., (2018) and the mean activation technique in Morcos et al. (2018)? The authors only mention that mean replacement pruning extends the idea in Ye et al. (2018) to the non-constrained training setting, but it is very unclear what \"constraints\" are talked about. Some more detailed and formal comparisons should be added, together with potential empirical comparisons.\n2. In the abstract, the authors claim that they \"adapt an existing score function ...\", but from the main text it seems that absolute-valued Taylor expansion score is exactly the same one in Molchanov et al. (2016). Is this a typo (or misleading claim) in the abstract?\n3. There are no comparisons of the approach proposed in this paper with some existing state-of-the-art, apart from some simple comparisons between whether bias-propagation is adopted and some inner comparisons among different scoring functions.\n\nIt would also be much better if some charts/tables with certain metrics for improvement apart from pruning penalties (e.g., compression rates, or inference speed, etc.) instead of simply illustrative figures are shown. \n\n### some smaller suggestions/typos ###\n1. The plot legends/labels are kind of inconsistent with the description before the figures. For example, in the main text the authors mainly use \"pruning penalty\", while in the figures the y-axes are typically labelled as \"\\Delta-loss after pruning\", and the plot tag at page 5 bottom is different from those used in the plots, which introduces some unnecessary confusion.\n2. It is very unclear how the authors arrive at the conclusion \"This results suggests ... the training process\" from the \"winning ticket\" hypothesis.\n3. Several typos that can be easily spell-checked (e.g., \"the effect or pruning\" -> \"the effect of pruning\", etc.).\n\nI hope the authors can address these issues. Thanks!",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Overall score: 4",
            "review": "1. Pruning neurons in pre-trained CNNs is a very important issue in deep learning, and there are a number of related works have been investigated in Section 2. However, it is very strange that, I did not see any comparison experiments to these related works in this paper.\n\n2. The presentation of the experiment part is also wired, to report compression rates, speed-up rates, and accuracy might have a more explicit demonstration.\n\n3. ''This is often done by replacing the these units with zeroes\". However, in previous works, we can directly establish a compact network with fewer neurons after pruning some unimportant neurons. Thus, some considerations and motivations in Section 3.2 seem wrong. \n\n4. It seems that the neural network after using the proposed method has the same architecture as that of the original network, but some of it neurons are represented as mean replacement. Therefore, the compression and speed-up rates of the proposed method would be hard to implement in practice.\n\n5. The paper should be further proofread. There are considerable grammar mistakes and unclear sentences.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting and simple method, but needs clarification w.r.t. related methods and results",
            "review": "This paper proposes a simple improvement to methods for unit pruning. After identifying a unit to remove (selected by the experimenter’s pruning heuristic of choice), the activation of that unit is approximately incorporated into the subsequent unit by “mean replacement”. The mean unit activation (computed on a small subset of the training set) is multiplied by each outgoing weight (or convolutional filter) and added to each corresponding bias instead. Experiments show this method is generally better than the typical method of zero-replacement before fine-tuning, though the advantage is smaller after several epochs of fine-tuning.\n\nWhile I find this paper intriguing and applaud the extensive experimentation and documentation, I have some concerns as well:\n\t1. There are unanswered questions about how this method relates to existing work. It is not clear from the paper how the “mean replacement” method differs from the two most related works (Ye, 2018) and (Morcos, 2018), which propose variations on replacing units with constant values or mean activations, respectively. Also, why does the method in this paper seem to yield good results, while the related method (Morcos, 2018) yields “inferior performance”?\n\t2. The results are stated to only apply to networks “without batch normalization”. The reason seems intuitive: any change that can be merely rolled into the bias will be lost after normalization (depending perhaps on the ordering of normalization and the non-linearities). This leaves an annually decreasing fraction of networks to which this method is applicable, given the widespread use of batch norm.\n\t3. Critically, it’s difficult to compare this work against other pruning works given the lack of results reported in terms of final test error and the lack of the ubiquitous “error vs. %-pruned” plot.\n\t\nOverall, this paper is lacking some clarity, may be limited in originality, may be helpful for some common networks and composable with other pruning methods (significance), but has a good quality evaluation (subject to the clarity issues). I’m rating this paper below the threshold given the limitations, but I’m willing to consider an upgrade to the score if these questions are addressed.\n\nOther notes:\n\t4. What is your definition of a convolutional “pruning unit”? (From context, I’d presume it corresponds to an output activation map.)\n\t5. In Section 3.1:  replace “in practice, people …” with  something like “in practice, it is common to”.\n\t6. In Equation 3, is the absolute value of the pruning penalty used in the evaluation?\n\t7. In the footnote in Section 3.2, how many training samples are needed for a good approximation? How many are used in the experiments?\n\t8. There are a couple typos in Section 3.2: “replacing -the- these units with zeroes” and “each of these output*s*”.\n\t9. Presumably the “\\Delta Loss after pruning” in Figures 2-6 is validation or test loss, not training loss? Is this the cross-entropy loss? Also, it would be much easier to compare to other papers if test accuracy were reported instead or in addition.\n\t10. In Figure 4, the cost to recover using fine-tuning seems to be only roughly 2% of the original training time. How much time is lost to the process of computing the average unit activation?\n\nUPDATE: I've raised the score slightly to 5 after the rebuttals and revisions.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}