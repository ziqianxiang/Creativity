{
    "Decision": {
        "metareview": "This paper combines Prolog-like reasoning with distributional semantics, applied to natural language question answering. Given the importance of combining neural and symbolic techniques, this paper provides an important contribution. Further, the proposed method complements standard QA models as it can be easily combined with them.\n\nThe reviewers and AC note the following potential weaknesses:\n(1) The evaluation consisted primarily on small subsets of existing benchmarks, \n(2) the reviewers were concerned that the handcrafted rules were introducing domain information into the model, and (3) were unconvinced that the benefits of the proposed approach were actually complementary to existing neural models. \n\nThe authors addressed a number of these concerns in the response and their revision. They discussed how OpenIE affects the performance, and other questions the reviewers had. Further, they clarified that the rule templates are really high-level/generic and not \"prior knowledge\" as the reviewers had initially assumed. The revision also provided more error analysis, and heavily edited the paper for clarity. Although these changes increased the reviewer scores, a critical concern still remains: the evaluation is not performed on the complete question-answering benchmark, but on small subsets of the data, and the benefits are not significant. This makes the evaluation quite weak, and the authors are encouraged to identify appropriate evaluation benchmarks. \n\nThere is disagreement in the reviewer scores; even though all of them identified the weak evaluation as a concern, some are more forgiving than others, partly due to the other improvements made to the paper. The AC, however, agrees with reviewer 2 that the empirical results need to be sound for this paper to have an impact, and thus is recommending a rejection. Please note that paper was incredibly close to an acceptance, but identifying appropriate benchmarks will make the paper much stronger.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Important contribution, but ultimately weak evaluation"
    },
    "Reviews": [
        {
            "title": "interesting approach towards combining neural networks with logic reasoning",
            "review": "Update:\nI appreciate the through error analysis the authors have done in the revision, which addressed my major previous concerns. I've updated my score accordingly.\n\nThis paper presents an approach to combine Prolog-like reasoning with distributional semantics. First, extracted fact triples are unified (i.e. mapped to) predicates and entities. Next, reasoning is performed with rule templates, where predicates and entities are abstracted. Since the reasoning process is non-differentiable, zero-oder optimization is used to fine-tune the predicate / entity embeddings.\n\nThe general idea of combining logical reasoning with neural models is quite appealing. A sketch of the algorithm is to first build structured knowledge from the text, then do reasoning over it to answer queries. In this work, the first step is completely relied on an off-the-shelf tool, Open-IE. It would be useful to see whether this step is the bottle neck of such approaches. One possibility is to apply the model to knowledge graph reasoning, which would remove any noise introduced from the knowledge extraction step, and solely focus on evaluating reasoning.\n\nThe results are a bit restricted, as in only a subset of the datasets are evaluated. I suspect part of the reason is that most of the QA datasets which claims to require multi-step reasoning don't really need much reasoning... However, it would be useful to do some simple (perhaps qualitative) analysis on the data quality, and make sure that it indeed tests what it intended to. For the ensemble results in Table 1, usually even ensembling same models trained with different seed would show improvements, so I'm not completely convinced that BiDAF and NLProlog are complementary - would be nice to see error analysis here.\n\nQuestion:\nWhat is the size of hand-coded predicates and rules? What's the coverage of these rules on the datasets, i.e. are there questions unanswerable by the provided rules?\n\nOverall, while the results are limited, the approach is interesting, and hopefully will spur more work towards interpretable models with explicit reasoning.",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting direction, experiments are unconvincing",
            "review": "Updated after reading author revisions:\nI appreciate the clarifications, the response answered almost all of my small technical questions.  That plus the new error analysis increases my opinion about the paper, and I'm no longer concerned that the rule templates are hand-generated given their generality and small number.  I am still concerned that we don't actually know how well the methods work, because the test sets are small and the performance differences between the methods (in Table 1) are quite close.  I will raise my score one point.\n\nThe authors might try to evaluate using k-fold cross-validation with the training set, to obtain more examples for evaluation.\n\nOriginal review:\n\nThe paper presents a technique for using prolog along with neural representations and Open IE to perform reasoning with weak unification.\n\nI like the basic direction of trying to combine prolog with neural models, and the weak unification notion.  The approach seems sufficiently novel, and the GRL is a reasonable heuristic.\n\nI do, however, have significant concerns about the experiments.  The data sets are selected subsets of other standard benchmarks, rather than the entire benchmarks, and the test sets are quite small (e.g., the \"developer\" column where the NLProlog approach shows some of the larger wins -- when ensembled with previous techniques -- is based on a test set of only 29 examples).  Given the hand-annotated nature of much of the input knowledge (the rule templates), this introduces an important concern that the experimental wins will not be robust in more realistic settings where different knowledge may be required.\n\nMinor comments/questions\npage 2: \"without the need to transforming\"\nI did not understand how individual symbols, predicates and entities, have embeddings that come from sentence vectors (Section 4.1).\nThe learning objective in Section 4.2 seems reasonable, but I did not understand how \"evolution\" was part of the strategy there.\nThe example rule template for transitivity isn't actually transivity unless p_i=p_j for all i,j, I found that a little confusing.\nWhere are \"t-norms\" (mentioned at the top of page 6) used?  I did not see this.\n\"candidates entities\" -> \"candidate entities\"\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Promising unification of neural representations with learned logical rules",
            "review": "\n\nUPDATE: Given the authors' rebuttal and the clear improvements to their paper, I've increased my rating of the work.\n\n=======================\n\nThis paper presents NLProlog, a method that combines logical rules with distributed representations for reasoning on natural language statements. Natural language statements (first converted to logical triples) and templated logical rules are embedded in a vector space using a pretrained sentence encoder. These embedded \"symbols\" can be compared in vector space, and their similarity used in a theorem prover (Prolog) modified to support weak unification. The theorem prover determines the answer to a natural language query by constructing a proof according to its logical rules.\n\nTraining through the non-differentiable theorem prover occurs via an \"evolutionary strategy,\" which enables the model to fine-tune its sentence encoders and learn domain-specific logic rules directly from text. The authors also propose a Gradual Rule Learning (GRL) algorithm that seems necessary for the optimization process to converge on good solutions.\n\nDespite the model's complexity, the paper was fairly clear to me.\n\nAlthough the proposed model is a conglomeration of pre-existing parts, the combination is original to my knowledge. The use of Open Information Extraction to transform natural language statements to logical statements, which amenable to theorem provers, is novel and also circumvents the complicated preprocessing required by previous related works.\n\nThe authors evaluate the proposed approach on subsets of the Wikihop dataset and BABI-1k. NLProlog performs competitively with neural models, similarly augmented with Sent2Vec but lacking explicit logical rules, only on the 'country' subset of Wikihop. It does not compete with or clearly outperform these models in general. As the authors state, it further \"struggles to find meaningful rules for the predicates 'developer' and 'publisher'.\"\n\nNLProlog demonstrates strong performance on a subset of problems labelled unanimously by annotators to require multi-hop reasoning. Unfortunately, this is only done for the \"country\" subset of Wikihop, on which the model was already shown to have the strongest performance. I'd find this more convincing if similar improvements were shown on the other subsets (publisher, developer).\n\nTaking into account also that the BABI subset was used only for ablation, the limited results call into question the significance of the work. It would definitely benefit from more extensive experimental validation. On the other hand, it's very positive to see that NLProlog seems to succeed where the neural models fail, and vice versa, so that the two approaches can be combined in an ensemble to achieve state-of-the-art results. This suggests that the paper's line of research has something to add to the community and should be pursued further. I'd find this result more interesting if an error analysis elucidated some characteristics of the examples that each approach does well/poorly on.\n\nI'd like to see more analysis in general, that answers questions including:\n- How reliable is the Open IE system and how does its performance impact the end task?\n- How well-specified must the a priori rule structures be to achieve good performance? Further, how does the number and structure of the rules (a hyperparameter in this work) affect performance?\n- What is the run-time/complexity of the exhaustive proof search during training?\n- Relatedly, you state that you limit the rule complexity to two body atoms in the rule templates for BABI. Can you estimate what rule complexity is required in the Wikihop tasks?\n\nI would like to recommend this work more confidently because it tackles such an important problem and does so in an interesting, well-conceived way. My reluctance arises from the limited experimental validation and analysis. Given more analysis details and experimental evidence from the authors, I'm happy to raise my recommendation.\n\nPros:\n- the method complements standard deep QA models to achieve state-of-the-art results in an ensemble.\n- unifying neural representations with logical/symbolic formalisms is an important research direction.\n- a code release is planned.\n\nCons:\n- a very complex model, whose details are occasionally unclear; the algorithms in Appendix A are helpful but they are not in the main text.\n- the model expresses only a limited subset of first order logic; dynamically changing world states are not supported (yet).\n- limited experimental validation.\n- it's good to be able to incorporate prior knowledge, but it seems like it's quite necessary to pre-specify rules (in template form).\n\nMinor quibble: Evolutionary learning strategies, such as genetic algorithms, go back a long way. It's strange using only a reference from 2017 to introduce them.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}