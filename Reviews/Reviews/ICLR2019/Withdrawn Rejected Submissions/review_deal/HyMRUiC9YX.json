{
    "Decision": {
        "metareview": "While the paper contains significant information, most insights have already been revealed in previous work as noted by R1. \nThe empirical novelty is therefore limited and the authors do not provide theoretical analysis to complement this.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Needs improvements."
    },
    "Reviews": [
        {
            "title": "Paper that presents an experimental study of adversarial examples transferability with a contribution based on loss smoothing. The study is interesting with good illustrations and potential improvements but seems a bit limited, the conclusions are rather expected or unsurprising.",
            "review": "This paper addresses the problem of adversarial transferability, i.e. the ability that an adversarial example generated by one model can successfully fool another model. There are numerous papers on this topic recently, such as Fawzi'15, Liu'17, Dong'18, Athalye'18...\nThe authors propose tot study two types of factors that might influence transferability: model-specific parameters and smoothness of loss surface for constructing adversarial examples. Two experimental studies are made for each influence factor from existing architectures. Another attack strategy aiming at smoothing the loss surface is proposed, an experimental evaluation shows the effectiveness of the proposed method.\n\nPros\n-the proposed experimental studies can be interesting to the community\n-many interesting illustrations are provided.\n\nCons\n-The conclusions of the study were suggested by previous papers or are rather expected: adversarial transfer is not symmetric: Deep models less transferable than shallow ones, averaging gradient is better\n-I find the experimental studies a bit limited and I would expect larger studies which would have improve the interest of the paper.\n-Only two influence factors are studied, again the paper would be more interesting with a more general study\n\nThe paper has an interesting potential but seems a bit limited in its present form.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Interesting insights and attack broadening our understanding of the scope of the problem of adversarial examples",
            "review": "The paper explores how the architecture, smoothness of the decision boundary and test accuracy of a model impacts the transferability of examples produced from it.  The paper provides a couple of novel insights, such as the asymmetry when transferring adversarial examples from one model to another. In addition, a novel method is proposed to enhance the transferability of adversarial examples from any model, through using smoothed gradients.\n\nThe experiments seem to show that the effect is rather large, and also makes the examples more robust to other transformations such as JPEG compression. Overall, these are interesting insights that could lead to further developments in making models more robust to adversarial examples. In particular, deriving adversarial examples that are both transferable and resilient to certain usual image transformations shows that the scope of the issue with adversarial examples may be even greater than what is understood today.\n\nThe paper is rather clear. Unfortunately, it is riddled with grammatical errors and should be proof-read carefully. A lot of singular/plurals are off, and some formulations are odd or downright unclear. Some examples (there are way too many to report them all):\n\n- \"Transfer-based attackS ... since they ...*\n- \"of adversarial exampleS ...\"\n- \"from model A can transfer to model B\"\n- \"less transferable than *those from* a shallow model\"?\n- \"investigations, We \": don't capitalize\n- \"the averaging *has* a smoothing effect\"\n- \"our motivation are\"\n- \"contributed it to\"\n- \"available *to the* adversary\"\n- \"crafting adversarial perturbationS\"\n- \"directly evaluation\"\n- \"be fixed 100\"\n\nPros:\n- Transferability and robustness of adversarial examples is a very important problem\n- Interesting insights, esp. the construction and evaluation of examples that are more resilient to certain image transformations\n- Experimental results are convincing\n\nCons:\n- Contribution overall may be a bit limited\n- Grammatical errors and odd formulations all over the place",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Enhancing the Transferability of Adversarial Examples with Smoothed Gradient Attacks",
            "review": "Summary. The authors empirically investigate the influence of the architecture and the capacity of an NN-model on the transferability of adversarial examples. They also study the influence of the smoothness. From the obtained results, they propose the smoothed gradient attack showing improvements on the transferability of adversarial examples.\n\nPros.  \n* Robustness of neural nets is a challenging problem of interest for ICLR\n* The paper is well written\n* The experimental study is convincing\n* The experimental results for the smoothed gradient attacks are promising\n\nCons.\n* The results of the experimental study are somehow expected\n* the idea of smoothing gradients is not new\n\nEvaluation.\nThe experimental study of the transferability of adversarial examples is well designed. Experimental protocol is convincing. The smoothed gradient attacks improve many previously proposed attacks. Therefore, my opinion is rather positive. But, as a non expert in the field, I am not completely convinced by the novelty of the approach.\n\nSome details.\nTypos: That l8 abstract; systems l9 intro; and l2 related work; directly evaluation l2 Section4, must has l-10 p4; \n* the choice \\sigma = 15 in Section 6.2 should be justified by the following study\n* \\sigma is not given in Figure 3(a)",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}