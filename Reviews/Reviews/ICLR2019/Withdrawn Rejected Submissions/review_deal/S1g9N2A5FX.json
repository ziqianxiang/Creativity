{
    "Decision": {
        "metareview": "The presented method proposes to use saliency maps as a component for an additional metric of forgetting in continual learning, and as a tool as additional information to improve learning on new tasks. \n\nPros: \n+ R2 & R3: Clearly written and easy to follow. \n+ R3: New metric to compare saliency masks\n+ R3: Interesting idea to utilize previously learned saliency masks to augment learning new tasks. \n+ R1: Performance improvements observed.\n\nCons:\n- R1 & R2: Novelty is limited in the context of prior works in this field. Unanswered by authors.\n- R2: Concerns around method's ability to use salient but disconnected components. Unanswered by authors.\n- R2: Experiments needed on more realistic datasets, such as ImageNet. Unanswered by authors. \n- R3: Performance gains are small. \n- R1 & R2: Literature review is insufficient. \n\nReviewers are leaning reject, and R2's concerns have not been answered by the authors at all. Idea seems interesting, authors are encouraged to take into careful consideration the feedback from authors and continue their research.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Saliency maps utilized for continual learning, but concerns around novelty and performance improvements."
    },
    "Reviews": [
        {
            "title": "Interpretable Continual Learning",
            "review": "Authors propose an incremental continual learning framework which is based on saliency maps on the learned tasks(i.e., explanations) with the ultimate goal of learning new tasks, while avoiding catastrophic forgetting. To this end, authors employ an attention mechanism based on average saliency masks computed on the predictions of the earlier task. In addition, a new metric, Flexible Saliency Metric (FSM) is proposed to evaluate the generated saliency maps. Authors employ three public, well-known datasets to evaluate the performance of their proposed framework.\n\nThe paper is well written and easy to follow. The methodology is sound and the results demonstrate that the proposed framework outperforms very recent conditional learning approaches. Nevertheless I have some major concerns with the methodology, proposed evaluation metric and experiments. Please find below my comments.\n\n- Technical novelty is rather limited. Contribution is incremental with respect to previous works on CL, as they use the variational CL (VCL) framework of Nguyen at al, 2018 and the weight of evidence (WE), as used in Zintgraf et al., 2017, to compute the saliency maps. From these saliency maps, a mask is computed to focus the attention in subsequent tasks, by averaging the explanations. This, however, limits the applicability of the proposed framework to ‘similar’ images (as pointed out by the authors). Another limitation of this technique is that explanations on learned tasks should correspond, spatially, to meaningful/discriminative areas for new tasks. Otherwise, the use of explanations on this CL approach would not work.\n- According to the authors, one of the limitations of known metrics to evaluate CL approaches is that ‘the area of the saliency regions should be all connected, wasting opportunity to identify salient but possibly non-connected areas, such as the two eyes of an animal’. Nevertheless, I do not see how this can be alleviated in the proposed FSM. The first term of eq (8), i.e., log(d_sal) will be large in the case of, for example, the two eyes of an animal, favouring again for connected saliency regions. How d_sal is computed? Is it a dense matrix between all pair of points?  \n- Being the FSM one of the main contributions of this work, experiments to assess its usability are insufficient. Authors should correlate the values obtained across the different CL frameworks with FSM to the actual performance in terms of precision/accuracy. Results demonstrate that the proposed ICL approach achieves the lowest values, in terms of FSM, but any interpretation can be done if it is not correlated with well established evaluation metrics.\n- Furthermore, it would be interesting to see how this method performs in more complex datasets, such as ImageNet, where tasks within the continual learning process may differ a lot. \n- I also feel the literature on CL is scarce and it does not motivate the choices of the manuscript. Authors should include a more detailed literature on this problem. \n\nMinor comments\n\n- In page 3, which is the difference between benchmarks and medical data, as datasets? Public medical data are also benchmarks.\n- How the z value in eq (6) is found? An ablation study to see the impact on the final results would be interesting.\n- In page 5, when describing the limitations of current methods for saliency map evaluation (‘It remains tricky how to identify,….,etc),what does etc mean? Please be more concise on the limitations. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A paper with a relevant and interesting contribution that lacks clarity and motivation",
            "review": "Summary:\nIn this paper, the authors propose a framework for continual learning based on explanations for performed classifications of previously learned tasks. In this framework, an average saliency map is computed for all images in the test set of a previous task to identify image regions, which are important for that task. When learning the next task, this average saliency map is used in an attention mechanism to help learning the new task and to prevent catastrophic forgetting of previously learned tasks. Furthermore, the authors propose a new metric for the goodness of a saliency map by taking into account the number of pixels in the map, the average distance between pixels in the map, as well as the prediction probability given only the salient pixels.\nThe authors report that their approach achieves the best average classification accuracy for 3 out of 4 benchmark datasets compared to other state-of-the-art approaches.\n\nRelevance:\nThis work is relevant to researchers in the field of continual/life-long learning, since it proposes a framework, which should be possible to integrate into different approaches in this field.\n\n\nSignificance:\nThe proposed work is significant, since it explores a new direction of using learner generated, interpretable explanations of the currently learned task as help for learning new tasks. Furthermore, it proposes a new metric for the goodness of saliency maps.\n\n\nSoundness:\nIn general, the proposed approach of using the average saliency map as attention mask for learning appears to be reasonable. However, the following implicit assumptions/limitations of the approach should be made more clear:\n\t- important features for the new task should be in similar locations as important features of the old task (for example, one would expect that the proposed approach would negatively affect learning the new task if the important features of the old task were all located in the bottom of the image, while all important features for the new task are in the top)\n\t- the locations for important features should be comparatively stable (for example, one would expect the average saliency map to become fairly meaningless if important features, such as the face of a dog, can appear anywhere in the image. Therefore, an interesting baseline for the evaluation of the ICL approach would be a predefined, fixed attention map consisting of concentric circles with the image center as their center, to show that the proposed approach does more than just deemphasizing the corners of the image)\n\nFurthermore, the authors appear to imply that increased FSM values for an old task after training on a new task indicate catastrophic forgetting. While this is a reasonable assumption, it does not necessarily seem to be the case that a larger, more disconnected saliency map indicates worse classification performance. Comparatively small changes in FSM may not affect the classification performance at all, while larger changes may not necessarily lead to worse classifications either. For example, by increasing the amount or size of image regions to be considered, the classifier may accidentally become more robust on an old task. Therefore, it may be a good idea for the authors to analyze the correlation between FSM changes and accuracy changes.\n\nEvaluation:\nThe evaluation of the proposed approach on the four used datasets appears to be reasonable and well done. However, given that the achieved performance gains over the state-of-the-art are fairly small, it would be good to assess if the obtained improvements are statistically significant. \nFurthermore, it may be informative to show the saliency maps in Figure 5 not only for cases in which the learner classified the image correctly in both time steps, but also cases in which the learner classified the image correctly the first time and incorrectly the second time. Additionally, the previously mentioned evaluation steps, i.e., using a fixed attention map as baseline for the evaluation and evaluating the correlation between FSM and accuracy may be informative to illustrate the advantages of the proposed approach.\n\nClarity:\nThe paper is clearly written and easy to follow. One minor issue is that the first sentence of the third paragraph in Section 4 is not a full sentence and therefore difficult to understand.\nFurthermore, on page 6, it is stated that the surrounding square $\\hat{x}_i$ is 15 x 15 pixels, while the size of the square $x_i$ is 10 x 10. This appears strange, since it would mean that $x_i$ cannot be in the center of $\\hat{x}_i$. \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Reasonable approach with good results; incremental novelty ",
            "review": "This paper proposes an extension to the continual learning framework using existing variational continual learning (VCL) as the base method. In particular, it proposes to use the weight of evidence (WE) (from Zintgraf et al 2017) for each task. Firstly, this WE can be used to visualize the learned model (as used in Zintgraf et. al. 2017). The novelty of this paper is:\n1. to use this WE from the current task to generate a silence map (by smoothing the WE) for the next task.  This is interpreted the learned the learned attention region. Such an approach is named Interpretable COntinual Learning (ICL) \n2. The paper proposes a metric for the saliency map naming FSM which is an extension of existing metric SSR. The extension is to take pixel count to compute the area instead of using rectangular region area, as well as taking the distance between pixels into account. This metric can be used to evaluate the level of catastrophic forgetting.\n\nPro:\nIn general, the idea is very intuitive and make sense.  The paper also demonstrates superior performance with the proposed method on continual learning on all classic tasks comparing with VCL and EWC. \nThe presentation is very easy to follow. \nIt seems like a valid and flexible extension that can be used in other continual learning frameworks.\n\nCons:\nThe theoretical contribution is very limited. The work is rather incremental from current state-of-the-art methods. \nThere should be a better discussion of related work on the topic. The paper currently only mentions the most related work for the proposed method,  using the whole section 2 to describe VCL and use section 3 to describe FSM and half of section 5 to describe SSR. A general overview of related work in these directions are needed.  \n\nOther:\n1. The paper should also consider more recently proposed evaluation metrics such as discussed in https://arxiv.org/pdf/1805.09733.pdf \n2. The author should try to avoid using yellow color in plots. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}