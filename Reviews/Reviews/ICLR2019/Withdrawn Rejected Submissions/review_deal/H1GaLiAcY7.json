{
    "Decision": {
        "metareview": "AR1 finds the paper overly lengthy and ill-focused on contributions of this work. Moreover, AR1 would like to see more results for G-ZSL. AR2 finds the  paper is lacking in clarity, e.g. Eq. 9, and complete definition of the end-to-end decision pipeline is missing. AR2 points that the manuscript relies on GZSL and comparisons to it but other more recent methods could be also cited:\n- Generalized Zero-Shot Learning via Synthesized Examples by Verma et al.\n- Zero-Shot Kernel Learning by Zhang et al.\n- Model Selection for Generalized Zero-shot Learning by Zhang et al.\n- Generalized Zero-Shot Learning with Deep Calibration Network by Liu et al.\n- Multi-modal Cycle-consistent Generalized Zero-Shot Learning by Felix et al.\n- Open Set Learning with Counterfactual Images\n- Feature Generating Networks for Zero-Shot Learning\nThough, the authors are welcome to find even more relevant papers in google scholar.\n\nOverall, AC finds the paper interesting and finds the idea has some merits. Nonetheless, two reviewers maintained their scores below borderline due to numerous worries highlighted above. The authors are encouraged to work on presentation of this method and comparisons to more recent papers where possible. AC encourages the authors to re-submit their improved manuscript as, at this time, it feels this paper is not ready and cannot be accepted to ICLR.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "The idea has some merits."
    },
    "Reviews": [
        {
            "title": "a paper with a good potential but difficult to read and missing recent baselines",
            "review": "This paper deals with the difficult problem of novelty recognition which is the core issue in open set learning and generalized zero-shot learning. Indeed a method able to separate samples between known and unknown domains in these settings would clearly indicate the direction for their solution. The idea proposed here consists in starting from the extreme value theory and then using bootstrapping to model the confidence score for a sample of belonging or not to a certain class. Through a probabilistic evaluation (based on K-S test) on the trustworthy of each category classifiers, the domain separation is extended to consider also an uncertain domain and the separation threshold is progressively refined. Once the domains are separated, classification can be performed disjointly in each of them.\n\n+ Having a way to define known/unknown and uncertain samples on the basis of which one can\nthen proceed to solve OSL and GZSL sounds as a very effective strategy. Moreover, all the parts of the method are \nbased on reliable probabilistic principles.\n \n- Unfortunately the text is not easy to read. There are several repetitions and disordered lists (same numbers used multiple times or mixing names and numbers for the items) which distract the reader. As a side note, it would be better to avoid mentioning dataset names without their description and definition ('aPY' appears out of the blue in the introduction). \n\n- The experiments extends over different datasets and the ablation study is valuable. However to understand how the proposed method advances over the current state of the art it is important to consider and discuss the most recent publications  on OSL and GZSL. See for instance\nOpen Set Learning with Counterfactual Images, ECCV 2018\nFeature Generating Networks for Zero-Shot Learning, CVPR 2018\n\n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting ideas on domain separation, impressive results on GZSL, but some problems with clarity and comparative evaluation",
            "review": "This paper describes an approach to domain separation based on bootstrapping to identify similarity cutoff thresholds for known classes, followed by a Kolmogorov-Smirnoff test to refine the bootstrapped in-distribution zones. The authors apply these techniques to two general recognition problems: open-world recognition, and Generalized Zero-shot Learning (GZSL). Experimental results are given on a variety of datasets, and a thorough comparative evaluation on GZSL is performed.\n\nThe paper has the following strong points:\n\n 1. The motivations for each element of the proposed approaches are fairly well presented and are compelling.\n \n 2. The experimental results on GZSL are impressive, especially compared to established approaches.\n\nThe paper also has the following weak points:\n\n 1. The writing is a bit rough throughout, though not to extreme distraction. The abstract starts right off with the awkward \"This paper studies the problem of domain division problem...\" The manuscript needs more careful revision for clarity.\n\n 2. Related to the previous point, there are several elements of the technical exposition that are lacking in clarity. For example, it is unclear what eq. 9 is defining exactly. It seems to be the final decision rule, but it is not clear how seen, unseen, and uncertain samples are determined. Algorithm 1 is clear, but there is never a clear, complete definition of the end-to-end decision pipeline given. I feel like it would be difficult to reproduce the results of this article without significant trial-and-error.\n\n 3. The authors seems to have relied on the Xian et al. paper to extract data for their comparative evaluation on GZSL. There are more recent works from 2018 that should be included, such as:\n\n Arora, Gundeep, Vinay Kumar Verma, Ashish Mishra and Piyush Rai. â€œGeneralized Zero-Shot Learning via Synthesized Examples.\" CVPR 2018.\n\nIn summary, this paper has many interesting ideas, and the GZSL results are indeed impressive (with respect to the results in the comparison). However, there are many problems with clarity and missing, recent work in the comparative evaluation.\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Good but lengthty paper; approach seems solid and results are generally convincing but could show more comparisons and examples",
            "review": "This paper proposes to introduce a new domain, the uncertain domain, to better handle the division between seen/unseen domains in open-set and generalized zero-shot learning. The approach handles test samples estimated to be from the seen class in one way, and ones that belong to either the unseen or uncertain domain in another way. This idea handles the problem that test instances may incorrectly be attributed to one of the seen classes. The authors evaluate their approach on several relevant datasets against a wide variety of methods for OSL and ZSL, and show convincing results. \n\nI have three concerns. One is that the method sections of the paper are fairly lengthy, including an extensive explanation of prior work, e.g. EVT, so time is spent reading before the reader gets to the interesting part of the proposed method, and this time could be better focused around the contributions of *this* work. \n\nFor the G-ZSL experiments, most of the methods seem to be older methods tackling ZSL not G-ZSL so perhaps more relevant baselines could be found.\n\nOn a related note, it would be good to include some qualitative examples that might reveal some intuitive reasons for the large margin between the performance of the proposed work, and other approaches; in some cases this margin seems rather large, and while the authors attempt to explain it, something beyond a textual explanation might be useful. ",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}