{
    "Decision": {
        "metareview": "Pros:\n\n- The paper is well written\n\nCons:\n\n- Not very novel\n\n- Evaluation only on sentiment classification, whereas approaches applicable in broader context exists\n\n\n- There are question re baselines (R3)\n\nNeither reviewer was particularly enthusiastic about the paper, I believe, mostly because of the limited score and novelty. \n ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "A reasonable but not very novel approach to semi-supervised sentiment classification"
    },
    "Reviews": [
        {
            "title": "Nice Application of Variational Bayes semi-supervised learning",
            "review": "This paper jointly trains a sentiment classifier with a sentiment and domain-aware embedding\nmodel, using both labeled and unlabeled data. When sentiment label is observed, this model is trained\nwith the usual cross entropy and maximum likelihood objectives; for unlabeled data, it uses pseudo\nlabels produced by the sentiment classifier with variational Bayes objective. This idea is not novel but the authors report that there is no previous work that jointly trains sentiment aware embeddings with a sentiment classifier specifically, and makes use of an unlabeled corpus to improve both. However, there are general and broader methods such as 'Toward Controlled Generation of Text' by Hu et al that apply semi-supervised techniques for generation (not classification) with specific constraints (sentiment, domain, etc). There are other recent methods such as 'Improving Language Understanding by Generative Pre-Training' by Redford et al that use the idea of generative pre-training with discriminative fine-tuning that are task-agnostic and achieve very good performance - how does the paper compare to this approach? \nThe experiments and analysis is very well written in the paper. Table 4 also shows very interesting, somewhat surprising results in the paper. The authors say that they will release the code and data for this technique which will be useful for the sentiment analysis research community.  \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting approach and well conducted evaluation; some details missing and limited applicability",
            "review": "The authors propose a semi-supervised learning techhnique involving jointly tuning word embeddings and a classifier. The idea is to rapidly adapt models to new domains with minimal (actually, zero) supervision by exploiting such embeddings.\n\nIn effect, this is an approach to \"disentangling\" sentiment from domain, via a variational objective and semi-supervision via the embedding parameters. This is a nice idea as disentanglement enables transfer (or should). The experiments are well-executed (albeit on a limited set of classification tasks). Still the comparisons are relatively exhaustive, and the authors have done a nice job of providing ablations. I found Table 4 and Figure 2 particularly nice. \n\n- The authors should speak to the generalizability of this approach beyond sentiment tasks, as presently it seems largely constrained to this domain. This would of course hinder the potential utility/impact of the work.\n\n- Due to the very concise description of baselines, it was not obvious to me if these were also taking a semi-supervised approach? I *think* the pivot-based model is. But then how was CNN+ELMo trained exactly? With zero target sentiment labels, I presume? If so, an obvious baseline would be to \"pseudo-label\" instances in the target domain first, and then use these predictions as a target to fine-tune the CNN (or whatever), back-propping through to the embeddings. Was this done? In general more details on the baselines and training setups should be included, even if only in the Appendix.\n\n- The strategy, I think, is to learn a prediction model p_\\phi(y|z, D) where \\phi are model parameters. Then this is applied to instances in the target dataset to infer latent z, and then use these inferred labels to fine-tune word embeddings. Specifically, sentiment label information is pushed into embeddings via a modified CBOW objective that effectively shifts the meaning (as codified in the distributed representation) via task specific sentiment. One thing here that confused me is that this would seem to perform this affine transformation to all words, but only certain of these will exhibit domain specific variation with respect to sentiment. Can the authors speak to this? \n\n- I found Eq 7 counterintuitive, since it treats sentiment and domain independently, but the authors explicitly noted above that this is not the case, i.e., words will depend jointly on sentiment + domain. I actually think p(w_i|y) also depends on the domain via M (implicitly), but perhaps this should be made explicit (or perhaps I am misunderstanding something!)\n\n- In 2.1, the authors assume a prior p(z|c) and then say that `'naively' marginalizing over this performs poorly. But I not think the particular prior distribution used was not discussed here. Could they elaborate? \n\n- I think i indices are needed on the w's in Eq 6?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Review #3",
            "review": "This paper proposes to jointly train a classifier with a domain and label-aware word embedding model and a variational Bayes model for sentiment domain adaptation. The model is evaluated on a standard multi-domain sentiment analysis dataset where it achieves convincing results against strong baselines. Extensive ablations are conducted.\n\nPros:\n- The paper is clearly written. I particularly appreciated Figure 1 as it might otherwise be difficult to see the relation of the different components of the model.\n- The model achieves convincing results and ablations and analyses are extensive.\n\nCons:\n- None of the presented ideas are entirely novel. The model rather combines many existing ideas successfully.\n- The framework consisting of many components (particularly the joint training with CBOW as indicated in the appendix) seems rather brittle and very task-specific. I am concerned if this framework will be able to work on other tasks. I would love to see an evaluation on another dataset. \n- The joint variational Bayes approach seems to be the most interesting aspect of the paper. Despite the ablations, it's not entirely clear to me, though, how useful this component is and if it can be applied beyond this particular model. I would like to see one of the baselines models or another model augmented with this component. \n\nQuestions:\n- Do you alternate updates between each of the components or use a more sophisticated multi-task learning strategy when training the word embedding model and the other components jointly? Did you try fine-tuning the trained word embeddings with the classifier?\n- Why do you use this particular affine transformation for learning sentiment-specific word embeddings? Did you try, for instance, an MLP as used in [1]?\n- You say that you use a classifier q_φ(z |D, c) in order to benefit from more freedom of design for Bayesian inference. Could you elaborate why you use this classifier in addition to the label classifier q_φ(y |D, c)? In Table 6, it seems that it doesn't help much. The use of the term \"classifier\" is confusing at times, as it seems to be both used to refer to the latent variable and the label classifier.\n\n[1] Tang, D., Wei, F., Yang, N., Zhou, M., Liu, T., & Qin, B. (2014). Learning Sentiment-Specific Word Embedding. Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, 1, 1555–1565.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}