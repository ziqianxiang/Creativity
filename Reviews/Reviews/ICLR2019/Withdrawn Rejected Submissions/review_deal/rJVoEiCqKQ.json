{
    "Decision": {
        "metareview": "Strengths:\nThe method extends [21], which proposes an unordered set prediction model for multi-class classification.\nThe submission proposes a formulation to learn the distribution over unobservable permutation variables based on deep networks and uses a MAP  estimator for inference.\nWhile the failure of NMS to detect overlapping objects is expected, the experiments showing that perm-set prediction handles them well is interesting and promising. \n\nWeaknesses:\n\nReviewer 1: \"I find the paper still too scattered, trying to solve diverse problems with a hammer without properly motivating / analyzing key details of this hammer. So I keep my rating.\"\nReviewer 2: \"I'm glad that the authors are seeing good performance and seem to have an effective method for matching outputs to fixed predictions, however the quality of the paper is too poor for publication.\"\n\nPoints of contention:\n\n Although there was one reviewer who gave a high rating, they were not responsive in the rebuttal phase.  The other two reviewers took into account the author responses, and a contributed comment by an unaffiliated reviewer, and both concluded that the paper still had serious issues.  The main issues were: lack of clear methodology and poor clarity (AnonReviewer2), and poor organization and lack of motivation for modeling choices (AnonReviewer1).",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Area chair recommendation"
    },
    "Reviews": [
        {
            "title": "novel, potentially significant & with limitation on large-scale problem",
            "review": "\nThe paper is really interesting. Set prediction problem has lots of applications in AI applications and the problem has not been conquered by deep networks. \n\nThe paper proposes a formulation to learn the distribution over unobservable permutation variables based on deep networks and uses a MAP  estimator for inference.  It has object detection applications. The results show that it can outperform YOLOv2 and Faster R-CNN in a small pedestrian detection dataset which contains heavy occlusions. \n\nThe limitation is clearly stated in the last part of the paper that the number of possible permutations exponentially grows with the maximum set size (cardinality). \n\nIn the author response period, I would like the author give more details about the pedestrian detection experiments, such as how many dense layers are used after ResNet-101, what are the training and inference time, is it possible to report results on PASCAL VOC (only the person class).\n\nThe method is exciting for object detection funs.  I would like to encourage the authors to release the code and let the whole object detection community overcome the limitation in the paper. \n\n\n\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting results on object detection for overlapping objects and CAPTCHA toy problem, but key details seem unclear",
            "review": "— Summary\nThe method extends [21], which proposes an unordered set prediction model for multi-class classification. For that problem, [21] can assume logistic outputs for all distinct classes. This work extends set prediction to the object detection task, where box identity is not distinct — this is handled by an additional model output that reasons about the most likely object permutations. The permutation predictions are used during training, but are not needed at inference time — as shown in Fig1 and Eq 7. Results are on detection of overlapping objects and a CAPTCHA toy summation example.\n\n— Clarity \nThe exposition is not particularly clear in several places: \n - U^m in Eq 1 is undefined and un-discussed. What probability term does it correspond to? It is supposed to make probabilities of different cardinalities comparable, but the exact mechanism is unclear. \n - The term p(w) disappears on the left hand side of Eq 2. \n - Notation in Sec. 3.2 is very cumbersome, making it hard to follow. Furthermore, I found the description ambiguous, preventing me from understanding how exactly the permutation head output is used in Eq 5. Specifically, there is some confusion about estimation of w~, which seems based on frequency estimation from past SGD iterations (Eq 3). If so, why does term f2 in Eq 5 contain the permutation head output O2 and how do the two relate? \n - The network architecture is never described, especially the transition from Conv to Dense and the layer sizes, making the work hard to reproduce. The dimensions of the convolutional feature map matter (probably need to be kept tractable). \n\n— Significance\nKey aspects of the model are not particularly clear, specifically about how the permutation prediction ( the key novelty here) is used to benefit training. \n— Term f2 in Eq5 uses w~ estimates, which appeared to be based on statistics from past SGD runs, yet also depends on the output of the permutation head O2. Am I misinterpreting the method?\n— In the paragraph right after Eq5, it’s claimed that “Empirically, in our applications, we found out that estimation of the permutations from just f1 [in Eq5] is sufficient to train properly … by using the Hungarian algorithm”. So then f2 term is not even used in. Eq5? If so, what is the significance of the permutation head other than adding an auxiliary loss? \n\nFurthermore, there are no experimental results demonstrating the effect of the permutation head and the design choices above — if we could get by with only using the Hungarian algorithm, why bother classifying an exponential number of permutations? Do they help when added as an auxiliary loss?  \n\nWhile the failure of NMS to detect overlapping objects is expected, the experiments showing that perm-set prediction handles them well is interesting and promising. Solving the general case with larger images and many instances would increase the impact significantly — and likely require a combination of perm-set prediction and image tiling, although this is just a hypothesis. The Captcha toy example also shows some interesting behavior emerging — without digit-specific annotations (otherwise it would be multi-class classification setup from [21]), the model can handle the majority of summations correctly. \n\n— Experimental results\nThe results are interesting proofs-of-concept but a few more experiments/answers would be helpful:\n- It still appears that PR curve in the high-precision regime (fig 3b) has lower precision than FRCNN/YOLO. Any idea as to why? \n- Ablation results on the effect of the permutation predictions vs Hungarian algorithm, etc would be helpful, as discussed above. \n- How sensitive is the method to seeing a certain cardinality? What if it never sees 3 pedestrians in an image, but only 1,2,4 will it fail to predict 3? Or alternatively, if we train a model that can handle up to 5-6 entities with examples than have <=4? What is the right way of data augmentation for this model (was there any and should there be?)\n- Given that values for U differ across applications, how sensitive is the output / how much sweeping did you have to do? \n\n-- Related work\nTo the best of my knowledge it's representative. It would help to cite more recent work that decreases detector dependence on NMS. For example, \"Learning Non-Maximum Suppression\", Hosang, Benenson, Schiele, CVPR 2017 or \"Relation Networks for Object Detection\", by Hu et al, CVPR 2018 and references therein. ",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Lacks clarity of methodology.",
            "review": "This paper looks to predict \"unstructured\" set output data. It extends Rezatofighi et al 2018 by modeling a latent permutation.\n\nUnfortunately, there is a bit of an identity crisis happening in this paper. There are several choices that do not follow based on the data the paper considers. \n1) The paper claims to want to predict unordered sets, yet the model is clearly indicating a dependence in the order of the outputs and the input p_m(\\pi | x_i, w) (1); this feels like a very odd choice to me. The outputs are either unordered sets, where you would have a permutation invariant (or exchangeable) likelihood, or they are ordered sequence where the order of the outputs does matter, as some are more likely than others.\n2) The paper still makes very odd choices even if one ignores the above and wants to model some orderings as more likely than others. The way the permutation, or the order of the data, accounts in the likelihood (2) does not make sense. Conditioned on the permutation of the set, the points are exchangeable. Let's just consider a 2 element \"set\" at the moment Y = (y_1, y_2). Order matters, so either this is being observed as pi=(1, 2) or pi=(2, 1), both of which depend on the input x. However, the likelihood of the points does not actually depend on the order in any traditional sense of the word. we have:\np_\\pi((1, 2) | x, w) p_y(y_1 |  x, w, (1, 2)) p_y(y_2 |  x, w, (1, 2)) + p_\\pi((2, 1) | x, w) p_y(y_1 |  x, w, (2, 1)) p_y(y_2 |  x, w, (2, 1))\n*Note that in here (as in eq. 2) the output distribution p_y does not know what the index is of what it is outputting, since it is iid.* So what does this mean? It means that the order (permutation) can only affect the distribution in an iid (exchangeable, order invariant) way. Essentially the paper has just written a mixture model for the output points where there are as many components as permutations. I don't think this makes much sense, and if it was an intentional choice, the paper did a poor job of indicating it.\n3) Supposing even still that one does want a mixture model with as many components as permutations, there are still some issues. It is very unclear how the dependence on \\pi drops out when getting a MAP estimate of outputs in section 3.3. This needs to be justified.\n\nThere are some stylistic shortcomings as well. For example, the related works paper would read better if it wasn't one long block (i.e. break it into several paragraphs). Also, the paper claims that it will use a super script m to denote a known cardinality, yet omits \\mathcal{Y}_i^{m_i} in the training set of the first sentence in 3.1. But these and other points are minor.\n\nThe paper should not be published until it can resolve or make sense of the methodological discrepancies between what it says it looks to do and what it actually does as described in points 1), 2), and 3) above.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}