{
    "Decision": {
        "metareview": "The paper proposes GAN regularized by Determinantal Point Process to learn diverse data samples.\n\nThe reviewers and AC commonly note the critical limitation of novelty of this paper.  The authors pointed out\n\n\"To the best of our knowledge, we are the first to introduce modeling data diversity using a Point process kernel that we embed within a generative model. \"\n\nAC does not think this is convincing enough to meet the high standard of ICLR.\n\nAC decided the paper might not be ready to publish in the current form.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Limited novelty"
    },
    "Reviews": [
        {
            "title": "The authors’ motivation from DPP is arguable",
            "review": "This paper proposes generative adversarial networks regularized by Determinantal Point Process (DPP) to learn diverse data space. DPP is a probabilistic model that encourages the diversity between the dataset. Authors observe that previous generative models have a mode-collapse problem, and they add generative DPP (GDPP) loss (eq (5)) as a diversity regularizer. Experiments show the GDPP loss is practically helpful to learn under synthetic multi-modal data and real-world image generation.\n\nThe paper is well written and easy to comprehend the motivations and main contributions. And the experimental results seem to be interesting. However, there are some arguable issues:\n\n- The main contribution is adding GDPP loss to the original generative models. The authors claim that the GDPP loss (eq (5)) is motivated by the DPP, but I think it does not utilize DPP characteristics at all. The proposed loss is rather close to eigenvalues/vectors matching rather than DPP. It does not seem to be capture DPP properties even assuming the training is perfect. In particular, DPP measures the similarity as the volume of spanned space, while the GDPP loss uses the cosine similarity.\n\n- The GDPP loss is a function of eigenvalues/vectors of kernels, which is generated by internal features of the discriminator. I am curious how to compute the eigenvalues/vectors. Also, the gradient of functions of eigenvalues/vectors is not straightforward as it takes at least a cubic time-complexity with a dimension. It is better to clarify the time complexity for computing the loss and its gradients.\n\n- In addition, if the feature kernel is not a full rank, it is deficient, i.e., some eigenvalues can be zeros. Do you compute the loss all eigenvalues? or compute only some eigenvectors?\n\n- In section 5, the analysis of time-efficiency is not sufficient. Authors report the performance varying the number of iterations. However, since the loss computes eigenvectors/values, the cost per iteration should be larger than other competitors. It is natural to compare the elapsed time or number of FLOPS.\n\n- Although the proposed method shows the best results for the experiments, it is desirable to compare to more diversity encouraging generative models, e.g., DeLiGAN [1]. In addition, I could not recognize the effectiveness of proposals in the experiments of image dataset.\n\nIn overall, I think the proposed idea is interesting, but the authors’ motivation from DPP is arguable. In addition, I do not find enough novelty.\n\nMinor issues:\n- What is cos(v,w)? Please specify the definition of this.\n- Where is Fig. 2k ? Please add the sub-index in Figure 2.\n\n[1] Gurumurthy, Swaminathan, Ravi Kiran Sarvadevabhatla, and R. Venkatesh Babu. “DeLiGAN: Generative Adversarial Networks for Diverse and Limited Data.” CVPR. 2017",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The connection between the propsoed regularizer and the DPP is not precise.",
            "review": "For training GANs, the authors propose a regularizer that is inspired by DPP, which encourage diversity. This new regularizer is tested on several benchmark datasets and compared against other mode-collapse mitigating approaches. \n\n   \nIn section 2, important references to recent techniques to mitigate mode collapse are missing, e.g.\nBourGAN (https://arxiv.org/abs/1805.07674)\nPacGAN (https://arxiv.org/abs/1712.04086)\nD2GAN (https://arxiv.org/abs/1709.03831)\n\nAlso related is evaluation of mode collapse as in \nOn GANs and GMMs (https://arxiv.org/abs/1805.12462) \n\nThe actual loss that is proposed as in (5) and (6), seems far from the motivation that is explained as in Eq (3), using generator as a point process that resembles DPP. This conceptual gap makes the proposed explanation w.r.t DPP unsatisfactory. A more natural approach would be simply add $det(L_{S_B})$ itself as a regularizer. Extensive experimental comparisons with this straightforward regularizer is in order. \n\nIt is not immediate if the proposed diversity regularizer $L_g^{DPP}$ in (5) is differentiable in general, as it involves computing the eigen-vectors. Elaborate on the implementation of the gradient update with respect to this new regularizer. \n \n\nExperiments: \n\n1. The results in Table 3 for stacked-MNIST are very different from VEEGAN paper. Explain why a different setting was used compared to VEEGAN experiments. \n\n2. Similar experiments have been done in Unrolled-GAN paper. Add the experiment from that setting also. \n\n3. In general, split the experiments to two parts: one where the same setting is used as in the literature (e.g. VEEGAN, Unrolled GAN) and the results are compared against those reported in those papers. Another where new settings are studied, and the experiments of the baseline methods are also run by the authors. This is critical to differentiate such cases, as hyper parameters of competing algorithms could have not been tuned as rigorously as the proposed method. This improves the credibility of the experimental results, eventually leading to reproducibility. \n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "This paper integrates DPP with GAN and promotes diversity in learning generator distribution",
            "review": "The paper proposes to introduce DPP into the vanilla GAN loss and uses it as a way to regularize the generator to produce more diverse outputs, in order to combat the mode-collapse problem. Since the proposed method is added as a simple loss regularizer, the approach does not introduce additional parameters, therefore, less training difficulties. The results on synthetic data seems promising, but there is insufficient evaluation being performed on real and larger dataset where the mode collapse problems are more likely to happen.\n\n- Method\nThe proposed methods seem sensible. But there are some critical details missing from the current text that prevents me from assessing this paper clearly. \n\n* How are the \\lambda and v in Eq.6 calculated? It seems to me that you need to estimate the eigenvalues and eigenvectors at every iteration of your training. I am aware of that many DPP-based models suffer from scalability issues. Could you discuss the potential overhead of this procedure? Also in experiments, you claim \"DPP-GAN is cost-free, we observe that the training of GDPP-GAN has an indistinguishable running time than the DCGAN, which are the fastest models to finish training“, which is hard to believe.. could you give more details and analysis on the overhead here?\n\n* In Eq.6 why there are both  \"a diversity magnitude loss L_m\", and \"diversity structure loss L_s\". What do they specifically try to capture respectively? Could you give a geometric interpretation on this part?\n\n* what is the batch size used in your experiments on MNIST and CIFAR-10. It seems to me that the effectiveness of GDPP would rely on batch size used as per my understanding you will estimate the DPP kernel using the current batch of samples (generated or real)? \n\n* Despite the fact that GDPP wants to reduce parameters introduced, it is not very intuitive to understand how it would work to use the features outputted by D as the DPP features as well. As D, as the discriminator itself, is trained to distinguish real from fake, while mimicking the eigenvalues/vectors of real data. How would these two goals be reconciled by the same set of parameters?\n\n- Experiments\nThe results on the synthetic data seem promising, but the results on MNIST and CIFAR-10 are not impressive enough:\n* The visual quality of Figure.9 does not look very appealing. I believe many simple variants DCGAN can produce better quality of images\n* Why your DCGAN baseline on CIFAR-10 only reports inception score around 5 (with high variance, see Figure.5 and Table 3)? I believe vanilla DCGANs can easily attain an IS at 5.5 to 6, as reported in most recent GAN literature.\n* More visual results on CIFAR10 should have been presented in order to demonstrate DPP does generate images with as many classes as existed in CIFAR-10 (which is 10)\n* The results could be much more convincing if the authors could show the generation results and evaluation metrics on larger/more real datasets other than CIFAR-10 and MNIST. See GAN literature in 2018 about what dataset to use.\n\n\n- Presentation\nMost parts of this paper are well written. There are few typos and grammatical errors across the text which I believe are easily fixable. There are some missing details that hinder the understanding of some technical parts of the paper. See above for detailed comments.\n\n- Other\nPromoting diversity in (deep) generative models isn't a new topic. It would be good if the authors could established connections/differences between this work and this line of relevant  works. \n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}