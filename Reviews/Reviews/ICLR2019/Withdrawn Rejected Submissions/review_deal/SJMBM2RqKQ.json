{
    "Decision": {
        "metareview": "Reviewers are in a consensus and recommended to reject. However, the reviewers did not engage at all with the authors, and did not acknowledge whether their concerns have been answered. I therefore lean to reject, and would recommend the authors to resubmit. Please take reviewers' comments into consideration to improve your submission should you decide to resubmit.\n\n",
        "confidence": "2: The area chair is not sure",
        "recommendation": "Reject",
        "title": "Paper decision"
    },
    "Reviews": [
        {
            "title": "Good motivation, minor contributions in term of algorithms",
            "review": "Motivated from leveraging the uncertainty information in Bayesian learning, the authors propose two algorithms to prevent forgetting: Pruning and Regularization. Experiments on several sequential learning tasks show the improved performance.\n\nQuality:  The description on the related work is comprehensive. The proposed algorithms seem easy to follow. \n \nClarity: Low \n\nThe contributions in terms of algorithms are clearly presented. However, the writing can be largely improved.\n\n(1) Some claims are improper:  I don't think it's accurate to say that most of lifelong learning is non-Bayesian (In introduction), and EWC is derived from a Bayesian perspective, and Variational Conditional Learning is a very Bayesian approach.\n\n(2) Please proofread the submission: \nTypos: e.g.,  \"Beysian\", \"citestochastic methods\";  \nStyle: x is not bold occasionally, but has the meaning given the context. \n\nOriginality: It seems to be the first work that leverages the variance in Bayesian Neural Nets (BNN) to prevent forgetting. My understanding that EWC also consider the variance, but in a different way. \n\nSignificance: \nIt is good to consider variance/uncertainty for lifelong learning, and should be encouraged.\nHowever, the comparison to the representative algorithms or state-of-the-art is missing in this submission. For example, EWC/IS, or method in [*].  Is it possible to run the experiments on more standard datasets, such as [*].\n\n[*] Overcoming Catastrophic Forgetting with Hard Attention to the Task, ICML 2018\n\n\nQuestions:\n1. In (6), there are three terms on the right side, it seems the 2nd term include the 3rd term, why do we need to add the 3rd term again?\n\n2. \"Once a task is learned, an associated binary mask is saved which will be used at inference to recover key parameters to the desired task. The overhead memory caused by saving the binary mask (less than 20MB for ResNet18), is negligible given the fact it completely eliminates the forgetting\"\n\nTo me, saving a binary mask means saving \"partial\" model. First, this is additional parameter saving. Second, in the inference stage, one can recover the corresponding best model using the mask, how close is it to cheating? (Perhaps I am not an expert in lifelong learning). \nCan you put the model size of ResNet18, so that the readers can understand 20MB is small/negligible compared to the full model. \n\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "The paper addresses the problem of lifelong learning of neural networks - a setting where learning is performed on a continuously arriving new tasks without having access to previously encountered data.\nAuthors propose a method that prevents catastrophic forgetting typical for naive application of stochastic gradient descent by preventing supposedly important weights to change (in either soft of hard manner), where the weight importance is assessed by its signal to noise ratio estimated from the corresponding (approximate) posterior distribution.\nAuthors evaluate their approach on a set of image classification datasets and find it superior to the PackNet baseline as well as few simpler ones.\n\nThe idea of using uncertainty estimates obtained from Bayesian training to adjust weight updates is natural and potentially very promising. \nHowever, to me this paper does not seem to investigate the idea sufficiently deep.\n\nThe weight pruning or hard masking variant of the method depends on a very important hyperparameter p (size of the mask) which is unclear how to set beforehand. \n\nI also struggle with understanding the weight regularisation or soft masking variant. \nAuthors seem to get their inspiration in the idea of assumed density filtering, where the posterior for 1:T-1 is approximated and used a prior for task T (last sentence on page 5).\nAt the same time, in Algorithm 2, line 6 the prior is defined as the standard BBB mixture prior and not the approximate posterior from the previous task.\nQuite oddly, parameters of the _approximate posterior_ are being quadratically regularalized to not deviate from parameters of the _approximate posterior_ from the previous task. \nThis deviates from the original idea and requires additional justification.\nBesides that, I find the way this regularisation is applied potentially problematic for the variance parameter (last term in eq. 6).\nHere authors apply the regularisation to the parameter of the softplus transformation they use, but scale it with the inverse std deviation which is the “classical” parametrisation. The choice of parametrisation was not discussed, however, clearly different parametrizations may lead to very different results. \n\nOn the experimental side, I have two major issues:\n1. The datasets considered are very small, authors could consider using ImageNet, especially given that they already work with 224x224 images.\n2. The only prior work used as a baseline is PackNet, while there is no reason why other established methods such as EWC are not applicable.\n\nMinor comments:\nThe middle expression in eq. 5 seems to miss the -log p(D_T | D_{1:T-1}) term which does not change the latter expression (since it does not depend on parameters theta).\nPage 3: “citestochastic methods”, a citation seems to be missing.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Nice combination of ideas, but requires more development.",
            "review": "In this paper, a framework for lifelong learning based on Bayesian neural network is proposed. The key idea is to combine iterative pruning for multi-task learning along with the weight regularization. The idea of iterative pruning was first considered by Mallya et al., 2018 and weight regularization was considered for Bayesian neural network by Nguyen et al., 2018.\n\nPros: \n- Combination of two idea seems novel. I like the idea of considering the weight parameter as the \"global\" random variables and the mask parameters as the task-specific random variables. \n\nCons: \n- In general, there is lack of explanation/justification on the combination of two ideas. Especially, there is lack of explanation on how to apply the whole algorithm (e.g., text states that complete algorithm is in Algorithm 3., but there is no Algorithm 3. in the paper). \n\n- I do not understand how equation (6) is developed, and why hyper-parameters are need for \"regularization of weights\", comparing with the Variational Continual Learning (VCL, Nguyen et al., 2018). More explanation seems necessary for justification of the algorithm.\n\n- More stronger baselines need to be considered for the experiments. Why is there no comparison with the existing continual learning algorithms? At the very least, comparison with the VCL or Elastic Weight Consolidation (EWC, Kirkpatrick et al., 2017) seems necessary since one of the key idea is about regularization for weights.\n\n\nIn general, I think it is a nice idea to combine two existing approaches. However, the algorithm lacks justification in general and experimental results are not very persuasive.   ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}