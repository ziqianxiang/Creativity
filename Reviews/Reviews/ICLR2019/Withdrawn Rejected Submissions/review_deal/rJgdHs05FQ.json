{
    "Decision": "",
    "Reviews": [
        {
            "title": "Nothing particularly new",
            "review": "First the paper is poorly written. The abstract contains the glaring typo \"optical convergence\", presumably meant to be \"optimal convergence\" and the last two paragraphs of page 2 are near identical repeats. Besides these egregious errors that could easily be fixed with better proofreading, the text and mathematics are difficult to follow and not precise. For example, in Equation (1), i and j appear both as subscripts and feature map indices.\n\nSecond, the approach is not particularly well motivated nor analysed. Why for example use cosine and sine functions? Is this some connection to Fourier domain analysis? Moreover, since neural networks can approximate other functions, is there an equivalent (possibly slower and deeper) multi-layer perceptron equivalent to the proposed aggregation functions?\n\nLast, the experimental results are not very compelling with state-of-the-art on HMBD51 now around 72% and UCF101 now around 95% (Feichtenhofer et al., 2017). The faster convergence time (demonstrated as more rapid decrease in loss as a function of training iteration) is also underwhelming.\n\nAll up more work needs to be done in the paper for it to make a valuable contribution.",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Poor presentation and weak technical contents.",
            "review": "Summary: \nThis paper presents a non-linear channel-aggregation layer (NCAL) for deep neural networks.\nTo globally aggregate channel features, NCAL first projects the feature map along the channel dimension into the new feature space of the same channel dimensionality by means of trigonometric functions like discrete cosine transform (DCT).\nSo-transformed feature map is multiplied with the original one in a point-wise manner (Hadamard Product), and then passed to the next layer in the neural network.\nThe experimental results on action classification using UCF101 and HMDB51 show that the NCAL slightly boosts the performance.\n\n\nComments:\nThe reviewer regards this paper falls below the border due to the following negatives.\n\n1. Poor presentation\n- This paper is written in poor English, containing considerable amount of grammatical errors. The reviewer strongly recommends the authors to proof-read the manuscript before submission.\n\n- As to mathematical presentation, the notations are conflicted and/or confusing; especially, in Eq.(1), the notations of i and j are conflicted and thus it is difficult to understand its mathematical meaning at first glance, though it actually shows a simple \"3D\" conv. And, some functions that compose the method, such as G and H, are not clearly defined throughout the paper.\n\n- The term of \"hand-crafted rule\" is found several times in this paper, but it is unclear since the authors do not give any definition nor examples for the term. What does it actually mean?\n\n- It is trivial to show Fig.5 which merely explains trigonometric functions.\n\n2. Technical content\n- First of all, the reviewer guesses that the authors might misunderstand the \"3D\" operations, such as 3D-conv and 3D-pool. In the literature of action recognition, the 3D operations generally work in the spatio-temporal domain (X-Y-T = \"3\"D); thus, the 3D pooling aggregates features across X-Y-T space and the 3D conv filters are usually applied to the whole feature channels, except for grouped conv. This misunderstanding would be a critical flaw of this work, leading to the incorrect comparison described below.\n\n- It is unclear why the global channel aggregation (3) is necessary; the theoretical reason/motivation is not found in this manuscript. In ConvNet, feature channels encode different characteristics and thus it makes less sense to aggregate those heterogeneous information; note that the 3D-pooling aggregates them along X-Y-T, NOT along channel. And, why do the authors employ trigonometric functions in (3)? Such a transformation is closely related to DCT that maps a feature \"sequence\" into \"frequency\" domain. From this perspective, the reviewer has two concerns about the forms (3,4).\n First, extracting frequency characteristics along channel dimension via (3) would be less effective. The frequency information is valuable only for the signals that are sequenced in structured order such as on temporal and/or spatial domain. The CNN feature channels, however, do not exhibit such structural order since we can arbitrarily swap the feature channels by manipulating the filter weights.\n Second, it is not clearly discussed what kind of physical characteristics are extracted through the multiplication of the original feature and the frequency feature in (4). The reviewer does not understand how useful so-combined features are for classification.\n As to the second issue, the multiplication (Hadamard Product) can also be seen in the literature of bilinear model [a]. In that framework, the multiplication form is naturally derived from the low-rank approximation of bilinear weights through introducing trainable weights in contrast to this work that employs the fixed weights (W^1 and W^2).\n\n- The temporal information of the feature vector sequence {V_k} is not considered in this work, though the objective of this paper is \"action\" recognition as the title says. The channel aggregation along the temporal axis is discussed with thorough experiments in [b].\n\n[a] Jin-Hwa Kim, Kyoung Woon On, Woosang Lim, Jeonghee Kim, Jung-Woo Ha, and Byoung-Tak Zhang. \"Hadamard Product for Low-rank Bilinear Pooling\". In ICLR2017.\n[b] Carreira, J., & Zisserman, A. \"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\". In CVPR2017.\n\n3. Performance\n- The performance improvement is quite limited, compared to the standard CNN. To convince the readers of the improvement by the method, the authors have to show the statistical significance such as by reporting the standard deviation of test accuracies over three splits in those datasets. And, as mentioned above, the method of \"3D convolution\" would be wrongly implemented.\n\n- Although the authors state many times that the method makes convergence in training faster, the charts in Fig.3~4 do not support the authors' claim; from those charts, all the methods are converged around 300 iterations. Note that the convergence point can be found when the training loss does not decrease any more, and the training loss value itself is not a proper measure for comparing the performance of the models; we can easily reduce training loss by employing the more complex models, though they poorly work on test samples due to overfitting.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Non linear 'channel aggregation' to improve on 3D convs and various 3D pooling methods. Badly written paper with low novelty and limited and unconvincing empirical evaluation.",
            "review": "Summary\nThe paper proposes a method for channel aggregation in CNNs for the task of human action \nrecognition. The main component proposed is the nonlinear channel aggregation layer (NCAL) which can \nbe potentially inserted in any CNN architecture. Empirical results are reported on UCF101 and \nHMDB51.\n\nGeneral comments:\nThe paper is not very well written and it's hard to fully understand it. From the related works \nsection I deduce that the method proposed competes with 3D convs and 3D pooling methods in some way. \nWith this assumption my specific points are as follows.\n                                              \n                                       \nPositive                        \n- The general direction is somewhat interesting, i.e. the current methods methods do a linear \n  computation over the channels at any intermediate step of the CNN architecture, this paper aims to\n  explore more complex nonlinear computations. \n  \n  \nNegatives:\n- The paper is badly written with many hard to appreciate parts e.g.\n\n\"We conjecture that there is complex nonlinear relationship among the channels of CNN features. Once\nthis implicit relationship is explicitly modeled, such accomplishment will facilitate converging\nwith faster search to the optimal trajectory.\"\nWhat exactly do you mean by the implicit relationship? How would you get ideas to explicitly model \nit?                                                                                         \n\n\"these temporal pooling and variants tend to result in the reduced resolution, which will achieve\ncoarse classifications\"                 \nIn what sense reduced resolution, eventually everything has to be reduced to a #classes size vector \ngiving the probability of the classes. How would you fix this?\n\n- The main equation (3) is not understandable, G is said to be the \"linear kernel functions of \n  NCAL\", what is that? and what does G(cp) mean, what is p?\n\n- The positioning of the paper is also not very clearly defined, sometimes it argues as being an \n  improvement of 3D pooling, while at others it seems to try and improve frame aggregation\n  for video representation. This should also be clearly clarified and discussed.\n\n- The exprimental results are also not very convincing, on UCF101 compared to the baseline accuracy \n  of 79.5 the best NCAL version gets 80 (and this is not the cross-validated value) while on HMDB51 \n  it gets 50 cf. std CNN's 49.7\n\n\nUnfortunately, overall the paper is hard to understand and the empirical evaluation is not \nconvincing.\n\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}