{
    "Decision": {
        "metareview": "mnist and small picture variants are not that impressive.\nit is a minor extension of VAEs which also are not common in sota systems.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "limited novelty and limited experimental evaluation"
    },
    "Reviews": [
        {
            "title": "Creating semantic embeddings using textual representations",
            "review": "Summary\n=========\nThe authors present an extension to the VAE model by exploring the possibility of using the label space to create a new embedding space, which they call Probabilistic Semantic Embedding (PSE). \nThey present two different extension of PSE, PSE and PSE*.\nThe idea of additionally supporting the latent embedding, created by a VAE, by using available textual descriptors seems promising. \nThe proposed model was evaluated on two tasks, label-to-image generation and image annotation.\nAlthough the work is interesting, there are a few questions that I am not clear about and have several comments. \n\nQuestions\n=========\n1. How was the word2vec model trained? Did you use an existing pretrained model (e.g. available as download) or did you train the embedding model yourself? If so, on what data? \n2. The major novelty of this approach is the use of annotations supporting images and textual (pretrained) embedding spaces, but no related work regarding Wes was neither introduced in the Related Work section nor was it clearly explained in the text.\n3. Why did the authors focus on the w2v model instead of more promising approaches as fastText or ELMo? \n4. How does your model deal with OOV word(s) as input? For example, when used as Image Generator.\n5. Table 1 shows results achieved on MNIST but not Fashion-MNIST; was the evaluation performed on MNIST only? \n6. Table 2 presents the impact of the use of pretrained embeddings (word2vec) instead of one-hot vectors for labels. Which one do the models presented in Table 1 use? \n7. Could you explain the small difference between using one-hot vs pretrained label encodings, presented in Table 2? \n8. Also, can you explain how the numbers in table 2 were achieved (e.g. sum over all, average of all, etc.). When comparing the values presented here to the values of the same measure in table 1, one does notice the big difference between them. \n\nComments\n=========\n1. Section 2, page2: “As derived in the original paper…” references which paper (i.e. Kingma et al)? \n2. VAE or beta-VAE model is not referenced (mentioned on page 5);\n3. Authors do agree that the corpora used is not optimal for the adequate evaluation of the proposed model. It would be interesting to see the use of this approach on a more realistic data set;\n4. Unclear sentence: “Compared with the VAE, latent codes where images with the same labels are clustered.”;\n5. The authors claim that one of the results of this work is the possibility to generalize for unseen cases (zero-shot learning). It would be interesting to see the performance of this model compared to SOTA in CV in terms of the zero-shot learning task;\n6. Figure 2 visualizes proposed embedding space (2D) but it shows VAE and beta-VAE models and omits to show PSE. VAE and beta-VAE are neither introduced nor referenced in text;\n7. Table 1: mark best performing with bold. It does, however, outperform other evaluated models when using 20D embedding space;\n8. Page 7: in text you mention generation accuracy and in Table 1 the same value is defined as Generation Correctness (%). ",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "This paper presents a VAE model that jointly models images and their labels.",
            "review": "\n\nThis paper presents a VAE model that jointly models images and their labels. Specifically, the following the VAE framework, the proposed model encodes an image into a latent variable, whose prior is conditioned on the labels of the image, and the latent variable is used to reconstruct the image. The paper also presents a variant which also reconstructs the labels \n\n\nMy comments are as follows:\n\n1. About the significance and originality, although to my knowledge, there seems to be no the exact match in the existing approaches of the idea of incorporating labels into the prior of the latent variable of VAE, the idea seems a little bit trivial and less of technical depth. Moreover, in terms of performance, it seems that the proposed model is not significantly better than the previous models. Therefore, my major concern of this paper goes to the significance.\n\n2. In terms of experiments, I am not convinced that using 20D of PSE VS 10D of CVAE is a fair comparison, although the CVAE will use another 10 dimensions to encode 10 labels with one-hot form. Moreover, using the same settings for all the models in comparison may not be perfect because different models may have different best settings. It would be better if the validation set is used to tune the settings a little bit. \n\n3. Does the proposed model use the word embeddings of the labels? It could be better to report both results of word embeddings and one-hot encoding of the labels, to see if word embeddings help. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A simple extension of VAE",
            "review": "This paper proposes to replace the traditional KL term of VAE with the KL between two conditional distributions, which is to equip the model with the ability to address multimodal data. Moreover, the paper also extend the model to add an additional network to predict the label from the reconstructed image to enhance the decoder with supervised information. \n\nIn general, the model is contrived and the  novelty of the paper is incremental. Is Eq. 2 the ELBO of the new model? If so, the authors should provide the derivation of the ELBO. If not, can you prove the objective is the correct one to be optimized?\nMoreover, the model is just an trivial extension of VAE and all key techniques are borrowed from existing work (Chen et al. 2016).\n\nThe experiments are only conducted on MNIST and Fashion-MNIST, which is not sufficient. CIFAT10 should be at least added, and other more challenging benchmarks should also be considered to make the model more solid.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}