{
    "Decision": {
        "metareview": "This paper proposes an optimization algorithm based on 'weak contraction mapping'. The paper is written poorly without clear definitions and mathematical rigor. Reviewers doubt both the correctness and the usefulness of the proposed method.  I strongly suggest authors to rewrite the paper addressing all the reviews before submitting to a different venue. ",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "ICLR 2019 decision"
    },
    "Reviews": [
        {
            "title": "The paper is highly unconvincing ",
            "review": "This paper considers self-maps of metric spaces where the range is strictly smaller than the domain.  Under this condition this tries to show that such a map has a fixed point.  Now the paper suggests that such a \"weakly contractive\" map has a fixed point and tries to use such maps to find the global minima of functions.  \n\nEven if all the proofs in this paper were right I do not see what this has anything to do with learning and why such a paper has been submitted to ICLR! This paper should probably be submitted to an optimization journal!\n\nThe basic proofs here are completely unclear. Like in Lemma 1.2, its not even clear what the variable \"x\" is in the limit! The limit is being taken over the sequence index as far as I can see. Top of page 3 tries to describe an algorithm which can leverage weak contraction to get the global minima if it exists. But this description is hardly making any sense to me. I don't see how the function to be optimized is being used to define the weakly contractive \"T\" map in the paragraph just below the proof of Lemma 1.4. (How is that parameter \"h\" even chosen in the definitions of X^{>} and X^{\\leq}?) \n\nWithout a clear pseudocode there is almost nothing concrete in the paper to judge correctness by. The experiments are all set-up on standardized functions which have nothing to do with learning setups. So the relevance of the experiments is completely unclear, let alone the fact that the description is too muddled up.  \n\nAlso the notation used in the paper is highly non-standard and that makes reading very difficult. For example \"D\" seems to be the symbol for diameter of the metric space. So D is a property of the metric space (X,d) and its not a part of the definition of the metric-space as the weird notation \"(X,d and D)\" seems to suggest!  Also the definition 2 is ambiguous because it uses a {\\cal R} which doesnt seem to have been defined anywhere!\n\n",
            "rating": "3: Clear rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Review: weak contraction mapping and optimization",
            "review": "This paper proposes an approach to zeroth order optimization based on the Banach fixed point theorem for contractive maps. They define a \"weak contraction map,\" argue that it will have a unique fixed point, and use this to propose a zeroth order optimization algorithm which iteratively identifies sublevel sets of the objective until convergence to the optimum.\n\nAt each iteration $t$, the $f(x_t)$-sublevel set of $f$ is found using a root-finding algorithm, and the next point $x_{t+1}$ is calculated by averaging a collection of points on the boundary of the sublevel set.\n\nMy main concern about this paper is that the optimization algorithm works neither in theory nor in realistic practical scenarios. There are two main issues:\n(1) Identifying the sublevel sets requires solving equations of the form $f(x) = L$, which is just as hard as optimizing $f$ in the first place! In many realistic scenarios, e.g. machine learning problems, you know what the minimum value of the function is, so you could just solve $f(x) = f^*$ and be done in one step! Even if you don't know the optimal value, you could do some version of binary search. Also, for the two or three dimensional problems with relatively simple expressions that the authors experimented on, finding roots might be possible, but for higher dimensions or more complicated functions, finding these roots would require numerical optimization--which is the problem we are trying to solve in the first place.\n(2) The authors seem to imply that this algorithm would work for any $f$, however, consider the function in 1 dimension $f(x) = 1$ for all $x \\neq x^*$, and $f(x^*) = 0$. For this function, the $f(x_t)$-sublevel sets are the entire domain until $x_t = x^*$. It is unclear what \"points on the contours\" would mean in this case, but whatever those contours are, the algorithm would never converge on this function because the function value of $x_0, x_1, ...$ would all be the same, so the contours would remain the same. This function might seem a little ridiculous, but continuous or even Lipschitz version of this counterexample could be constructed by smoothing things out around $x^*$, and a function such as this could be obfuscated by writing it down with a long, complicated expression making it hard to identify $x^*$ by inspection.\n\nThere are some typos/typesetting issues. It seems that all of the theorem and lemma statements in Section 2 are missing the bold \"Theorem\" and \"Lemma\" heading. In the paragraph after equation (2), \"weak contraction mapping\" is defined twice, I believe the first definition should be just a \"contraction mapping.\"",
            "rating": "1: Trivial or wrong",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Ill-defined",
            "review": "The authors propose to study what they call weak contraction map. The idea may have its merits, but in the present form, it is not acceptable.\n\nNotably, the key definition of the paper, that is that of the weak contraction mapping (starting with \"Then a mapping T : X â†’ X is called weak\") is incomplete, because it uses a \\mathcal{R}, which is never defined. This makes it hard to evaluate any of the results. \n\nFurther, there is no clear separation between text and theorems. Worse, the theorems are not self-contained. E.g. what could perhaps be Theorem 2 (Starting with \"x* is a fixed-point of T in X0.\") does not define x*.\n\nWhile I cannot be certain because of the reasons stated above, the authors seem to have had in mind something like the Kakutani theorem:\nhttps://en.wikipedia.org/wiki/Kakutani_fixed-point_theorem\nwhich they don't cite. Their assumptions on the map are weaker than that of Kakutani (upper hemicontinuity), which makes me a bit doubtful as to whether the statements could be proven, even if made precise. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}