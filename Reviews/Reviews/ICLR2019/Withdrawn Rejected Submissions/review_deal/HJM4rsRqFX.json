{
    "Decision": {
        "metareview": "The paper proposes a novel variational inference framework for knowledge graphs which is evaluated on link prediction benchmark sets and is competitive to previous generative approaches.\nWhile the idea is interstnig and technically correct, the originality of the contribution is limited,\nand the paper would be clearly improved by providing a clearer motivation for using generative models instead of standard methods and a experimental demonstration of  the benefits of using a generative instead of a discriminative model,  especially since the standard method perform slightly better in the experiments. Overall, the work is slightly under the acceptance threshold.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Intersting work with slighlty limited originality that would benefit from a clearer motivation. "
    },
    "Reviews": [
        {
            "title": "This work proposed variational embedding for knowledge graph inference tasks. However, neither the methods nor the results are really impressive",
            "review": "\nThis work proposed two variational embedding methods for knowledge graph inference tasks. The experiments show slight improvements compared to other variational embedding methods, e.g., KG2E, TransG, and slight improvement on the WN18 dataset compared with the non-variational method. On the other hand, both the embedding method and the training of variational models used in this work are already well developed. Thus, this work doesnâ€™t show too much novel contribution. However, the reviewer really appreciate the visualization provided in Fig. 4. \nMinor issues:\n1)\tNotation of the KL divergence is not conventional\n2)\tThere are some mistakes of indices for predicates, e.g., in Eq. 7, 8.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting variational framework, results not convincing enough",
            "review": "* The paper proposed a neural variational inference framework for knowledge graph embedding. The paper proposed two models (Latent Fact Model and Latent Information Model) where the neural variational inference is carried out, with competitive results on standard datasets (WN18 and FB15K).\n\n* I am not fully convinced of the advantage of this variational inference approach compared with the optimization approach used in TransE, TransG, DistMult and ComplEx. As can be seen in Table 1, the best performance on WN18-RR and FB15K-257 are obtained without variational inference. In Table 2, performance of the variational inference approach is not as good as other approaches under the MR or Raw Hits metrics. Moreover, performance on FB15K is not reported in Table 2, which makes the result not as complete as Table 1.\n\n* It seems that the main difference between Latent Fact Model and Latent Information Model is the way prior is imposed on h. The authors may want to explain in plain language the differences and the motivation behind that.\n\n* It is unclear how the (\\tau,y) labeled triples are generated, especially for the negative examples with y=0. Is it obtained by randomly corrupting the triples in the knowledge base, as done in other work? It would be better to make this point clear.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting work, not mature for publication at ICLR",
            "review": "The paper presents two variational inference frameworks for generative models of knowledge graphs. Such models are based respectively on latent fact model and latent information model.\nThe authors argue that with the presented framework the underlying probabilistic semantics can be discovered. Experiments show performances comparable with state-of-art approaches.\n\nUnfortunately, the paper seems to me not clear and rather incomplete in its actual form.\nOverall, the proposal is novel. I cannot decide about significance because results do not outperform those of other approaches. To this extent, the authors should better discuss the results, explaining in more detail why this approach should be used instead of others (scales better, is faster, etc.).\n\nIn the abstract, it is asserted that one can discover underlying probabilistic semantics, but in the corpus of the paper this aspect is not described or mentioned in detail.\nSimilar problem for the reference to von-Mises distribution. This distribution is just named, it is said that the framework can handle such a distribution, but a reference to a paper and/or a short paragraph to explain the sentence are missing. This statement now results to be just information disconnected by the rest of the paper.\n\nIn a similar way, many other points suffer from a poor organization in my opinion.\nWhen describing LIM an error is introduced here that is then copied and pasted throughout the paper: in the productory on p, p is in R not in E. This is a simple typo, but the fact that it is repeated so many times, also in the proof, gives me the feeling that the paper was written at the last moment.\nFigures 1 and 2 are never referred.\n\nFormula 6 must be better explained. If I have not lost something, n is the number of labeled triples, s_c is undefined, b_c is the probability of s_c to be equal to 1, the index i is never used. The paper lacks information here.\n\nAs regards the experimental part, some results are shown in subsection 4.3 called link prediction, others in section 5 called link prediction analysis. This organization does not seem to me to be really optimal. I would suggest creating an experimental section.\nMoreover, the tests should be better explained, the tables are shown without specifying how they are built and how the values are collected. Information is provided in the appendix but could be included in the paper as the maximum limit is of 10 pages (8 suggested but I think an extra half page can be used).\nThe knowledge bases used should be at least cited, I know that freebase and wordnet are well-known but somewhere, in the description of the test, the name should be included. Also to specify the characteristics of the versions (WN18 vs WN18RR). Moreover, what does the value -257 in column 1, row 4 means?\nThen, it is said that Table 1 shows improvements for ComplEx, but such improvements are rather low, is there a way to prove their significance? Otherwise, I would say that the performance is the same for WN18.\nTables 1 and 2 contain cells with '-' value, what does it mean?\n\nDiscussion about table 3 is incomplete in my opinion. First of all, the \"proportion\" column should be described. Also, on one hand, it is true that the _member_meronym is the least accurate and prominent but the most problem may come from _hypernym, which is the most prominent and the accuracy is also low. This fact is highlighted for table 4 but not for table 3.\n\nMinor issues\n- sec 3: references to Miao et al. must be enclosed by brackets\n- sec 4.3: \"We believe this *is* due to ...\"\n- sec 5.2: what is Model A? Also, the sentence seems incomplete.\n\nPros:\n- Novel approach\n\nCons\n- Test results are not convincing\n- The paper is not mathematically sound\n- The paper needs to be re-organized",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}