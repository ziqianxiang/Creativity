{
    "Decision": {
        "metareview": "The authors replace the large filtering step in the permutohedral lattice with a spatially varying convolutional kernel. They show that inference is more efficient and training is easier.\n\nIn practice, the synthetic experiments seem to show a greater improvement than appears in real data.  There are concerns about the clarity, lack of theoretical proofs, and at times overstated claims that do not have sufficient support.\n\nThe ratings before the rebuttal and discussion were 7-4-6.  After, R1 adjusted their score from 6 to 4.  R2 initially gave a 7 but later said \"I think the authors missed an opportunity here. I rated it as an accept, because I saw what it could have been after a good revision. The core idea is good, but fully agree with R1 and R3 that the paper needs work (which the authors were not willing to do). I checked the latest revision (as of Monday morning). None of R3's writing/claims issues are fixed, neither were my additional experimental requests, not even R1's typos.\" There is therefore a consensus among reviewers for reject.\n",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Area chair recommendation"
    },
    "Reviews": [
        {
            "title": "Nice speedup over DenseCRF",
            "review": "+ well written\n+ Good idea\n- Technical section not fully clear\n- Some experimental issues\n\nThe paper is well written, and clearly explains the background material and concepts. It might almost be a bit too detailed, as the main technical section (4) feels a bit rushed. (more below). \n\nFrom what I can judge the main idea in the paper is sound. The authors replace the large filtering step in the permutohedral lattice with a spatially varying convolutional kernel. They show that inference is more efficient and training is easier.\n\nThe technical section is not very clear. For example: Are the filter weights recomputed for each spatial location, is there any acceleration that speeds this up? How large can the authors make the filter kernel, before the perhutohedral lattice is faster again?\n\nFinally, the experimental section has some room for improvement. I liked the comparison of decoupled and coupled CRF training, but I didn't get much out of the synthetic experiments. I found it particularly confusing since Table 1 doesn't mention that the experiments use ground truth (test) labels that were corrupted.\nSecond, it would be nice to have a side-to-side comparison between ConvCRF and CRFasRNN. I'd recommend the authors to either use the CRFasRNN training setup for both methods, or spend the week or two training CRFasRNN using their training procedure. It is fine to do either of the two experiments and have four entries in that table.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Confusing notation, insufficient analysis, main contribution unclear",
            "review": "The authors propose an efficient method to perform message passing on a truncated Gaussian kernel CRF. The main contributions are the definition of a specific form of truncated Gaussian kernel that allows for fast message passing via convolutions, and the implementation of such parallelized message passing on GPU. \n\nIn my opinion, the paper fails to convey the main idea in a clear and precise manner, the notation is mixed and often confusing, furthermore there are a number of sentences that should be rephrased to be less sensationalist, or removed. The experiments seem to show performance in par with the FullCRF on decoupled training, which seem in contrast with the much bigger performance gain of the first experiment on syntetic data. No discussion has been provided as to the possible reasons of this performance gap, although the experimental settings appear to be similar. Finally, in the last experiments with end-to-end training the authors report a performance improvement over CRFasRNN, a 3 years old paper that is far away in terms of performance with the current SOTA on Pascal VOC. The authors base on a different network than that of the CRFasRNN baseline (i.e., the difference is not only in the CRF implementation, but rather the whole network before the CRF in the proposed method), it is therefore difficult to say whether the performance improvement is due to the ResNet101 + FCN unary potentials, which is not a contribution of this manuscript, or to the proposed CRF. In general, I believe that the considerable speed gain of the proposed method might be enough to justify a publication, but the paper should be phrased in that sense if that was the intention of the authors. It is unclear to me whether the main contribution they claim is segmentation performance (IoU) or speed or both. The main contributions of this work should be stated clearly, and the modelling differences w.r.t. the FullCRF model that they aim to improve should be more explicit in the text rather than let to the reader to infer comparing the formulas.\n\nOn these grounds, I suggest a major revision of the paper and I don't recommend publication at this stage.\n\n\n\nMAJOR\n\n1) I firmly advocate against making strong claims, unless supported by solid proofs. I strongly recommend to rephrase, if not remove, exaggerate claims such as:\n\na) \"[deep networks] lack the capability to utilize context information and cannot model interactions between predictions directly\". This is simply not true. Any CNN with enough layers will exploit contextual information. Furthermore, any autoregressive model will model the interaction between predictions directly. See e.g., \"RiFCN: Recurrent Network in Fully Convolutional Network for Semantic Segmentation of High Resolution Remote Sensing Images\" by Mou et Al., \"ReSeg: A Recurrent Neural Network-based Model for Semantic Segmentation\" by Visin et Al., or \"Predicting Deeper into the Future of Semantic Segmentation\" by Luc et Al. for video semantic segmentation.\n\nb) \"CRF inference is two orders of magnitude slower than CNN inference\": this, of course, depends on the kind of CRF.\n\nc) \"The long training times of the current generation of CRFs also make more in-depth research and experiments with such structured models impractical\": again, not true. While it's true that CRFs tend to be slow, research with such models is not impractical and indeed there are papers that focus exactly on that (among the others, some of the ones cited in this manuscript).\n\nd) \"we propose to add the strong and valid assumption of conditional independence\": as with every assumption, this is an approximation. I wouldn't claim it to be valid nor invalid, as it is simply a modeling choice.\n\ne) \"Predictions are pixel-wise and conditionally independendent (given the common feature base of nearby pixels). Structured knowledge and background context is ignored in these models.\". It's unclear what is meant by \"structured knowledge\", but to my best understanding this sentence is misleading or wrong. Background context is considered by CNN-based models, as well as the general structure in the image.\n\nf) \"In the context of semantic segmentation most CRF based approaches are based on the Fully Connected CRF\". CRFs have been used much earlier than 2011, before Fully Connected CRF was published.\n\ng) \"This makes the theoretical foundation of ConvCRF very promising, strong and valid assumptions are the powerhouse of machine learning modelling.\" The authors here propose a logical, but quite obvious, approximation, i.e., to constrain the CRF to model dependencies in a local neighborhood. This is the same implicit assumption of many other Gaussian kernels and algorithms for approximated inference. For how it's surely valid, and possibly strong, I don't see how it can make a \"theoretical foundation\". The self-congratulatory closure is unnecessary, and inappropriate.\n\n\n\n2) While CRFs have been used for a long time on visual data, the citations in this work focus mostly on the last few years. I suggest to add at least one of the following:\n* “Discriminative fields for modeling spatial dependencies in natural images\" 2003\n* \"Multiscale conditional random fields for image labelling\" 2004\n* “Textonboost: Joint appearance, shape and context modeling for mulit-class object recognition and segmentation,” 2006\n\nIt could also be beneficial to the reader to add to the references broad overview works, such as \"An Introduction to Conditional Random Fields\" by Charles Sutton and Andrew McCallum, 2011, and/or \"Structured prediction and learning in computer vision\" by Nowozin and Lampert, 2011.\n\n\n\n3) Line 5 of the algorithm adds the unary potentials at each iteration of message passing. Can you elaborate on the motivation behind this choice? The algorithm is already initialized with such potentials, and to my best knowledge unary potentials are not usually added in the mean field message passing loop. It would be interesting to compare the performance of the algorithm with and without this addition.\n\n\n\n4) Sec4.1 reports that the filters are constant over the channel dimension c and that, in other words, this can be seen as applying the convolution over the dimension c. I fail to understand this sentence. My understanding from the formula is that the same kernel is applied to all the channels of the input, i.e., the channels of the input fed to the CRF are all processed in the same way. This should be explained clearly and the reasoning behind this choice should be explained as well. Furthermore, if I am not mistaken the authors learn a different filter in each position *of the input* rather than reusing the same filters at every position. This choice should be clarified and discussed.\n\n\n\n5) Regarding the implementation, is there a reason not to apply a convolution with a flipped kernel to compute the cross-correlation? Also, IIRC if the kernel is symmetric (as should be for a Gaussian kernel) convolution and cross-correlation are the same. \n\n\n\n6) The notation is often ambiguous and at times unnecessarely heavy. I strongly recommend to go over the manuscript and use a consistent notation, making sure that every element of the notation is introduced before or right after it's used. In particular,\n\na) Sec3: in the text, a segmentation instance is referred to as X, while in the formula as \\hat x. \\tilde I is never introduced. k_{\\alpha} is defined but I believe never used (I suggest to drop the name if there is no reference to it). Is there a reason to drop the subscript G in the FullCRF pairwise potential? Or conversely, is there a reason to have it everywhere else? Furthermore, there doesn't seem to be a difference between k_G, k_g and g, I suggest to use only one consistent notation to refer to the Gaussian kernels throughout the paper. It's also unclear if the I superscript is needed for the feature vectors. \n\nb) Sec4.1, The shape of the Gaussian kernels is the same as that of the input. I believe that the input in this context refers to a patch and not to the whole image. If so, this should be specified, otherwise the dimensions of the kernel should be referred to with a different letter than those of the input. \n\nc) Sec4.1, I believe dx and dy refer to the in-kernel displacement. Their semantic is not clear from the text and should be defined properly.\n\nd) Sec4.1, the feature vectors are defined in the text as f_1..f_d. The formula of the kernel uses f_i^{(d)} instead. It's unclear what the superscripts stands for and whether it is actually useful or redundant.\n\ne) Sec4.1, x and y are not defined, I suspect they refer to the position of the pixel, which was previously encoded as p_i and p_j. Once again, the notation should be consistent across the manuscript.\n\nf) In the definition of the convCRFs, w is used for the width of the input, w_i for the weights of the kernels. In the FullCRF, w^{(1)} and w^{(2)} for the potentials, w^{(m)} for the sum over the kernels. k is used for the kernel dimension, k_G to refer to the kernel itself, as well as g. The notation could be made less ambiguous and consistent (superscript vs subscript semantics).\n\ng) Sec3, the number of pixel is defined as n but in Formula 2 N is used instead.\n\ng) Vectors and matrices should be bold-face. The use of capital letters for constants might also improve the readability of the manuscript.\n\n\n\n7) The experiments with the Conv (ConvCRF?) variants of Table 2 are not discussed in the text.\n\n\n\n8) Although Sec5.2 concludes with \"The experiments also confirm the observation of Sec5.1, that ConvCRF performs slightly better than FullCRF\", Sec5.1 reported that \"it can be seen that ConvCRFs outperform FullCRFs significantly\". The authors should decide whether the results are slightly better or outperform the baseline. In general a in-depth discussion on the performance of the algorithm is missing.\n\n\n\n9) Sec5.3, it's unclear what this sentence means \"introduce an auxiliary unary loss to counterbalance the vanishing gradient problem\". If such a term has been added, it should be reported in a formula and it's effectiveness should be supported by experimental data.\n\n\n\nMINOR\n\nm1) In the related work, the sentence \"transposed convolution layers are applied at the end of the prediction pipeline ot produce high-resolution output\" seems to suggest these are always applied, while many recent methods rely on bilinear upsampling to recover the original resolution. Please rephrase it accordingly.\n\nm2) In Parameter learning in CRF: \"the idea utilizes, that for the message passing the identity .. is valid.\" This sentence doesn't make any sense to me. Is it possible it is a leftover?\n\nm4) In Sec3, the features vectors [...] may depend on the input image I. I am confused as to when they might be independent of the image. Can you elaborate on that?\n\nm5) In Sec3, it's unclear to me what the vertical bar in the Pot model stands for. I believe the correct formula should be 1_{[xi != xj]}.\n\nm6) In mean field inference, Algorithm 1 does not refer to FullCRFs.\n\nm7) End of page 6, \"Note that this gives FullCRFs a natural advantage. The performance of CRFs however is very robust [...]\". Why is this an advantage for FullCRFs? How does that relate to the following sentence?\n\nm8) Sec4.1, the authors claim that one of the key contribution of the paper is that exact message passing is efficient. Given the locality assumption, message passing is approximate - which is also why it's efficient. The authors could instead argue that using convolutions is faster and possibly leads to better final performance than using the permutohedral lattice approximation (although it's unclear whether this is the case from the experiments), with proper reference to compelling results in this direction.\n\nFinally, a few typos:\n* Abstract, space missing after GPUs\n* Introduction, Convolutional Neuronal -> Convolutional Neural\n* Introduction, order of magnitude slower then -> than\n* Introduction, to slow -> too slow\n* Parameter learning in CRF: missing space before proposed to use gradient descent\n* Parameter learning in CRF: gradient decent -> descent\n* Parameter learning in CRF: extra comma after \"another advantage of this method is\"\n* Sec 3: \"weighted sum of Gaussian kernels\", the apex of the second should be \"M\" I believe.\n* Sec 3: \"can be chosen arbitrary\" -> arbitrarily\n* Sec 5.2, beginning of page 8: then -> than",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Using convolution in CRFs to increase inference and training time speed",
            "review": "The paper is well written with many relevant references and easy to read. Some points that need clarification and mentioned below. \nThe main points of this paper are the use of the convolution operator to perform the message passing mean field inference. Using this operation allows us to get away from the permutohedral lattice and yet allows speed up of 100x. This also means, that training will be able to done faster. Besides this the training parameters can also be learnt. These are the main contributions. The denoising task experiment shows positive results. The idea could be used in the future by others looking for faster model inference and training.\n\nIf a Manhattan distance d is used i.e. dx,dy<k in equation (6), why is this a FullCRF? It seems like the new CRF is no longer a fully connected one. \n\nPage 5, first paragraph describing how the reorganization in the GPU is avoided is not very clear. It would be helpful to a reader to have more details and explanations about this.\n\nIt is not clear from the experimental results how much improvement allowing to train the CRF parameters gets or might get. Comparing to the Deeplab results etc for the non-trained case, the non-trained model still seems to be performing competitively. Table 2 of Table 3 does not really bring out the advantage of training. The +C, +T, +CT don't seem to be hugely different in terms of validation metrics. Note that Table 3 does not mention other models that might not be trained (assuming that those results are in Table 2) but the text also mentions that the training is not completely fair.\n\nIn section 5, Unary, it is mentioned that the network is not trained on larger datasets like other work, why?\nAnd under CRF, what does iterations are unrolled mean?\n\nIn section 5.1, why does the random flipping help in simulating inaccuracies?\n\n\nMinor points:\nAbstract: Add space after \"GPUs.\".\nWould be good to define what Q, *, ' indicate in paragraph 4, page 2.\n\"hight\" -> \"height\" in section 4.1\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}