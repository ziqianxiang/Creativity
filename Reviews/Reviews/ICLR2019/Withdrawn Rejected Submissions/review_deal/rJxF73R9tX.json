{
    "Decision": {
        "metareview": "The reviewers felt that the method was natural and the writing was mostly clear (although could be improved by providing better signposting and fixing typos). However, there was also general agreement that comparison to other methods was weak; one reviewer also points out that the way that the reported numbers compare the methods on different sets of data, which might be an inaccurate measure of performance (this is more minor than the overall issue of lack of comparisons). While the authors provided more comparison experiments during the author response, it is in general the responsibility of authors to have a close-to-final work at the time of submission.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "natural idea but insufficient comparison to other methods"
    },
    "Reviews": [
        {
            "title": "Good paper, writing and comparison need to be improved",
            "review": "The paper introduces a new loss function for training a deep neural network which can abstain.\nThe paper was easy to read, and they had thorough experiments and looked at their model performance in different angles (in existence of structured noise, in existence of unstructured noise and open world detection).  However, I think this paper has some issues which are listed below:\n\n\n1)  Although there are very few works regarding abstaining in DNN, I would like to see what the paper offers that is not addressed by the existing literature. Right now, in the experiment, there is no comparison to the previous work, and in the introduction, the difference is not clear. I think having an extra related work section regarding comparison would be useful.\n\n2) The experiment section was thorough, and the authors look at the performance of DAC at different angles; however, as far as I understand one of the significant contributions of the paper is to define abstain class during training instead of post-processing (e.g., abstaining on all examples where the network has low confidence). Therefore, I would like to see a better comparison to a network that has soft-max score cut-off rather than plain DNN. In figure 1-d the comparison is not clear since you did not report the coverage. I think it would be great if you can compare either with related work or tune a softmax-score on a validation set and then compare with your method. \n\n3) There are some typos, misuse of \\citet instead of \\citep spacing between parenthesis; especially in figures, texts overlap, the spacing is not correct, some figures donâ€™t have a caption, etc.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Re: Abstention classifiers",
            "review": "This manuscript introduces deep abstaining classifiers (DAC) which modifies the multiclass cross-entropy loss with an abstention loss, which is then applied to perturbed image classification tasks.  The authors report improved classification performance at a number of tasks.\n\nQuality\n+ The formulation, while simple, appears justified, and the authors provide guidance on setting/auto-tuning the hyperparameter.\n+ Several different settings were used to demonstrate their modification.\n- There are no comparisons against other rejection/abstention classifiers or approaches.  Post-learning calibration and abstaining on scores that represent uncertainty are mentioned and it would strengthen the argument of the paper since this is probably the most straightforward altnerative approach, i.e., learn a NN, calibrate predictions, have it abstain where uncertain.\n- The comparison against the baseline NN should also include the performance of the baseline NN on the samples where DAC chose not to abstain, so that accuracies between NN and DAC are comparable. E.g. in Table 1, (74.81, coverage 1.000) and (80.09, coverage 0.895) have accuracies based on different test sets (partially overlapping).\n- The last set of experiments adds smudging to the out-of-set (open set) classification tasks.  It is somewhat unclear why smudging needs to be combined with this task.\n\nClarity\n- The paper could be better organized with additional signposting to guide the reader. \n\nOriginality\n+ Material is original to my knowledge.\n\nSignificance\n+ The method does appear to work reasonably and the authors provide detail in several use cases.\n- However, there are no direct comparison against other abstainers and the perturbations are somewhat artificial.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Comparsion with \"Generalized cross entropy loss for training deep neural networks with noisy labels\".",
            "review": "This paper formulates a new deep method called deep abstaining classifer. Their main idea is to introduce a new modified loss function that utilizes an absention output allowing the DNN to learn when abstention is a better option. The core idea resemble KWIK framework [1], which has been theoretical justified.\n\nPros:\n\n1. The authors find a new direction for learning with noisy labels. Based on Eq. (1) (the modified loss), the propose \\alpha auto-tuning algorithm, which is relatively novel. \n\n2. The authors perform numerical experiments to demonstrate the efficacy of their framework. And their experimental result support their previous claims.\nFor example, they conduct experiments on CIFAR-10 and CIFAR-100. Besides, they conduct experiments on open-world detection dataset.\n\nCons:\n\nWe have three questions in the following.\n\n1. Clarity: in Section 3, the author claim real-world data is corrupted in some non-arbitrary manner. However, in practice, it is really hard to reason the corrpution procedure for agnostic noisy dataset like Clothing1M [2]. The authors are encouraged to explain this point more.\n\n2. Related works: In deep learning with noisy labels, there are three main directions, including small-loss trick [3], estimating noise transition matrix [4,5], and explicit and implicit regularization [6]. I would appreciate if the authors can survey and compare more baselines in their paper.\n\n3. Experiment: \n3.1 Baselines: For noisy labels, the author should compare with [7] directly, which is highly related to your work. Namely, designing new loss function can overcome the issue of noisy labels. Without this comparison, the reported result has less impact. Moreover, the authors should add MentorNet [2] as a baseline https://github.com/google/mentornet\n\n3.2 Datasets: For datasets, I think the author should first compare their methods on symmetric and aysmmetric noisy data. Besides, the authors are encouraged to conduct 1 NLP dataset.\n\nReferences:\n\n[1] L. Li, M. Littman, and T. Walsh. Knows what it knows: a framework for self-aware learning. In ICML, 2008.\n\n[2] T. Xiao, T. Xia, Y. Yang, C. Huang, and X. Wang. Learning from massive noisy labeled data for image classification. In CVPR, 2015.\n\n[3] L. Jiang, Z. Zhou, T. Leung, L. Li, and L. Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In ICML, 2018.\n\n[4] G. Patrini, A. Rozza, A. Menon, R. Nock, and L. Qu. Making deep neural networks robust to label noise: A loss correction approach. In CVPR, 2017.\n\n[5] J. Goldberger and E. Ben-Reuven. Training deep neural-networks using a noise adaptation layer. In ICLR, 2017.\n\n[6] T. Miyato, S. Maeda, M. Koyama, and S. Ishii. Virtual adversarial training: A regularization method for supervised and semi-supervised learning. ICLR, 2016.\n\n[7] Z. Zhang and M. Sabuncu. Generalized cross entropy loss for training deep neural networks with noisy labels. In NIPS, 2018.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}