{
    "Decision": "",
    "Reviews": [
        {
            "title": "Gradient based optimization of spiking networks via differentiable approximations during backpropagation",
            "review": "In this work, the authors investigate the training of spiking (leaky integrate and fire) neural networks, for which the normally used threshold function is replaced with the sigmoid function for backpropagation. They demonstrate the proposed method for an autoencoder network on MNIST and Fashion-MNIST, as well as an audio to image synthesis task. The reconstruction loss of the ANN and SNN models is compared, typically with an advantage for the ANN model, but on Fashion-MNIST the SNN results look better.\n\nThe paper addresses learning of deep SNNs, which is a difficult topic with relevance to both the machine learning and computational neuroscience communities. Since the paper does not aim for biological plausibility, the target audience is ML and neuromorphic engineering. For ICLR this is a paper of medium relevance.\n\nThe originality of the work is low, because approaches that propose to replace the non-differentiable threshold function with a differentiable proxy, in this case membrane potentials, have been known for several years, e.g. \"Spiking Deep Networks with LIF Neurons\", Eric Hunsberger and Chris Eliasmith, 2015, and \"Training Deep Spiking Neural Networks Using Backpropagation\", Jun-Haeng Lee et al. 2016. The main novelty is therefore the application to autoencoders, but overall this reduces originality and hence relevance for ICLR. A thorough discussion and differentiation to previous work is missing.\n\nAnother criticism is that the relevance of the multi-modal experiments for the idea of replacing the threshold function with a sigmoid function is not clear. Instead, the authors could provide additional experiments on classification tasks or investigate the scalability of the idea for deep (more layers) networks (e.g., on CIFAR10 classification). In general, the experimental section could be more tailored towards the central idea of the paper.\n\nWhile some of the parameters are explored in detail, the choice of others is not motivated. For example, the network sizes are just given without further justification, similarly the parameters for ANN training, which might have required more fine-tuning (e.g. learning rates). Figure 3(b) remains strange, because at some batch number the unmasked version simply ceases to work, but this could have been explained without a graph. Especially the comparison to the ANN without ANN would have required more fine tuning of learning rates, thus I do not see much value in the AE-SNN outperforming this method. The resulting reconstructions in Figures 4c look like they have some completely dark and some very strongly firing pixels, which indicates a far-from-perfect reconstruction. Actually the final reconstruction MSE of 0.2 on the binary MNIST images looks rather high.\nI find it surprising that the SNN outperforms the ANN on Fashion-MNIST, and I don't really see a reason why this should happen, and the argument in the article is not convincing, neither are the differences explored in detail. I therefore assume this is a bad parameter setting for the ANNs, and would encourage the authors to test and evaluate this in more detail.\n\n\nPros:\n+ Overall the paper is well written and has a transparent and meaningful structure. The central ideas are laid out in a comprehensive manner.\n+ In general, the training of spiking neural networks remains a challenging task and investigation of potential solutions is relevant to ICLR.\n\nCons:\n- Low originality and missing comparison to related work\n- Unconvincing experimental section\n\n\nMinor remarks:\n* The title is misleading in the sense, that the spatial part of the spatio-temporal representation is not related to actual space, and further, that the backpropagation is not spike-based\n* The figures appear blurry, and in the case of Fig. 2 is very hard to read.\n* In Figure 3c the unit of the spike train duration is not given in figure or caption.\n* There are a number of grammatical errors.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "hard to get a handle on due to very limited clarity",
            "review": "The paper is hard to read, and hard to get a handle on the significance of the result.\n\nThe work describes an error-backpropagation rule based on an approximation of the activation of each neuron, where an error measure is taken from the membrane potential of the output neuron and then backpropagated in auto encoders with a single hidden layer (which severely limits the complexity of backprop). The backprop as proposed is essentially standard backprop, where a continuous approximation of the forward activation is made such that the gradients can be computed. There is mention of applying effectively BPTT, but I do not see that in the model (sec 2.3). \n\nI am also concerned as to whether the comparison with ANNs is correct in section 3.1. Why only one epoch with specific parameters? Do the parameters matter? \n\nThe quality of the work is unclear in places, like whether the comparisons are valid. The clarity is problematic, also because the grammar is off in many places. \n\nI am also highly dubious about the claim that auto encoders can only learn the hidden representations  of only one modality. Citation? Or a detailed explanation. \n\nThe performance shown in Figure 7 for the SNN seems rather poor compared to an ANN, if the comparison is valid. The reported results in Table 1 are confusing, as some are and some are not following from the graphs. ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Neuromorphic learning rule that needs comparisons and a temporally more interesting task",
            "review": "\"Learning spatio-temporal representations using spike-based backpropagation\" submitted to ICLR 2019 describes a gradient based learning algorithm for discrete-time feed-forward leaky-integrate-and-fire network. Based on (1) the mean square error of the membrane potential for misclassified time points, and (2) smooth approximation of the firing threshold with a sigmoid funciton, the authors obtain a chain rule through the network. The resulting algorithm is very far from being biologically plasible. They train an autoencoder for images and audio-to-image translator. Although this reviewer is happy to see spiking neural network in ICLR, there are several major flaws.\n\n1. Comparison with previous methods: the authors cite (Bohte 2002) and (Lee 2016) as alternate backpropagation schemes, however their performance is not compared. In addition, a large portion of the literature on training spiking neural networks is missing: Spikeprop, ReSuMe, Tempotron (and its extensions), SuperSpike, Huh & Sejnowski 2017, to name a few. I suggest comparing with these existing methods.\n\n2. Effect of leak coefficient (Fig 3a) indicates that alpha = 0.1 performs significantly better than less leak. Why didn't you investigate even larger alpha (shorter time constant)? As indicated by Fig 2b, your time constants seems to be very long relative to the time steps.\n\n3. (Comment) Bernoulli encoding of intensity (Poisson process discretized over 15 or 60 time steps) in the image is similar to dropout regularization, but not equivalent because (1) you only apply it to the encoding layer, and (2) probability depends on the strength of the image. Despite this difference, this encoding scheme seems to be providing some robustness to the encoding.\n\n4. (Minor) Spike-MSE is just number of spikes that were precisely matched in discrete time, and normalized MSE is proportional to the correlation coefficient, right? The names of the metric you use are somewhat misleading.\n\n5. (Wishlist) I'd love to see the features learned by the auto/trans-encoder. Does it extract receptive fields that are gabor-like? For MNIST, does it obtain common line segments?\n\n6. The sigmoid activation function assumption is unprincipled. How is the width of the sigmoid chosen? Have you tried to optimize the sigmoid for training performances? Is this related to the escape rate approximation?\n\n7. In general, training SNN with gradient descent is difficult because of the non-smooth threshold. Small changes can bring very large changes to the entire future outputs. The proposed method is no exception. The reason it doesn't seem destructive due to the static nature of the task. In a realistic setting where spike times are sparse and relative precisions carries information, I do not believe this algorithm can solve the temporal credit assignment problem. I suggest including a temporal task where the input is changing over time (not just the noise).\n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}