{
    "Decision": {
        "metareview": "This paper introduces Mahe, a model-agnostic hierarchical explanation technique, that constructs a hierarchy of explanations, from local, context-dependent ones (like LIME) to global, context-free ones. The reviewers found the proposed work to be a quite interesting application of the neural interaction detection (NID) framework, and overall found the results to be quite extensive and promising.\n\nThe reviewers and the AC note the following as the primary concerns of the paper: (1) a crucial concern with the proposed work is the clarity of writing in the paper, and (2) the proposed work is quite expensive, computationally, as the exhaustive search is needed over local interactions.\n\nThe reviewers appreciated the detailed comments and the revision, and felt the revised the manuscript was much improved by the additional editing, details in the papers, and the additional experiments. However, both reviewer 1 and 3 have strong reservations about the computational complexity of the approach, and the additional experiments did not alleviate it. Further, reviewer 1 is still concerned about the clarity of the work, finding much of the proposed work to be unclear, and recommends further revisions.\n\nGiven these considerations, everyone felt that the idea is strong and most of the experiments are quite promising. However, without further editing and some efficiency strategies, it barely misses the bar of acceptance. \n",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Expensive approach, unclear writing"
    },
    "Reviews": [
        {
            "title": "interesting paper with a thorough evaluation ",
            "review": "Summary\n\nThis paper proposes a method named Mahe that can provide hierarchical explanations for a model: including both context-dependent(instance level) and context-free (global) explanations by a local interpretation algorithm. It obtains context-free explanations through generalizing context-dependent interactions to explain global behaviors. The effectiveness is shown through a number of synthetic and real-world data experiments.\n\nThe paper provides an interesting way to get context-free explanations from local explanations. The experiments are well designed and the paper is overall written well. \n\nMajor comments\n\n0. The motivation of the local-MLP models is not convincing. \n\n1. Of particular concern is the computational time cost of the model, as it involves retraining and an exhaustive search through local interactions to get context-free explanations.\n\nThe paper provides no experiments about timing cost to show the relative computational scalability of the proposed method. As Mahe trains MLPs per data sample and searches through all interactions for finding context-free explanations, this raises concerns.\n\n2. The paper includes no baseline comparisons for finding context-free interactions.\n\n3. Non-linear GAM is replaced by linear approximations in the experiments. More experiments showing the advantage of non-linear function approximation is recommended. \n\n4. Minor Comments: In the description, \"L + 1 different levels of a hierarchical explanation which constitutes the context-dependent explanation\", What does L indicate? The order of interactions?\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Promising idea, but results could be better.",
            "review": "Summary of the paper:\nThe authors propose a framework called Mahe that provides context-dependent and context-free explanations for a given (neural network) model’s prediction. Context-dependent explanations are found by applying NID (Tsang et al, 2018) on a set of data points sampled from a neighborhood around the given input point. Further, the generalized additive model representing the function approximation around the given input is incrementally built by selectively computing higher-order-interaction terms using NID again. Each such added term results in an explanation at a level in the hierarchy. Context-free explanations are generated in two ways: 1) when a local explanation shows same polarity among all valid data points, and 2) by negating the local explanations’ polarity at a data point, fine-tuning the model on the resulting modified function approximation, and regenerating the local explanations for other data points; if the polarity is reversed for all other data points, then the local explanation is also a global explanation\n\nStrengths:\n- Broadens the application of NID to provide hierarchical explanations and context-free explanations\n- Experiments on context-free explanations show promising results, for instance, on the Sentiment-LSTM model and in Supplementary A. Would be great to see more results on this front. \n\nQuestions for authors:\n- The experimental results only show that using higher order interactions results in a better function approximation (explanation), but explanations for level > 2 do not seem to be that good (Table 5). For the image example, they look slightly better. \n- The contribution seems incremental, given that Tsang et al (2018) already explored explanations based on interactions. \n\nConclusion\nConsidering that the NID idea has been broadened to context-free explanations, the paper shows promise, but it is a weak accept because the other contributions do not seem fully worked out. \n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Clear methodological contribution but not written clearly enough",
            "review": "Summary\n=======\nThe authors extended the linear local attribution method LIME for interpreting black box models by non-linear functions to more accurately approximate black box models locally and identifying interactions between model input variables using the previously published neural interaction detection (NID) framework. They further propose a method to discern between context-dependent and context-free interactions. I found the paper hard to understand without being familiar with previously published literature on detecting interactions and could not understand their approach to detect context-free interactions as well as some aspects of their evaluation. I have also concerns about the practically of their method due to the high runtime and the notion of locality in the light of high-dimensional inputs. In the following, I will briefly summarizing my major criticism and give further details below.\n\nSummary of major criticism\n=====================\n1) The paper is hard to understand without being familiar with previously published literature in the field.\nThe authors do not describe how they define the interaction sets X_I in equation (3).\n\n2) I could not understand their approach for detecting context-free interactions (section 4.2).\n3) It is unclear how discrete variables are locally modified. Can the approach be used for a combination of differently distributed variables, e.g. categorical and continuous variables?\n4) Evaluation metrics such as MSE and R-precision are not described and I could not understand other important aspects of their evaluation, e.g. superpixels (figure 6), why and how they modified network architectures for evaluating context-free interactions (section 5.3), or how they asked Amazon Medical Turk users.\n5) The authors did not compare the runtime of Mathe with LIME, which is presumably high due to the need of fitting multiple non-linear models (equation 3) and sampling the local neighborhood.\n6) The authors  did not compare the total number of model parameters of Mathe with LIME, which might also account for the higher accuracy (lower MSE). \n7) The authors did not evaluate the accuracy and runtime of Mathe on high-dimensional inputs, e.g. large images.\n\n\nDetails\n=====  \n\nAbstract\n---------------------------\n1. The abstract is hard to understand since ‘context-dependent’ and ‘context-free’ are undefined. The authors should also not use ‘dependencies’ as synonym for ‘interactions’.\n\nIntroduction\n---------------------------\n2. The difference between interactions and context-free and context dependent interactions is unclear. Is a variable without interactions context-free, e.g. Buffalo does not interact with water, and a variable with interactions context-dependent? Also, ‘classes of data’ is unclear, which can be misinterpreted as class labels for classification problems. The authors should also clarify what they mean by ‘performance and generality’ in the last section of the introduction.\n\nSection 3.1\n---------------\n3. The description of the model function f(x) and attribution scores phi(x) is unclear. Since f(x) is undefined when it is first mentioned after equation (1), I suggest to first define f(x) and afterwards define phi(x). The purpose of the attribution score function phi(x) is also unclear without prior knowledge. The authors should more clearly describe that f(x) is the target function (model) of interest, e.g. a classifier, and phi(x) locally approximates f(x) and is interpretable in contrast to f(x).\n\nSection 4.1\n---------------\n4. The authors should justify why they are sampling x ~ N(x, sigma * I), which assumes that data instances are iid Normal. This is not the case, e.g., if x is categorical or contains a combination of categorical and continuous variables, and variables are correlated. How is sigma chosen? How many samples are used depending on the dimension of x?\n\n5. The authors should briefly describe the basic idea of NID.\n\n6. How are points sampled from the epsilon neighborhood of x? What is a link function?\n\n7. The subsection ‘Hierarchical Interaction Attribution’ is hard to understand without being familiar Tsang et al. The authors should give an example of a hierarchical explanation with different layers. \n\nSection 4.2\n---------------\n8. How is the ‘local vicinity’ defined? Which distance metric is used? This is in particular problematic if x is high-dimensional due the the curse of dimensionality. How are continuous and categorical variables locally modified? Did the authors meant to use a lowercase ‘k’ in equation (4), i.e. ‘phi_k =’ instead of ‘phi_K’? I find this section hard to understand without being familiar with the cited literature.\n\nSection 5.1\n---------------\n9. The number of local vicinity samples is unclear. Did the authors use 1k local vicinity samples for synthetic experiments (Table 1) and 5k samples for real-word synthetic experiments?\n\n10. What is the dimensionality (number of words, characters, or pixels) of real world datasets? This is important since it influences the number samples that are required to approximate the vicinity of a particular data point. It is in particular interesting to know how the model accuracy and runtime depends on the dimensionality and the number of local vicinity samples.\n\n11. The authors should define the evaluation metrics (MSE, R-precision) in addition to citing them.\n\n12. How did the authors choose the interaction sets X_I in equation (3) and (4)? How many MLPs (functions g(.)) did the authors fit to learn phi(x)? Is the number of MLPs the same for LIME and Mathe? Otherwise the performance gain of Mathe over LIME can also be attributed the increased number of models and model parameters (ensemble size). \n\n13. What is the average training time of Mathe and baseline models on the different datasets?\n\nSection 5.2.2\n-----------------\n14. How did the authors choose sigma (0.4, 6, 0.4) for the different datasets?\n\n15. How did Amazon medical turk users evaluate Mathe vs. LIME interactions? Were they given for each sentence the best Mathe and best LIME interaction and asked to decide which one is better? Figure 4 should be more clearly described in the caption. The sentence ‘The result of this experiment is that the majority of preferred explanation …’ is unclear and unjustified by only showing one example in Figure 4.\n\nSection 5.2.3\n-----------------\n16. The authors should discuss figure 6. The results indicate that neither LIME nor Mathe is able to clearly identify the object of interest, e.g. the water buffalo, and interactions, e.g. between the buffalo and water.\n\nSection 5.3\n---------------\n17. The sentence ‘... the presence of a French word for “this” or “that”, cet, which …’ is unclear. I suggest to give an example to illustrate which interactions are supposed to be detected. The modification of the Transformer model and the reason why this is necessary is unclear. Overall, I find this evaluation unclear and insufficient since it only applies to a particular interaction.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}