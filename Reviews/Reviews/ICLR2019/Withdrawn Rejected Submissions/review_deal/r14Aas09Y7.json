{
    "Decision": {
        "metareview": "The paper introduces a GAN architecture for generating small patches of an image and subsequently combining them. Following the rebuttal and discussion, reviewers still rate the paper as marginally above or below the acceptance threshold.\n\nIn response to updates, AnonReviewer3 comments that \"ablation experiments do make the paper stronger\" but it \"still lacks convincing experiments for its main motivating use case: generating outputs at a resolution that won't fit in memory within a single forward pass\".\n\nAnonReviewer2 points to the major shortcoming that \"throughout the exposition it is never really clear why COCO-GAN is a good idea beyond the fact that it somehow works. I was missing a concrete use case where COCO-GAN performs much better.\"\n\nThough authors provide additional experiments and reference high-resolution output during the discussion phase, they caution that these results are preliminary and could likely benefit from more time/work devoted to training.\n\nOn balance, the AC agrees with the reviewers that the paper contains some interesting ideas, but also believes that experimental validation simply needs more work, and as a result the paper does not meet the bar for acceptance.\n",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "metareview: interesting idea, experiments could be improved"
    },
    "Reviews": [
        {
            "title": "Interesting Ideas, but not validated",
            "review": "The paper describes a GAN architecture and training methodology where a generator is trained to generate \"micro-\" patches, being passed as input a latent vector and patch co-ordinates. Micro-patches generated for different adjacent locations with the same latent vector are combined to generate a \"macro\" patch. This \"macro\" output is trained against a discriminator that tries to label this output as real and fake, as well as predict the location of the macro patch and the value of the latent vector. The generator is trained to fool the discriminator's label, and minimize the error in the prediction of location and latent vector information.\n\n- The paper proposes a combination of different interesting strategies. However, a major drawback of the method is that it's not clear which of these are critical to the quality of the generated output.\n\n- Firstly, it isn't clear to me why the further breakdown of the macro patch into micro patches is useful. There appears to be no separate loss on these intermediate outputs. Surely, a DC-GAN like architecture with sufficient capacity would be as well able to generate \"macro\" patches. The paper needs to justify this split into micro patches with a comparison to a direct architecture that generates the macro patches (everything else being the same). Note that applications like \"interpolation\" of micro patches could be achieved simply by interpolating crops of the macro patch.\n\n- As a means of simply producing high-resolution images, it appears that \"PGGAN\" performs better than the proposed method. Therefore, the paper doesn't clearly explain the setting when the division into patches produces a better result. It is worth noting that the idea of applying \"local\" critics (i.e., discriminators acting on sub-regions) isn't new (e.g., Generative Image Inpainting with Contextual Attention in CVPR 2018). What's new is the proposed method's way of achieving consistency between different regions by providing the 'co-ordinate' of the patch as input (and seeking consistency in the latent vector through a loss)---rather than applying a discriminator at a coarser level on the downsampled image. But given the poorer performance compared to PGGAN, it isn't clear that there is a an advantage to this approach.\n\nOverall, the paper brings up some interesting ideas, but it doesn't motivate all its design choices, and doesn't make a clear argument about the settings in which the proposed method would provide an actual advantage.\n\n===Post-rebuttal\n\nI'm upgrading my score from 5 to 6, because some of the ablation experiments do make the paper stronger. Having said that, I still think this is a borderline paper. \"Co-ordinate conditioning\" is an interesting approach, but I think the paper still lacks convincing experiments for its main motivating use case: generating outputs at a resolution that won't fit in memory within a single forward pass. (This motivation wasn't clear in the initial version, but is clearer now).\n\nThe authors' displayed some high-resolution results during the rebuttal phase, but note that they haven't tuned the hyper-parameter for these (and so the results might not be the best they can be). Moreover, they scale up the sizes of their micro and macro patches so that they're still the same factor below the full image. I think a version of this paper whose main experimental focus is on high-resolution data generation, and especially, from much smaller micro-macro patches, would make a more convincing case. \n\nSo while the paper is about at the borderline for acceptance, I do think it could be much stronger with a focus on high-resolution image experiments (which is after all, forms its motivation).\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "interesting idea that surprisingly works",
            "review": "+ Interesting and novel idea\n+ It works\n- Insufficient ablation and comparison\n- Unclear what the advantages of the presented framework are\n\nThe presented idea is clearly new and a deviation from standard GAN architectures. I was surprised to see that this actually produces visually coherent results. I was certain that it would create ugly seams at the boundary. For this reason I like the submission overall.\n\nHowever, the submission has two major short-comings. First, throughout the exposition it is never really clear why COCO-GAN is a good idea beyond the fact that it somehow works. I was missing a concrete use case where COCO-GAN performs much better.\n\nSecond, I was missing any sort of ablation experiments. The authors only evaluate the complete system, and never show which components are actually needed. Specifically, I'd have liked to see experiments:\n * with/without a context model Q\n * with a standard discriminator (single output or convolutional), but a micro-coordinate generator\n * with a macro-block discriminator, but a standard generator\n * without coordinate conditioning, but different Generator parameters for each coordinate\n\nThese experiments would help better understand the strength of COCO-GAN and how it fits in with other GAN models.\n\nMinor:\nThe name of the method is not ideal. First, it collides with the COCO dataset. Second, it does not become clear why the proposed GAN uses a \"Conditional Coordinate until late in the exposition. Third, the main idea could easily stand without the coordinate conditioning (see above).",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting idea but needs more work",
            "review": "This paper proposes to constrain the Generator of a WGAN-GP on patches locations to generate small images (“micro-patches”), with an additional smoothness condition so these can be combined into full images. This is done by concatenating micro-patches into macro patches, that are fed to the Discriminator.  The discriminator aims at classifying the macro-patches as fake or real, while additionally recovering the latent noise used for generation as well as the spatial prior.\n\nThere are many grammar and syntax issues (e.g. the very first sentence of the introduction is not correct (“Human perception has only partial access to the surrounding environment due to the limited acuity area of fovea, and therefore human learns to recognize or reconstruct the world by moving their eyesight.”). The paper goes to 10 pages but does so by adding redundant information (e.g. the intro is highly redundant) while some important details are missing  \n\nThe paper does not cite, discuss or compare with the related work “Synthesizing Images of Humans in Unseen Poses”, by G. Lalakrishan et al. in CVPR 2018. \n\nPage. 3, in the overview the authors mention annotated components: in what sense, and how are these annotated?\nHow are the patches generated? By random cropping? \n\nStill in the overview, page 3, the first sentence states that D has an auxiliary head Q, but later it is stated that D has two auxiliary prediction heads.  Why is the content prediction head trained separately while the spatial one is trained jointly with the discriminator? Is this based on intuition or the result of experimentations?\n\nWhat is the advantage in practice of using macro-patches for the Discriminator rather than full images obtained by concatenating the micro-patches? Has this comparison been done?\n\nWhile this is done by concatenation for micro-patches, how is the smoothness between macro-patches imposed?\n\nHow would this method generalise to objects with less/no structure?\n\nIn section 3.4, the various statements are not accompanied by justification or citations. In particular, how do existing image pinpointing frameworks all assume the spatial position of remaining parts of the image is known?\n\nHow does figure 5 show that model can be misled to learn reasonable but incorrect spatial patterns?\n\nIs there any intuition/justification as to why discrete uniform sampling would work so much better than continuous uniform sampling? Could these results be included?\n\nHow were the samples in Figure.2 chosen? Given that the appendix. C shows mostly the same image, the reader is led to believe these are carefully curated samples rather than random ones.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}