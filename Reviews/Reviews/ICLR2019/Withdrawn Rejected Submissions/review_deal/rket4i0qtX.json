{
    "Decision": {
        "metareview": "The paper studies an narrowly focused but interesting problem -- if the Visual Question answering model “FILM” from Perez et al (2018) is able to decide if “most” of the objects have a certain attribute or color. While the work itself is appreciate by the reviewers, concerns remain about the conclusion being limited in scope due to the synthetic nature of the data, and the analysis fairly narrow (a single model with a single very specific task). We encourage the authors to use reviewer feedback to make the manuscript stronger for a future deadline. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "meta-review"
    },
    "Reviews": [
        {
            "title": "Strong, hyper-focused contribution to VQA understanding",
            "review": "This paper studies how the FiLM visual question answering (VQA) model answer questions involving the quantifier ‘most’. This quantifier is chosen for study because it cannot be expressed in first order logic (i.e., high-order logic is required), and secondly because there are two different algorithmic approaches to answering questions involving ‘most’ (cardinality-based strategy and pairing-based strategy). Experiments are performed by designing abstract visual scenes with controlled numerosity and spatial layouts, and applying methodologies from pyscholinguistics. The paper concludes that the model learns an approximate number system (ANS), consistent with the cardinality-based strategy, with implications for understanding the conditions under which existing VQA models should perform well or badly (and possibly for improving VQA models). \n\nStrengths:\n- The research question is clear and well-conceived. In general, it seems there are significant opportunities for better collaboration between the experimental psychology and machine learning communities, and this is a good example of the benefits.\n- The paper is clear, highly-focused, and well-written.\n\nWeaknesses:\n- The arguments for why the experimental evidence actually supports the existance of an approximate number system (ANS) could be made more clear. For example, the section on “Ratios andWeber fraction” argues that “these curves align well with the trend predicted by Weber’s law”, but does not explain how the experimental data would present if the alternative hypothesis (pairing-based strategy) was being used. What would the pairing-based strategy look like in Figure 6 right? Are there not significance tests that could be used to more carefully quantify the level of support for the two alternative strategies?\n- The experiments seem very similar to Wu et al. 2018, which is considered to be prior work under the ICLR guidelines. While this paper is acknowledged in the related work, it would be helpful to expand further on the relationship between these works, so the originality and contribution of this paper can be better evaluated.\n- In some ways it is not that surprising that the CNN more easily learns an approximate number system rather than a pairing-based algorithm, as the later would presumably need to learn a different convolutional filter for every possible spatial arrangement of the pairs (which would be very sample inefficient). Therefore, it might be interesting to consider, are there any circumstances under which the CNN would learn a pairing based algorithm? For example, what if the spatial configuration of the pairs was simplified, so they were always side-by-side at a fixed distance? If pairing-based algorithms emerged under simplified scenarios, this might have implications for the design of CNN filters (if we want models that are capable of learning these types of functions).\n\nSummary:\nI regard this as a good paper, with a couple of weakness that could be addressed as indicated.",
            "rating": "7: Good paper, accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting direction and discussion to study the relationship “most” with limited experimental evaluation focusing on a single model.",
            "review": "Problem and contribution:\nThe paper studies if the Visual Question answering model “FILM” from Perez et al (2018) is able to decide if “most” of the objects have a certain attribute or color. \nFor this it tries to mimic the setup used to test human abilities in the study by Pietroski et al. (2009).\n\nThe main contribution of this is work is a discussion of how a model could solve the problem of deciding “most” and the study which shows that the studied model has some ability to do this. From this the paper concludes that the model is likely to have some approximate number system.\n\n\nStrengths:\n1.\tThe paper looks at a new angle to study and characterize CNN models in general, and VQA models in particular by looking into the psycholinguistic literature experimental setup studied with human subjects.\n2.\tThe paper studies different variants of controlling for different factors (e.g. pairing data points, area used, different training data and pre-trained vs. trained from scratch CNN models)\n3.\tIt is interesting to see that the models performance reasonably aligns with the curve predicted by “Weber’s law”.\n\n\nWeaknesses:\n4.\tNumber of objects vs. ratios is not disentangled: While the paper clarifies that not only a smaller number of objects are used, it would be interesting to understand if similar conclusions hold if only the same number or about the same number of total objects are used but the ratios change (at least for more extreme ratios, 1:2, this seems to be the case as they achieve 100% accuracy).\n5.\tThe paper only focusses on a single VQA model (FILM) which limits the understanding if this observation is specific to this model; what about other models such as the one from Hudson & Manning (2018), or Relation Networks (Santoro et al) or even simpler baselines: A system which two attention mechanisms (without normalizations) which are sum pooled and then compared would sort of explicitly encode the idea of the APN system. It would be valuable to compare them to see how different systems (can) solve this task. I would expect that the architecture favors certain capabilities; e.g. Relation Networks might lead more to a paring-based strategy. Or Zhang et al. (2018) might be able to exploit explicit counting to solve the task.\n6.\tThe “most” ability or APN ability seems to be highly related to accumulation in neural networks. The paper FiLM uses global max-pooling and I am wondering if this affect this ability. \n7.\tThe study is only performed on symbols which a very large training set (given the difficulty of the problem) and it not clear how well this generalizes to real images or scenarios with less training data. \n7.1.\tMaybe beyond the scope of this work, but it would be interesting to understand how much training data different models need to obtain this capability.\n8.\tFor evaluation: Are there distractors, i.e. elements which don’t belong to set A or B? If not, how would distractors affect it.\n9.\tClarity: \n9.1.\tThe equation between equation (1) and (2) misses a number [I will call it 1.5 for now]\n9.2.\tIn formula (1.5) “<=>” seems to be used at different levels (?) it would be good to use brackets to make clear which level “<=>” refers to.\n\nMinor:\n10.\tThe title suggests that the paper studies multiple VQA models but only a single model is studied.\n\nConclusion:\nThe paper looks into an interesting direction to study CNN models but has some limitations including studying only a single VQA model type, limited to artificially generated images. \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting analysis of quantifier interpretation in a VQA model, but the theoretical discussion is unsatisfying",
            "review": "The paper analyzes the strategy that a visual question answering model (FiLM) uses to verify statements containing the quantifier \"most\" (\"most of the dots are red\"). It finds that the model is sensitive to the ratio of objects that satisfy the predicate (that are red) to objects that do not; as the ratio decreases (e.g. 10 red dots compared to 9 blue dots), the model's performance decreases too. This is consistent with human behavior.\n\nStrengths:\n* The introduction lays out an ambitious program of comparing humans to deep neural networks.\n* The experimental results are interesting (although of modest scope) and support the hypothesis that the network is not counting the objects but rather is using an approximation that is sensitive to the ratio between the red and non-red items.\n\nWeaknesses:\n* The architecture of the particular model is described very briefly, and at multiple points there’s an implication that this is an investigation of “deep learning models” more generally, even though those models may vary widely. While the authors are using an existing model, they shouldn't assume that the reader has read the paper describing that model. I would like to see more discussion of whether it is at all plausible for this model to acquire the pairing strategy, compared to alternative VQA models (e.g., using relation networks).\n* I found it difficult to follow the theoretical motivation for performing the work. The goal seems to be to test whether the network is performing the task in way that \"if not human-like, at least is cognitively plausible\". I don't understand what is meant by cognitively plausible but not human-like; perhaps an example of a cognitively implausible mechanism would help clarify this issue. Later in the same paragraph, the authors argue that \"in the case of a human-centered domain like natural language, ultimately, some degree of comparability to human performance is indispensable\". This assertion is not justified, and seems surprising to me; we have very useful natural language processing systems that do not perform in a way that is comparable to humans (the hedge \"some degree of\" is really neither here nor there). In general, I don't understand why we would want a visual question answering system that returns approximate answers -- isn't it better to have it count exactly how many red dots there are compared to non-red dots?\n* The authors assume that explicit counting is not \"likely to be learned by the 'one-glance' feed-forward-style neural network\" evaluated in the paper. What is this statement based on? Why would a \"one-glance\" network have trouble counting objects? (What is a “one-glance network”?)\n* Another vague concept that is used without clarification: it is argued that if the network implements something like the Approximate Number System, that shows that it can \"learn and utilize higher-level concepts than mere pattern matching\". What is \"pattern matching\" and how does it differ from \"higher-level concepts\"?\n* Why would the pairing strategy in a neural network be affected by the clustering of the objects? I understand why a human who needs to saccade back and forth between the two groups of objects might lose track of the objects that have been paired so far, but I don't understand why that would affect the architecture in question.\n\nMinor comments:\n* Is the definition of \"most\" really a central piece of evidence for \"the apparent importance of a cardinality concept to human cognition\"? Our ability to count seems sufficient to me. Perhaps I'm not understanding what the authors have in mind here.\n* Please use the terms \"interpretation\" and \"verification\" consistently.\n* \"One over the other strategy\" -> \"one strategy over the other\".\n* The paper is almost 9 pages long, but the contribution does not appear more substantial than a standard 8-page submission.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}