{
    "Decision": {
        "metareview": "This paper explores an approach to testing the information bottleneck hypothesis of deep learning, specifically the idea that layers in a deep model successively discard information about the input which is irrelevant to the task being performed by the model, in full-scale ResNet models that are too large to admit the more standard binning-based estimators used in other work. Instead, to lower-bound I(x;h), the authors propose using the log-likelihood of a generative model (PixelCNN++). They also attempt visualize what sort of information is lost and what is retained by examining PixelCNN++ reconstructions from the hidden representation at different positions in a ResNet trained to perform image classification on the CINIC-10 task. To lower-bound I(y;h), they perform classification. In the experiments, the evolution of the bounds on I(x;h) and I(y;h) are tracked as a function of training epoch, and visualizations (reconstructions of the input) are shown to support the argument that color-invariance and diversity of samples increases during the compression phase of training. These tests are done on models trained to perform either image classification or autoencoding. This paper enjoyed a good discussion between the reviewers and the authors. The reviewers liked the quantitative analysis of \"usable information\" using PixelCNN++, though R2 wanted additional experiments to better quantify the limitations of the PixelCNN++ model to provide the reader with a better understanding of plots in Fig. 3, as well as more points sampled during training. Both R2 and R3 had reservations about the qualitative analysis based on the visualizations, which constitute the bulk of the paper. Unfortunately, the PixelCNN++ training is computationally intensive enough that these requests could not be fulfilled during the ICLR discussion phase. While the AC recommends that this submission be rejected from ICLR, this is a promising line of research. The authors should address the constructive suggestions of R2 and R3 and submit this work elsewhere.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Neat approach, but more validation is needed"
    },
    "Reviews": [
        {
            "title": "Empirical evaluation of information retained across layers of classification ResNets using pixelCNN decoders.",
            "review": "\n* Summary: \n\nThis work is an empirical study of the relevance of the Information Bottleneck principle as a way of understanding deep-learning. It is carried out in the setting of realistically sized networks trained on natural images dataset. This is, in spirit, a meaningful and sensible contribution to the ongoing debate. Being a largely empirical contribution, its value hinges on the exhaustivity and clarity of the experiments carried out. As it stands, I believe that these should be, and can be, improved. Details to support this opinion are given below. A summary of my expectations is given at the end.\n\n\n* Summary of the approach and significance:\n\nThe IB principle relies on estimating the mutual information between i) the input and an intermediate layer, I(x,h), and an intermediate layer and the output, I(h, y). Previous work has relied on binning strategies to estimate these quantities. This is not applicable in a real-sized problem such as classification of natural images with deep networks. This paper proposes to invert a first deep model using a second, generative, model which must reconstruct the input of the first given some intermediate layer. The information progressively discarded by the first network should be modelled as uncertainty by the second. This yields a lower bound on the mutual information, with a tightness that depends on the expressivity of the generative model.\n\nI believe the goal to be meaningful and a valuable contribution: going forward, testing this assumption in realistic setting is essential to the debate. The proposed approach to do this seems sensible to me. It is similar to cited work by Nash et al., however both works are concurrent and so far unpublished and should be considered as complementary point of views on the same problem.\n\nPartial conclusion: The goal is meaningful and sensible.\n\n* Quality of writing.\n\nIn sections 1, 2 and 3, the motivation is clear and contains relevant information. I feel it could be polished further. In particular, some redundant information could be condensed. The introduction to the IB principle, though understandable, could be improved. Here are some opinions:\n\n>> Paragraphs 3 and 4 of 1.0: A reference to M. Saxe et al. could already be made there: it is a major 'opponent' in the debate to which you are empirically contributing.\n\n>> In paragraph 1.1: Points 1) and 2) are redundant. So are 3) and 4). Paragraph 1.1 as a whole is largely redundant with the previous paragraph, these could be collapsed. \n\n>> In section 2: I feel that the main intuitions of the encoder / decoder distributions (I(y,h) / I(x,h)), the information plane, and the optimal bottleneck representations (Sections 2.1 to 2.3 of Schwartz-Ziv & Tishby) could be better conveyed in 2, though I understand the need for brevity. \n\n>> Related works: Descriptions of related works could be condensed. On the other hands, the points of these papers that you contradict in you experiment section could be explicitly mentioned again there.\n\n>> End of section 3, section 4: The fact that estimation of the MI by traditional means is not applicable in your setting is repeated many times throughout the paper, in noticeably rapid succession in that region. Some mentions should be removed.\n\t\n### More minor points:\n\n>> Paragraphs 2 of 1.0:\n- 'the extraction of typical abstract properties...' this statement is vague and thus debatable: the channel-wise mean in RGB space, for instance, is not an especially abstract property. \n- Reference is made to Zhang et al. to justify the need for more analysis of generalization in deep-learning. This paper can be considered controversial. Mention could be made of other works, for instance about the inaplicability of traditional generalization bounds and attempts to improve them.\n\n>> Pseudo code algorithm.\n- Could be summarized in the main body and pushed to the annex.\n\n>> The choice of pixCNN as a generative model could be discussed more. There are some good reasons to prefer this to L2 regression for instance. \n\nPartial conclusion: The description of the method contains relevant information and is functional, but the writing could be improved.\n\t\n\t\n* Experimental results.\n\n> The contribution and novelty of this paper is largely empirical. Therefore the experimental results should be held to a high standard of clarity and exhaustivity.\n\n\n*** The choice of dataset:\nThe experimental setup seems to be fair in terms of dataset / split chosen: the abundance of data for the three steps (encoding, decoding, evaluation) is a notable strength.\n\n*** The quality of the lower bound: Uncertainty when reconstructing the image may come from the fact that information has been discarded. Variance may also come from the pixCNN++, which is imperfect. You mention this (paragraph 4.1) but do not take experimental steps to measure it. Please consider reporting the performance of your generative model i) without conditioning, ii) conditioned on one-hot ground truth labels, and optionally iii) on grayscale/downsampled versions of the image without otherwise modifying the training setup. These values will give the reader an idea of the significance of variations in MI measured and give a 'scale' to your figures, strengthening your claims.\n\n*** The evolution of compression *accross iterations* for a fixed layer\nI will focus on the classification setting for now.\n\nQualitatively: Figures 1, 4 and 5 do not convince me that a meaningful evolution in the type of information discarded *across training iterations* can be observed visually. In figures 1 and 4, the network seems to learn invariances to some coloring, and its preferred colours vary across iterations. Beyond that I cannot see much, except maybe for column (f) of figure 4, despite your claim in section 2, paragraph 2.\n\nQuantitatively: Curves in Figure 2 a) are more convincing, though a notion of scale is missing, as already discussed. The evolution of I(y; h) across iterations is very clear, in Figure 2 a) and especially 3 a). The evolution of I(x, h) much less so. h3 and h4 do not seem to show anything meaningful. In h2 the decrease in I(x, h) is supported by only 2 points in the curve (epoch 10 to epoch 100, and epoch 100 to epoch 200, figures 2a and 3c). Epochs displayed are also incoherent from one curve to the next (epoch 15 is missing for h2 in fig 3c) which raises suspicion. It appears important to i) display more points, to show that this is not just noise and ii) track more layers to confirm the trend, supported by a single layer so far (see next paragraph). I understand that each of these points require training of a generative model, but I feel it is necessary to make reliable conclusions.  \n\nMinor: In figure 2, epochs should be added as labels to the colours.  \n\n*** The evolution of compression *across layers* for a fixed iteration\n\t\t\nConversely, the evolution of the MI across layers is very convincingly demonstrated, and I feel this is perhaps the main strength of this paper. All curves display consistent trends across layers, and Figure 5 qualitatively displays much more invariance to pose, detail, etc than Figure 4. This is interesting, and could be made more central: i) by making a figure that compares samples across layers, for a fixed iteration, side by side. \n\nOn the downside, I believe it is important to track more layers, as it is to me the main interest of your results. The second paragraph of section 5 does not give a good idea of the spread of these layers to someone not familiar with the resnet architecture used. For example, the penultimate layer of the network could be used (the layer at which the most compression is to be expected).\n\n*** On the auto-encoder experiments.\n\n> Little detail is given about the way the auto-encoder is constructed. In particular, one expects the type of bottleneck used (necessary so that the network does not learn the identity function) to have large impact on the amount of information discarded in the encoding process. This dependency is not discussed. More crucially, experiments with different types / strength of bottleneck are not given, and would, in my opinion, be key to an analysis of this dependency through the IB principle. \n\n> Furthermore, no qualitative analysis is provided in this setting.\n\n> Without these additions, I find the Auto-encoding setting an unconvincing distraction from the main contribution of this paper. \t\n\n***  main avenues of improvement:\n\t\t\n> Two kinds of progression in compression are demonstrated in your paper: across layers, and across iterations. \nAs it stands, results evidence the former more convincingly than the latter, both qualitatively and quantitatively.\nI believe results could be presented in a way that clearly takes better advantage of this, as I will detail further.\nMore data points (across layer and epochs) would be beneficial. I feel that the auto-encoder setting, as it stands, is a distraction.\nI would find this paper more convincing if experiments focused more on showing how layers progressively discard information, and less on the 'training phases' that are so far less clear.\n\n*** Additional comments\n\nThe following are a number of points that would be worthwhile to discuss in the paper\n\n> As it stands, it seems the line of reasoning and experimental setup seems to rely on the chain-structured nature of the considered neural net architecture. Can the same line of reasoning be applied to networks with more general computational graphs, such as dense-nets [a], mulit-scale denseness [b], fractal nets [c] etc.\n\n[a] Huang, G.; Liu, Z.; van der Maaten, L. & Weinberger, K. Densely connected convolutional networks CVPR, 2017\n[b] Huang, G.; Chen, D.; Li, T.; Wu, F.; van der Maaten, L. & Weinberger, K. Multi-Scale Dense Networks for Resource Efficient Image Classification ICLR, 2018\n[c] https://arxiv.org/abs/1605.07648\n\n> Why is it that earlier layers are estimated to have larger MI with the target y than later layers before convergence? Sure, later layers compress certain information about the input x, which could be informative on the response variable y. But since the MI estimate for early layers depends on the same network architecture as the one used to compute the later layers from the early ones, the result seems counter intuitive. See paragraph \"forward direction\" in section 4.1.\n\n> The orange curve in fig 3a estimating I(x;y) is not commented upon. How was it obtained, what is its relevance to the discussion?\n\n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An empirical study with specious results",
            "review": "## Summary\n\nThis paper is an empirical study which attempts to test some of the claims regarding the information bottleneck principle applied to deep learning. To estimate the mutual information (I(x; h) and I(y; h)) in neural networks, the authors define a lower bound on the MI. Then a PixelCNN++ model (for I(x; h)) and a partially frozen classifier (for I(y; h)) are used to compute the MI during classifier and autoencoder training. For both tasks, the authors report the mutual information between hidden layers and input training data first increase for a while and then decrease. The generated images conditioned on hidden layers by the PixelCNN++ were shown to demonstrate the fitting and compression of data in a visual and intuitive fashion.\n\nIn general, the paper is well-written and organized. The idea behind the paper is not novel. Shwartz-Ziv & Tishby (2017) and Nash et al. (2018) also attempt to test the information bottleneck principle by estimating the mutual information. The results of this paper are specious and hard to be explained. \n\n## Issues with the tightness of the lower bound\nThe tightness of the lower bound is dependent on the KL divergence between the true conditional distribution p(x|h) and the approximating distribution q(x|h). Does the adopted PixelCNN++ is good enough to approximate the true conditional distribution? There is not any discussion.\n\n## Issues with the results of autoencoder\nThe decrease of the mutual information in autoencoder training is very specious. Since the decoder part of autoencoder should generate better and better images during the training process, does it mean that the PixelCNN++ was worse? Does it imply that the optimization of the PixelCNN++ has some unknown problems?\n\n## Issues with the connection between this paper and Nash et al. (2018)\nThese two paper have used the same lower bound and the same PixelCNN++ for estimating the mutual information. The observations are also similar. Both of these papers found the mutual information between inputs and network layers decreases over the training. The differences of these two papers are the adopted neural networks and the dataset, which are kind of minor.  \n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting empirical work on compression in Resnets with partially inconclusive results",
            "review": "-> Summary\n\nThe authors propose to extend the analysis of Shwartz-Ziv & Tishby on the information bottleneck principle in artificial neural network training to realistic large-scale settings. They do so by replacing otherwise intractable quantities with tractable bounds in forms of classifiers for I(y;h) and Pixel CNNs for I(x;h). In conclusion, they observe two phases during training, one that maximizes mutual information between input and hidden representation and a second one that compresses the representation at the end of training, in line with the predictions from toy tasks of Shwartz-Ziv & Tishby.\n\n-> Quality\n\nThe paper is very well written, all concepts are well-motivated and explained.\n\n-> Significance\n\nThe main novelty is to replace intractable quantities in the analysis of the information bottleneck with tractable bounds in form of auxiliary models. The idea is neat and makes a lot of sense. On the other hand, some of the results and the bounds themselves are well-known and can thus not be considered novel. The main contribution is thus the empirical analysis itself and given some overly confident claims on qualitative results and missing ablation on the quantitative side, I am not convinced that the overall results are very conclusive.\n\n-> Main Concerns\n\nThe authors make a lot of claims about the qualitative diversity of samples from deeper layers h4 of the network as compared to h1 and h2. However, I do not agree with this. When I look at the samples I see a lot of variations early in training and also in layers h1 and h2. The difference to h4 seems marginal at best and not as clear cut as the authors present it. Thus, these claims should be softened.\n\nIn figure 1 I tend to say that samples at epoch 1 are more varied than at epoch 200. In figure 5 (b) seems pretty color invariant and not only (f) as claimed. In fact (f) seems pretty stable and consistent to me.\n\nThe bound in equation (2) might be quite loose, depending on the quality of the classifier or pixel CNN. Even though there is no way to test this, it should be discussed.\n\nWhat is the effect of weight decay here? I suspect that weight decay plays a crucial role in the final compression phase observed in e.g. figure 3 (c), but might not be a necessary condition to make the network generalize. An ablation experiment verifying or falsifying this statement would be important to conduct and without it I am not convinced that the shown curves are conclusive.\n\n-> Minor\n\n- You seem to use a weird math font, is this on purpose? It does not seem to be the ICLR standard.\n- The bound in equation (2) is a standard variational bound and has been used many times, the authors make it sound like it is their contribution. You should maybe cite basic work and recent work on variational information bottleneck here.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}