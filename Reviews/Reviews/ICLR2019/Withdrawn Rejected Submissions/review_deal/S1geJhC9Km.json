{
    "Decision": {
        "metareview": "All reviewers agree to reject. While there were many positive points to this work, reviewers believed that it was not yet ready for acceptance.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Meta-Review for interpretable predictive models paper"
    },
    "Reviews": [
        {
            "title": "The paper does not solve the question it proposed",
            "review": "The paper describes a question about discretize continuous features or group discrete features in the preprocessing step, which they call feature quantification. It considers that a joint training of feature quantification and a discriminative model can lead to a better performance than treating feature quantification as a preprocessing step. \n\nThis paper has many typos, grammar mistakes and question marks, which make it hard to follow. The question proposed is simple and easy to understand. However, I don't convinced by the solution in this paper. Since it is a hard optimization question, the authors proposed a relaxation approach in section 3.1. I do not think that exp(a+bx) is able to approach step functions since exp(a+bx) is monotone. I think Figure 1 is misleading. For grouping discrete features, the author propose to use exp(\\alpha_{x_j, j}^h) and hoping that some \\alpha parameters can be optimized to be equal, which is too simple. The exponential transformation here does not have an effect. It is more interesting to consider how to add some constraints. For example, if the discrete feature is ordinal, how one can assure that the grouped discrete feature is still ordinal. The relaxation in this paper is too much without handling any interesting constraints and the proposed exp(a+bx) can not approach step functions. The authors do not provide a good way to select number of cut points, which I think is a hard but interesting question.\n\nThe work also lacks value in literature review, optimization and experiments.",
            "rating": "2: Strong rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The presentation is unclear ",
            "review": "This paper presents a feature quantization technique for logistic regression, which has already been a common practice in \n many finance applications.  The text feels rushed. From the current presentation, I find it difficult to understand what is the motivation of adopting the proposed relaxation of the optimization method, and how is the neural network-based estimation strategy connected to the logistic regression model. It seems the difference lies in the parameterized nonlinear transformation such that the cutting points can be somehow optimized.  The quality of the experiments performed is way below the expectation for ICLR. Although numerical experiments are performed on both simulated data and credit scoring data, it is still unclear whether the proposed method has superiority over competitors.  \n\nQuestion: In the test phase, how would the proposed method handle features that are not seen in the training phase? ",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "many typos",
            "review": "i take reviewing very seriously, and it often takes hours per paper. this paper, however, has many typos, grammatical errors, and seems to have been submitted last minute.  therefore, i have read the paper quickly.\nthat said, i do not understand the results.\nclearly, many discretization methods have previously been described, as alluded to by citing the taxonomy paper on the subject.  the authors state they have developed a better approach.  however, i do not see a comparison to the state of the art in the simulations, and i do not follow the results of Table 2, which columns correspond to which particular algorithms? in either case, the proposed approach does not seem to improve the empirical results, nor have theoretical guarantees, so i am not particularly impressed with the results either.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}