{
    "Decision": "",
    "Reviews": [
        {
            "title": "Misleading title and not novel enough.",
            "review": "The paper proposes to use a gabor and schmid operators as first layer in a CNN\nand to do gradient descent to their parameters.\nI think that the title is over-selling and that ultimately misleads the reader.\n\nClarity needs to be improved and the text should be polished, it contains lot \nof repetitions for example.\n\nIn the contribution the author mention a new framework, I think it is better to\nsay it is a different layer for convolutional networks as the computational\nparadigm is exactly the same. \n\nIn the related work the authors try to motivate their approach but I am afraid \nin a too hand-wavy manner. For example for gabor it is written that is based \non human vision. Even if this has been shown, to some degree, by Hubel and Wiesel\nwhy would this work for a CNN that has nothing to do with the human vision?\n\nIn Section 3.2.1 it is mentioned that gabor may be an optimal feature extractor,\nwhat does it mean? Optimal with respect to what? Overall the section is too \nvague and does not seem, frankly, to make any good point.\n\nThe two operators proposed in the work are indeed differentiable, but use \nperiodic functions and divisions that could trigger numerical issues and instabilities\nduring training. This should be addressed in the text.\n\nI find the many definitions, theorems and corollaries overwhelming considering\nwhat is in the end proposed.\n\nExperiments are too weak and not sufficient to draw any conclusions. \nIn 5.1 please do at least 10 runs and report mean and variance.\nAdversarial stability is misleading as it has nothing to do with adversarial \nexamples but it is rather an ablation study.\nThe experiment on generalization is using the test set for training to make\nuse of small amount of data, but this makes things completely not comparable. \nUse rather a random subset of the training set as it is customary to do.\n\nOverall I don't find the motivation of this strong enough, in fact DL research \nseems to move in the opposite direction, and results are not convincing.",
            "rating": "2: Strong rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Review for the paper Geometric Operator Convolutional Neural Network",
            "review": "I appreciate the responses authors provided to my comments. Many of my main concerns have been addressed there. \n\nHaving said this, I do not consider the contribution of this paper substantial given the fact the a more involved framework (CKN) has been already known. I honestly believe that the findings of the authors are interesting but doubt that we use Gabor features in the first layer of CNNs from now on. \n\nIf the paper is accepted, I kindly encourage the authors to reflect their answers to my comments in their work. For the sake of completeness, I have incorporated my comments and authors responses below.\n\nGood luck\n\n-------------------------------------------------------------------------------------------------------------\nI would like to get my head around a few points and appreciate clarifications on \n\n- To me the title is a bit misleading, especially the word geometric seems a bit far-stretched. can you explain why geometric is essential here?\n\n- In experiments, given that the Gabor filters have less tunable parameters, did the authors keep the number of channels similar to their CNN counterparts or increased the number of channels (Gabor filters) to match the number of tunable parameters in CNNs?\n\n- have authors evaluated their solution on large scale problems, say image classification on image-net?\n\n- what will happen if more than 1 layer of Gabor filters is considered? I am curious to know whether the performance decreases or not\n\n- how is your proposal different from previous studies where learning the parameters of a kernel function (e.g., CKN by Mairal et al.) has been discussed? I am not very much convinced that the proposed approach is brand-new.\n\n- can you explain how you initialize the Gabor filters? Can you also report [min,max] accuracies over say 10runs if random initialization is used?   \n\n\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\nRe: Some clarifications  \nICLR 2019 Conference Paper273 Authors\n25 Oct 2018ICLR 2019 Conference Paper273 Official CommentReaders:  Everyone\nComment: Q1 feedback: \n  The title of our paper is originated from geometric operators in traditional image process algorithms. Geometric properties in geometric operators, such as symmetry, account for the word formation. The kernels in the first convolutional layer in AlexNet \\cite{krizhevsky2012imagenet} show similarity with Gabor operator kernels in vision, and there is redundancy of parameters in CNNs, which inspire us to combine geometric operators in the traditional image process algorithms into CNNs.\n\nQ2 feedback:\n  In our experiments, the output channel number of the first convolutional layer keeps the same between common CNN and the corresponding GO-CNN. Therefore, the number of trainable parameters of common CNN is larger than that of the corresponding GO-CNN. There is theoretical guarantee in our article that, under less parameter degrees of freedom, the approximation ability of the Geometric Operator Convolutional Network is not worse than that of common CNN, and the parameter redundancy of common CNN is further verified.\n\nQ3 feedback:\n  The main purpose of this article is to validate and analysis the potential of the proposed architecture in it, and experiments on large scale dataset are not considered in this article. We are going to study applications by the proposed architecture on large scale datasets in the future. \n\nQ4 feedback:\n  One of the motivations in this paper is to observe that the visualization of the first layer of the AlexNet convolution kernel has certain geometric characteristics, such as symmetry and volatility, and parameter redundancy. The visualization of other layer convolution kernels does not show obvious geometric characteristics (\\cite{krizhevsky2012imagenet} ). In addition, in the MNIST experiment, the experimental effect of replacing the two-layer ordinary convolution kernel with the geometric operator kernel is the same as that of replacing the first-layer convolution kernel. At the same time, in order to reduce the computational complexity and the convenience of theoretical analyses, only the results of replacing one layer are considered in this paper, and the research of replacing multiple layers will be carried out in the future.\n\nQ5 feedback:\n  There are many related studies that have similarities with the method presented in this article, which are discussed in the part of related work. As for CKN mentioned, there are at least three differences with the GO-CNN proposed in this article:\n1. The number of trainable parameters about convolution kernels is unchanged in CKN comparing to common CNN, however that of the corresponding GO-CNN is smaller.\n2. CKN calculates the convolution kernel by approximating the Gaussian kernel with linear functions, and GO-CNN directly learn proper parameters of the geometric operator functions from training samples to get the convolution kernel.\n3. CKN uses an energy function as loss for better performance in approximation, and GO-CNN uses directly cross entropy as loss for better performance in classification.\nTherefore, GO-CNN proposed in this article is very different from CKN, and other similar studies discussed in the related work section.\n\nQ6 feedback:\n  In this article, we use random uniform initializer to initialize the five parameters in Gabor kernel function, wherein \\phi_{init} ~ U(-\\pi, \\pi), \\lambda_{init} ~ U(2, 10), \\theta_{init} ~ U(0, 2\\pi), \\sigma_{init} ~ U(0, 2\\pi), and \\gamma_{init} ~ U(0, 1).\n  The model’s accuracy rates over ten experiments on the Cifar-10/100 test set if random initialization is used are listed as following:\n1. GO-ResNet18 achieves accuracy of 95.17%±0.13% in Cifar-10 and 77.59%±0.04% in Cifar-100.\n2. GO-ResNet34 achieves accuracy of 95.77%±0.14% in Cifar-10 and 78.26%±0.03% in Cifar-100.\n3. GO-ResNet50 achieves accuracy of 94.72%±0.08% in Cifar-10 and 79.50%±0.06% in Cifar-100. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Missing many technical details and more thorough evaluation",
            "review": "This work replaces first convolutional layers with combination of Gabor and Schmidt filters with learnable parameters. However it does not provide enough technical details which would allow this work to be reproducible and the experimental section does not verify almost any of the design choices which would allow the reader to asses the main factors which lead to the obtained network performance .\n\nI do not believe that this paper is of sufficient technical quality for this conference, thus I would not recommend this paper for acceptance. I believe that the amount of changes required for addressing the following issues would require a resubmission.\n\nMainly, the text misses many technical details of the work, for example:\n- How are the derivatives of the Gabor/Schmidt filter parameters computed? Automatic differentiation? What are the resulting distributions of these parameters, considering that some of them have to be non-negative? (e.g. \\sigma for Gabor filters). How does they differ between each other after training? How are they initialised? Are the learning rates the same for each of the GO parameters?\n- What is the hit on performance when the filter parameters are initialised by hand and not trained? (e.g. the ones visualised in Figure 2 in appendix, which span the spatial frequency spectrum). What is the performance of a random initialisation?\n- What is the processing speed of the network, e.g. training time versus training time of the vanilla CNN?\n- What are the confidence intervals for the adversial stability experiment? (Table 3). The difference between the proposed algorithm and vanilla CNN are so small it might be easily a result of for example a favourable draw of the random rotations.\n- How does this method performs against other methods addressing the Conv1 approximation with fixed bases [1] or bases with learnable parameters? [2]\n\nAdditionally, it is not clear what the proof is proving as it is clear that a CNN has the ability to learn the Gabor/Schmidt filters exactly. However,  for this to hold the other way around and for the universal approximator theorem to hold a sufficient number of predefined filters would have to be used where the sufficient number of filters has no upper bound, thus reducing practicality of this proof. More trivially, without any upper bound on the number of predefined filters, one can simply use any bases (which are by definition injective) for generating the exact CNN filters which lead to a good performance. More interesting would be to show (empirically) that the predefined Gabor/Schmidt bases are more efficient for a sparse coding the manifold of CNN filters with good performance, which would have some practical implications regarding the aptness of these predefined filters.\n\n[1] Yao, Hu, et al. \"Gabor feature based convolutional neural network for object recognition in natural scene.\" Information Science and Control Engineering (ICISCE), 2016 3rd International Conference on. IEEE, 2016.\n[2] Qiu, Qiang, et al. \"DCFNet: Deep Neural Network with Decomposed Convolutional Filters.\" arXiv preprint arXiv:1802.04145 (2018).",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}