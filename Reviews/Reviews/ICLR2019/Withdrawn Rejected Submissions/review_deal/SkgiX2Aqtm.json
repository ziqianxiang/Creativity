{
    "Decision": {
        "metareview": "The presented approach demonstrates an invertible architecture for auto-encoding, which demonstrates improvements in performance relative to VAE and WAE's on MNIST. \n\nPros:\n+ R3: The idea of pseudo-inversion is interesting.\n+ R3: Manuscript is clear. \n\nCons:\n- R1,2,3: Additional experiments needed on CIFAR, ImageNet, others.\n- R1: Presentation unclear. Authors have not made any apparent attempt to improve the clarity of the manuscript, though they make their point that the method allows dimensionality reduction in their response.\n- R1, R2: Main advantages not clear.  \n- R3: Text could be compressed further to allow room for additional experiments. \n\nReviewers lean reject, and authors have not updated experiments. Authors are encouraged to continue to improve the work.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "New approach for an Invertible Architecture Autoencoder shows promise, but experiments incomplete."
    },
    "Reviews": [
        {
            "title": "Review",
            "review": "PIE extend NICE and Real NVP into situations which require having a smaller dimensionality of the latent variable (d) compared to the dimensionality of the observed variable (D), i.e. d < D. This is done by learning an extension function g(z) from R^d to R^{D-d} and then using the change of variables formula on x and [z, g(z)]. To model probabilistically the deterministic function g(z) is replaced by Normal distribution with mean g(z) and a small variance.\n\nPIE is used to build deep generative models and trained on the MNIST dataset. The authors show that the models learnt via PIE produce sharper samples than VAEs and Wasserstein autoencoders (WAEs). No comparison to real NVP is made, which should be the main baseline of comparison to answer the question of \"what is the advantage of having d < D?\". Further MNIST is no longer a good enough benchmark to evaluate deep generative models. Most representative work in this literature use CIFAR-10, downsampled Imagenet, or Imagenet at 256x256.\n\nThis work falls short of the standards of ICLR in a few ways:\n\n1. The presentation is unclear. The explanation of the extension-restriction idea is overly complicated. Further, the paper does very little to properly contextualize this work in the literature. Real NVP and flow-based models are mentioned but the proposed technique is not compared to it. The authors say they \"introduce new class of likelihood-based Auto-Encoders\", but this is false as far as I understood. The technique is not even an autoencoder since a separate decoder is not trained, and is obtained by exactly inverting the encoder as in real NVP.\n\n2. The experiments are weak. The samples shown are of poor quality, and on a very simplisitic dataset (MNIST). The authors compare with vanilla VAEs, but ignore more recent improvements to VAE such as VAE-IAF, flow-based models, and also autoregressive models. A heuristic is used to measure sharpness and only used to compare against VAE and WAE. Since all these models allow likelihood evaluation, likelihoods should also have been compared.\n\n3. The technique itself is a small change over real NVP and it's not clear whether this change brings any improvements or provides any insights about generative modeling.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "An interesting model without thorough evaluations  ",
            "review": "In this paper, an invertible encoding method is proposed for learning latent representations and deep generators via inverting the encoder. The proposed method can be seen as an autoencoder without the need to learn the decoder. This can be computed by inverting the encoder. To the best of my knowledge the proposed method is novel and its building blocks are described adequately. \n\nMy main questions are the following: What is the main advantage of this model? Does it make the problem of deep generative model learning tractable? If so, under what conditions?\n\nDiscussion of prior art and relevant methods is limited in the paper and it can be extended. The authors may want to consider discussing relevant work on invertible autoencoders (e.g., https://arxiv.org/pdf/1802.06869.pdf) and methods like https://openreview.net/pdf?id=ryj38zWRb which can be seen as symmetric to the proposed one in the sense that an encoderless autoencoder is learnt. \n\nThe experimental evaluation is limited. The authors should consider to compare their method with other relevant models such as those mentioned above as well as GANs and their variants. Experiments on other more complex real-world data (e.g., faces) are also needed in order to prove the merits of the proposed model.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "A nice paper but needs stronger experiment results",
            "review": "General:\nIn general, this is a well-written paper and I feel pleasant to read the paper. The paper proposed a model named Pseudo Invertible Autoencoder(PIE) which combines invertible architecture and inference model.\n\nStrength:\n1. The explanation of the paper is very clear and consistent.\n2. The idea is interesting. A lot of papers related to the inverse problem focus on perfect invertibility, but the author(s) emphasize the importance of invertible compression and relate PIE to the inference model.\n\nPossible Improvements:\n1. The experiments could have been more convincing: 1) The only competitors are VAE and WAE. 2)The only data set has been tested was MNIST data set. There are many great works mentioned in the paper and those works should also be compared in a way.\n2. The content could be more compact so that more experiments can be shown to support the paper. It seems to me there is too much explanation to previous works in the paper. \n3. The paper has 9 pages which exceed the suggestion a little bit.\n4. I am not sure if the author(s) checked the grammar of the paper carefully. I found quite few typos in the paper. Page 3: 'Rather then' should be 'Rather than' and 'As we are interested' should be as 'As we are interested in'; Page 4: 'Can me' should be 'Can be'; Page 6: 'Better then' should be 'Better than'; Fig.6 (b): Should it be '0' or 'g(z)'?\n\nConclusion:\nThis is a good and clean paper in general. It explains the related work and presents PIE with necessary details. My biggest concern is that empirical validation(experiment) is poor. As a conclusion, I tend to vote for weak rejection.\n\nMinor Suggestion:\nRefer to the conference instead of arXiv if the paper was already published.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}