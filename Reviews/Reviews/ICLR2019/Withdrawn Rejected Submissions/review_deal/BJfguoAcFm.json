{
    "Decision": {
        "metareview": "This work propose a method for learning a Kolmogorov model,  which is a binary random variable model that is very similar (or identical) to a matrix factorization model. The work proposes an alternative optimization approach that is again similar to matrix factorization approaches.  Unfortunately, no discussion or experiments are made to compare the  proposed problem and method with standard matrix factorization; without such comparison, it is unclear if the proposed is substantially new, or a reformation of a standard problem. The authors are encouraged to improve the draft to clarify the connection matrix factorization and standard factor models. ",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Clarification and comparison needed"
    },
    "Reviews": [
        {
            "title": "An interesting formulation and approach. Some concerns about pertinence and related work",
            "review": "The paper deals with an interesting problem. The presentation is clear the the approach intuitive.  However, the reviewer has some concerns about the pertinence of the approach and the relationship with related work.\n\nIt would be very helpful if the authors could contrast and compare the proposed approach (both qualitatively and quantitatively in their numerical experiments)  with methods for sparse non-negative matrix factorization. These would also lend themselves to causal interpretation.  \n\nThe need for modeling probabilities p_u,i in the key motivating applications is questionable. Indeed in both recommendation systems and gene expression datasets the observations are not readily in the form of probabilities. For instance in the experiments, the authors normalize the level of gene expressions to make is look as a probability, which by the way is very different from the i.id uniform setup considered in setting 1. For the movielens dataset, it is unclear how the data was preprocessed to obtain the observed p_ui.\n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "interesting paper but somewhat unclear",
            "review": "The paper considers a solution to a statistical association problem. The proposed solution involves a decomposition they call a kolmogorov model (what sort is not justified in any way and confused me a lot). The decomposition has two parts 1) a discrete basis function that needs to be discovered and 2) a discrete distribution over the basis elements. The define an optimization problem (2) which has a data term and some binary and simplex constraints and they propose a relaxation and decomposition of this optimization problem. They go on to claim that (mutual) causal relations can be then inferred by inspecting the representations they have learnt but they give little details on how and what impacts this distinction has in practice.  This may be obvious to a subfield expert but it is not clear to me at all. The paper is locally consistent but I have trouble understanding the contribution and placing in the broad machine learning field. \n\nI am not an expert in causality so I cannot evaluate the contribution but I can say that what interests me are section 2.2 and sec. 4-5. And they both require a lot better writing. 2.2 made things much more intuitive but i fail to see how the indicator variable annotations (action, scifi, etc.) can possibly come out of the data. I think this is an important point to support the interpretability claim. As for 4 I think there is room for intuition building there as well as limitations (e.g. what sort of inferences can be made and not etc.) Finally for 5 i find that very interesting but i find it difficult to have the right intuition about what the support condition means and how that helps in a practical setting.\n\npros:\n- causality and interpretability are major directions of research\n- seems like a valid contribution on an interesting problem\ncons:\n- the highlevel picture is relatively clear but i find important things very difficult to grasp \n- the kolmogorov model definition i find confusing but i am not an expert in causality (the introduction should give some intuition about what that is and why it is a good idea).\n- find it very hard to have a coherent picture of the limitations and assess the contributions of the paper.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "the method is succinct and interesting, some concerns about data and complexity ",
            "review": "The reviewer finds that the proposed method interesting. The model is very clean, and the implication in causal inference is significant. The writing is also clean and clear. The reviewer has several concerns:\n\n1) the algorithm seems not very scalable. In the two subproblems, there is one solved by a large number of parallel SDRs. SDR is quite expensive, and for each column in the data matrix one has to solve an SDR in each iteration. This is too much for large scale recommender systems. In fact, in the experiment 1 on MovieLens, the algorithm was only tested on a not-so-large dataset and run 5 iterations. The reviewer feels that more scenarios should be tested (e.g., more iterations, various sizes of dataset, etc.). Fixing the number of iterations also sounds a bit funny since it is more intuitive to stop the algorithm using some validation set or when the algorithm converges under a certain criterion.\n\n2) The algorithm works with *probability* of binary data. This is quite hard to estimate in practice. For example, people ``'likes'' a movie for only once. It is hard to tell what is the probability of generating this ````\"like\". It seems that the experiment part of this paper did not clearly state how to obtain the probability that the algorithm needs.\n\n3) The proposed method is a special nonnegative matrix factorization, which could be unidentifiable. How to circumvent such situation? Since identifiability of NMF affects interpretability a lot.\n ",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}