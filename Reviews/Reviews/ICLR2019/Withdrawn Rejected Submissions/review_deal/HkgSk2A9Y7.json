{
    "Decision": {
        "metareview": "The reviewers liked the paper in general but the empirical evaluation lacks studies on a wider range of different data sets.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Paper"
    },
    "Reviews": [
        {
            "title": "Good balance of theory and practice, lackluster experiment results",
            "review": "Authors propose using gossip algorithms as a general method of computing approximate average over a set of workers approximately. Gossip algorithm approach is to perform linear iterations to compute consensus, they adapt this to practical setting by sending only to 1 or 2 neighbors at a time, and rotating the neighbors.\n\nExperiments are reasonably comprehensive -- they compare against AllReduce on ImageNet which is a well-tuned implementation, and D-PSGD.\n\nTheir algorithm seems to trade-off latency for accuracy -- for large number of nodes, AllReduce requires large number of sequential communication steps, whereas their algorithm requires a single communication step regardless of number of nodes. Their \"time per iteration\" result support this, at 32 nodes they require less time per iteration than all-reduce. However, I don't understand why time per iteration grows with number of nodes, I expect it to be constant for their algorithm.\n\nThe improvements seem to be quite modest which may have to do with AllReduce being very well optimized. In fact, their experimental results speak against using their algorithm in practice -- the relevant Figure is 2a and their algorithm seems to be worse than AllReduce. \n\nSuggestions:\n- I didn't see motivation for particular choice of mixing matrix they used -- directed exponential graph. This seems to be more complicated than using fully-connected graph, why is it better?\n- From experiment section, it seems that switching to this algorithm is a net loss. Can you provide some analysis when this algorithm is preferrable\n- Time per iteration increases with number of nodes? Why? Appendix A.3 suggests that only a 2-nodes are receiving at any step regardless of world-size",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "An interesting work that needs some clarification ",
            "review": "This paper demonstrates the benefit of stochastic gradient push (SGP) in the distributed training of neural networks. The contributions are twofold: (1) the paper proves the convergence of SGP for nonconvex smooth functions and gives a reasonable estimation of the convergence rate; (2) the paper did many experiments and shows the SGP can achieve a significant speed-up in the low-latency environment without sacrificing too much predictive performance. \n\nI like this work. Although SGP is not the contribution of this paper, the paper strengthens the algorithm in theoretical perspective and broadens its usage into deep neural network training. \n\nOne thing the authors need to clarify is how to generate/choose P^{(k)}. This is different from Markov-Chain, since time invariant MCs will fix the transition kernels. Here P^{(k)} seems to be randomly sampled for each k. According to the theory, P^{(k)} also must correspond to a strongly connected graph. Then it is better to explain how to control the sparsity of each P^{(k)} and sample its values. And if P^{(k)} needs to vary each step, how to notify P^{(k)} to all the nodes in the cluster and how to maintain its consistency across the nodes? This seems another communication workload, but the paper never mentions that.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting application of PushSum, but how does it fare relative to AD-PSGD?",
            "review": "# overview\nThis paper leverages a consensus based approach for computing and communicating approximate gradient averages to each node running a decentralized version of stochastic gradient descent.\n\nThough the PushSum idea isn't new, its application to distributed SGD and corresponding convergence analysis represents a valuable contribution, and the experimental results indicate a potentially large speedup (in highly variable or latent networks) without substantially sacrificing model accuracy.\n\nThe paper itself is reasonably comprehensive but does miss out on comparisons with more recent but equally promising approaches, namely AD-PSGD. \n\n# pros\n* Empirically shown to be significantly faster than SGD, D-PSGD in high-latency, communication bound configurations which is a fairly common real-world setup. There is an accuracy tradeoff at work here, but performance doesn't seem to suffer too much as the node count scales.\n* introduces and proves theoretical guarantees for SGP approximate distributed average convergence for smooth, non-convex case, including upper bounded convergence rates.\n\n# cons\n* biggest criticism is that AD-PSGD from Lian et al 2018 is not included in experimental comparisons even though the paper is referenced. Authors state that asynchronous methods typically generalize worse than their synchonous counterparts but that isn't what Lian et al found in their comparison with D-PSGD (see table 2 and 3 from their paper). This comparison would be particularly interesting as AD-PSGD also performs well in the high network latency regime that SGP is touted for.\n* would've liked to see comparison on other tasks beyond just image classification on ResNet.\n\n# other comments\n* Didn't see mention of specific iteration count value(s) K used in experiments or hyperparameters A.3. Since it bounds the convergence rate, this would be important to include.\n* Found a few small typos:\n  * pg. 5: Relatively -> Relative\n  * pg. 7, fig. 2: part -> par\n  * pg. 8, sec. 5.3. par. 2: achieves -> achieved\n  * pg. 8, sec. 5.3, par. 2: \"neighbors also to increases\" (drop \"to\")\n  * pg. 12, sec. A.2: \"send-buffer to filled\" -> \"send-buffer to be filled\"",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}