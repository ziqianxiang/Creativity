{
    "Decision": {
        "metareview": "This paper proposes a new method to mine sentence from Wikipedia and use them to train an MT system, and also a topic-based loss function. In particular, the first contribution, which is the main aspect of the proposal is effective, outperforming methods for fully unsupervised learning.\n\nThe main concern with the proposed method, or at least it's description in the paper, is that it isn't framed appropriately with respect to previous work on mining parallel sentences from comparable corpora such as Wikipedia. Based on interaction in the reviews, I feel that things are now framed a bit better, and there are additional baselines, but still the explanation in the paper isn't framed with respect to this previous work, and also the baselines are not competitive, despite previous work reporting very nice results for these previous methods.\n\nI feel like this could be a very nice paper at some point if it's re-written with the appropriate references to previous work, and experimental results where the baselines are done appropriately. Thus at this time I'm not recommending that the paper be accepted, but encourage the authors to re-submit a revised version in the future.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Method is likely useful, but paper needs to be re-framed in light of previous work."
    },
    "Reviews": [
        {
            "title": "Nice BLEU score improvements over existing work but will it generalise to low-resource language pairs?",
            "review": "This paper proposes a method to train a machine translation system using weakly paired bilingual documents from Wikipedia. A pair of sentences from a weak document pair are used as training data if their cosine similarity exceeds c1, and the similarity between this sentence pair is c2 greater than any other pair in the documents, under sentence representations formed from word embeddings trained with MUSE. The neural translation model learns to translate from language X to Y, and from Y to X using the same encoder and decoder parameters, but the decoder is aware of the intended target language given an embedding of the intended language. The model is also trained to minimise the KL divergence between the distribution of terms in the target language document and the distribution of terms in the current model output. The model also uses the denoising autoencoding and reconstruction objectives of Lample et al. (2017). The results show improvements over the Lample et al. (2017) and that performance is heavily dependent on the number of sentences extracted from the weakly aligned documents.\n\nPositives\n- Large improvement over previous attempts at unsupervised MT for the En-De language pair.\n- Informative ablation study in Section 4.4 of the relative contribution of each part of the overall objective function (Eq 9).\n\nNegatives\n- The introduction gave the impression that this method would be applied to low-resource language pairs but it was applied to two high-resource language pairs. Because you have not evaluated on a low-resource language pair, it's not clear how your proposed method would generalise to a low-resource setting.\n\nQuestions\n- Can you give some intuition for why you remove the first principal component from the word embeddings in Equations 1 - 3?\n- Are the Supervised results in Table 2 actually a fair reflection of a reasonable NMT model trained with sub-word representations and back translated data?\n- What is the total number of sentences in the weakly paired documents in Table 1? It would be useful to know the proportion of sentences you managed to extract to train your models.\n\nComments\n- Koehn et al. (2003) is not an example of any kind of neural network architecture.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "the claimed \"new direction\" has been explored before.",
            "review": "The major issue in this paper is that the \"new direction\" in this paper has been explored before [1]. Therefore the introduction needs to be rewritten with arguing the difference between existing methods. \n\nThe proposed method highly relies on the percentage of implicitly aligned data. I suggest the author do more experiments on different data set with a significant difference in this \"percentage\". Otherwise, we have no idea about the performance's sensitivity to the different datasets. \n\nMore detailed explanations are needed. For example, what do you mean by \"p(w)  as the estimated frequency\"? Why do we need to remove the first principal components?\n\nSection 3.2 title is \" aligning topic distribution\" but actually it is doing word distribution alignment.\n\nDo you do normalization for P(w^Y;d_i^X,\\theta) in eq.6 which is defined on the entire vocab's distribution?\n\nI think the measurement of the alignment accuracy and more experiments with different settings of \\alpha and \\beta are needed.\n\nCitation needed for \"Second, many previous works suggest  that the word distribution ...\"\n\n[1] Munteanu et al, \"Improving Machine Translation Performance by Exploiting Non-Parallel Corpora\", 2006",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "nice contribution",
            "review": "Summary\nThe authors propose a relatively simple approach to mine noisy parallel sentences which are useful to greatly improve performance of purely unsupervised MT algorithms.\nThe method consists of a) mining documents that refer to the same topic, b) extracting from these documents parallel sentences, c) training the usual unsup MT pipeline with two additional losses, one that encourages good translation of the extracted parallel sentences and another one forcing the distribution of words to match at the document level.\n\nNovelty: the approach is novel.\n\nClarity: the paper is clearly written.\n\nEmpirical validation: The empirical validation is solid but limited. The authors could further strengthen it by testing on low-resource language pairs (En-Ro, En-Ur).\nIt would also be useful to report more stats about the retrieved sentences in tab. 1 (average length compared to ground truth, BLEU using as reference the translation of a SoA supervised MT method, etc.)\n\nQuestions\n1) Sec. 3.2 is the least clear of the paper. The notation of eq. 7 is quite unclear because of the overloading (e.g., P refers to both the model and the empirical distribution).\nI am also unclear about this constraint about matching the topic distribution: as far as I understood, the model gets only one gradient signal for the whole document. I find then surprising that the authors managed to get any significant improvement by adding this term.\nRelated to this term, how is it computed? Are documents translated on the fly as training proceeds? Could the authors provide more details?\n\n2) Have the authors considered matching sentences to any other sentence in the monolingual corpus as opposed to sentences in the comparable document?\n ",
            "rating": "7: Good paper, accept",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        }
    ]
}