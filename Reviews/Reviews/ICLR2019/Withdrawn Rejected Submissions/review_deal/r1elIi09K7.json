{
    "Decision": {
        "metareview": "The paper presents an approach to address the open-set recognition task based\non inter and intra class distances. All reviewers are concerned with novelty\nand more experimental comparisons. Authors have added some results, but\nreviewers did not think these were enough to make the paper convincing enough.\nOverall I agree with reviewers and recommend to reject the paper.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "meta-review"
    },
    "Reviews": [
        {
            "title": "A reasonable  paper needing further justifications",
            "review": "The paper proposed a NN-based model for open set recognition via finding a better feature space where larger inter-class (P2) and smaller intra-class distances (P1) are satisfied. In the proposed model, the inter- and intra-class distances are measured basing on the mean of final linear layer features from each class, and a kind of L2 loss is defined to ensure the properties of the feature space during the training progress. Then the proposed outlier score defined as the minimum inter-class distance becomes the key for the open set recognition task.\n\nGenerally, this paper is well written and easy to read. The proposed threshold estimation method for outlier score based on assumed contamination ratio is reasonable. And three datasets in two domains are used to prove the modelâ€™s effectiveness.\n\nMajor comments:\n1.\tThis paper seems less novel.\nThere exist several methods aiming to find a better feature space satisfying the mentioned feature distance properties by adjusting the optimized loss functions, such as Center Loss (Wen et.al 2016) and Additive Angular Margin (Deng et.al 2018). I think the idea Combining ii-loss with Cross Entropy Loss proposed in this paper is quite similar to the Center Loss except that\na)\tthe ii-loss contains a part for maximizing the minimum inter-class distance;\nb)\tthe ii-loss and cross entropy loss are optimized separately.\nSince results shown in Center Loss that without pushing the inter-class distance, the feature space still satisfied P1 and P2, this paper seems not that novel, at least some comparation can be added to analyze the improvement for adding the inter-class part.\n\n2.\tThis paper seems less convincing as well.\nThe paper introduces that the two properties (larger inter-class and smaller intra-class distances) can lead to larger spaces among known classes for the instances of the unknown classes to occupy. However, it keeps uncertain if this can be generalized to unseen classes. In this sense, it is better to conduct some additional theoretical analysis or perform more experiments to validate this. In particular, only one plot was performed to verify this point on one single dataset. Maybe more plots of the distributions can be provided on more additional datasets.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The paper focuses on open set classification which is a clearly desirable feature for all machine learning classification algorithms. The idea is very simple and the experiments should include more comparative results with the baselines.",
            "review": "\nThe paper focuses on open set classification where one wants to design a classifier able to accurately classify samples from training (known classes) and able to reject samples from unknown classes. Such a feature is would be clearly desirable for all machine learning classification algorithms. The paper presents a representation learning based approach for this problem. \n\nThe idea is very simple. It consists in learning a neural classifier with a constraint on the representation space of samples (i.e. the one implemented in a chosen hidden layer of the network) aiming at optimizing a Fisher-discriminant-like criterion. This criterion aims at minimizing the variance of the representation of the samples within a class and to make representations of samples from different classes (actually the means per class) well separated. The learning is eventually performed by adding a usual cross entropy classification loss on the output layer to the Fisher like criterion. The rejection of samples from unknown classes is performed via a threshold on the minimum distance of a sample representation and the class means in the representations space.  The idea is well thought but the innovation is indeed low. \n\nExperiments are performed on three, but small, datasets including the simple Mnist dataset. Experimental results compare the proposed approach and its variants to two recent baselines, OpenMax and G_OpenMax. Experiments show the proposed approach outperform the two baselines but in some cases the confidence interval is quite large and prevent definitive conclusions (e.g. up to 0.05 in Table 2). Visualization of projected data show as expected the interesting feature of the representation space. Yet the experimental analysis does not seem as deeps the ones in the two papers where baselines were published. For instance results are shown with respect to a measure of the experimental setting named openness in [Ge and al.]. Moreover the paper by  [Ge and al.] conclude to the superiority of their proposal with respect to OpenMax which is not fully consistent with the results reported in this paper. Also experiments were performed on much bigger datasets in these two references with ILSVRC 2012 dataset in [Bendale and al., 2016] while [Ge and al.]  used a handwritten diet dataset with more than 350 classes. It would drastically strengthen the paper if the authors could provide comparative results on these datasets too.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "The method needs more discussions and more comparison baselines.",
            "review": "This paper deals with the open set classification problem, where in addition to the known classes, the method should also be able to recognize the unknown class. The main idea is based on two parts: learning a discriminative representation, and a threshold based detection rule. To learn the embedding, the authors propose to minimize the inner class distance (between each instance to its center) and enlarge the distance between centers. The outlier score of an instance is computed as the minimum distance between known class prototypes. Experiments on various datasets show the ability of the learned method.\n\nI'm not completely sure whether the whole approach is novel or not in the open set recognition domain, but both parts are not novel enough. Pulling similar instances together and pushing dissimilar ones away is the main idea in embedding learning. The ii-loss is similar to the triplet-center loss in the paper \"He et al. Triplet-Center Loss for Multi-View 3D Object Retrieval. CVPR18\". \n\nAlthough in the experiments the proposed method achieves good results in most cases, the reviewer suggests the authors comparing with more baselines to make the work solid.\n1. Comparing with other embedding learning methods with the same outlier detection score. \nThe authors should prove that the proposed embedding is important enough in the open set case. For example, using the center loss (Wen et al. A discriminative feature learning approach for deep face recognition. ECCV16), triplet-center loss, triplet loss (computing class centers after embedding).\n\n2. Discuss more on the outlier score part. \nHow to differentiate the known class outlier and new class? Will the problem be more difficult when the unknown class contains more heterogeneous classes? The authors can also apply existing open set recognition rule on the learned embedding.\n\nSome detailed questions:\n1. What's the difference between \"the network weights are first updated to minimize on ii-loss and then in a separate step updated to minimize cross entropy loss\" and optimize both loss terms simultaneously?\n2. \"We assume that a certain percent of the training set to be noise/outliers\", how to determine the concrete value? Is 1% the helpful one for all cases?\n3. Since there is not optimize over the unknown classes in training, could the reason for \"the unknown class instances fully occupy the open space between the known classes\" is the unknown classes are randomly sampled from the whole class set? For example, if classes about animals are known classes and classes about scene compose the unknown class, will the unknown class also occupy the whole space in this case?\n4. What is the motivation of making \"the unknown class instances fully occupy the open space between the known classes\"?",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}