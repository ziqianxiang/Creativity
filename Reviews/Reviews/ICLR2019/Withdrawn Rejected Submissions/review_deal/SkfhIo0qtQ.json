{
    "Decision": {
        "metareview": "Using volumetric convolutions, this paper focuses on learning in (rather than on) the unit sphere.\n\nThe novelty of the approach is debatable, and the mathematical analysis not strong enough to merit that.  In combination with good but not outstanding results, interest of the research community is doubted.  An extended experimental analysis of the method would greatly improve the paper.",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "good paper, but some improvement possible"
    },
    "Reviews": [
        {
            "title": "Benefit for volumetric data not clear",
            "review": "The work concerns convolution in the unit sphere. It differentiates itself from previously mentioned work by working in the volume space and not the surface space. While I can't say I understand all of the implications of the work,  I was left with several questions. Many of these questions are in regards to claims made by the authors whose answer or reference was not made clear.\n\n- It was not made clear why there is a benefit to convolving the object in the unit sphere vs the unit cube, especially given that the work was not able to perform better than other work that was based on the unit sphere. This point was the stated problem of the paper. Although it was mentioned that the unit sphere preserves all of the points of the object, it isn't clear if the transformation causes any deformations of the object. Furthermore, the fixing of one axis seems to be a way to hack around problems of increased dimensionality, but there was no justification given.\n\n- How does the number of trainable layers help to differentiate resource usage. Wouldn't a better measure be number of parameters? The authors make that claim that shallowness is a virtue, but there is little discussion as to the size of each layer in comparable terms.\n\n- Why was no \"ablation\" or \"accuracy vs trained layers\" data shown for the Modelnet40 dataset? I would think that would be stronger evidence than for the Modelnet10 data.\n\n- Why wasn't the 1d conv net used for creating the viewing angles included in the size of the architecture? Was there a verification as to what the filters from this network were actually giving? The authors mention how we should interpret them, but not enough information about the structure of the network is given to satisfy this question.\n\n- I would have liked to see a description of the types of features that are found by these networks.\n\n- The authors say they are only going to show experiments on one possible use case, but then make claims for other use cases. I am referencing that since the texture data in the datasets used is constant, there was no need to model the texture data. There is no experimental evidence to show this is the case, however.\n\nOverall, I think the paper would have been stronger if it had more experiments.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        },
        {
            "title": "Closely related to the recent spherical CNN and SE(n) equivariant network papers, but mathematically less clean",
            "review": "There is a great amount of interest in extending the notion of equivariance in neural networks from \njust translations to other groups. In particular, in the past year a sequence of papers have appeared \nstarting with (Cohen, Geiger et al.) on \"spherical CNNs\" that achieve equivariance to rotations for images \npainted on the surface of the unit sphere.\n\nThe present paper extends these ideas to volumetric data in the unit ball (rather than just the sphere) \nby the use of Zernike polynomials. Since Zernike polynomials can be expressed as the product of spherical \nharmonics with a radial function, this is essentially the same as adding a radial component to a spherical \nCNN. \n\nThe main result of the paper appears to be Theorem 1, which shows that what the authors define as \nvolumetric convolution is equivariant to rotations. This is split across Sections 4.2 and 4.3.. However, \napart from the radial component, this result is bascally the same as the SO3-equivariance of spherical CNNs, \nas discussed in three very recent spherical CNN papers: (Cohen, Geiger et al.) (Esteves Allen-Blanchette et al) \nand (Kondor, Lin and Trivedi). However, the somewhat more abstract, representation theoretic approach \nof some of these works allows a more compact derivation than the one in the present paper.\n\nThe authors also fail to cite recent work on SE(2) and SE(3) equivariant neural networks. SE(3) comprises \nall rotations and translations of R^3, so the latter, in particular, encapuslates SO(3) equivariance as \na special case. In particular, part of the construction in (Weiler, Hamprecht and Storath, CVPR 2018) \nis to add  Gaussian radial functions to SO(2) equivariant filters, which is just the 2D analog of \nwhat is happening in the present paper. Then in (Weiler, Geiger, et al., 2018) the same is done in 3D, \nexcept of course they go further by also adding translation equivariance. Admittedly, these papers are \nvery new, so the authors might not have known about them.\n\nI also find some of the mathematical details a little puzzling:\n\n1. As explained in the spherical CNN papers, taking the cross correlation of two functions on the sphere \n(by extension, in the unit ball) naturally results in a function that lives on the rotation group SO(3), i.e. \nthe cross-correlation (or convolution) is parametrized by three Euler angles. I don't understand why the \nauthors restrict themselves to considering just two angles, forcing their filters to be polar, as \nderived in Section 5. This seems like an artificial restriction that will limit the power of their approach. \n\n2. The paper mentions that Zernike polynomials are \"orthogonal and complete in B^3\". I think what they mean \nis that they are an ortogonal and complete basis for an appropriate space of functions on B^3, and that \nspace of functions is L_2(B^3). However, this is still not enough. For (3) to hold, one also needs the \nbasis to be orthonormal. Please be more precise.\n\n3. In the same vein, at one point in the proof, the authors mention that \"rotations are unitary operators \nin a Hilbert space\". This is not true of Hilbert spaces in general. It requires the above orthonormality etc.. \n\n4. Exactly as a consequence of orthonorlamity, Equation 5 is essentially just a generalized Fourier transform \non B^3, hence, in principle, it can be inverted analytically. I understand that the fact that the input \nimage is rasterized complicates things and in a practical implementation it might be expedient to invert (5) \nby using the pseudo-inverse. However, this is a one-time operations and is really just a hack. It seems strange \nthat the authors use a special iterative method just to invert a close to unitary matrix.\n\nThe mathematical shortcomings of the paper could be compensated by amazingly good experimental results. \nThe actual results are good, but still not best-in-class, possibly because at the end of the day the network \nis still only rotationally equivariant and does not take into account translations. \n\nThe spherical CNN and SE(n) equivariance papers generally apply the group equivariant operations consistently \nacross multiple layers. In contrast, the present paper only applies it in the first layer, and then uses a \ncombination of tricks like multiple viewpoints and bilinear pooling to boost performance. Unfortunately, the \nbenefits of this additional conceptual complexity are not entirely borne out in the experimental results.\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "specific to unit-ball",
            "review": "Volumetric Convolution, Automatic Representation Learning in Unit Ball\n\nThis work proposes to tackle the challenging problem of learning on unit balls. The method uses volumetric convolutions based on the Zernike polynomial trick, which makes it convenient to use on convolution networks. Invariance to 3D rotation enables a transformation to a volumetric space, where convolutions could be used in a conventional process. Clarity of the methodology may benefit from a motivation discussed from a global perspective. The reader is currently facing heavy mathematical concepts fairly quickly with global rationale on the proposed choices, in particular, in the explanation of symmetry analysis. Clarity on the use of 2D and 3D features could also benefit from more details on what is exactly proposed. Results are shown on an object recognition task achieving performance comparable with the state-of-the-art. \n\nPositive\n+ Tackles the difficult problem of extending graph learning to arbitrary topologies, particularly on unit balls\n+ The contributions are multifold -therotical framework for modeling volumetric convolutions over functions defined on unit-balls, -derivation of the formulation, to make it usable by neural nets, -measures of axial symmetry on unit-balls\n\nSpecific comments\n- How to handle mixed topologies, for instance, with random presence of holes in the meshes\n- Extension beyond unit balls?\n- Fundamentaly, arbitrary genus-0 meshes are topologically equivalent to a sphere, however, there can be severe metric distorsion when transforming shapes to a sphere (e.g, transforming a banana to a sphere, the ends gets severely atrophied) - Does this pose a problem - how to handle these metric distorsion?\n- Zernike polynomials are based on the spherical harmonics - could this be generalized to arbitrary graph harmonics? Beyond spherical shapes?\n\n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}