{
    "Decision": {
        "metareview": "The paper presents an architecture search method which jointly optimises the architecture and its weights. As noted by reviewers, the method is very close to Shirakawa et al., with the main innovation being the use of categorical distributions to model the architecture. This is a minor innovation, and while the results are promising, they are not strong enough to justify acceptance based on the results alone.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "insufficient novelty"
    },
    "Reviews": [
        {
            "title": "Simple and effective method with limited novelty",
            "review": "The authors propose to formulate the neural network architecture as a collection of multivariate categorical distributions. They further derive sample-based gradient estimators for both the stochastic architecture and the deterministic parameters, which leads to a simple alternating algorithm for architecture search.\n\nPros:\n+ Intuitions and formulations are easy to comprehend.\n+ Simpler to implement than most prior methods.\n+ Appealing results (on CIFAR-10) as compared to the state-of-the-art.\n\nCons:\n- Limited technical novelty. The approach is a straightforward extension of Shirakawa et al. 2018. The main algorithm is essentially the same except minor differences in gradient derivations.\n- Lack of theoretical justifications. It seems all the derivations at the beginning of Section 2 assume the architecture is optimized wrt the training set. However, the authors ended up splitting the dataset into two parts in the experiments and optimize the architecture wrt a separate validation set instead. This would invalidate all the previous derivations.\n- The method is a degenerated version of ENAS. A closer look at eq (2) and (3) suggests the resulting iterative algorithm is almost the same as that in ENAS, where the weights are optimized using GD wrt the training set and the architecture is optimized using the log-derivative trick wrt the validation set. The only distinction are (i) using a degenerated controller/policy formulated as categorical distributions (ii) using the validation loss instead of the validation accuracy as the reward (according to eq. (3)). This is also empirically reflected in Table 1, which shows the proposed PDAS is similar to ENAS both in terms of efficiency and performance. The mathematical resemblance with ENAS is not necessarily bad, but the authors need to make it more explicit in the paper. \n\nMinor issues:\n* I'm not sure whether it's a good practice to report the \"best\" test error among multiple runs in Table 1.\n* The method is not really \"parameterless\" as claimed in the introduction. For example, a suitable learning rate adaptation rule can be task-specific thus requires manual tuning/design. The method also consists of some additional hyperparameters like the \\lambda in the utility transform.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Proposes an architecture search technique, easy to read. Not confident about the baselines and how this is compared to the literature.",
            "review": "This paper proposes an architecture search technique in which the hyperparameters are modeled as categorical distribution and learned jointly with the NN. The paper is written well. I am not an expert of the literature in this domain so will not be able to judge the paper regarding where it is located in the related work field.\n\nPros:\n-This is a very important line of research direction that aims to make DNNs practical, easy to deploy and cost-effective for production pipelines.  \n-The categorical distribution for hyperparameters makes sense, and the derivation of the joint training seems original idea. I liked the fact that you need to train the NN just twice (the second one only to fine tune with optimized parameters)   \n-Two very different problems (inpainting/encoding-decoding + CNN/classification) have been demonstrated.\n-Existing experiments have been explained with enough detail except for minor points.\n\nCons:\n-I speculate that there is a trade-off between the number of different parameters and whether one training is good enough to learn the architecture distribution. i.e., When you have huge networks and many parameters, how well this method works? I think the authors could provide some experimental study suggesting their users what a good use case of this algorithm is compared to other techniques in the literature. In what type of network and complexity this search method works better than others?\n-E-CAE for in-painting seems to be working significantly better than the proposed technique. Regarding results, I was expecting more insights into why this is the case. As above, at what type of a problem one should pick which algorithm? If the 7hours vs. 3days GPU difference negligible for a client, should one pick E-CAE?  \n-In theory, there has been shown lambda samples (equation 2 and 3). However, the algorithm seems to be using just 2? If I didn't miss, this is not discussed thoroughly. I speculate that this parameter is essential as the categorical distribution gets a bigger search space. Also the reliability of the model and final performance, how does it change concerning this parameter?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Lacking novelty, but cool results",
            "review": "This paper presents a joint optimization approach for the continuous weights and categorical structures of neural networks. The idea is the standard stochastic relaxation of introducing a parametrised distribution over the categorical parameters and marginalising it. The method then follows by alternating gradient descent on the weights and the parameters of the categorical distribution.\n\nThis exact approach was proposed in https://arxiv.org/abs/1801.07650 by Shirakawa et al. The only innovation in this work is that it uses categorical distributions with more than two values. This is a minor innovation.\n\nThe experiments are however interesting as the paper compares to the latest hyper-parameters optimization strategies for neural nets on simple tasks (eg CIFAR10) and gets comparable results. However, given that this is the biggest contribution of the paper, it would have been nice to see results in more complex tasks, eg imagenet or translation.\n\nI very much enjoyed the simplicity of the approach, but the question of innovation is making wonder whether this paper makes the ICLR bar of acceptance. The paper is also hard to read because of many English typos.   ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}