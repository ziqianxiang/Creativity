{
    "Decision": {
        "metareview": "Reviewers generally found the RKHS perspective interesting, but did not feel that the results in the work (many of which were already known or follow easily from known theory) are sufficient to form a complete paper. Authors are encouraged to read the detailed reviewer comments which contain a number of critiques and suggestions for improvement.",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "interesting perspective but insufficient contribution"
    },
    "Reviews": [
        {
            "title": "Well written with interesting findings, but limited novelty",
            "review": "Regularizing RKHS norm is a classic way to prevent overfitting. The authors\nnote the connections between RKHS norm and several common regularization and\nrobustness enhancement techniques, including gradient penalty, robust\noptimization via PGD and spectral norm normalization. They can be seen as upper\nor lower bounds of the RKHS norm.\n\nThere are some interesting findings in the experiments. For example, for\nimproving generalization, using the gradient penalty based method seems to work\nbest.  For improving robustness, adversarial training with PGD has the best\nresults (which matches the conclusions by Madry et al.); but as shown in Figure\n2, because adversarial training only decreases a lower bound of RKHS norm, it\ndoes not necessarily decrease the upper bound (the product of spectral norms).\nThis can be shown as a weakness of adversarial training if the authors explore\nfurther and deeper in this direction.\n\nOverall, this paper has many interesting results, but its contribution is\nlimited because:\n\n1. The regularization techniques in reproducing kernel Hilbert space (RKHS) has\nbeen well studied by previous literature. This paper simply applies these\nresults to deep neural networks, by treating the neural network as a big\nblack-box function f(x).  Many of the results have been already presented in\nprevious works like Bietti & Mairal (2018).\n\n2. In experiments, the authors explored many existing methods on improving\ngeneralization and robustness. However all these methods are known and not new.\nIdeally, the authors can go further and propose a new regularization method\nbased on the connection between neural networks and RKHS, and conduct\nexperiments to show its effectiveness.\n\nThe paper is overall well written, and the introductions to RKHS and each\nregularization techniques are very clear. The provided experiments also include\nsome interesting findings. My major concern is the lack of novel contributions\nin this paper.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting ideas, but not enough of an independent contribution",
            "review": "This paper looks at adversarial examples from the context of RKHS norms for neural networks.  The work builds conceptually on the work of Bietti and Mairal (2018), who investigate approximate RKHS norms for neural networks (including computation via a specialized convolutional kernel), and Xu et al., (2009) which looks at robustness properties of kernel classifiers.  The authors discuss how the RKHS norm of neural network functions provide robustness guarantees for the resulting classifier, both in terms of a straightforward robustness property for a given example, as well as in terms of generalization guarantees about robustness.\n\nOverall, I think there are some interesting ideas in this work, but ultimately not enough to make a compelling independent paper.  The core issue here is that the RKHS properties are used only in a very minimal manner to actually provide much analysis or insight into the robustness properties of the network.  For example, the upper bound in (8) seems to be central here to illustrating how a bound on the RKHS norm can be upper bounded as a function of the operator l2 norm of the inner weight matrices (though the actual form of the bound isn't mentioned), and the latter term could thus provide a certified bound on the robustness loss of a classifier.  However, there are two big issues here: 1) it's trivial to directly bound the l2 robustness of a classifier by the product of the weight spectral norms and 2) the actual regularization term the authors proposed to use (the sum of spectral norms) is notably _not_ an upper bound on either the robust loss or the RKHS norm; naturally, this penalty along with the constrained version will still provide some degree of control over the actual robustness, but the authors don't connect this to any real bound.  I also think the authors aren't properly acknowledging just how similar this is to past work: the Parseval networks paper (Cisse et al., 2017), for instance, presents a lot of similar discussion of how to bound generalization error based based upon terms involving operator norms of the matrices, and the actual spectral normalization penalty that the authors advocate for has been studied by Miyato et al. (2018).  To be clear, both of these past works (and several similar ones) are of course cited by the current paper, but from a practical standpoint it's just not clear to me what the takeaways should be here above and beyond this past work, other than the fact that these quantities _also_ bound the relevant RKHS norms.  Likewise the generalization bound in the paper is a fairly straightforward application of existing bounds given the mechanics of the RKHS norm defined by previous work.\n\nTo be clear, I think the RKHS perspective that the authors advocate for here is actually quite interesting.  I wasn't particularly familiar with the Bietti and Mairal (2018) work, and going through it in some detail for reviewing this paper, I think it's an important directly for analysis of deep networks, including from a perspective of robustness.  But the results here seem more like a brief follow-on note to the past work, not a complete set of results in and of themselves.  Indeed, because the robustness perspective here can largely be derived completely independently of the RKHS framework, and because the resulting training procedures seem to be essentially identical to previously-proposed approaches, the mere contribution of connecting these works to the RKHS norm doesn't seem independently to be enough of a contribution in my mind.\n\nOne final, though more minor, point: It's worth pointing out that (globally) bounding the Lipschitz constant seems top stringent a condition for most networks, and most papers on certifiable robustness seem to instead focus on some kind of local Lipschitz bound around the training or test examples.  Thus, it's debatable whether even the lower bound on the RKHS norm is really reasonable to consider for the purposes of adversarial robustness.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review",
            "review": "In this paper, the authors consider CNN models from the lens of kernel methods. They build upon past work that showed that such models can be seen to lie in appropriate RKHS, and derive upper and lower bounds for the kernel norm. These bounds can be used as regularizers that help train more robust neural networks, especially in the context of euclidean perturbations of the inputs, and training GANs. They show that the bounds can also be used to recover existing special cases such as spectral norm penalizations and gradient regularization. They derive generalization bounds from the point of view of adversarial learning, and report experiments to buttress their claims.\n\nOverall, the paper is a little confusing. A lot of the times, the result seem to be a derivative of the work by Bietti and Mairal, and looks like the main results in this paper are intertwined with stuff B+M already showed in their paper. It's hard to ascertain what exactly the contributions are, and how they might not be a straightforward consequence of prior work (for example, combining results from Bietti and Mairal; and generalization bounds for linear models). It might be nice to carefully delineate the authors' work from the former, and present their contributions. \n\nPage 4: Other Connections with Lower bounds: The first line \" \"we may also consider ... \". This line is vague. How will you ensure the amount of deformation is such that the set \\bar{U} is contained in U ?\n\nPage 4 last paragraph: \"One advantage ... complex architectures in practice\" : True, but the tightness of the bounds *do* depend on \"f\" (specifically the RKHS norm). It needs to be ascertained when equality holds in the bounds you propose, so that we know how tight they are. What if the bounds are too loose to be practical?\n\neqn (8): use something else to denote the function 'U'. You used 'U' before to denote the set. \n\neqn (12): does \\tilde{O} hide polylog factors? please clarify. \n\n\n\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"
        }
    ]
}