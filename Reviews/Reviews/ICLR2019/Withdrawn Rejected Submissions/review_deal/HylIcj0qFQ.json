{
    "Decision": "",
    "Reviews": [
        {
            "title": " Interesting results that are well presented, but reads like a lab report with minimal background research, and lacks novelty or significant experimental insight",
            "review": "Missing references about VC dimension /shattering, Rademacher complexity, etc.\n\nI would like to see more discussion and motivation of using MI to measure capacity (of NNs, or in other contexts). I am not an expert in this area, so I do not know what the appropriate references would be, but only one reference about MI is cited. The paragraph under eqn (1) is helpful, but the relationship between classification accuracy and MI still seems unclear to me.\n\nI also find it is not clear exactly what the MI is measured between - this should be made clearer in the main text, and also in appendix B. Xi and f(theta, Xi) are defined, but nothing else is. It is fairly easy for someone familiar with the notation to guess what the variables refer to, but this should be explicitly stated to avoid confusion and ambiguity. What exactly is Y? The output of the softmax?\n\nAside from the lack of clarity about notation/what symbols represent, I have two main issues with appendix B.\nFirst is the claim \"Note that X and Y are independent as well as Yi and Yj when i neq j\"; I think it should be made clearer that X and Y are independent only in this setting because the experiments are with random data, and it does not seem obvious to me that Yi and Yj are independent. \nSecond, using average accuracy as the probability that the class is the true class seems strange to me for random data. Maybe it's fine and I just haven't wrapped my head around it, or I misunderstood something, but I would like to understand why it makes sense to do this.\n\nIs it standard not to quantize bias values? why does having a large dynamic range mean they shouldn't be quantized?\n\nI find section 3 not very clear. I understand why the loss under perturbation is interesting, but this should be discussed along with what are the results of your experiments. The procedure for doing this should also be cited, unless you came up with it on your own in which case the justification for it should be further discussed.\nI assume you don't do this, but the way the section is worded makes it sound like you train networks with a noisy loss.\n\nIt would be interesting to investigate the claims about parameter-sharing in CNNs (and RNNs) increasing their capacity as measured by MI; e.g. plot MI vs. #times filter is used for different convnet configurations, and #timesteps for RNNs.\n\nQuality: 6/10 The writing is mostly clear to follow, although paragraphs don't always flow well into each other and some sections assume a lot of knowledge. \nClarity: 7/10 Results are clearly presented, although more intuition and context would be helpful, and some sections are not well explained or contextualized\nOriginality: 2/10 The methods are not novel, to my knowledge, and there is little exploration or insight given for the extensive experimental results\nSignificance: 7/10 measuring and reporting results is valuable, and the reported results are interesting\n\nPros:\n - interesting results, good plots\n - overall well structured and explained\n\nCons:\n - plots could use more explanation and interpretation in the captions, and more investigation and insight from the experiments\n - some sections are not clearly worded and I think the objective/interpretation of the experiments would not be clear to someone even a little unfamiliar with the approaches cited\n\n\nSpecific comments/nits (in order reading through paper):\n1. First paragraph of intro is kind of fluff/unnecessary. I would suggest beginning with the 3rd paragraph and work in the second.\n2. It is usually advised in scientific writing not to use phrases like \"it is known\". \"It has been shown by [refs]\" would be better.\n3. \"in the over-parameter region\" -> overparameterized\n4. \"real-models\" -> real models (although this seems like a bit of an odd thing to say to me. What are fake models?? maybe \"empirical study\" would be better)\n5. \"Related work and backgrounds\" remove s\n6. \"capacity ... is related to the learnability of networks\" I don't think this makes it more clear; it just brings up the question about what you mean by learnabilty. Maybe \"how much a network can learn to capture about a dataset\" or something like that. \n7. \"is shown as\" odd phrasing, maybe \"is defined as?\n8. \"classification task (Collins et al)\" -> \"classiification task, as in Collins et al\"\n9. mention what scikit learn uses for hyperparameter tuning / why you use this\n10. Figure 1 would benefit from a bit more explanation in the caption (e.g. memorization performance on/of what; explain what the acronyms mean and what the results tell us)\n11. Some of the hyperparameter specifications here could be put in an appendix if you need space. Some of this information is also not specific to FCDNNs and should go in the preamble before the subsections for each architecture\n12. Figure 2: Why does accuracy go to 1.4? Like Figure 1, caption would benefit from more information and some interpretation. Why do you think the MI levels off/goes up on the right hand side of A?\n13. References about capacity here at the end of 4.1 should go in the background and related work section\n14. \"Result is consistent with theoretical study\" In what ways? How consistent is it? What does the theory say?\n15. Mention if you use truncated bptt in the RNN experiments\n16. Mention what it means for \"all models use full capacity\"\n17. VLSI mentioned without definition\n18. \"RNNs have the tendency of demanding more bits when compared to FCDNNs\" I find this sentence unclear\n19. \"conducting memorization tasks, rather than inferencing with unseen data\" -> saying \"generalization tasks\" would be more accurate; maybe this is being too picky but they can inference with unseen data just fine wihtout requiring more parameter precision; it's only if we care about the generalization performance that they require more parameter precision.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting analysis, but a bit confusing in some parts",
            "review": "This paper presents an analysis of the capacity of different models of deep neural networks with and without parameter quantization. The capacity of a network is calculated as the maximum of the mutual information between the real output and the neural network output, considering both of them as random variables. For the estimation of the network capacity the network is trained to maximize the mutual information given random inputs and random labels. As shown in Fig. 2 (a), the capacity of the network corresponds to the maximum number of random samples that a network can memorize. The capacity can be divided by the number of parameters, so that we can estimate how many bits of information every parameter can memorize, and therefore having an estimation of the maximum parameter quantization that we can use without losing memorization capabilities. Interestingly, the measured capacity seems to not depend on the number of parameters, but on the architecture of the network. Experiments on real data seem to show that the estimation made is conservative and when the aim of the network is generalization, the number of bits per parameter can be reduced further.\n\nPros:\n- The idea of evaluating the network capability of memorization for estimating the quantization of the parameters make sense to me and is novel in my knowledge.\n- With the proposed experiments, one can have an idea about a possible quantization of the network parameters that is independent of the data that we want to train on.\n\nCons:\n- The presentation of the paper is sometimes confusing. The conclusion gives a better explanation of the work than the introduction. Sec. 3.3 talks about weight perturbation, but no figure or experiments are shown until section 5.2 Figures are often very far from the corresponding text. In general, I found difficult to keep track of where we are in the paper.\n- Some parts of the text should be improved for a better comprehension. For instance in equ.1 \\hat{Y} is not defined. Also in the same section, the authors talk about mutual information of a trained network, but in my understanding the mutual information should be between two random variables. See also additional comments.\n- The connection between memorization and generalization is not clear. The authors say that the estimation obtained with memorization is conservative, but it would be good to have a better understanding of that. Finally we want to speed-up the network with quantization and if the estimation is too conservative, we will be force to empirically test the quantization again, and therefore the proposed estimation would not really help.\n- The proposed experiments can help us to estimate the amount of quantization of a given network independently of the data, which is quite nice. However, this estimation is still based on relatively long experiments.\n\nOverall evaluation:\nThe proposed idea and experiments seem interesting, however the presentation of the paper needs some extra work to make it easier to read and understand. It took me several passes before understanding the paper.\nI am willing to increase my score if the authors will be able to improve the quality of the presentation of the text and the experiments.\n\nAdditional comments:\n- From the experiments the estimated bits per parameter for memorization are: 2.3 bit/param for the fully connected networks, 3 bits/param for CNN and 3.7 for RNN. The idea is that more the parameters are \"shared\" and more bits they require. Now, based on your observations, the actual capacity when using quantized parameters is of 6, 8 and 10 respectively. So, why there is a discrepancy between estimation and real experiments?\n- In the last paragraph of sec. 3.1 the authors explain the training protocol for the experiments. I do not fully understand the need of those three phases, and the meaning of the boundary values for the hyper-parameters.\n- In Fig. 4 N_{in} is confusing because before you used N for the number of samples and n_{in} for the number of input dimensions.\n- From Fig. 3(a), it seems that for fully connected it is needed at least a 5 bits quantization to keep full accuracy. Why in the text you always mention 6 bits instead? ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A good setup but very thin on relevant conceptual details",
            "review": "\nThis paper indeed asks a very pertinent question about quantifying the effect of  parameter quantization on a neural net's performance. The authors take a very principled approach towards exploring this by splitting up their experiments for (fully connected) DNN, CNN and RNN.  And they define the notion of \"network capacity per parameter\" which they show is varying in a small interval around 2 for all architectures and data set sizes. \n\nBut the overall analysis of the paper is pretty thin and its hard to extract any specific insight out of this paper except to say that RNN's performance is hit the most by parameter quantization possibly because it had the largest capacity per parameter. \n\nBut this conclusion comes from a context which has multiple unconvincing issues surrounding it which I list below, \n\n1. \nIsnt plot 2(b) essentially saying that there is something wrong with this notion of \"capacity per parameter\" because it doesnt seem to be very sensitive to data size or architecture? Across a wide range of changes it seems to be hardly varying and that seems to suggest that it is possibly sensing some approximate invariant rather than a discriminator between the different situations! And I cant see any plot showing how this capacity vs parameters changes when quantization is done. Shouldnt that have been the most crucial thing to demonstrate? \n\n2.\nThe basic notion of \"capacity\" comes from the equation (1) which seems tied to using 0/1 labels and binary data vectors. But most experiments (figure 6 and 7 say) in this paper do not seem to be in this setup. Given this why should any of the insights in section 3.1 transfer to the rest of the paper? \n\n3.\nTo the best of my understanding it seems to me that a lot is going on in how the quantization is done and how the training plays with this. This is only lightly mentioned in the beginning of section 3.2 and this is hardly any information to understand exactly as to how quantization has been implemented in training. I strongly feel that a lot more needs to be said about it and there should have been a clear pseudocode explaining this process. For all I know at this point, literally all conclusions depend on this implementation detail and that is missing. \n\n4.\nEquation 3 looks somewhat confusing to me. The RHS is a random variable/function. Then what does it mean to say that the this random function is being plotted in Appendix C? \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}