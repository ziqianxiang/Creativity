{
    "Decision": {
        "title": "The paper was withdrawn",
        "metareview": "The paper was withdrawn",
        "recommendation": "Reject",
        "confidence": "5: The area chair is absolutely certain"
    },
    "Reviews": [
        {
            "title": "Promising idea but devil in the details?",
            "review": "The paper proposes a novel approach to address the issue of mode collapse in the GANs. I see two interesting ideas here: (a) Since the GAN formulation seeks to achieve distributional alignment by the generator PDF end the PDF corresponding to the real, target data, the paper proposes to represent the real data using the embedding from an AE encoder, and, (b) achieve distributional alignment via an importance sampling formulation. The paper claims that their implementation of the above ideas helps improves the issues of mode collapse and mode oscillation, thereby (?) improving sample diversity and speeds up convergence. \n\nThe ideas seem promising and I was hoping that the paper carefully implemented an approach based on the above, compared with the existing approaches and reported the results carefully. I find that the paper falls short of doing this and does not merit a publication at this point. A major revision of the work is needed.\n\nThe main shortcomings of the paper follow:\n\n1.\tClarity: The paper greatly suffers from a loose handling of technical concepts and terminology; statements are not made in a careful and measured manner; and, grammatical mistakes abound. There are too many to list them all. Following are exemplary but symptomatic of the way the entire paper is written.\n\na.\t“Dual importance weights iteratively maximize the representation of generated samples for both distributions”. Maximize the representation?\n\nb.\t“Experimental evaluation shows that the proposed network learns complete modes of target distribution more stable and faster than state of the art methods.” What is meant by ‘more stable’? Please provide the metric used to measure the stability and indicate which experiment validates this claim.\n\nc.\t“Main reason of mode collapsing problem is that the discriminator is incapable of delivering any information about samples’ diversity. Once the generator finds optimal point of a fixed discriminator in each generator training step, the network produces same samples driving the expectation value in objective function becomes minimum regardless of input noise vectors.” Loose and overly broad statements about the underlying problems and speculations about the mechanisms and underlying behavior of the algorithms – both the state of the art ones and the proposed one, shouldn’t be made unless there is a strong justification provided via mathematical proofs or experiments. \n\nd.\t“Auto-encoder not only decreases the dimensionality of input data but also finds optimal abstraction of input data for better discrimination between subjects.” Optimal abstraction of input data for better discrimination between subjects? \n\ne.\tEquation (2) should use the 2-norm since s_r and s_g are not scalars. \n\n2.\tImplementation and technical details:\n\na.\tThe distance defined in Equation (2) and using it to modify the generator loss function in (3) seems to be based on a heuristic. The authors should formally derive it from importance sampling. This will help formally ground the proposed modifications to the objective function and help understand the expected benefits and the convergence properties better.\n\nb.\tSecondly, the proposed distance function in (2) is supposed to be obtained using a kernel density estimator. KDEs bring their own challenges, especially when used in high-dimension spaces. It is not clear what the bias/ variance properties of the proposed KDE estimator are and how it impacts the overall objective. Further, no details are shared about the dimensionality of the embedding space and the bandwidths used to compute the KDE.\n\nc.\tBeyond the KDE, there are other mathematical / implementation details missing making it practically impossible to replicate results. For example, what are the mathematical expressions for the two set of weight?\n\nd.\tHigh quality sample ratio (HQS) metric is neither defined nor cited from other works. It is not clear how the quality is measured and how the high-quality samples are obtained. \n\n3.\tInsufficient/ inadequate experimental validation:\n\na.\tWhile experiments on toy dataset (mixture of gaussian) shows slight improvements compared to baselines, the experiments on CIFAR and MNIST only report qualitative results in Figure 4,5 and 6. This is not sufficient to establish that the proposed approach works better than approaches compared with. \n\nb.\tQuantitative evaluation on real datasets using the IS or the FID score (or even the metrics in Table 1) to establish the claimed improvement in performance – sample diversity and the quality of generated images. Perceptual measures such as SSIM and the one proposed in Zhang et al (CVPR 2018, arXiv 1801.03924) should be used to measure image quality. Precision, Recall and F1 can be used to provide a measure of similarity between the real and generated data.\n\nc.\tThe claim about improved convergence is not adequately validated. \n\nd.\tAside: Since the real target data is represented by an AE embedding, the time taken to train the AE should be used when comparing baselines that do not have pre-training, in Figure 4. \n\nI’m willing to revise my opinion if the authors address the above issues in the forthcoming discussion phase.\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Insufficient motivation, evaluation, and comparison to prior work",
            "review": "Summary:\nThis paper proposes an approach to tackle mode collapse in GANs by using a pretrained autoencoder. Kernel density estimators are used to approximate the density of the generated and the real samples in the feature space of the autoencoder, using a buffer of samples over multiple iterations. A new regularization term is added to the generator loss that pulls together random real and generated samples in the embedding space, with a weight proportional to their distance and the product of their likelihoods. The approach is evaluated on a number of low-d toy problems, stacked MNIST, and CIFAR-10. \n\nOverall, I found the paper fairly confusing and poorly written, with unconvincing experiments. The added regularization term is not well-motivated, not theoretically grounded, and it’s not clear whether it even helps on any of the image datasets (Fig 5f exhibits clear mode collapse of the proposed approach). There are also a number of related papers that were not discussed but exhibit similarities to this technique (matching in the feature space of an autoencoder). The authors should review the related work, elaborate on the theoretical justification and properties of the proposed regularizer, and perform more quantitative evaluations on image datasets.\n\nStrengths:\n+ I appreciated the quantitative comparison on the low-d toy datasets (2d and 3d MoGs), reporting modes captured, and JSD.\n+ The idea of combining non-parametric density estimators with GANs is interesting and underexplored.\n\nWeaknesses:\n- Poorly written, incorrect grammar throughout that distracts from the content along with a number of factually incorrect statements about concepts and related work.\n- Missing discussion/comparison to numerous related works: (1) autoencoders and GANs: ALI/BiGAN, MMD (e.g. Generative Moment Matching Networks) that leverage IPMs on top of feature spaces often learned by autoencoders, FID/KID that match densities in feature space, VAE-GANs that incorporate a reconstruction loss in feature space. (2) dynamics-based approaches for avoiding mode collapse, e.g. Numerics of GANs. (3) Kernel-density based approaches to GAN training kernel (Sinn & Rawat, 2017), (4) connections to continual learning in GANs where buffers of data are used (Seff et al., 2017).\n- The proposed approach is poorly motivated and presented. Are there any theoretical guarantees when using the extra dual importance-weighted distance? Why do you need a time-varying KDE estimate for the the fixed data density? Why pull arbitrary real and generated pairs together in the feature space? \n- Experiments looking at proposed approach over steps give the proposed technique an unfair advantage as you have to train an autoencoder first and that does not count towards the step count. You should evaluate wall time vs. a quantitative metric (# modes?) and offset your technique by the time it takes to train the autoencoder.\n- No quantitative metrics on image experiments (e.g. # modes on stacked MNIST, FID/KID for CIFAR-10).\n- Fig 5f shows that the proposed technique has horrible problems with mode collapse (row 5 has the same green 4 repeated).\n\nMinor nits:\n- “Trained to generate a sample image” -> distribution of images, not a single image\n- “Main reason of mode collapsing problem is that the discriminator is incapable of delivering any information...” citation? That is one of many hypothesis. The explanation that follows does not make sense as the discriminator is continually updated over training, not fixed.\n- “Auto-encoder trained with real dataset optimally reduces the dimension of the dataset” -> optimal in what sense? Citation or more explanation needed.\n- Eq 2 should be ||s_r - s_g|| as s_r and s_g are vectors, not scalars\n- I found the panels on your technique in Fig 2 confusing. I think presenting an example in 1d could be simpler to understand.\n- Missing details on KDE. What Kernel? How many samples did you use in the buffer?\n- Fig 6: how did you choose these panels? Were they random? Cherry picked? The DCGAN paper does not exhibit nearly as extreme mode collapse in their figures.\n- How did you choose alpha? How did you choose parameters of the KDE?\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Exploiting importance sampling in the latent space of auto-encoder to alleviate mode collapse",
            "review": "This paper proposed a new regularizer for the objective of GAN’s generator, with the purpose of alleviating the mode collapse problem. More specifically, with a pretrained auto-encoder, the regularizer is defined as a weighted distance between the latent codes of data samples and generated samples. Two different weights are used for data samples and generated samples, respectively. Accordingly comes the name “Dual Importance Weight GAN”.\n\nEven though experimental results seem convincing, the paper is not considered well-written. Detailed comments are listed below.\n\n(1) Notations are confusing. For example, it’s hard to tell vectors from scalars.\n(2) I think the introduced weights, w_r and w_k, play an important part in the proposed algorithm. However, there are no related analysis or experiments to discuss their influence.\n(3) In the paragraph before Sec. 4, the authors mentioned “we calculate distances among all real samples to all generated samples and assign pair one by one minimizing average distance” What does that mean? Mini-batch learning is used in the experiments, right? \n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}