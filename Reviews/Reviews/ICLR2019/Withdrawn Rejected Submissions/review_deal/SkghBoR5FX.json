{
    "Decision": {
        "metareview": "With scores of 5, 4 and 3 the paper is just too far away from the threshold for acceptance.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Aggregate rating of the paper just too far away from acceptance threshold."
    },
    "Reviews": [
        {
            "title": "Fast Gradient Sign Method (FGSM) is extended to the  temporal domain for action recognition attacking, but novelty is limited and experiments are unconvincing",
            "review": "The paper addresses the problem of adversarial attack for an optical-flow-based action recognition in both the white-box setting (i.e., gradients are available) and the black-box settings (i.e., the gradients cannot be computed by the optical flow algorithm). A video is partitioned into fixed-size temporal intervals, a state-of-the-art deep optical flow estimator is applied on each pair of two consecutive frames within the interval, and perturbations are applied to each frame (or selected frames using saliency cues) within the interval to attack the recognition system using Fast Gradient Sign Method (FGSM). Experiments are carried out on the UCF-101 dataset, in the white-box and black-box settings, and show that the method is able to effectively attack the system.\n\nStrengths:\n- Considering the relatively unexplored problem of attacking action recognition in the temporal domain .\n- Extending the Fast Gradient Sign Method (FGSM) to the temporal domain\n\nWeaknesses:\n - Novelty seems incremental. What appears to be novel is the extension of FGSM from image classification to action recognition (i.e., Sec 3.2) -- specifically, the gradient computation through both the action classifier and the optical flow estimator.  The paper proposes a simple solution that incorporates an existing differential deep optical flow network (FlowNet2.0) into another existing differential action classification model (TwoStream Network). Combining two existing networks seems insufficient for the problem statement as explained next.\n\n- Experiments seem unconvincing. Sec. 5.1 and 5.2 present effectiveness of the proposed attacking approach when using FlowNet2.0 as the optical flow estimator. However, the attacking effectiveness (i.e.,  accuracy drop) may be a consequence of using FlowNet2.0 which is known to be sensitive to additive perturbations.  FlowNet2.0-based action recognition is more sensitive to the perturbations than other methods like TVL1 and Far. \n\n",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Some interesting observations; But not good enough!",
            "review": "Summary:\nThis paper presents a framework for generating adversarial perturbations for videos. Specifically, the paper proceeds by using a standard image-based adversarial noise generation setup (such as the FGSM scheme), and applies it to the motion stream of a two-stream action recognition pipeline; this motion stream typically using optical flow images. As such flow generation is usually done offline and thus is not differentiable, the paper resorts to the recent FlowNet 2.0 scheme that uses an end-to-end learnable deep flow generation model. Three variants of the scheme are provided, (i) that perturbs all frames in a flow stack, (ii) that perturbs only a sparse set of frames as decided by the importance of a frame to action classification, and (iii) a variant of (ii) that recalculates the gradients for all frames if the ones selected in (ii) were not adversarial. Experiments are provided on UCF101 dataset and show promise. Analysis is presented on the transferability of  the learned noise to flow images generated via external means.\n\nStrengths:\n1) The different variants of the scheme and sparse selection of the frames to be perturbed are interesting. \n2) The paper makes some interesting observations, namely that (i) only a single frame perturbation might be sufficient to make the video adversarial, and (ii) perturbations computed via FlowNet models are not transferable to those with flow computed via external software -- which is often the practice.\n\nWeaknesses:\n1) I think the main weakness of this paper is the lack of any surprise/significant novelty in the presented approach. The main idea follows the common trend in adversarial noise generation for image classification problems, except that the inputs are a stack of frames instead of  a single one; however, such a setting do not seem to bring along any non-trivial challenges. In the second contribution of this paper -- on the sparse selection of frames to attack, there is a lack of clarity in how one would do the iterative attacks at test time, given such sparse frame selection is done via computing the frame level saliency values via the classification loss, which depends on ground truth class labels, which are unavailable at test time. \n\n2) There are previous works that have attempted video level adversarial perturbation generation, which the paper do not cite or contrast to; such as a few below. Further, the literature survey fails to provide any compelling motivation as to why video perturbation generation is any difficult than image based noise generation -- it does not appear so from the subsequent text that this problem deserves any special treatment in the considered context.\n[a] Learning Discriminative Video Representations Using Adversarial Perturbations, Wang and Cherian, ECCV 2018\n[b] Sparse Adversarial Perturbations for Videos, Wei et al., arxiv, 2018\n\n3) It is unclear why the paper chose to consider flow produced by a FlowNet model as their inputs for the attack? Why not consider the flow images directly? Of course, the optical flow algorithm may not be differentiable, but that is perhaps besides the point; the focus should be in perturbing flow, in whatever way it is generated. To that end, given that flow (on static camera images) can be sparse, it would be interesting to see how would a perturbation be generated that needs to operate on local regions (where motion happens). In my opinion, using a FlowNet model for flow generation trivializes the proposed algorithm.\n\n4) It could have been interesting if the paper also provided some qualitative results of the optical flow images generated by FlowNet after adding perturbations to the input frames. Are these flow images also quasi-impercitable? \n\nOverall, I think the paper has some observations that may be slightly interesting; however, it lacks novelty and the analysis or presentation are unconvincing.",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Need attack results on spatial stream",
            "review": "This paper proposes an effective attack technique for the widely used optical flow based classification models in white-box and black-box settings. The most interesting result is on the sparsity and frame salience, which could have a lot of applications. But the main idea is to transfer the standard attack techniques from image to video domain. I have some concerns as below. \n\n1. Page 3, \"...while the temporal stream alone achieves 83.7%. Thus, if the motion stream can be fooled, the entire model is compromised.\"\n\nThis statement is not exactly correct. Motion stream is better on UCF101 and HMDB51 dataset, which are two medium scale action recognition dataset. On other large-scale datasets like Sports1M, Kinetics, ActivityNet, etc., motion stream performs much worse than spatial stream. Hence, the motivation of the paper is unclear. Especially for real-world applications, due to real-time requirement, people usually just use the spatial stream. Hence, the current flow attack setting has limited usage. It is very important to show attack results on spatial stream as well. \n\n2. For FlowNet2, authors use gradient of the loss wrt the input images. However, FlowNet2 is a very large network consisting of 5 FlowNets. I am curious what the gradients will look like after the long back-propagation. Can authors comment on this by drawing a figure of magnitude distribution of gradients in the very early layers? \n\n\nDue to limited novelty, I recommend an initial rating of 5. \n\n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}