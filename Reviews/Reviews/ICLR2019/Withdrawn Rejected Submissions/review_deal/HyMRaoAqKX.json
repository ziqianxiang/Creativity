{
    "Decision": {
        "metareview": "The paper proposes an original idea for training a generative model based on an objective inspired by a VAE-like evidence lower bound (ELBO), reformulated as two KL terms, which are then approximately optimized by two GANs. They thus use implicit distributions for both the posterior and the conditional likelihood. The idea is original and intriguing. But reviewers and AC found that the paper currently suffered from the following weaknesses: a) The presentation of the approach is unclear, due primarily to the fact that it doesn't throughout unambiguously enough separate the VAE-like ELBO *inspiration*, from what happens when replacing the two KL terms by GANs, i.e. the actual algorithm used. This is a big conceptual jump that would deserve being discussed and analyzed more carefully and thoroughly. b) Reviewers agreed that the paper does not sufficiently evaluate the approach in comparative experiments with alternatives, in particular its generative capabilities, in addition to the provided evaluations of the learned representation on downstream tasks.\nReviewers did not reach a clear consensus on this paper, although discussion led two of them to revise their assessment score slightly towards each other's. One reviewer judged the paper currently too confusing (point a) putting more weight on this aspect than the other reviewers. \nBased on the paper and the review discussion thread, the AC judges that while it is an original, interesting and potentially promising approach, its presentation can and should be much clarified and improved.\n",
        "confidence": "3: The area chair is somewhat confident",
        "recommendation": "Reject",
        "title": "Interesting idea whose presentation could be less confusing"
    },
    "Reviews": [
        {
            "title": "Experiments in paper do not implement the objective in paper.",
            "review": "This paper introduces the implicit autoencoder, which purports to be a VAE with an implicit encoding and decoding distribution.\n\nMy principle problem with the paper and reason for my strong rejection is that there appears to be a complete separation between the discussion and theory of the paper and the actual experiments run.  The paper's discussion and theory all centers around rewriting the ordinary ELBO lower bound on the marginal likelihood in equations (4) through (7) where it is shown that this can be recast in the form of two KL divergences, one between the representational joint q(x,z) = p_data(x) encoder(z|x) and the 'reconstruction joint' r(x,z) = encoder_marginal(z) decoder(x|z), and one between the encoding marginal q(z) and the generative prior p(z).   The entire text of the paper then discusses the similarities between this formulation of the objective and some of the alternatives as well as discussing how this objective might behave in various limits.\n\nHowever, this is not the objective that is actually trained. In the  \"Training Process\" section is it revealed that an ordinary GAN discriminator is trained.  The ordinary GAN objective does not minimize a KL divergence, it is a minimax formulation of a Jensen Shannon divergence as the original GAN paper notes.  More specifically, you can optimize a KL divergence with a GAN, as shown in the f-GAN paper (1606.00709) but this requires attention be paid to the functional form of the loss and structure of the discriminator.  No such care was taken in this case.  As such the training process does not minimize the objective derived or discussed.  Not to mention that in practice a further hack is employed wherein only the negative example passes gradients to the generator.  \n\nWhile is not specified in the training process section, assuming the ordinary GAN objective (Equation 1) is used, according to their own reference (AVB) the optimal decoder should be:  D = 1/(1 + r(z,x)/q(z,x))  for which we have that what they deem the 'generative loss of the reconstruction GAN' is T = log(1 + r(z,x)/q(z,x))  .   When we take unbiased gradients of the expectation of this quantity, we do not obtain an unbiased gradient of the KL divergence between q(z,x) and r(z,x).\n\nThroughout the paper, factorized Gaussian distributions are equated with tractable variational approximations.  While it is common to use a mean field gaussian distribution for the decoder in VAEs this is by no means required.  Many papers have investigated the use of more powerful autoregressive or flow based decoders, as this paper itself cites (van der Oord et al. 2016).  The text further misrepresents the current literature when it claims that the IAE uniquely \"generalizes the idea of deterministic reconstruction to stochastic reconstruction by learning a decoder distribution that learns to match to the inverse encoder distribution\".  All VAEs have employ stochastic reconstruction, if the authors again here meant to distinguish a powerful implicit decoder from a mean field gaussian one, the choice of language here is wrong.\n\nGiven that there are three joint distributions in equation (the generative model, the representational joint and the reconstruction joint), the use of Conditional entropy H(x|z) and mutual information I(x, z) are ambiguous.  While the particular joint distribution is implied by context in the equations, please spell it out for the reader.\n\nThe \"Global vs. Local Decomposition of Information in IAEs\" section conflates dimensionality with information capacity.  While these are likely correlated for real neural networks, at least fundamentally an arbitrary amount of information could be stored in even a 1 dimensional continuous random variable.  This is not addressed.  \n\nThe actual experiments look nice, its just that objective used to train the resulting networks is not the one presented in the paper. \n\n------\n\nIn light of the author's response I am changing my review from 2 to 3.  I still feel as though the paper should be rejected.  While I appreciate that there is a clear history of using GANs to target otherwise intractable objectives, I still feel like those papers are all very explicit about the fact that they are modifying the objective when they do so.  I find this paper confusing and at times erroneous.  The added appendix on the bits back argument for instance I believe is flawed.\n\n\"It first transmits z, which ideally would only require H(z) bits; however, since the code is designed\nunder p(z), the sender has to pay the penalty of KL(q(z)kp(z)) extra bits\"\n\nFalse.  The sender is not trying to send an unconditional latent code, they are trying to send the code for a given image, z \\sim q(z|x).  Under usual communication schemes this would be sent via an entropic code designed for the shared prior at the cost of the cross entropy \\int q(z|x) \\log p(z) and the excess bits would be KL(q(z|x) | p(z)), not Kl(q(z)|p(z)).  \n\nThe appendix ends with \"IAE only minimizes the extra number of bits required for transmitting x, while the VAE minimizes the total number of bits required for the transmission\" but the IAE = VAE by Equation (4-6).  They are equivalent, how can one minimizing something the other doesn't?  In general the paper to me reads at times as VAE=IAE but IAE is better.  While it very well might be true that the objective trained in the paper (a joint GAN objective attempting to minimize the Jensen Shannon divergence between both  (1) the joint data density q(z,x) and the aggregated reconstruction density r(z,x) and (2) the aggregated posterior q(z) and the prior p(z)) is better than a VAE (as the experiments themselves suggest), the rhetoric of the paper suggests that the IAE referred to throughout is Equation (6).  Equation 6 is equivalent to a VAE.\n\nI think the paper would greatly benefit from a rewriting of the central story.  The paper has a good idea in it, I just feel as though it is not well presented in its current form and worry that if accepted in this form might cause more confusion than clarity.  Combined with what I view as some technical flaws especially in the appendices I still must vote for a rejection.",
            "rating": "3: Clear rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting models (with a potentially indifferent encoder?)",
            "review": "The paper presents two generative autoencoding models, that optimize a variational objective by adversarial training of implicit distributions. Applications in generative modeling, clustering, semi-supervised learning and disentangling “global” vs “local” variations in data are presented. \n\nIn particular, the first model, called implicit autoencoder, maximizes the ELBO using two adversarial objectives: an adversarial regularizer penalizes the deviation of the aggregated posterior from the prior and the adversarial reconstruction penalizes the disagreement between the joint distribution and the joint reconstruction. Since both implicit distributions use a noise source, they can both explain variations in the data. The paper argues (and presents experimental results to suggest) that the global vs local information is the separation in these two components. The second architecture, called _flipped_ implicit autoencoder replaces the role of code and input in the first architecture, changing the training objective to reverse KL-divergence. The relationship between the proposed models to several prior works including ALI, BiGAN, AVB, adversarial autoencoders, wake-sleep, infoGAN is discussed. \n\nThe paper is nicely written, and the theory part seems to be sound. The strength of this paper is that it ties together a variety of different autoencoding generative architectures. In particular, I found it interesting that AVB and InfoGAN become special cases of the regular and flipped model, where an implicit term in the loss is replaced by an explicit likelihood term. \n\nI have some issues/questions (did I miss something obvious?):\n\n1) A mode of failure: suppose the encoder simply produces a garbled code that does not reflect that data manifold, yet it has the right aggregated posterior. In this case, the implicit generator and discriminator should ignore the code. However, the generator can still match the joint reconstruction and to the correct joint distribution. The loss can go towards its minimum. Note that this is not a problem in AVB.\n\n2) Global vs local info: a closely related issue to previous failure mode is that encoder has no incentive to produce informative codes. While the paper argues that the size of the code can decide the decomposition of local vs. global information, even for a wide bottleneck in the autoencoder, the code can have no (or very little) information.\n\n3) Could you please elaborate on the footnotes of page 3?",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Increasing the expressiveness of decoder by an implicit decoder looks interesting, and it enables the decompositions of high-level abstract information from low one.",
            "review": "The paper proposed an implicit auto-encoder, featuring both the encoder and decoder constituted by implicit distributions. Adversary training is used train the models, similar to the technique used in the AVB model. The main difference with AVB is the use of an implicit decoder, which endows the model with the ability to disentangle the data into high-level abstract representation and local representation. Although sharing some similarities, the extension of using implicit decoder is interesting, and leading to some interesting results. \n\nMy main concern on this paper is the lack of any quantitive results to compare with other similar models. We only see the model can do some task, but cannot assess how well it did comparing to other models.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}