{
    "Decision": {
        "metareview": "The authors present a method using a VAE to model segmentation masks directly. Errors in reconstruction of masks by the VAE indicate that the mask may be outside the distribution of common mask shapes, and are used to predict poor quality segmentation scenarios that fall outside the distribution of common segmentations. \n\nPros:\n+ R2: Technical idea is interesting, and a number of baselines used to compare. \n+ R1 & R4: Method is novel. \n\nCons:\n- R3 & R4: The method ignores the original input in its prediction, making the method wholly reliant on shape priors. In situations where the shape prior is weak, the method may be expected to fail. Authors have confirmed this, but not added any experiments to quantify its effect. \n- R4: The baseline regressor method is missing key details, which makes it impossible to judge if the comparison is fair (i.e. at minimum, number of learned parameters for each model, number of convolutional layers, structure of network, etc.). Authors have not provided these details. Authors have not investigated datasets with weak shape prior to see how methods compare in this setting.\n- R2: GANs can be used as a baseline. Authors confirmed, but did not supply results. \n\nReviewers generally agree that the idea is novel, but the value of the approach cannot be determined due to missing baseline experiments, and missing details of baselines. Recommend reject in current form, but encourage authors to complete experiments. ",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Promising direction of research for detecting poor quality segmentation, but further experiments and analysis must be completed. "
    },
    "Reviews": [
        {
            "title": "Interesting approach and seems to have adequate convincing experiments ",
            "review": "Summary:\n      The paper tries to predict the quality of output of a segmentation algorithm applied to medical images. The approach of this paper is to looks at the \"true\" shape of the segmentation on the training samples and learn a VAE for the shape feature on them  for training samples.  For the test samples (that are new and are segmented only the algorithm whose quality is to be predicted), a linear function of the loss function of the learnt VAE applied to the output for the segmentation is used to predict quality. The linear function is tuned to the VAE loss of the output of the specific segmentation algorithm on the training samples.\n\n The basic premise is that VAE minimizes the gap between between the log likelihood of the true shape and the VAE loss function. Therefore, the gap should be small for \"good\" shapes while very bad for \"bad/wrong\" shapes. Therefore the VAE loss trained on the good shapes on the training examples can indicate the goodness of a segmentation algorithm's output.\n\nPros:\n  I think the authors have compared to the number of baselines on three medical imaging datasets and show that their method via various metrics clearly outperforms others on this specific medical imaging application.\n\nI like the primary technical idea behind the paper of detecting low quality outputs by projecting to the range space of a VAE and looking at its likelihood.\n\nCons:\n1)  I dont know about the apriori assumption that shape of the segmentation will be the right feature to actually focus on. How general is this assumption for medical imaging tasks ?\n\n2) Authors say - \"Variational autoencoder(VAE) (Kingma & Welling, 2013), compared with AE, has stronger representation capability\" - Why does the VAE have stronger representation capability?  - I dont understand this part.  Is it because it outputs the probabilities z given Y and Y given z that is somehow more useful ?\n\n3) Can GANs be used instead of VAEs? Is there a natural loss function that could be used in this case during quality prediction?\n\n\nDisclaimer: I am not an expert in the area for segmentation of medical images.\n",
            "rating": "7: Good paper, accept",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting idea, but evaluation and relevant background literature is not thorough. ",
            "review": "The authors present a method to detect poor quality segmentation results by using a VAE to understand the statistical distribution of segmentation masks, and detect outliers from that distribution in predictions. Method is compared to a few baselines to show improved results.\n\nPros:\n\n1) The idea seems slightly novel, simple, and elegant, with respectable results.\n\nCons:\n\n1) This method is related to Out-of-Distribution (OOD) detection, which is an entire field unto itself. None of the relevant literature around OOD has been covered by this paper, including several recent ICLR papers:\n\nHendrycks, Gimpel, \"A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS\" ICLR 2017\nLiang et al. \"ENHANCING THE RELIABILITY OF OUT-OF-DISTRIBUTION IMAGE DETECTION IN NEURAL NETWORKS\" ICLR 2018\n\n2) The method is not compared to more naive approaches, such as building a network to take as input both modalities of original image and segmentation mask, and predict (classify) poor quality. \n\n3) The method assumes segmentation masks have some strong statistical prior. This may be the case for organs, but can completely break down in other cases, such as skin lesion segmentation ( http://challenge2018.isic-archive.com ). In this circumstance, reviewer questions if more naive approach in (2) above would work better.\n\n\nReviewer believes authors have a good line of research, but that it requires additional literature review and experiments before it is ready for publication. \n\n\nEDIT: Reviewer has considered the response by the authors. Key details of the baseline regressor are missing, such as the exact network structure used. As a result: 1) Reviewer is unable to determine if the baseline is a proper fair comparison. 2) Authors have confirmed the methods reliance on strong shape prior, but this caveat is not clearly mentioned in the paper as a requirement for the method to work. Furthermore, authors did not quantify what affect this reliance has by adding experiments on datasets with weak shape priors mentioned by reviewer. As a result, reviewer is lowering score. Reviewer encourages authors to continue this line of research, but carefully consider the feedback given to make the work stronger before publication.\n",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting and novel way of quantifying the quality of segmentations",
            "review": "This paper explores the idea of having a VAE modelling the probability distribution of the real segmentations, in order to quantify the quality of the predicted segmentation (using another network). The paper refines this idea by applying regression over two parameters. The overall idea is interesting and novel to the best of my knowledge. Experimental results look convincing.\n\nThe paper does a good job at presenting the motivation, reads well in general, and it is well written (except the paragraph Entropy Uncertainty in Sec. 4.2 which contains several typos).\n\nSome comments:\nS(F(X); Î¸) looks good enough as an estimator. It would be good to see how it does by itself, reporting that as an ablation experiment, assessing how important it is to carry out the second step (fitting a, b).\nIn the last paragraph of Sec. 2, I am not sure what it is meant by \"Variational autoencoder(VAE) (Kingma & Welling, 2013), compared with AE, has stronger representation capability and can also serve as a generative model\". No doubt about the latter point, but not sure about the former.\nSec. 3.3 is somewhat confusing, for example: what is E in eq. 9 should be L?\n\nRevision: in light of the relevant papers brought up by AnonReviewer3 and AnonReviewer4, that have not been discussed in the paper, I modify my rating to 6.",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Evaluates the quality of segmentation using  a shape prior learned from ground-truth masks with a variational autoencoder",
            "review": "This paper presents an approach to evaluate the quality of segmentations. To achieve this, a variational auto-encoder (VAE) is trained on the ground truth masks to extract shape-relevant information in the feature space, assuming that incorrect segmentations will be far from the normal distribution. Then, a regression model is trained to predict the quality of the segmentation based on the shape-learned features. The authors use several datasets focusing on pancreas segmentation to evaluate their quality-assessment approach, showing competitive performance with respect to other approaches.\n\nThe paper is well written, easy to follow in general, and the methodology is sound. Nevertheless, I have some concerns related to the applicability of this approach.\n\n- Closely related works in the literature are missing:\n\nThere is a closely related recent work that used auto-encoders on the sets of ground-truth masks to build representations of shape and constrain the outputs of deep networks: Otkay et al., Anatomically Constrained Neural Networks (ACNN): Application to Cardiac Image Enhancement and Segmentation, IEEE TMI 2017\n\nThis work does not focus directly on quality assessment. However, I believe the loss in this work, which evaluates the difference between the obtained segmentation (characterized by the outputs of a deep network) and an auto-encoder description of shape, can be used directly as a criterion for evaluating the quality of segmentation (on validation data) in term of consistency with the shape prior. I think this work is very closely related and should be discussed. \n\nAlso, a quick google search provided some missing references related to this work. I think including comparisons to the recent work in [1], for example, would be appropriate. As the focus is on quality assessment of medical image segmentation, I would suggest a deeper review of the literature.\n\n[1] Vanya V Valindria, Ioannis Lavdas, Wenjia Bai, Konstantinos Kamnitsas, Eric O Aboagye, Andrea G Rockall, Daniel Rueckert, and Ben Glocker. Reverse classification accuracy: Predict- ing segmentation performance in the absence of ground truth. IEEE Transactions on Medical Imaging, 2017. \n[2] S. Chabrier, B. Emile, C. Rosenberger, and H. Laurent, âUnsupervised performance evaluation of image segmentation,â EURASIP Journal on Applied Signal Processing, vol. 2006, pp. 217â217, 2006. \n[3] Gao H, Tang Y, Jing L, Li H, Ding H. A Novel Unsupervised Segmentation Quality Evaluation Method for Remote Sensing Images. Sensors. 2017 Oct 24;17(10):2427.\n\n- The proposed quality assessment uses the learned shape features.  Even though it is strong prior information, there  might be situations where the predicted segmentation might be plausible in terms of shape, but is not a good segmentation. \n\n-  I wonder how this approach works in problems with a high size/shape variation. For example, in the case of tumors, where their shape is unpredictable and each unknown case can be seen as a ârareâ example.\n\n- To better capture the shape in the proposed approach, images need to be aligned, which limits the applicability of this approach to aligned volumes only. \n\n- This approach gives a global hint about a given segmentation result, as a whole. I think it would be more interesting to provide local information on a segmentation, as it may happen that a predicted contour is generally correct, but there are some crispy borders in some points due to low contrast, for example. Even though the quality assessment would say that the prediction is correct, the contour may be unusable for certain applications, where a minimal surface distance is required (e.g., radiotherapy).\n\n- As the quality assessment is based on shape and not in image information, it would be interesting to see how accurately it predicts the performance on different image modalities (for example, the method is trained on ground truth masks corresponding to CT images and quality is assessed in segmentations performed in MRI).\n\nIf I understood correctly, comparison with other methods is done with the same dataset under the same conditions (i.e., all the images are pre-aligned). As the other methods might not have the limitation of requiring aligned images, it would be interesting to compare also the performances in this situation.\n\nHow the training (or the VAE) is adapted for DeepLab-3, as it is based on 2D convolutions?\n\nMinor: The paper needs a proof-read to fix some issues (e.g. âthe properties of F is encodedâ)\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}