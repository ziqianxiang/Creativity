{
    "Decision": {
        "metareview": "The paper proposes a method for saving computation in surveillance videos (videos without camera motion) by re-using features from parts of the image that do not change. The results show that this significantly saves computation time, which is a big benefit, given also the amount of surveillance video input available for processing nowadays. Reviewers request comparisons to obvious baselines, e.g., selecting a subset of frames for processing or performing a low level pixel matching to select the pixels to compute new features on. Such experiments would make this paper much stronger. There is no rebuttal  and thus no ground for discussion or acceptance.\n",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "lacking experiments against simple baselines"
    },
    "Reviews": [
        {
            "title": "Incremental contribution",
            "review": "In this paper, the authors propose a dynamic convolution model by exploiting the inter-scene similarity. The computation cost is reduced significantly by reusing the feature map. In general, the paper is present clearly, but the technical contribution is rather incremental. I have several concerns:\n1. The authors should further clarify their advantages over the popular framework of CNN+LSTM. Actually, I did not see it. \n2.  What is the difference between the proposed method and applying incremental learning on CNN?\n3. The proposed method reduced the computation in which phase, training or tesing?\n4. The experimental section is rather weak. The authors should make more comprehensive evaluation on the larger dataset. Currently, the authors only use some small dataset with short videos, which makes the acceleration unnecessary. \n",
            "rating": "3: Clear rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Needs more analysis and explanation",
            "review": "Summary - This paper proposes a technique to reduce the compute cost when applying recognition models in surveillance models. The core idea is to analytically compute the pixels that changed across frames and only apply the convolution operation to those pixels. The authors term this as dynamic convolution and evaluate this method on the SSD architecture across datasets like PETS, AVSS, VIRAT.\n\nPaper strengths\n- The problem of reducing computational requirements when using CNNs for video analysis is well motivated. \n- The authors analyze a standard model on benchmark datasets which makes it easier to understand and place their results in context.\n\nPaper weaknesses\n- A simple baseline that only processes a frame if \\sum_{ij} D_{ij} exceeds a threshold is never mentioned or compared against. In general, the paper does not compare against any other existing work which reduces compute for video analysis, e.g., tracking. This makes it harder to appreciate the contribution or practical benefit of using this method.\n- The paper has many spelling and grammar mistakes - \"siliarlity\", \"critiria\" etc.\n- Continuous convolutions - It is not clear to me what is meant by this term. It is used many times and there is an entire section of results on it (Table 6), but without clearly understanding this concept, I cannot fully appreciate the results.\n- Section 5.2 - what criteria or metric is used to compute scene similarity?\n- Overall, I think this paper can be substantially improved in terms of providing details on the proposed approach and comparing against baselines to demonstrate that Dynamic-Convolutions are helpful.\n- Design decisions such as cell-based convolution (Figure 3) are never evaluated empirically.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Review for DynCNN: An Effective Dynamic Architecture on Convolutional Neural Network for Surveillance Videos ",
            "review": "The paper addresses the problem of computational inefficiency in video surveillance understanding approaches. It suggests an approach called Dynamic Convolution consists of Frame differencing, Prediction, and Dyn-Convolution steps. The idea is to reuse some of the convolutional feature maps, and frame features particularly when there is a significant similarity among the frames. The paper evaluates the results on 4 public datasets. However, it just compares the approach to a baseline, which is indeed applying convnet on all frames. \n\n- State of the art is not well-studied in the paper. Video understanding approaches usually are not just applying convnet on all frames. Many of the approaches on video analysis, select a random set of frames (or just a single frame) [5], and extract the features for them. There is another set of work on attention, that try to extracts the most important spatio-temporal [1-4] information to solve a certain task. These approaches are usually computationally less expensive than applying convnet on all video frames. I suggest the authors compare their model with these approaches. \n\n[1] Spatially Adaptive Computation Time for Residual Networks., Figurnov et al. \n[2] Recurrent Models of Visual Attention, Mnih et al.\n [3] Action recognition using visual attention, Sharma et al.\n [4] End-to-end learning of action detection from frame glimpses in videos, Yeung et al.\n [5] Two-Stream Convolutional Networks for Action Recognition in Videos, Simonyan et al. \n\n- In addition, car and pedestrian detection performance is part of the evaluation process. In this case, the approach should be also compared to the state-of-the-art tracking approaches (that are cheaper to acquire) in terms of computational efficiency and performance. \n- The writing of the paper should also improve to make the paper more understandable and easier to follow. Some examples: 1. Unnecessary information can be summarized. For example, many details on the computational costs in abstract and the introduction can just simply be replaced by stating that “these approaches are computationally costly”.  2. Using present tense for the SoTA approaches is more common.“ShuffleNet (Zhang et al. (2017)) proposed two new strategies”.  3. Long sentences are difficult to follow: “In real surveillance video application, although the calculation reduction on convolution is the main concern of speeding up the overall processing time, the data transfer is another important factor which contributes to the time”\n  + The problem of large-scale video understanding is an important and interesting problem to tackle.  ",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        }
    ]
}