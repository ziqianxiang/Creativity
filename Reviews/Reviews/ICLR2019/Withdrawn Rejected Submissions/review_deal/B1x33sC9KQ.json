{
    "Decision": {
        "metareview": "The paper describes a clipping method to improve the performance of quantization. The reviewers have a consensus on rejection due to the contribution is not significant. ",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "incremental work"
    },
    "Reviews": [
        {
            "title": "Errors and Contributions not significant ",
            "review": "The paper describes a clipping method to improve the performance of one particular type of quantization method that is naive clipping to closest \"bins\". The contribution of the paper is the (possibly incorrect) derivation of the clipping value that causes the least quantization error IF assumptions can be made about the distribution of the parameters (in a non-bayesian sense). Thus, the significance is low due to both reasons.\n\nOne conceptual issue is the assumed relationship between quantization error and classification accuracy. The literature has shown that high quantization error does not necessarily mean low classification accuracy when using non-uniform quantization. The proposed clipping does not account for classification accuracy (on training set), but I understand the motivation being that the training set is not available. \n\n1. There seems to be an error in derivation of Eq (3), the first term should be $(x-sgn(x).\\alpha) = x+\\alpha$ for $x$ negative. Please comment on this.\n\n2. When solving the integrals, the authors simply pull the solution \"out of the hat\" and show that the derivative is the integrand. This is a very opaque presentation that we cannot see how you solved the integral. What is C in $\\psi(x)$?\n\n3. The assumptions on the parameters are only valid for the particular model/dataset/precision. The assumption does not generalize arbitrarily. For example, models with quantized weights have bi-modal distributions. How would you clip the  activations after e.g. a ReLu? This is without going in to the weaknesses of the K-S test. \n\n4. Experiments do not show any comparison to the large body of prior work in this area. \n\n5. Page 4, para below (3), what is \"common additive orthogonal noise\"? You should explain or give intuition instead of simply referring to a different paper.\n\n6. In the uniform case, one would think f(x)=1/<range of the interval>=2\\alpha. Why is it 1/\\Delta?\n\n6. Section 4, range should be [-\\alpha, \\alpha] instead of [\\alpha, -\\alpha]? Since \\alpha is positive.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "review",
            "review": "This paper derives a formula for finding the minimum and maximum clipping values for uniform quantization which minimize the square error resulting from quantization, for either a Laplace or Gaussian distribution over pre-quantized value. This seems like too small a contribution to warrant a paper. I wasn't convinced that appropriate baselines were used in experiments. There were a number of statements that I believed to be technically slightly incorrect. There were also some small language problems (though these didn't hinder understanding).\n\nmore specific comments:\n\nabstract:\n\"derive exact expressions\" -- these expressions aren't exact. they turn out to be based on a piecewise zeroth order Taylor approximation to the density.\n\nmain paper:\n\"allow fit bigger networks into\" -> \"allow bigger network to fit into\"\n\"that we are need\" -> \"that need\"\n\"introduces an additional\" -> \"introduces additional\"\nclippig -> clipping\n\nit's not clear a-priori that information loss is the property to minimize that maximizes performance of the quantized network.\n\n\"distributions of tensors\" -> \"distribution of tensor elements\"\nthis comment also applies in a number of other places, where the writing refers to the marginal distribution of values taken on by entries in a tensor as the distribution over the tensor. note that a distribution over tensors is a joint distribution over all entries in a tensor. e.g. it would capture things like eigenvalues, entry-entry covariance, rather than just marginal statistics.\n\n\"than they could have by working individually\" -> \"than could have been achieved by each individually\"\n\nWhy the focus on small activation bit depth? I would imagine weight bit-depth was more important than activation bit depth. Especially since you're using ?32-bit? precision in the weight/activations multiplications, so activations are computed at a high bit depth anyways.\n\nTable 1: Give absolute accuracies too! Improvement relative to what baseline?\n\nsec 2:\nsufficeint -> sufficient\n\\citep often used when it should instead be \\citet.\n\"As contrast\" -> \"In contrast\"\n\nsection 3:\nuniformity -> uniformly\n\nI don't believe the notion of p-value is being used correctly here w.r.t. the Kolmogorov-Smirnov test.\n\nFigure 1: The mean square error should never go to 0. This suggests something is wrong. If it's just a scaling issue, consider a semilogy plot.\n\nFigure 2: I'm unclear what baseline (no clipping) refers to in terms of clipping values. For uniform quantization there needs to be some min and max value.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "A simple but not very convincing clipping method for activation quantization in deep networks",
            "review": "This paper empirically finds that the distribution of activations in quantized networks follow  Gaussian or Laplacian distribution, and proposes to determine the optimal clipping factor by minimizing the quantization error based on the distribution assumption.\n\nThe pros of the work are its simplicity, the proposed clipping and quantization does not need additional re-training. However, while the key of this paper is to determine a good clipping factor, the authors use uniform density function to represent the middle part of both Gaussian and Laplacian distributions where the majority of data points lie in, but exact computation for the tails of the distributions at both ends. Thus the computation of quantization error is not quite convincing. Moreover, the authors do not compare with the other recent works that also clip the activations, thus it is hard to validate the efficacy of the proposed method.\n\nFor the experiments, the authors mention that a look-up table can be pre-computed for fast retrieval of clipping factors given the mean and sigma of a distribution.  However, the mean and sigma are continuous numbers, how is the look-up table made?  Moreover, how is the mean and std estimated for each weight tensor and what is  the complexity?\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}