{
    "Decision": {
        "metareview": "Reviewer ratings varied radically (from a 3 to an 8). However, the reviewer rating the paper as 8 provided extremely little justification for their rating. The reviewers providing lower ratings gave more detailed reviews, and also engaged in  discussion with the authors. Ultimately neither decided to champion the paper, and therefore, I cannot recommend acceptance.",
        "confidence": "4: The area chair is confident but not absolutely certain",
        "recommendation": "Reject",
        "title": "Radically different scores"
    },
    "Reviews": [
        {
            "title": "Well written and organized paper. Domain concepts presented fairly clearly. The approach and choices of classification algorithms is well articulated and results interesting. Good combination of known algorithms on a purposely built dataset (Originality questionable).",
            "review": "Contribution:\n\t- Using a known parameters crystallography simulator (X-ray beam, structure being analyzed, environment (crystalline or not)) built a dataset (called DiffraNet) of 25,000 512x512 grayscale labeled images of resulting diffraction images of various materials/structures (crystalline or not) .\n\t- carried various classification approaches of the dataset (labelled) images in two steps:\n\t\t- Feature extraction (Scale Invariant Feature Transform with the Bag-of-Visual-Words approach as local feature extractor, and the Gray-level Co-occurrence Matrix and Local Binary Patterns as global feature extractor) then\n\t\t- Classification of the diffraction images is carried with three approaches. Two using images described by extracted features (from the previous feature extraction step) coupled with either random Forests or Support Vector Machines and a third consisting in a Convolution Neural Network (CNN) topology named DeepFreak.\n\t\t- The images are classified according to the diffraction patterns they encompass into one of 5 classes: blank, no-crystal, weak, good and strong. The last three describing presence of a crystalline structure.\n\t\t- A fine tuning step of the various algorithms was carried using AutoML optimization tools.\nAll algorithms were off the shelf publicly available implementations and have previously been used for such domain applications (crystallography patterns).\nThe approach and choices of classification algorithms is well articulated and results interesting.\n\nA few questions though:\n•\tIn what way the diffraction images are ‘synthetic’? Aren’t they actual diffraction images but in a controlled known and controlled setting: set of parameters (beam, structure to analyze)?\no\tMore like a library of diffraction pattern images for various materials/structures.\n•\tHow many structures were analyzed (Were there 25000 for the 25000 pattern images), one image each?\no\tThis is to understand  the representability of the samples (structures) analyzed regarding the possible structures (Hundreds of thousands as per paper’s 2.1 ) .\n•\tWhat variations for each of the setting variabilities (X Ray beam(flux, beam size, divergence, and bandpass), crystal properties (unit cell, number of cells, and a structure factor table), and the experimental parameters (sources of background noise, detector point-spread, and shadows)) were used? \no\tThis is to assess the size of the pattern space.\n•\tWere any real-life setting obtained pattern samples classified using DiffraNet dataset patterns’ fine-tuned classification algorithms?\no\tThis is to assess the generalization level of the DiffraNet dataset patterns’ fine-tuned classification algorithms to real-life obtained patterns (relates to the previously stated representability of the samples).\no\tIf not, your statement “ … we plan to add new images and new classes that are common place in serial crystallography” (in 6. Conclusions) would be an appreciated validation of general usability of your DiffraNet fine–tuned setting.\n•\tWere all the structures analyzed crystalline? \no\tIt’s stated in Figure 2 and Table 6 that 2 classes are either blank or no-crystal but is that a known fact (purposely chosen) or no pattern images for crystalline structures due to inadequate experimental settings to uncover the crystalline nature of the analyzed structure?\n•\tWere the pattern images pre-processed in any manner before being classified?\n\n\nNota: In table 6, use no-crystal class as in Figure 2 for consistency. ",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "Interesting application domain, but no novelity in terms of methods; For a synthetic dataset, I would like to see the impact to real test data",
            "review": "This paper introduces a purely synthetic dataset for crystallography diffraction patterns. For this very specific application domain, this might be a very welcome approach, however, I feel the paper is not strong enough for ICLR for two reasons:\n\n1. The scope is too narrow for ICLR. Only a limited readership will be interested in this specific problem. Since the contribution is mainly on the dataset level and not on the methodological level, I suggest submitting such an article in venues more focused on the application domain. I can see no contribution which is general enough to be interesting for the broader readership. A new dataset might be of interest if it is a really challenging one where current approaches cannot yield high performance levels while it would be easy for domain experts to recognize.\n\n2. The experiments are only on synthetic data. I agree that synthetic data in general can be very useful, if generated correctly (this has been shown in many works). For a substantial article contribution, one should, however, in general add much more exhaustive experiments. Besides analyzing the behavior on synthetic data, one should perform tests on real data and see the influence of, e.g., pre-training on this synthetic dataset. Furthermore, comparison to pre-training on other datasets should be performed. ",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "The paper described a new open synthetic dataset for serial crystallography and compared three approach to classify these data. The paper is well written, clear and contribute an original dataset. The significance of the work need to be justified further by making comparison to real data. ",
            "review": "The paper describes a new open synthetic dataset for serial crystallography generated by a simulator. Three methods are proposed and implemented to demonstrate the classification of these diffraction images. The results from these methods are compared and clearly show the ones achieve high performance. The article structure is clear and is well written. The experiments are carried out in a professional way and statistical analysis is shown. It will be better if the authors can demonstrate how the models obtained from training the synthetic data perform in real scenario. Please also add some discussion on how good the synthetic data simulate the real data. Some image comparison between the synthetic data and real data should be analysed. ",
            "rating": "8: Top 50% of accepted papers, clear accept",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}