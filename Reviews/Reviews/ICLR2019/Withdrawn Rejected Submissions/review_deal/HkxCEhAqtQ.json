{
    "Decision": {
        "metareview": "This paper developed an accelerated gradient flow in the space of probability measures. Unfortunately, the reviewers think the practical usefulness of the proposed approach is not sufficiently supported by realistic experiments, and the clarity of the paper need to be significantly improved. The authors' rebuttal resolved some of the confusion the reviewers had, but we believe further substantial improvement will make this work a much stronger contribution. ",
        "confidence": "5: The area chair is absolutely certain",
        "recommendation": "Reject",
        "title": "Interesting ideas but method is not practical "
    },
    "Reviews": [
        {
            "title": "interesting derivation of 2nd gradient flows but with limited practical usefulness",
            "review": "This paper derives accelerated gradient flow formula in the space of probability measures from the view of optimal control formalism. The generalization of variational formulation from finite space to the space of probability measures seems new, but the resulting PDE seems to be a known result, which is the Fokker-Planck equation (with some minor modifications) for the 2nd order Langevin dynamic. From this point of view, the resulting algorithm from the derived PDE seems not having much practical advantage over SGHMC (a stochastic version of 2nd order Langevin dynamics).\n\nActually, I think the derivation of accelerated gradient flow formula from the view of optimal control formalism does not seem necessary. One can get the same formula by deriving it from Wasserstein gradient flows. When considering the functional as relative entropy, one can derive the formula simply from the Fokker-Planck equation of 2nd order Langevin dynamics. As a result, the proposed methods seems to be a new way to derive the Wasserstein gradient flow (or Fokker-Planck equation), which does not make impact the algorithm, e.g., both ways result in the same algorithm.\n\nBesides, I found the writing needs to be improved. There are a lot of background missing, or the descriptions are not clear enough.  For example:\n1. Page 2: the divergence operator is not defined, though I think it is a standard concept, but would be better to define it.\n2. Page 2: the Wasserstein gradient and Gateaux derivative are not defined, what are the specific meanings of \\nabla_\\rho F(\\rho) and \\partial F / \\partial \\rho?\n3. 1st line in Section 2: convex function f of d real variables seems odd, I guess the author means argument of f is d-dimensional variable.\n4. Section 2, the authors directly start with the variational problem (3) without introducing the problem. Why do we need to variational problem? It would be hard to follow for some one who does not have such background.\n5. Similarly, what is the role of Lyapunov function here in (6)? Why do we need it?\n6. Why do you define the Lagrangian L in the form of (10)? What is the relation between (10) and (2)?\n7. It is not clear what \"The stochastic process (X_t, Y_t) is Gaussian\" means in Proposition 1? It might need to be rephrased.\n8. Second last line in page 5: I guess \\nabla \\log(\\rho) should be \\nabla\\log(\\rho_t).\n\nFor the theory, I think eq.15 only applies when the PDE, e.g. (13), is solved exactly, thus there is not too much practical impact, as it is well known from the Wasserstein gradient theory that the PDE decays exponentially, as stated in the theorem. When considering numerical solutions, I think this results is useless.\n\nFor the relation with SGHMC, let's look at eq.16. Actually, the derivative of the log term \\nabla \\log \\rho_t(X_t)) is equivalent to a brownian motion term. This can be seen by considering the Fokker-Planck equation for Brownian motion, which is exactly d \\rho_t = \\Delta \\rho_t. Consequently, instead of using the numerical approximations proposed later, one cane simply replacing this term with a Brownian motion term, which reduces to SGHMC (with some constant multipliers in front). \n\nThe authors then shows empirically that the proposed method is better than SGHMC, which I think only comes from the numerical methods.\n\nFor the kernel approximation, it makes the particles in the algorithm interactive. This resembles other particle optimization based algorithms such as SVGD, or the latest particle interactive SGLD proposed in [1] or [2[.  I think these methods need to be compared.\n\n[1] Chen et al (2018), A Unified Particle-Optimization Framework for Scalable Bayesian Sampling.\n[2] Liu et al (2018), https://arxiv.org/pdf/1807.01750.pdf\n\nTo sum up, though the derivation of accelerated gradient flow formula seems interesting, the resulting algorithm does not seem benefit from this derivation. The algorithm seems to be able to derived from a more direct way of using Wasserstein gradient flows, which results in a Wasserstein gradient flow for 2nd order Langevin dynamics, and is thus well known. The experiments are not convincing, and fail to show the advantage of the proposed method. The proposed method needs to be compared with other related methods.",
            "rating": "4: Ok but not good enough - rejection",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        },
        {
            "title": "theoretically interesting",
            "review": "The articles adapt the framework developed in Wibisono & al to the (infinite dimensional) setting consisting in carrying out  gradient descent in the space of probability distributions.\n\nPROS:\n- the text is well written, with clear references to the literature and a high-level description of the current state-of-the-art.\n- there is a good balance between mathematical details and high-level descriptions of the methods\n- although I have not been able to check all the details of the proofs, the results appear to be correct.\n\nCONS:\n- while I think that this type of article is interesting, I was really frustrated to discover at the end that the proposed methods either rely on strong Gaussian assumptions, or  \"density estimations\". In other words, no \"practical\" method is really proposed.\n- no comparison with other existing method is provided.\n\n\n",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "3: The reviewer is fairly confident that the evaluation is correct"
        },
        {
            "title": "Interesting extension of the Bregman Lagrangian framework, but quite expensive",
            "review": "Summary: This paper introduces a functional extension of the Bregman Lagrangian framework of Wibisono et al. 2016. The basic idea is to define accelerated gradient flows on the space of probability distribution. Because the defined flows include a term depending on the current distribution of the system, which is difficult to compute in general, the authors introduce an interacting particle approximation as a practical numerical approximation. The experiments are a proof-of-concept on simple illustrative toy examples.\n\nQuality: The ideas are generally of high quality, but I think there might some typos (or at least some notation I did not understand). In particular\n- tilde{F} is not defined for Table 1\n- the lyapunov function for the vector column of table one includes a term referring to the functional over rho. I think this is a typo and should be f(x) - f(xmin) instead.\n\nClarity: The paper is generally clear throughout.\n\nOriginality & Significance: The paper is original to my knowledge, and a valuable extension to the interesting literature on the Bregman Lagrangian. The problem of simulating from probability distributions is an important one and this is an interesting connection between that problem and optimization.\n\nPros:\n- An interesting extension that may fuel future study.\n\nCons:\n- This algorithm appears naively to have an O(n^2) complexity per iteration, which is very expensive in terms of the number of particles. Most MCMC algorithms would have only O(n) complexity in the number of particles. This limits its applicability.\n",
            "rating": "6: Marginally above acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}