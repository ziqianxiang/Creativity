{
    "Decision": "",
    "Reviews": [
        {
            "title": "Mostly trivial claims",
            "review": "The paper claims that multi-hop reasoning (that is required in bAbI and WikiHop) is (1) not easy to learn directly and (2) direct supervision of the hop is often necessary. The paper also claims that (3) doing well on WikiHop doesn't necessarily mean the model is actually learning to hop.\n\nThe paper is easy to understand. I also agree with the claims. However, I think the claims are mostly trivial.\n\n(1) and (2) seem to be well-known to the community. In fact, the original Memory networks paper by Weston et al. (2015) uses strong supervision to solve bAbI, and the follow-up paper, End-to-end memory networks, attempts to solve bAbI without strong supervision, in which the authors were clearly aware of the fact that strong supervision helps the model to learn multi-hop much more easily. Furthermore, there exist numerous models, e.g. Kumar et al. (2016) that the authors cite, that do very good multi-hop reasoning on bAbI. Since many of these models can be considered as variants of end-to-end memory networks, the authors' claim that strong supervision is critical is not well-supported. Also, I feel that the paper is not comprehensively reviewing these related works.\n\nLastly, (3) could be a helpful and interesting observation of WikiHop dataset / Memory network, but pointing out the flaw of a dataset or the model alone does not seem to have enough contribution for ICLR.",
            "rating": "3: Clear rejection",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting investigation but insufficient proposition and results",
            "review": "The paper proposes to investigate the well-known problem of memory network learning and more precisely the difficulty of the attention learning supervision with such models. In the introduction, I strongly agree with the statement saying that while end-to-end memory network has been proposed, it is still very difficult to train such model with an off-the-shelf adaptive gradient descent algorithm and an end-to-end supervised loss.\n\nThe paper proposed to use a model with a 2-level attentive encoding of the memory blocks corresponding to a word and a sentence level. The authors start investigating in section 3 the use of an attention supervision. The authors investigate this attention supervision on the path-finding task of the Babi20 dataset and the Wikihop set of the QAngoroo dataset.\n\nAs secondary supervision signal, the authors proposed to use a 'pseudo-gold chain' reasoning information using the co-occurrences between the named entities of the questions and answers with the passages. It can be argued that this pseudo-gold reasoning chain is mainly possible because of the synthetic nature of the synthesis of the dataset which has been produced using a structured knowledge base.\n\nIn a sense, supervising attention in such way was already suggested in [Bordes and Weston 2015], the novelty seems very limited to me while the analysis provided by this work might be useful as an interesting starting point for further analysis and propositions in this domain.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"
        },
        {
            "title": "Interesting analysis, but...",
            "review": "This paper studies the behavior of memory network in the task of multi-hop reasoning. Although memory network was advertised to be capable of multi-hop reasoning, this paper argues that memory network fails to learn reasonable multi-hop reasoning. However, by incorporating the supervision of reasoning path by encouraging attentions to appropriate sentences, memory network was able to perform multi-hop reasoning.\n\nThe analysis in the paper is interesting. Especially, some of them I found very interesting is\n(i) Attention targets show that memory network does not attend to the appropriate sentences.\n(ii) On WikiHop, `NoText` (which doesn’t read given document at all) achieves 59.7, which is only 5.1 lower than SOTA.\n(iii) Encouraging attention to appropriate sentence leads to a dramatic performance gain (on bAbI path-finding and Wikihop Masked).\n\nHowever, I found some limitations as follows.\n\nFirst of all, bAbI QA and Wikihop are insufficient to draw attention.\n- bAbI QA is synthetic — If current models are struggling with synthetic datasets, it’s great to work on synthetic datasets, since working on the easier dataset and later move on to the harder, real dataset makes sense. However, bAbI QA was solved a while ago (2 years ago, in this venue) and people are less interested in synthetic multi-hop reasoning now.\n- WikiHop is pretty noisy — the authors of the original WikiHop paper has mentioned only 36% of questions have a unique multi-step answer (9% have a single-step answer, and 55% either have multiple possible answers or are noisy). In addition, this papers shows the model gets 59.7% without document, which means this task is not for multi-hop reasoning.\n\nSecond, this paper studies memory network in particular, but memory network is not used for multi-hop reasoning in a real dataset. For example, on Wikihop Masked, Memory network without supervision achieves 14.2 which means it doesn’t work at all. Even after adding supervision, it is worse than standard QA models (models designed for the single-hop task).\n\nLastly, the analysis of the attention targets without supervision does not give a new intuition about the incapability of the model in multi-hop reasoning, because the performance of the model is already bad (on bAbI path-finding and Wikihop Masked, since Wikihop standard seems to be meaningless).\n\nTo summarize, their motivation and the idea of encouraging attention to the right sentences is neat. In particular, since memory network has drawn a lot of attention, this study might give a new intuition to people who have been working on memory network. However, some limitations mentioned above made this paper not sufficient to be presented at ICLR main conference.\n\nI think the authors can try one of these to make the paper better.\n\n(i) Choose a pair of dataset and the model which the model performs reasonably on the dataset. (For example, bAbI except for path-finding & memory network, or Wikihop & Wikihop SOTA models), and try the same analysis. Then, the story will be “Though memory network performs well on this task, it turns out that it is not doing right multi-hop reasoning”. Also, it would be awesome if adding supervision can lead to a even higher performance by doing appropriate reasoning, but it shouldn’t be necessary.\n(ii) Try the same analysis in more widely used tasks and models. I think a pair of (Wikihop Masked, Wikihop Masked SOTA model) is sufficient.\n\nEven though the authors do not revise the paper (since it would take too long to revise), I think this paper is worth to be presented at ICLR workshop.",
            "rating": "5: Marginally below acceptance threshold",
            "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"
        }
    ]
}