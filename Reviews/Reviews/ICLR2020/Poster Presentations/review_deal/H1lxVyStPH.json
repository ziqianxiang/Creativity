{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "The authors introduce an approach to learn a random forest model and a representation simultaneously. The basic idea is to modify the representation so that subsequent trees in the random forest are less correlated.  The authors evaluate the technique empirically and show some modest gains. While the reviews were mixed, the approach is quite different from the usual approaches published at ICLR  and so I think it's worth highlighting this work.\n",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper aims to improve the random forest performance by iterative constructing & feeding more powerful features that are to be used by the random forest learning processing where a random subset of features are chosen from the current feature pool when making growing/stopping decision at the current split node. The idea is new and interesting, and its usefulness has been empirically shown. On the other hand, it is not clear how this additional procedure would do with the good properties of RFs such as less subjective to overfitting and bias. It would be very helpful if the paper could shred some lights in this regard.\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes a method for generalized image recognition based on random forest, that use directly the features extracted by the backbone, that assign pseudo-labels to the data. The learning is performed with a triplet loss adapted for better generalization.\nDecision: weak reject\nMotivation: the method is incremental and presented in general in a clear way and easy to follow, the authors present a simple but interesting trick to make the triplet loss more effective on a random forest in the case of generalization to a new unlabeled dataset. This method looks incremental to me because it is addressing the problem of pseudo-labelling for learning on a new dataset and instead of using confidence measures uses a random forest to assign labels. \nThe experimental section of the paper is a bit confusing because is not clear if the results presented are with comparable network (e.g. ResNet18) like the cited state-of-the-art papers, from further readings I am confident the autors compared fairly with similar architectures. Authors should perhaps stress they compare with state-of-the-art in fair condition to avoid confusion as in my case. How much is the overhead of building the random forest for each iteration of the learning (algorithm 1), a more detailed analysis on this is useful for understanding the method. Could this method be used to train a network from scratch on an unlabeled data or on data with noisy labels? How did the authors choose the T decision trees, is there any ablation study, general practice or euristics behind the choice of 1,10,50? The comparison with state-of-the-art Tab 3 and Tab 4 shows that for some datasets other techniques are better, did the authors draw some conclusions from that? Comparing Tab 3 and 4 with Tab 5/6/7/8/9 looks like this method can work but only in the case of much bigger network like ResNet50 and DenseNet 161 which can limit its use for high resources (computing power) cases.\nReplicability: I think with improvements in the experimental section the method results can be replicated. At the moment it lack many details like learning rates, epoch of training and other useful information that are useful.\nMinor: there are two lines out of the 9 page limit"
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "\nThe paper proposes a scheme to learn representations and a random\nforest model in a closely coupled manner, where the representations\nare learned to simultaneously improve the predictive performance of\nthe individual trees in the random forest and reduce the correlation\nbetween these trees. This is achieved via a novel triplet sampling\nscheme where the positive samples are used to improve the predictive\nperformance of the individual trees, while the negative samples are\nused to reduce the correlation between the trees. The empirical\nresults indicate the improvement of the proposed scheme over random\nforests learned over the original representations across various\ndatasets. \n\nThe manuscript is well presented and I am leaning towards accept, one\nmajor issue with this manuscript is the number of pages which crosses\nthe 8 page recommended limit in the ICLR CfP. Given that higher\nstandard, I feel that there are multiple minor issues which should be\naddressed. \n\n- It is not clear why the proposed scheme is especially well suited\n  for \"domain generalization\" and \"visual recognition\" and not for\n  general supervised classification tasks (like those on CIFAR, SVHN,\n  etc). This needs to be clarified.\n- The theoretical results for random forest rely on the independence\n  of the individual trees. Given that the trees in the random forest\n  are no longer independent in the proposed scheme, the upper bound in\n  Equation (1) may no longer be valid. While this does not affect the\n  empirical performance, it might be good to discuss the theoretical\n  implications of the proposed scheme.\n- It is not clear why the curves for the canonical features in Figure\n  3 not improving with the number of iterations (which corresponds to\n  number of trees to the best of my understanding). The results in\n  Table 1 do indicate improvement in the performance with canonical\n  features, putting Figure 3 and Table 1 at odds.\n\n\nMinor:\n\n- The individual trees in a random forest are supposed to have low\n  bias but high variance, and the heterogeneity between the trees is\n  supposed to squash the variance with the bagging. The introduction\n  mentions that the individual trees in the forest are \"less\n  biased\". Maybe this is because of our different definitions of bias\n  but any clarification here would be helpful.\n"
        }
    ]
}