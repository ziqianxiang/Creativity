{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "The authors propose a novel approach for measuring gradient staleness and use this measure to penalize stale gradients in an asynchronous stochastic gradient set up. Following previous work, they provide a convergence proof for their approach. Most importantly, they provide extensive evaluations comparing against previous approaches and show impressive gains over previous work.\n\nAfter the author response, the primary concerns from reviewers is regarding the gap between the proposed method and single worker SGD/synchronous SGD. I feel that the authors have made compelling arguments that ASGD is an important optimization paradigm to consider, so their improvements in narrowing the gap are of interest to the community. There were some concerns about the novelty of the theory, and my impression is that theorem is straightforward to prove based on assumptions and previous work, however, I view the main contribution of the paper as empirical.\n\nThis paper is borderline, but I think the impressive empirical results over existing work on ASGD is a worthwhile contribution and others will find it interesting, so I am recommending acceptance.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #2",
            "review": "This paper studies training large machine learning models in a distributed setup. For such a setup, as the number of workers increases, employing synchronous stochastic gradient descent incurs a significant delay due to the presence of straggling workers. Using asynchronous methods should circumvent the issue of stragglers. However, these asynchronous methods suffer from the stale gradients where by the time a worker sends the gradients to the master server, the model parameters have changed based on the gradients received from other workers. This leads to severe performance degradation in the models trained by using asynchronous methods, especially where the number of workers scales.\n\nThis paper proposes a gap-aware method to reduce the adverse impact of stale gradient on the asynchronous distributed learning. In particular, when the master receives a gradient from a worker, it computes the norm of the difference between the current model parameter and the past model parameter associated with the gradient. The master then computes *gap* value based on this norm and the norm of the average gradient. Before employing the gradient, the master scales the gradient by the computed gap value. The paper establishes the convergence rate for the gap-aware asynchronous method which is similar to the convergence rate of SGD. The paper then performs an extensive experimental evaluation of the proposed method over different datasets and models. The empirical results demonstrate the advantage of the proposed gap-aware method over other baselines.\n\nPros\n\n- The extensive empirical evaluation shows that the proposed method is effective in preventing performance degradation in an asynchronous setup across tasks and models. \n\n- The method outperforms other solutions to combat stale gradient, such as the staleness-aware method by Zhang et al.\n\n- The paper shows that the proposed method can be combined with DANA (Hakimi et al.) and achieves the performance very close to the synchronous setting while realizing the speed up provided by the asynchronous methods.\n\nCons\n\n- It was not clear to the reviewer how the convergence analysis of the proposed method differs from the existing analysis in the literature and if any novel ideas were involved in obtaining the theoretical results presented in the paper.\n\n- The gap-aware method increases the overhead at the master as it needs to store the most recent model parameters sent to each of the workers. This is much higher than the staleness-aware method where the master stores a single scalar for each worker. The paper barely discusses such overheads associated with the proposed method.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper introduces a new variant of asynchronous SGD, GA-ASGD, for distributed training. The goal is to mitigate the gradient staleness issue caused by asynchronously applying gradients to an old version of parameters. Prior work addresses this issue by penalizing the learning step of a worker linearly to its missed updates since getting a replica of parameters. However, that approach does not consider the differences between the old and new versions of parameters, which can cause over-penalization and under-penalization. The main contribution of this paper is to introduce a new way of measuring weight staleness and to explore the idea of penalizing the gradient itself to mitigate the staleness issue. The paper does a good job of discussing how GA can be applied to existing optimizers such as Adam. It performs empirical studies on ImageNet and Transformers-XL to conclude that GA-ASGD outperforms ASGD and the prior staleness aware approach. It also demonstrates the scalability of GA by scaling up to training with 128 asynchronous workers.\n\nStrengths:\n+ Introduced a novel approach to measure the parameter staleness, which helps penalize the gradients instead of the learning step. \n+ The approach seems to be easily applicable without much additional hyperparameter tuning. \n+ Evaluation on both image and NLP tasks demonstrate that GA leads to improvement over prior staleness aware approaches.\n\nWeaknesses:\n- Despite great improvements over prior ASGD based approaches, there is still a quite noticeable accuracy degradation compared to the SGD baseline. \n- The evaluation is done with simulation, and no report of the number of training steps to converge and end-to-end training time, making it difficult to compare the efficiency with SGD based approaches. \n\nOverall, I think this is good work. The idea of defining weights stableness as the minimal number of updates required to traverse the current distance between the master and worker weights seems to be reasonable. The comparison to prior ASGD based approaches are extensive, and the improvements seem decent. The fact that it does not require much or additional hyperparameter tuning also seems neat. \n\nMy major concern comes from results compared to SGD and motivation. The fact that almost all ASGD based workloads, even with the help of GA, cannot get on-par accuracy as the SGD baseline bothers me. In particular, the accuracy drops considerably as the number of asynchronous workers grows (Fig 1. and Fig. 2, and Table 3). For example,  the gap between the accuracy of GA vs. SGD can be as large as 3.46% when there are 128 workers. That gap might be closed with additional hyperparameter tuning, but it is unclear from the current draft and results. In the Transformer-XL example, GA has to limit the number of asynchronous workers to 4 in order to get close to baseline accuracy. It would have been better to show the trade-off between accuracy and performance in comparison with SGD. \n\nOn the other hand, the recent advance of SGD using large-batch training achieves great results on large model training such as BERT [1]. It helps to improve the compute/communication ratio, which seems to mitigate the straggler issue. Given that today's cloud service largely uses homogenous accelerators (TPU/GPU of the same SKU), it is less clear whether it is really beneficial to train with ASGD despite the improvements from GA.\n\nQuestion:\nOne question is about how the batch size should be changed as the number of workers increases. The convergence analysis indicates that by increasing the batch size, the convergence speed of GA-ASGD will decrease. Does that mean the batch size should remain relatively unchanged to avoid negatively impacting the end-to-end training?\n\nIs there any benefit to applying Gap to model parallelism paradigm such as pipeline parallelism?\n\n[1] \"Large Batch Optimization for Deep Learning: Training BERT in 76 minutes\", by You et. al."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper proposes a simple idea to mitigate gradient staleness in asynchronized distributed systems. Instead of scaling the staleness as in SA method, the authors propose to scale with the GAP, which is defined as the distance between current parameter and the staled parameter.\n\nThe paper is fairly well written, and the overall idea is interesting and simple in implementation. The authors also derive convergence bounds for the proposed algorithm and provide reasonable experimental results. I have the following comments:\n\n1. I think the theory, at the current stage, is not sufficient. The authors only provide a convergence bound for the proposed method, which does not tell anything about the advantages over other methods such as the ASGD and SA methods. I think a detailed comparison should be conducted. From the current presentation, it seems there is no theoretical advantages of the proposed method over existing methods, which seems to suggest that the empirical advantage might not come from the algorithm itself.\n\nI also notice that comparisons of convergence are illustrated in the appendix. However, it shows all SA and GA have similar convergence rates. This seems to indicate that SA and GA should performed similarly, which is not the case in the experiments.\n\n2. For experimental results, in Figure 2 (and others), how do you get the errors for different workers? I mean, how long do you need to run for each case? You should make sure that all the settings should use the same computational resources for fair comparisons, but this is not described in the text, making the results doubtable.\n"
        }
    ]
}