{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "This paper proposes to extend learning to learn framework based on zeroth-order optimization. Generally, the paper is well presented and easy to follow. The core idea is to incorporate another RNN to adaptively to learn the Gaussian sampling rule.  Although the method does not seem to have a strong theorical support, its effectiveness is evaluated in the well-organized experiments including realistic tasks like black-box adversarial attack. \nAll reviewers including two experts in this field admit the novelty of the methods and are positive to the acceptance. Iâ€™d like to support their opinions and recommend accepting the paper.\nAs R#1 still finds some details unclear, please try to clarify these points in the final version of the paper.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #1",
            "review": "This paper proposed a learning to learn (L2L) framework for zeroth-order (ZO) optimization, and demonstrated its effectiveness on black-box adversarial example generation.  The approach is novel since L2L provides a new perspective to zeroth-order optimization. \n\nHowever, I have some concerns about the current version. \n\n1) The knowledge that one should use to train UpdateRNN and  QueryRNN is not clear. A clear presentation is required \n\n2) Please clarify the optimization variables in (4). In general, the problem is not clearly defined. \n\n3) Eq. 5 is a query-expensive gradient estimate. Will it make training extremely expensive?\n\n4) The computation and query complexity are unclear during training and testing.\n\n5) Pros and cons of L2L? It seems that training a L2L network is not easy. Does its advantage exist only when inference? A better discussion should be made.\n\n########## post-feedback #######\nThanks for the response. In the pros of L2L, the authors mentioned \"The learned optimizer is trained on a small subset of optimization problems and apply in a wide range of problems in similar classes.\" In the setting of attack generation, does it mean that there exists an attack transferbility from a small group of training images to a large group of testing images? Is the transferbility a requirement for applying L2L in design of attacks. Please try to make these points clearer in the revised version. I keep my decision 'weak accept'. ",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "8: Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #2",
            "review": "This paper proposed a novel learning to learn framework based on zeroth-order optimization. Specifically, the framework consists of three parts: (1) UpdateRNN for learning the parameter update rules (2) Guided gradient estimation and search (3) QueryRNN that dynamically adapts the Gaussian sampling rules for covariance estimation in (2). \n\nExperimental results on generating adversarial examples from black-box machine learning models as well as a binary classification problem demonstrate improved performance over several existing baselines, such as better query efficiency or faster empirical convergence in the loss function. An ablation study is also conducted to study the effect of each component in the proposed framework. \n\nOverall, this paper is pleasant to read and well-motivated. The applications are of practical importance. Given that the empirical results suggest faster convergence than the compared methods, it will be great if the authors can also discuss how to prove the improved convergence in theory.\n\n*** Post-rebuttal comments\nI thank the authors for the clarification.\n***",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #3",
            "review": "The paper proposes a zeroth-order optimization framework that employs an RNN to modulate the sampling used to estimate gradients and a second RNN that models the parameter update. More specifically, query directions are sampled from a Gaussian distribution with a diagonal covariance whose evolution is determined by an RNN (QueryRNN). The resulting gradient estimates are used by an RNN (UpdateRNN) that learns the parameter update rule. This framework has the stated advantage that, unlike existing work in ZO optimization, it does not rely upon hand-designed strategies to reduce the variance common to ZO gradient estimators. The paper evaluates the proposed framework on MNIST and CFAR tasks, as well as a synthetic binary classification task. The results demonstrate faster convergence compared to baseline zeroth-order optimization algorithms, while ablations indicate the contributions of the different model components.\n\nThe primary contribution of the proposed method is the inclusion of a second network that learns to adapt the covariance of the Gaussian from which  query directions are sampled. The use of an RNN to model the parameter update rule is borrowed from previous work. The ablation studies show that the adaptive sampling strategy noticeably improves convergence as does the inclusion of the RNN update (the contribution of UpdateRNN is more significant in one ablation study, while the contribution of QueryRNN is greater in the other). \n\nGiven that a stated advantage of QueryRNN is reducing variance, it would be beneficial to compare against baselines such as Liu et al., 2018a,b and/or Guo et al., 2016 which similarly seek to reduce variance.\n\nThe paper includes a large number of typos (e.g., CIFAR-->CIAFR) and grammatical errors, but is otherwise clear.\n\nADDITIONAL COMMENTS/QUESTIONS\n\n* The related work discussion would benefit from a discussion of how Liu et al. 2018 and Guo et al. 2016 reduce variance\n\n* The computational complexity of the proposed method as compared to the baselines is unclear as is the scalability with dimensionality. At various points, the paper comments that other methods scale poorly with the dimensionality of the query space, which is true of the proposed method unless the operations are parallelized. Is this not possible with the baseline methods?\n\n* The paper makes hand wavy claims to the fact that modulating the diagonal covariance matrix allows the method to focus on certain subspaces. It would be helpful to make these claims more formal, particularly in light of the fact that the mean does not change.\n\n* The method relies upon a bit of a hack that samples from a standard Gaussian at random times. How important is this to performance? How sensitive is convergence to the frequency with which standard Gaussian sampling is used?\n\n* The discussion of Eqn. 5 as it relates to Eqn. 1 is unclear.\n\n\nUPDATE AFTER AUTHOR RESPONSE\n\nI appreciate the authors' thorough response, which resolved my primary questions/concerns, including comparisons to existing variance reduction methods (which should be incorporated into the main paper).",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        }
    ]
}