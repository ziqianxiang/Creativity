{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "Paper received reviews of A, WA, WR. AC has carefully read all reviews/responses. R1 is less experienced in this area. AC sides with R2,R3 and feels paper should be accepted. Interesting topic and interesting problem. Authors are encouraged to strengthen experiments in final version. ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "8: Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #2",
            "review": "The paper describes a model for the generation and optimization of molecules (de novo molecular design), which combines a genetic algorithm based on the SELFIES string representation and a trained discriminator. \nThe performance of the method is then shown on a small number of optimization tasks, and analyzed in detail.\n\nOverall, this reviewer thinks this is a very interesting approach with a lot of potential, however, the experimental validation could be stronger.\n\n\nEmbedding in previous work:\nSeveral key references should be added. In particular, this reviewer would suggest that the paper from the AZ group (https://arxiv.org/abs/1701.01329) is added, \n which first introduced the language model (LM)-based class of molecule generation models, and the RL paradigm of a molecule-generating agent, which takes actions in an environment to construct a molecule, receiving reward from an external scoring function.\nAlso, the previous paper by Liu et al (“Constrained Graph Variational Autoencoders for\nMolecule Design”, NeurIPS 2018,  https://arxiv.org/pdf/1805.09076.pdf ) should be cited, in particular, because it highlights the competitiveness of the LM based baselines.\n\nIn Table 2, it would be great to include a reference to the DEFactor paper from Yoshua Bengio’s lab (https://arxiv.org/abs/1811.09766), which achieves comparable performance to the strongest baseline.\n\nIn addition, the authors should cite earlier work on using GAs for de novo design, which have a rich tradition in chemoinformatics since the 1990ies.\n\nExperimental:\n\nRe 4.1. In the unconstrained optimization task, several baselines are missing. In particular, a language model + RL baseline should be considered. This model has also shown strong performance (in terms of optimization and quality) in the state of the art benchmark set (Guacamol https://pubs.acs.org/doi/10.1021/acs.jcim.8b00839 ) -  the code is available on github\n\nCan the authors explain why they believe the physchem only function ”log(P) - SA(m) - RingPenalty(m)” is a relevant scoring function for the tasks that are faced in real life drug and materials discovery? It would be great if the authors would consider using the Guacamol benchmarks which have been designed by domain experts to allow a more fine grained assessment on tasks relevant to practical drug and materials design, while still being tractable computationally. Also, the guacamol paper provides a benchmark to assess the quality of molecules, which is currently missing in the present work.\n\nRe 4.2. And 4.3.\nThe long term experiment and the molecule class exploration analysis are great, and well presented. I like the analysis of how the different classes emerge. However, are you sure that the GA is not just exploited the deficiencies of the rdkit logP calculator (which itself is just a model) by creating the molecules with the long sulfur chains? Also, I am not sure that it is likely that one would be able to synthesize these molecules in the lab.\n\nRe 4.4\nThe results on the constrained optimization are impressive, however, it is not really clear if the GA is not simply exploiting deficiencies in the scoring function again.\n\n\nOverall, this reviewer believes the proposed model is very promising (in particular also because GA’s are cool), however, the experimental validation could be more rigorous, which can be addressed by considering the guacamol benchmarks. If this results can provided, this reviewer will raise their recommendation to 'accept' (regardless of outcome of the benchmark)\n\n#####\nAfter response:\nConsidering the authors' response, I adapt my recommendation to accept. I acknowledge the short time the authors have  to run additional experiments. nevertheless, I would suggest that the authors at least run more challenging benchmarks later and report the results e.g. as a blogpost or in a leaderboard.\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The authors present an algorithm to explore the generation of new organic molecules using a genetic algorithm.\nThe genetic algorithm will select molecules generated via mutation and cross over, according to a fitness function that includes a discriminator trained from generated molecules.\nThe mutation rule seems to be 50% insertions and 50% replacements of single SELFIES characters, plus a rule for the direct addition of phenyl groups with 4% chance.\nNo crossover rule is used.\nThe metric used is a maximum penalized logP score proposed by Gomez-Bombarelli, et al. \nThe work shows a huge improvement on this score using their proposed algorithm.\nAdditionally, the authors show some of the promise of the work in constrained optimization:\nThe algorithm can, with minor modifications, generate molecules with specific properties, and improve low scoring molecule.\nThere is also a study on the hyperparameter \\beta - low beta tends generate high scoring molecules, and high beta generates molecules similar to the dataset.\n\nBecause of the novel genetic algorithm based search method, as well as the large improvement on prior literature, I am leaning towards an accept for this paper.\n- Paper uses a metric well motivated by prior literature, J(m)\n- There are constrained optimization studies showing different ways to use the algorithm\n- The authors show the effect of the hyperparameter \\beta on the algorithm - it seems to be difficult to interpolate between molecules in the dataset and molecules with high scores.\n- All previous work have been with SMILES strings, where this work is the only one that builds up on SELFIES strings.\n  It is not a sincere comparison - it would be better if the authors indicated which works use SMILES and which one uses SELFIES.\n  A more sincere baseline would be to take a baseline model and apply it to SELFIES, while showing that the genetic algorithm based approach shows more viability.\n  At least ORGAN seems to operate on SMILES strings, so it would be not too hard to change the underlying sequences to SELFIES strings.\n- Some quantifiable metric of diversity of generated molecules might be a good analysis, it's unclear whether the model is simply memorizing a few high scoring molecules.\n\n\nTwo questions I have might improve the paper if they are answered in the text:\n1) It seems to be the discriminator will decide whether molecules are in the dataset or not.\n   If it is well trained and with a high penalty (e.g. time adaptive case), the GA will pick high J(m) molecules that are in the dataset.\n   An analysis of the topline of the dataset might be useful - what is the J(m) of the best molecule in the dataset?\n   If you simply seed a non-time adaptive GA with the best J(m) molecule, would it be able to reach the same levels?\n\n2) Seeing the molecules generated in Figure 7d, it seems to imply to me that that algorithm is finding \"bugs\" in the simulation metric.\n   Since the ICLR community does not have many chemists, it would be useful to make some claims about the chemical viability of these compounds outside of simulations.\n   Are there molecules that are similar looking to the generated ones?\n   Perhaps some analysis on whether the GA is overfitting to the synthetic metric of J(m) would be helpful.\n\nNits:\n- Use uppercase ZINC in all cases to refer to the dataset\n- Last sentence \"An important future generalization...\" awkward phrasing.\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "Generating novel drug molecules is an important problem. Prior approaches to solve this problem has explored approaches like VAEs, GANs and Genetic Algorithms. The authors propose a genetic algorithm that is augmented with Neural Networks for this purpose. The authors claim impressive performance with their algorithms. While maximizing for Penalized logP, the molecules that they generate have almost twice the maximum Penalized logP reported in the literature. \n\nFrom a purely molecular optimization point of view, their results are impressive. However, I suspect the paper does not clearly illuminate what is going on. For example, the Random SELFIES performs twice as good as state of the art generative models from couple of years back like JT-VAE, SD-VAE and Grammar VAE.  I suspect what is happening is that the random model and the models proposed by the authors are veering too much from the training data. The authors indeed suggest that this is the case in the discussion about the parameter beta. For small values of beta, the generated molecules move away from the reference distribution. While standard VAE models tries to ensure that the training and generated models are from similar distributions, the models proposed by the authors face no such constraint, for small values of beta. This makes the comparison with other models unfair - because other models try their best to generate molecules from the reference distribution, while at the same time trying to optimize for molecular properties like higher penalized logP. If those models had the freedom not to restrict its exploration to the training distribution, one can obviously generate molecules with higher penalized logP.\n\nThe authors seem to suggest that moving away from the reference distribution might be desirable, if we can get molecules with higher penalized logP. Indeed, this is not the case. Zinc is a database of small drug-like molecules. When they move away from this distribution, they will start generating molecules which are not drug-like and which perform poorly in other metrics like QED and Synthetic Accessibility. In this sense, the results claimed by the authors are misleading.\n\nCan the authors plot a distribution of molecular properties (molecular weight, Synthetic Accessibility, QED, logP and number of Rings) for zinc, and the generated molecules with different values of beta, so that we can analyze this phenomenon better? Code for this (along with examples) can be found in the MOSES toolkit: https://github.com/molecularsets/moses"
        }
    ]
}