{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "This paper offers an innovative approach to adjusting style transfer parameters.\nThe reviewers were consistent, and all recommend acceptance.  I concur. \n",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #3",
            "review": "The paper proposed a generative model for image style transfer in real time. In particular, comparing to the existing work, the proposed method is able to generate a series of transferred images instead of one, and more importantly, users can adjust different parameters without re-training the network to control over the synthesized output. The proposed method was evaluated on publicly-available datasets, and achieved convincing experimental results.\n\nPros:\n- The problems that the paper tried to solve is interesting and important. I think the proposed model could make some contributions to related research communities.\n- The idea of learning and incorporating \"adjustable loss weights\" is interesting and reasonable.\n- The paper is well written and easy to understand.\n- Experimental results appear to be promising.\n\nCons:\n- The \"adjust loss weights\" are able to control the synthesized output, but does each of them have a particular meaning? For example, if I want to generate other outputs more realistic, colorful, or in other styles, is it possible for the users to (roughly) know which parameter should be adjust, and how?\n- Following the above question, I suggest the authors to provide more qualitative results with different \"loss weights\", and give some detailed explanations.\n- Some typos and missing links could be corrected.\n\nI think the proposed approach is reasonable and and experimental results are convincing. I'm not an expert in this area, and I'm not sure about the method's novelty. If other reviewers find other existing work that proposed very similar ideas, then this would have an impact on my recommendation.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper presents an approach for style transfer with controlable parameters. The controllable parameters correspond to the weights associated to \"style losses\" or ordinary style transfer models (distance between gram matrices of generated vs style image at specific layers of a network). The authors propose to learn a single architecture that takes these parameters as input to generate an image that resembles what would be generated by optimizing directly on these parameters. Examples of transfer and of the effect of these parameters are given. A quantitative evaluation shows that the effect of changing the parameters of the new network has the effect of reducing the loss at the desired layers.\n\nOverall, I found the idea of learning controllable parameters interesting. The technical contribution is to show that learning the weights of instance normalization as a function of the hyperparameters actually is satisfactory. To be honest, I am not sure to understand why playing on instance normalization weights turns to be effective for learning an equivalent of a reduction of per-layer loss. I would have liked more motivation and intuition behind it.\n\nThe paper seems overall a bit incremental with respect to prior work on style transfer. While adjustable parameters could have application in more general tasks of image generation (for instance, in the line of work on disentangled representations), it is unclear how the specific approach of learning instance normalization weights extends beyond style transfer. As such, my feeling is that the paper is borderline.\n\nother comments:\n- I found Figure 7 important because it guarantees learning has the desired effect. However, there is a bit a lack of baseline/topline: how do the true losses decrease when their weights increase?"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Strengths:\n + Interesting problem\n + Good results\nAreas of improvement:\n - Structure of paper\n - Main technical section (4.1) very hard to understand.\n\nThe paper works on a very interesting and important problem. To the best of my knowledge there is no real time style transfer method that can adjust certain style parameters after it has been trained. The paper addresses this by parametrizing the normalization layers in the style transfer model, and training with a parametrized loss function. The results look compelling both in the paper, and the supplemental webpage.\n\nThe main area of improvement is the structure of the paper itself. The paper spends 4 pages on introduction, motivation and background. This unfortunately only leaves less than half a page for the main technical section. This main technical section is very dense, technical choices poorly motivated, and the section is impossible to understand in a single read (I had to read it 3-4 times). I'd highly encourage the authors to consolidate some of the early parts of the paper and greatly expand the technical section. For example, the first two paragraphs in section 4 can easily go into the introduction to avoid having to motivate the method twice. The main technical section should be motivated better. I had to constantly jump forth and back between background and technical section to understand where the technical changes are applied. It would help to have a more consistent story.\n\n\nMinor:\n * Figure reference bottom page 2 broken (??)"
        }
    ]
}