{
    "Decision": {
        "decision": "Accept (Poster)",
        "comment": "This paper proposes and evaluates a formulation of graph convolutional networks for multi-relation graphs. The paper was reviewed by three experts working in this area and received three Weak Accept decisions. The reviewers identified some concerns, including novelty with respect to existing work and specific details of the experimental setup and results that were not clear. The authors have addressed most of these concerns in their response, including adding a table that explicitly explains the contribution with respect to existing work and clarifying the missing details. Given the unanimous Weak Accept decision, the ACs also recommend Accept as a poster.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes a graph convolutional  network based model for joint embedding of nodes and relations in a multi-relational graph. The framework comprises of node/relation embedding, nonparametric compositional operation as in knowledge graph embedding, and finally convolution operation with direction specific weight matrices. The performance is evaluated on link prediction, and node/graph classification tasks.\n\nOverall, the paper is well written and literature is sufficiently discussed. The performance of the proposed model on the diverse tasks looks good.  I have just two minor comments:\n\n1. The difference and overlap with Schlichtkrull et al. (2017) should be more elaborated on. Right now, the paper reads that the main difference is only in employing the basis representation for initial relation features in your work.\n\n2. There are some inconsistencies in Table 2. For example, H@3 for SCAN is same as COMPGCN for FB15k dataset. Also, for WN18RR dataset, MR of ConvKB is better but it's not in boldface!"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This work introduces a GCN (Graph Convolutional Network) framework for multi-relational graphs. \n\nAuthors conducted a decent literature review and generalized several existing approaches to Knowledge Graph embedding into one framework regarding these model’s components:\n- entity-relation composition operator\n- relation weights matrix definition\n\nThere are two very close recent works (mentioned by authors), namely Weighted GCN (Shang et al., 2019) and Vectorized Relational GCN (Ye et. al., 2019), but this work proposes a more generic model. Therefore, although the idea is quite incremental, the overall work is well written and experiments with ablation study on different model’s components bring the value into it.\n\nMinor comments:\n- In table 2 SACN method outperforms COMPGCN based on H@10 (0.54 vs 0.535) for FB15k-237 dataset, but not highlighted with bold.\n- Authors write: “limited to embedding only the nodes of the graph” about Weighted Graph Convolutional Network (Shang et al., 2019), however that paper in fact does relation embeddings (see. e.g. figure 1 in that paper). The block at the bottom of the figure 1 called \"Relation Embedding\". I would propose to discuss this issue and comment on exact differences/similarities with the proposed approach.\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "In this paper, the authors developed GCN on multi-relational graphs and proposed CompGCN. In comparison with existing multi-relational GCN, CompGCN leverages insights from knowledge graph embedding and learns representations of both nodes and relations, with the aim to alleviate the problem of over-parameterization. Moreover, to improve the scalability w.r.t. the number of relations, the initial relation representations are expressed as a linear combination of a fixed number of basis vectors. In contrast to existing works, the basis vectors are only defined for initialization but not for every GCN layer. The authors also compared the proposed CompGCN with other existing GCN variants and summarized the relationships between CompGCN and other models. In the experiments, three tasks including link prediction, node classification and graph classification were performed to evaluate the performance of the proposed method. By comparing with existing methods, the effectiveness of the proposed method was demonstrated.\n\nThere are several concerns on this paper. First, this work is somewhat incremental on R-GCN (\"Modeling relational data with graph convolutional networks\"). Although the differences were highlighted, the overall technical contribution is limited. In this paper, relation representations are learned jointly with node representations, but it is not clear on what are the benefits by doing so, or how significant the over-parameterization problem can be alleviated in this manner. Second, the experimental setup is unclear. As for the datasets, some more descriptions about the meaning of relationships and labels should be provided. As for the three different tasks, what loss functions were used for model training, how to obtain graph-level representations from node-level representations for graph classification, should be clarified. Third, in Table 2, there are some missing values of some compared methods, but it is not clear on their absence. Finally, from the results of Figure 3, it is hard to see the scalability of the proposed method w.r.t. the increasing number of relations since the variable is the number of basis. It is suggested to provide some more results to show the insights of advantages of the proposed method, such as the accuracy change w.r.t. increasing number of relations and the corresponding running time, in comparison with other methods.\n"
        }
    ]
}