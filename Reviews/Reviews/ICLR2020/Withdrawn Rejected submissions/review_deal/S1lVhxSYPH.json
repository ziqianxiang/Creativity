{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper presents a quantization method that generates per-layer hybrid filter banks consisting of full-precision and ternary weight filters for MobileNets. The paper is well-written. However, it is incremental. Moreover, empirical results are not convincing enough. Experiments are only performed on ImageNet. Comparison on more datasets and more model architectures should be performed.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper presents a quantization method that generates per-layer hybrid filter banks consisting of full-precision and ternary weight filters for MobileNets. \n\nStrength:\n(1)\tThe paper proposes to only quantize easy-to-quantize weight filters of a network layer to ternary values while also preserving the representational ability of the overall network by relying on few full-precision difficult-to-quantize weight filters. \n(2)\tThe proposed method maintains a good balance between overall computational costs and predictive performance of the overall network. Experimental results show that the proposed hybrid filter banks for MobileNets achieves savings in energy and reduction in model size while preserving comparable accuracy. \n(3)\tThe description is clear in general. \n\nWeakness:\n(1)\tThough the paper claims that recent works on binary/ternary quantization either do not demonstrate their potential to quantize MobileNets on ImageNet dataset or incur modest to significant drop in accuracy while quantizing MobileNets with 4-6-bit weights, it may worth comparing to the methods that achieved start-of-art results on other datasets to demonstrate the efficiency of the proposed method. \n(2)\tFigure 1 and Figure 2 is a little blurry. \n(3).  How is about the performance compared to latest work? Is it possible to apply current framework to MobileNetV2 ? If can, what's performance?\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes a novel quantization method towards the MobileNets architecture, with the consideration of balance between accuracy and computation costs. Specifically, the paper proposes a layer-wise hybrid filter banks which only quantizes a fraction of convolutional filters to ternary values while remaining the rest as full-precision filters. The method is tested empirically on ImageNet dataset.\n\nThis paper is generally well written with good clarity. Several concerns are as follows:\n\n1. This paper is incremental in nature, with a natural generalization of (Tschannen et al.(2018)). But it is still an interesting contribution. For this kind of paper, I would like to see a more complete set of empirical results. However, The experiments only perform comparison on ImageNet dataset. Though this dataset has a reasonable size, however, as in many cases, different datasets can bias the performance of different models. To strengthen the results, could the experiments be conducted on multiple datasets as in (Tschannen et al.(2018))?\n\n2. The proposed method is only designed for MobileNets. Is it possible to apply the hybrid filter banks to other neural network architecture?\n"
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review": "The authors focus on quantizing the MobileNets architecture to ternary values, resulting in less space and compute.\n\nThe space of making neural networks more energy efficient is vital towards their deployment in the real world.\n\nI think the authors over-state their claims of no loss in accuracy, in Table 2 we see a clear loss in accuracy from MobileNets to MobileNets + Hybrid Filter Banks.\n\nI think this research is quite incremental over MobileNets and is unlikely to spur further research strains. I think a better venue for this research may be a more systems-focused conference or journal.\n\nThere is a significant amount of compute and training complexity required to reduce the model size, e.g. versus model pruning or tensor decomposition. It seems this research would be incredibly difficult to reproduce."
        }
    ]
}