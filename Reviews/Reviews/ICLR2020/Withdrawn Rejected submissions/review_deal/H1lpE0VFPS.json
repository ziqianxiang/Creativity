{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "In this paper, the authors propose a Gaussian mixture model for object detection that is more expressive, and captures cases where the distribution of the bounding box coordinates could be multi-modal and cross-correlated (often owing to occlusion). The authors present the problem formally, describe how the additional parameters can be learned, and show the performance enhancement on a few datasets using their approach.\n\nThe paper tackles the problem of object detection under occlusion in a principled way and the results appear promising. The strong points of the paper:\n1. Clearly written with discussion of how the proposal related to earlier work.\n2. Fairly thorough empirical investigation with several datasets and competitive baselines.\n3. Interesting observations on the qualitative performance of the model.\n\nA couple of concerns:\n1. The work appears somewhat incremental in going from the cited Gaussian model (He et al.) to a multi-variate Gaussian to a mixture of multi-variate Gaussians.\n2. Grammatical error: “might not as”.\n\nIn summary, I think the paper does a good job of proposing a viable solution to an interesting problem, with my only major concern being its incremental nature. However, the exposition is clear and the results promising, leading me to recommend this paper for acceptance."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "Summary:\n\nThe authors propose to use mixture models for bounding box detection models in order to robustify against occlusion.\nIn practice, they try models which use Gaussian, Multivariate Gaussian, Mixture of Gaussian and Mixture of MVN models and find improved performance compared to deterministic models of bounding boxes in a variety of experiments.\nThe prediction task here is given a region of interest to predict a bounding box consisting of 4 points for the corners of the box. The authors demonstrate usefulness on a variety of datasets.\n\nComments:\nFirst, the proposed method has very little technical depth or complexity and is extremely straightforward. This is actually an advantage of the paper, as it makes it a useful trick for a variety of systems that perform this task, but also increases the burden of empirical evidence for its usefulness. Given that there is no particular technical novelty here apart from the application domain of mixture density networks, the paper has to convince based on sheer empirical evidence.\n\nPros:\nThe model makes sense, as images are fraught with ambiguity and when not having access to a generative model to resolve ambiguities through posterior inference the best a predictor can do is regress to these ambiguities, i.e. the different bounding boxes one might expect at object intersections.\nSuggestion: it would be great if the authors could come up with a toy dataset with ambiguous but known bounding boxes (i.e. overlapping objects with particular poses) to study how well the proposed model recovers those structures. \nReal-world datasets are great, but we have little understanding of what effect exactly is helping the classification here and an additional toy setting would increase the clarity of the modeling ideas.\n\nCons:\nThe authors handle their Gaussian Mixture Models (GMMs) unconventionally.\nIn particular, they consider predictions to be the expectation of the GMM, i.e. the expected mean.\nLet's consider a toy system with two bounding boxes which do not overlap and constitute two modes. The mean over the two boxes could easily cover an area of an image that has no support under either bounding box.\nAs such, predictions with such multimodal and multivariate models have to be made by enumeration and/or sampling from the predictive distribution p(x|I), such that for example K bounding boxes are sampled from a model -for instance the mean of each  component for simplicity or multiple samples from each component- and evaluation is performed over each of the K boxes and then the metrics are averaged. In contrast, the authors average the bounding box and then calculate their metrics. Respectfully, I believe this is statistically unsound use of the model and undermines the empirical value of the experiments.\nOn experiments: it is unclear whether multivariate models and multimodality matter and what their effects are. The authors find that different datasets behave differently, which makes sense if more or less occlusion is present, but unfortunately the problem mentioned above undermines the results here. \nFinally, the authors state that during testing they ignore the covariance structures, which also seems ill-advised as the model is reduced to a deterministic one in that case. It would be interesting to present results contrasting this to samples from the model.\n\nOverall: the authors appear to not sufficiently utilize the structure offered by their potentially multivariate and multimodal observation model appropriately. Instead, they effectively use it as a regularizer for training and just utilize its expectation during testing.\n\nMinor comment:\nThe authors should call their model a 'mixture density network' (Bishop 1994) and cite the relevant paper, as this is a well-described technique for density estimation and the authors apply it to the task at hand.\n\nDecision:\nGiven the simplicity of the model and the potentially broad usecases within the object detection field, I was expecting a more thorough empirical analysis here. The idea is simple but appealing. It, however, requires significantly more empirical depth and analysis to be considered for publication. A good start would be to mitigate the concerns I expressed for the evaluation of the model.\n\n"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper proposes to predict a distribution of bounding boxes when detecting objects in images, instead of a single bounding box. The motivation is that there may be multiple different annotations or wrong annotations, especially in case of partial occlusions which make it difficult for the human annotator to precisely define the bounding box.\nTo predict a distribution, Faster RCNN is modified to predict, for each detected object, a mixture of Gaussians for the bounding box, given an initial bounding box for the object. Training is done by optimizing the log-likelihood of the annotations given the predicted mixture-of-Gaussians.\n\nThe method itself is technically sound. My main concern is that I think this paper considers an artificial problem. There is inherently a single valid bounding box for an object. If the annotations are multi-modal, then the solution should be to fix the annotations like the one in  Figure 1d, even if it requires manual work. It is true that it is difficult in practice to annotate exactly a bounding box, as in Figure 1b. However, in this case the annotations are not multimodal. It is reasonable to assume they follow a single Gaussian distribution, and this assumption is actually already made when minimizing a least-squares loss (or a robust version of it) as it is usually done.\n\nThe text has also some small language mistakes, this is however minor.\n"
        }
    ]
}