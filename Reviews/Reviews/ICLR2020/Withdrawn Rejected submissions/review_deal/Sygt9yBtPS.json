{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper proposes Text Embedding Bank (TEB) module for image paragraph generation. This module is trained to estimate paragraph vector given visual features from each region. Estimated paragraph vectors are concatenated to the visual features and used to generate the paragraph. Experimental results show that the combination of TEB and the existing methods outperforms the baselines.\n\nMy first concern is that the related papers are not cited:\n- Chatterjee and Schwing, Diverse and Coherent Paragraph Generation from Images. ECCV, 2018.\n- Wang et al., Convolutional Auto-encoding of Sentence Topics for Image Paragraph Generation. IJCAI, 2019.\n\nThe second concern is that the performance gain is not so convincing. While the Diversity model [Melas-Kyriazi+, EMNLP 2018] improves its CIDEr score with about eight points, the use of the TEB module improves it with about just one point. Additionally, I would like to recommend that an experiment on Amazon Dataset should be done as reported in [Chatterjee+Schwing, ECCV 2018] to show versatility.\n\nFinally, the explanations about the proposed method and the experimental results should be improved and detailed. For example, the description of Fig. 1 is finished using just a single sentence in the main text. There are no ablation studies using different hyperparameters such as a weight applied to the TEB', the sliding window size, and the sampling threshold for TEB. \n\nOverall, the presentation quality of the paper should be revised before being accepted in ICLR."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "# 1. Summary\nThe paper tackles the problem of generating long, paragraph-like, fine-grained captions from describing images. It proposed a text embedding bank (TEB) model to encode a paragraph into a fixed-length representation.   \n\nThe strengths of the paper are:\n* The tackled problem is relevant to the computer vision community\n\nThe rejection decision is supported by the following reasons:\n* Missing motivations: it is not clear how TEB is able to encode long paragraph-like sentences when compared to other standard decoders\n* Limited novelty: it seems that the only contribution is how the paragraph is encoded (TEB) which details are not clear (see point 3 below)\n* Writing need to be improved: Missing motivations, descriptions and details (see point 2 below)\n* Results are not consistent (see point 4 below)\n      \n\n# 2. Clarity and Motivation\nTEB is presented as novel model, however it is not clear how it overcomes issues from previous works on paragraph captioning (Sec. 2.2), i.e., what would be the main contributions with respect to the literature and what are the motivations of the proposed model. The authors try to explain that with the following sentence: \"all of these methods suffer from the fact that only a tiny partial scalar from ...\", which is not clear and very hard to understand without context.\nMoreover, the authors cited work on long-term dependency (Sec. 2.3) without explaining why this is relevant with respect to the current work. How is it related to the proposed method? How existing methods compare with the proposal TEB?\n\nUnfortunately there is not a high-level overview of the proposed method or the different components, and different sections of the paper are not consistent. This makes the paper and method really hard to read and understand. Going deeper into the explanation of the method (Sec. 3), the reader is right away confused by the used terminology. E.g. the paragraph \"The paragraph vector is based on word vectors. A word vector is the concept ...\" is not clear (What are a paragraph vector and word vectors?). The section continues with details about the method which are not very relevant for the proposed TEB model and can be summarised by citing encoder-decoder networks for image captioning, since it is pretty standard. The math is moreover incomplete with several gaps (e.g., Eq. 3: U and h not defined, how is the image encoded?, ...).     \n\nSec. 3.3, which seems to be the most important part of the proposed method, is only a sentence referring to Fig. 1. Although the text in Fig. 1 is verbose, it is eventually impossible to understand how TEB works in practice. To summarize, it would not be possible to implement TEB with the information provided in the paper.\n\n\n# 3. Novelty\nNovelty is not clear since there is not much information/details about how the TEB module is implemented (apart some references in the experiment section) or how this work positions itself compared to other existing techniques. Assuming that TEB is the only main novelty of the paper, it seems that the model is a minor extension of the method proposed by Melas-Kyriazi et al. (2018). \n\n\n# 4. Experimentation\nThe experiments and results are inconclusive and inconsistent:\n* It is not clear why the authors used the transformer as backbone network since the results are significantly lower (Table 1) than Melas-Kyriazi et al. (2018).\n* Adding TEB to the transformer do not have a significant improvement of the results (Table 1, still lower that Melas-Kyriazi et al. (2018)), meaning that the proposed TEB module is not important to have.\n* What it makes the method to surpass Melas-Kyriazi et al. (2018) is to add TEB to the diversity model presented by Melas-Kyriazi et al. (2018). However it is not clear why TEB is having such an improvement on such dataset but not having an improvement when coupled with the transformer net. The authors should have given an explanation or intuition why this is the case."
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This manuscript is disastrous in terms of writing. It seems this manuscript is written in a rush, where the method section barely introduces the idea, and the experiment section miss important evaluation. \n\nIt seems the authors try to use the objective in Eq.(1) to learn word embeddings. It is unknown how to learn paragraph embeddings similarly. It is confusing to learn paragraph embeddings. For example, the size of word vocabulary is limited, so as the size of W. However, the number of possible paragraphs is not limited, so how to maintain D? \n\nIt is also confusing how to integrate the so called TEB to existing captioning models. The manuscript only mentions the combination of TEB and transformer/diversity model using few sentences.\n\nTEB also seems an auxiliary objective on word embeddings or topic vectors (Krause 2017), instead of a new module.\n\nAs for experiments, only a single overall table and some qualitative samples are presented. Ablation studies are missing. Results analysis is missing. \n\nOverall, the idea may be good, but in current form this manuscript is not ready for publication. "
        }
    ]
}