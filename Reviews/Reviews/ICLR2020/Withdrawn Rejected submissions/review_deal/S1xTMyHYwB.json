{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "1. This paper proposed a random weight deconvolution architecture and show the reconstruction results for an autoencoder is good.\n2. The paper is largely based on https://papers.nips.cc/paper/6568-a-powerful-generative-model-using-random-weights-for-the-deep-image-representation.pdf, so the contribution is somewhat limited.\n3. Given the paper by He et al. it's not surprising to prove the theorems for deconvolution networks.\n4. Empirically the authors have shown the usefulness and also proved the effect of depth, number of channels and kernel sizes.\n5. The style transfer application is out of place and may be removed."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "I think paper needs significant amount of rewriting and reorganization. It took me quite a lot of time to understand the claims and explanations.  Furthermore, paper is not well connected to existing art. It is very well possible that I am missing some points or I didn't understand some sections. Authors needs to work on their presentation.\n\nI will review this paper with respect to my understing and I expect from authors to clarify points during rebuttal.\n\nThe authors use untrained randomly initialized convolutional encoder to understand/analyse deep representations. They provide experimental results by changing several hyperparameters e.g. size of kernel. The most important claim is untrained randomly initialized convolutional encoder can contain more useful information for reconstruction purpose than the pretrained version. They also give theoretical justification to some of their findings. \n\nThe results are surprising and at the same time they are expected. It is surprising because if results carry out to generic tasks then the computational requirement for training of convolutional autoencoders will decrease. However, I believe it is also expected because random projections can keep significant amount of information e.g. Johnsonâ€“Lindenstrauss lemma. Hence, a proper connection with random matric theory/random linear algebra is needed to access the novelty of the claims.\n\nAuthors support their claims with empirical evidence. However, they compare random initialized convolutional encoder with a pretrained auto encoder which is designed for classification tasks. Loosely speaking autoencoders can be considered as compression methods however they may require much more information than a classification task. Hence, I am not so sure whether comparing a randomly initialized autoencoder with a pretrained version is fair. I suggest authors to compare against some self-supervised method e.g. jigsaw methods. \n\nI have checked the theoretical justification. Although, everything seems correct, I didn't find the theorem 1 and theorem 2 interesting. I am quite sure some these theorems are known. Especially theorem 1 seems similar to the theorems which are connecting GPs with neural networks. I will be delighted to update my review if otherwise is shown.\n\nI have given a weak reject to the paper. if authors supply more information on theoretical justification, more experiments and rewrite the paper then I am open to revise my judgment."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review": "Review:\n\nNOTE: I am not one of the original reviewers for this paper,\nso this review will be less thorough than it otherwise might.\nThus, I allow that I may have missed some crucial contribution\nhere and would encourage the authors to respond to the questions\nI ask in the text below so that any misunderstandings I have\ncan be corrected.\n\n========================      SUMMARY      =====================\n\nThis paper makes the claim that a randomly initialized auto-encoder\ncan do a good job reconstructing images.\nHowever, their own results show that this is not true;\nthe reconstructions are quite poor, which, unless I'm misunderstanding\nsomething, essentially had to be how it works.\n\nThey also suggest a number of applications that I find, in light of\nthe aforementioned problem, unconvincing.\n\nIn addition, the paper is very poorly written.\nIt took me a lot of effort to understand basic details of, e.g.\nhow experiments were conducted.\n\n======================== DETAILED COMMENTS =====================\nI wrote these as I read the text front-to-back.\n\n------------------------    Section One    ---------------------\nI found this section very hard to read.\nI think that ' overall random CNN-DCN architecture' refers to a standard \nconvolutional auto-encoder where both the encoder and the decoder are randomly\ninitialized, but it took me a long time to figure that out.\n\nI think the central claim here is that you can use such an\nautoencoder to do reconstruction.\nI feel like I must be missing something, because if this were\ntrue in the way I'm imagining, anyone who has ever trained an\nautoencoder would just start out with close to 0 reconstruction loss.\nSurely they would have noticed this?\n\n------------------------    Section Two    ---------------------\n>  Randomization indicates the stochastic assignment of weights\n> to the deep neural network.\nI'm quite confused about this sentence. \nAre you talking about something different than just the way everyone\ninitializes neural networks?\nIf not, why have you given it a special name?\n\n>  Zeiler et al. Zeiler & Fergus\nTypo?\n\n>  Daniely et al. Daniely et al. (2016)\nAlso a typo?\nA lot of your citations are like this.\n\n------------------------   Section Three   ---------------------\n\n> We build a CNN-DCN architecture on the layer of the feature\n> representation to be studied.\nWhat does this sentence mean?\n\n> Training.\nSo you train an auto-encoder where the encoder weights are fixed at\ntheir random initialization and the decoder weights vary as normal?\nIt's very hard to tell from your description - please correct me if\nI'm wrong.\n\n> Specifically, we initialize the...\nWhy does this say specifically?\nIIUC, the last paragraph doesn't reference the initialization?\n\n>  We see that the training of DCN...\nIIUC, your comparison here is between\na) An autoencoder with the encoder weights fixed to their random initialization\nand the decoder weights updated as normal\nb) An autoencoder with the encoder weights 'pre-trained' somehow.\n\nIs this correct?\nI don't see where the pre-training is addressed.\nOn page 3, you say that you pre-trained the DCN (which is the encoder, I think).\nIs that just a typo?\nWhy do this experiment?\nWhy not include as a baseline the auto-encoder trained normally?\n\nI guess this partly gets at the phenomenon of object-recognizers throwing\naway certain details, but it's not as though this is a new observation?\n\n> The statistics are shown in Figure 11\nFig 11 is in the appendix, but this seems like one of your main experiments.\n\n> In Appendix 2, we also see that the reconstruction quality on\nVGG based deconvolution is better than that on AlexNet based deconvolution.\nSurely this is not surprising?\n\n------------------------   Section Four   ---------------------\n\n> For evaluation, we use the structural similarity (SSIM) index\nWhy not just report the MSE though?\n\n> consistent to the perceptron of human eyes.\nTypo\n\nAgain, the result you're describing here seems a priori ridiculous\nwithout some kind of caveat.\nThis makes me feel like I'm missing the caveat somehow.\nConsider your figure 2.\nThe green and red lines are autoencoders with randomly initialized\nencoders and decoders.\nYou then freeze the encoder weights and train the decoders, but\nbefore any gradient updates have been made these autoencoders\nare (again, IIUC) exactly the 'RANDOM CNN-DCN' you talk about\nhere.\nAnd those autoencoders start out with (slightly hard to read) something\nlike over 200 units (also unsure what your units are) of loss.\n\nAre the images in Fig 5 meant to give evidence for your earlier claim\nthat 'the images can still be reconstructed with satisfactory quality!'\n\nWhat do the different columns correspond to in Fig 8?\nAh - I see now that it's number of channels, but I'll\nleave this comment to show that I found the figure confusing.\n\nOK, so you have an encoder with one layer and a decoder with one\nlayer. Are there even non-linearities in this case?\nI am no longer confused in the way I mentioned earlier in this\nsection, but I also now think that these results are not useful.\n\nRegarding Fig 9, these results are quite far from being intersting/useful\nfor style transfer.\nI know you have a narrative about how it's nice not to have to train the\nnetworks involved, but nobody will make that trade-off in this case.\n\n\n------------------------   Section Five ---------------------\n\nIn my opinion, the first four sections of this paper are sufficiently\nflawed to merit rejection by themselves, so I have not read\nthis section in detail.\nI do suspect that the theorems you are proving are not interesting\nor already known, but I am not counting that suspicion in the review.\nIn particular, I'm pretty sure that Thm 1 is already known as a\nconsequence of work on the correspondence between infinitely wide\nneural networks and GPs.\n"
        }
    ]
}