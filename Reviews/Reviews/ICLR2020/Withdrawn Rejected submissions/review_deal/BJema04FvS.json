{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #4",
            "review": "This paper introduces an approach to compute the saliency map of a 3D point cloud, where the saliency is motivated from removing a region could result in a decrease in performance in shape classification. This idea was introduced in the image domain, and prior works leverage the so-called the natural neighborhood of image grids. However, such approaches do not naturally extend to 3D shapes, which are irregular, and particularly the 3D point cloud representation, which does not have well-defined connectivity information.  The basic idea of this approach is to apply variants Laplacian smoothing, which seeks to deform a shape to a sphere or a plane. This representation seeks to represent a pre-computed levelsets of masks, where each masked point is given by a linear combination of the corresponding points along this filtration (i.e., the weights of the combination depend on the mask value).\n\nAlthough the proposed approach has a good motivation. It exhibits several technical issues.\n1)\tFor images, when one sets the value of the mask to be zero, the corresponding pixel is 0. However, in the 3D representation, the ‘zero’ pixel is a point on a sphere, which does not vanish. It is unclear existing networks treat such regions the same way as convolution neural networks treat masked image regions.\n2)\tThe smoothing operator can be quite unstable. A small region on the original shape could correspond a large region on the resulting sphere. The densities of the smoothed point cloud could change drastically (which is not an issue for images). Such issues appear quite often for spherical parameterizations of triangular meshes. They can get worse on point clouds. It would also be good to quantitively evaluate the performance of the resulting smoothed point clouds.\n3)\tThe paper contains several adhoc parameters, such as 10 shapes for interpolation, switching spheres between planes (How to make such decisions for input point clouds that are like a half sphere?) \n4)\tAnother relevant question is how robust the proposed approach against a bad smoothing result is. Do the visualization results change?\n\nIn summary, although the motivation is good, the proposed approach is not convincing. The experimental results do not justify the robustness of the smoothing operator. \n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper introduces an approach to realize the visualization of important features from point cloud networks. In order to see what parts are important to the point cloud classification, this approach smooth parts of the point cloud to remove certain shape features and evaluate the result on the original network. In addition, the author proves that the distance from the point to its local plane can represent the local curvature, which inspires them to find a proper way to smooth the shape.\n\nI think the overall work is novel and interesting. But this paper also has some imprecise parts, here are a few:\n1)\tWhat is the motivation of using the constant mean curvature to smooth the point clouds?\n2)\tWhat is the value of β on the equation 11 in the experiments?\n3)\tThere are some typing errors, e.g. “the a” in the 35th line. And the format of reference is nonstandard in line 405 to 406.\n\n\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The paper proposes an algorithm to visualize the features learnt by 3D point cloud classifiers. The paper extends the I-GOS algorithms to point clouds. To enable the extension, the authors propose a novel algorithm to smooth point clouds which gradually smoothens the point cloud to a shape with a constant mean curvature. This is a first perturbation based algorithm for visualizing classifiers on point clouds. \n\nThe proposed approach is experimentally validated on the smoothing capability of the novel point smoothing algorithm as well as the visualizations of point cloud networks using the extended I-GOS algorithm.  The results demonstrate that the proposed approach could be a practical and useful visualization tool for researchers working on point clouds as well as a good baseline for others to improve upon.\n\nMy main concern that the proposed approach seems ad hoc and the paper doesn’t establish the (formal) properties of the proposed approach. For example, it is not clear what sequence of smooth shapes will result from the smoothing algorithm and what the properties of that sequence will be. There are some other concerns about the writing clarity, technical material and inadequate discussions for the experimental results (see questions/ concerns below). \n\nOverall, however, the authors do propose a potentially useful point cloud visualization algorithm. If the authors can address the following concerns/ queries in their response and in the paper draft, I may be persuaded to revise my rating upwards.\n\nConcerns/ Queries:\n\n- Refer lines 92-103: “A close relative of visualization is adversarial attack”? The paragraph tries to shoehorn a comparison between visualizations and adversarial attacks which is irrelevant and distracting (tangential) to the objectives of this work. This should be appropriately rephrased. \n\n- What is anti-shrinkage? How is it defined? How are the proposed algorithms formally or empirically anti-shrinkage?\n\n- What are the properties of the proposed smoothing algorithm? One way of thinking about point clouds is that a point cloud represents a shape on a differentiable manifold of shapes and the path between two shapes is represented by a geodesic. Then a smoothing operator may move the point cloud along the geodesic (shortest path) on the manifold of shape. In this vein, what are the properties of the proposed smoothing operator? What optimization problem is it a solution of?\n\n- It seems that iterative smoothing gradually moves an informative shape to a non-informative shape in a sequence of steps. Is the final shape the same for all original shapes – a sphere (lines 270-272)? Does this property formally hold? If so, why the notion of ‘potatoes’ in the title? \n\n- In Figure 2, Taubin smoothing is shown to contain artifacts on a non-uniformly sampled ellipse. However, it is not clear if the sequence of shapes resulting from the application of the proposed smoothing algorithm in the right panel are ‘desirable’. Indeed, what properties should hold?\n\n- It seems that the \\phi operator makes the smoothing operation local, via a local mask M. Why should it be separately computed and not be a part of a single diffusion process which diffuses the local saliencies first and then operates more globally as the effective impact of a diffusion process spreads?\n\n- Section 3.2 is not clear. The formulation in lines 204-209 implies that M is a solution to an optimization problem defined by the loss in (11). To compute that loss, the operator \\phi needs to be defined which is implied to be done by (14). The eventual optimization problem to solve is never discussion, nor the difficulty and the nature of the solution. Finally, not providing a definition of \\phi directly but just implying it causes confusion. I suggest that the authors make this section more clear. \n\n- Figs. 3 &4: It’ll be good to contrast these with results from the proposed algorithm.\n\n- Table 1: The results for the DDS and MR metric should be discussed. What do the experiments show?\n\n- Figure 5: How the color coding is done using the mask computed using the modified I-GOS algorithm in Figure 2 is not discussed and should be clarified. \n\n- In general, the authors should provide more explanations, discussions and takeaways for the conducted experiments. \n"
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposes a method for morphing structured 3D shapes into a blob while keeping the basic relative structure between points. For example, in Figure 1(a). My confusion is why this is a real machine learning problem, despite the fact that papers are apparently being written about it at good conferences. For example, the quantitative measures being used are “internal” to the problem and seem to presuppose that this is useful, but it’s not clear if this helps do classification better or generate fake data better, or what? In general the paper is written well and the presentation is clear, but the problem doesn’t seem important to me.\n\nAnother concern is that the method seems only tangentially related to deep learning. The algorithm itself appears to be unrelated to deep learning, but can be run on the output of a deep learning model. Much of the idea is at the technical level of kernel smoothing (e.g., Eq 14), which is useful but very simple and not clearly an ICLR-type deep learning technical advance.\n\nThe paper is also proposed as an extension of a 2D visualization technique called I-GOS in Qi et al, (2019) to 3D in Section 3.2. Gradients apparently are more complicated in this higher dimensionality, which is addressed by Eq 14."
        }
    ]
}