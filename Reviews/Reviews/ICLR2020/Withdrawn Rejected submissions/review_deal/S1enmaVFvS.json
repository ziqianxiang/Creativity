{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper presents an encoder-decoder based approach to construct a compressed latent space representation of each molecule. Then a second neural network segments the output and assigns an atomic number. Unlike previous works using 1D or 2D representations, the proposed method focuses on the 3D representations.\n\nThe reviewers have several major concerns. Firstly, the novelty of the paper seems to be limited as the proposed method mainly use the existing techniques. Secondly, there is no clear baseline to compare with. Finally, there is no clear quantitative results to measure the proposed method. The rebuttal did not well address these problems.\n\nOverall, this paper did not meet the standard of ICLR and I choose to reject the paper.\n",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The authors describe a method to encode and decode the position of atoms in 3-D molecules. An encoder-decoder architecture is used to create a representation of a molecule and to reconstruct the molecule from its representation. Then a second Neural Network segments the output and assigns an atomic number. Prior work on this task has used 1D (SMILES) and 2D (Graph) representations. The authors argues that exploiting 3D structure can create better representations.\n\nAs the paper's related work section shows, this is not the first attempt to use 3D structure to create molecular representations. Unfortunately, the paper does not compare their work to prior work on 3D structure representations (e.g Gebaur et al 2019). Also, it is not clear whether the 3D representation is better than 1D or 2D representations especially since there have been many new 1D models that perform very well for tasks like molecular property prediction (For example All SMILES VAE https://arxiv.org/abs/1905.13343 ). I think the community will benefit if the authors perform a comparison with state of the art 1D and 2D models. I think this is a main drawback of this work.\n\nAnother concern is that the authors claim that the errors in atomic numbers differ only by 1 or 2. But doesn't this show that the network has not learnt a good representation? Because atoms that differ in atomic number by 1 or 2 will have different valencies and hence exhibit different properties? On the other hand, if the authors can show that the errors in atomic numbers suggest they correspond to similar atoms (may be along the same column in the periodic table), then one can have better confidence that the network has learned a meaningful representation."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "N/A",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "PAPER SUMMARY: This paper addresses the problem of encoding and decoding 3D chemical structures, with the ultimate goal of generating 3D crystal structures. The authors propose an auto-encoder framework for encoding the 3D locations of atoms in the crystal to a latent representation and then decoding that representation back into 3D structure. The paper's contributions can be summarized as follows:\n1) A data representation that converts the 3D atom locations to a 3D voxel density map, so that they can be encoded by a standard 3D convolutional network.\n2) A decoder network that first estimates a 3D density map from the latent vector using upsampling and convolutions and then classifies the atom type (atomic number) per voxel using a 3D segmentation.\n3) The network is applied on unit cells of crystals or repeated unit cells from a dataset of crystal structures and the network is shown to be able to accurately reconstruct the 3D density maps, predict the number of atoms in the cell and perform fairly well in their classification into atomic types.\n\nI appreciate that the paper addresses an interesting problem that is not sufficiently explored and can motivate the development of novel methods that generate 3D molecules with particular structure and multiple types of atoms, however the current work combines existing methods, without any architectural modifications that exploit the new domain.  If the presentation of results and experiments is improved, this could be a good application paper in material science with an interesting combination of techniques from machine learning and computer vision. It would be more appropriate to submit this paper to a domain-specific venue rather than to ICLR. Therefore, I cannot justify its acceptance to ICLR in its current format.\n\nStrengths\n-----------------------\n1.\tNew domain: The paper addresses an interesting problem in a new domain. Previous work on generative models for molecules have concentrated on molecules with 1D structure (which can be represented as strings) or 2D structure (which can be represented as planar graphs). Generating 3D molecule structures is a challenging and interesting problem.\n2.\tEfficient data representation: The authors bypass the difficulties associated with modeling sets of 3D points with arbitrary structure by proposing a canonical, voxel-based density representation.\n3.\tJoint VAE + UNet training: The joint training of the encoder-decoder VAE and the 3D segmentation network results in a decoder that can reconstruct atom locations and atom types, being robust to mistakes in the density map reconstruction.\n4.\tQualitative results: There are nice visualizations of the reconstructed molecules and of the effect of the latent variable z. Figure 3 in particular does a great job at elucidating the outputs of the network and the reconstruction quality.\n\nWeaknesses\n------------------------\n1.\tLimited methodological novelty: The methods used in the paper, i.e. the data representation (see detailed comments), the encoder network, the decoder network and the segmentation network are all existing methods without any (or with only minor) modifications.  Their combination also seems straightforward, except for the joint training of the VAE and the segmentation network, which has not been tried before to the best of my knowledge. Networks have not been modified to exploit the intricacies of the new domain/task, such as symmetries, repetition of unit cells, large number of atoms.\n2.\tLack of comparison with other methods/baselines: There is no quantitative comparison with alternative baselines or methods or even discussion of such alternatives. It is understandable that the paper addresses a relatively new problem, however the method could be compared to CrystalGAN. Also, there is no justification of the advantages of using a voxel-based density map representation along with 3D convolutions vs, for instance, a graph representation along with graph convolutions (Xie & Grossman, [3]) or a point cloud GAN (Achlioptas). \n3.\tNo quantitative evaluation of the generative capabilities of the network: In the case of drug molecule generation, logP and QED scores  [4,5] are used to evaluate their drug-likeness. Without such scores in the crystal generation domain, it is not easy to judge how good a generated crystal is.  The need for some type of quantitative evaluation is especially important, since it is not as easy to qualitatively judge the quality of crystals obtained by sampling random latent vectors (Fig 5B) as in the case of generated images or text. The only such evaluation presented in the paper is related to the distribution of distances between atoms which seems to be close to their actual distribution in nature. \n4.\tPresentation of quantitative results: The quantitative results are scattered in text throughout the results section without being summarized in a table. Results about the distance of generated atoms w.r.t to their true location, the predicted atom counts, predicted atom types etc. for the cases of single unit cells and repeated unit cells should be added to a table to complete a rigorous experimental evaluation. \n\nAdditional Comments\n-------------------------\n1.\tLack of novelty: The data representation, which is presented as one of the core contributions of the paper, is not new. Radial basis functions have been used to generate 3D density maps (e.g. [2]) and 3D Convolutional VAEs (Brock2016, [1]) have been employed on density maps (e.g. occupancy maps) on computer vision tasks. \n2.\tConfusing description of the repeated unit cells case: It is not clear, especially for a general audience, how the repeated unit cells data are generated (in which directions are the unit cells repeated, how many times). It is also not clear how the training routine (conditioning) and the output post-processing (connected components + majority voting) is modified.\n3.\tAfter Eq. (2), q is the --approximate-- posterior …\n\nSuggested References\n--------------------------\n\n1.\tVoxNet: A 3D Convolutional Neural Network for Real-Time Object Recognition\n2.\tVV-NET: Voxel VAE Net with Group Convolutions for Point Cloud Segmentation\n3.\tDynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\n4.\tGraph Convolutional Policy Network forGoal-Directed Molecular Graph Generation\n5.\tGrammar Variational Autoencoder\n6.\t3D U-Net: Learning Dense VolumetricSegmentation from Sparse Annotation\n7.\tPointConv: Deep Convolutional Networks on 3D Point Clouds\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "The paper deals with accurately encoding and decoding 3D atomic positions and the crystal’s species using 2 sets of neural networks a) a VAE that builds a compressed latent space representation of a crystal and b) a UNET for segmenting the latent space into atoms and assigns each atom to its atomic number. Experiments were conducted on over 120K 3D samples of crystals and the results seem to be promising.\n\nThe paper is neatly written and well organized.\n\nComments:\n\nA) Figure 2: For completion, consider marking M and S as outputs of the VAE and U-Net respectively. \n\nB) In Section 3.1, why do the authors use a cube with side of ’10’ Angstrom? And why divide the cube into ’30’ bins?\n\nC) The paper revolves on vanilla 3D convolutions of the crystal structures. Have the authors considered how the results would change if SO(3) rotation invariant convolutions were used instead. The SO(3) convolutions would empower capturing all possible rotations of the crystal other than only its canonical form."
        }
    ]
}