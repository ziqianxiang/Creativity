{
    "Decision": {
        "decision": "Reject",
        "comment": "Thanks to reviewers and authors for an interesting discussion. It seems the central question is whether learning to identify correct bijections should be part of graph classification problems, or whether this leads to bias and overfitting. Reviews are generally negative, putting this in the lower third of the submissions. The paper, however, inspired an interesting discussion, and I would encourage the authors to continue this line of work, addressing the question of bias and overfitting more directly, possibly going beyond dataset evaluation and, for example, thinking about how to evaluate whether training on non-isomorphic graphs leads to better off-training set generalization.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This work probes graph classification datasets for isomorphism bias. They find substantial amount of bias in some datasets and show that they suffer from data leakage. They further perform a more fine-grained evaluation taking into consideration the node/edge types which reduce the perceived effects. They also provide some recommendations for measuring the 'right metrics' and release clean versions of the considered datasets.\n\nStrengths:\n- The methodology is rigorous and the datasets considered is extensive\n- The paper is well written\n\nConcerns:\n- Isomorphism is not necessarily a bad thing in graph classification tasks. Especially in chemistry where a bond decides if a compound is poisonous or not. Also, as the authors themselves mention, taking node/edge labels decrease the isomorphism in most datasets.\n- The results and recommendations presented in the paper are intuitive and somewhat trivial\n- I am not sure if ICLR is the right venue for this work"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The paper is concerned with the presence of isomorphism bias in commonly used graph learning benchmarks. In particular, the paper analyzes the amount of isomorphic graphs in 54 graph datasets and evaluates the performance of three graph classification methods under two isomorphism settings.\n\nCareful analyses of commonly used benchmarks can be important contributions that provide new insights into the performance of state-of-the-art models. The present paper's results on graph isomorphism properties can indeed be valuable for the ablation of models and testing their performance with regard to this property. I also found the relatively high label disagreements on some datasets (even under stronger isomorphism constraints) to be a surprising and useful result.\n\nHowever, the main assumption of the paper -- which equates the quality of a graph learning benchmark with the amount of isomorphic graphs that it contains, i.e., the lower the better -- seems questionable.\n\nThe paper argues that isomorphic graphs are akin to duplicate images in computer vision and should be removed from a dataset. While completely identical graphs are certainly problematic, the case seems different for isomorphic graphs. In the latter, a learning method is required to identify the correct bijection form V_1 to V_2 which is a non-trivial task. Testing on isomorphic graphs evaluates the ability of a model to infer these equivalence classes from data which is an important property. Moreover, being able to capture the equivalence relation can be important for various graph learning tasks, e.g., to facilitate that two topologically equivalent graphs are be classified similarly.  Going back to the computer vision analogy: it seems a more adequate comparison for graph isomorphism would be translation and scale invariance which are certainly desirable properties for CV models.\n\nIn addition, the dataset analysis could also be improved. For instance, the SYNTHETIC dataset includes continuous node attributes that are essential for classification and make the graphs non-isomorphic (when considering, for instance, each attribute vector as a unique node label). However, the attributes are not considered in the analysis what leads to a large number of isomorphic graphs. On a side note: the paper also incorrectly attributes the SYNTHETIC dataset to (Morris et al, 2016), but it is in fact from [1]. The synthetic dataset of Morris et al (SYNTHIE) does not consist of isomorphic graphs, while the SYNTHETIC dataset of [1] does so intentionally.\n\nThe results of Section 5 seem also not very surprising: After removing node labels, it is expected that the number of isomorphic graphs increases since a discriminating feature has been removed. Moreover, when accounting for node labels, many standard benchmarks seem to consist of significantly less isomorphic and mismatched graphs (as can be seen in the appendix).\n\nSince graph isomorphism != graph identity, the assumption Y_iso \\sub Y_train in Property 6 seems also not appropriate. The results of Theorem 6.1 on the other hand seems straightforward and would hold for any classification task for which the true label for an equivalence class of instances is known."
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "title": "Official Blind Review #5",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "The paper presents three contributions: (a) the observation that there’s train-to-test leakage in many graph classification datasets (under isomorphism equivalence), (b) what appears to be a theoretically motivated way of improving scores on such datasets, by focusing on solving the examples that are isomorphic with training instances, and (c) a recommendation to remove such leakage from test sets. I don’t think the paper meets the ICLR bar. While (a) is very interesting, and an important contribution, (b) and (c) are contradictory. The recommendation (c) is a bit of a no-brainer, and Property 6.1 and Theorem 6.1, providing the substance of (b), are near-trivial. \n\nMissing reference: Bordes et al. (2013) and Toutanova et al. (2015) show there’s train-to-test leakage (under isomorphism equivalence) in the FB15K dataset. "
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The authors discuss here the problem of isomorphism bias in graph dataset, i.e. the overfitting effect in learning networks whenever graph isomorphism features are incorporated within the model. This is a bias which jeopardises the validity and the reproducibility of several studies, and it is theoretically analogous to data leakage effects.\nThe authors fairly discuss the problem in the introduction, with a good coverage of the related literature; the background theory is reasonably discussed, although is not very deep. The experimental part is extensive and well described, and it shows the overfitting effect very clearly. However, the novelty of the work is limited, and also the proposed solutions cannot be claimed as superior to other approaches, due to the small improvement in accuracy."
        }
    ]
}