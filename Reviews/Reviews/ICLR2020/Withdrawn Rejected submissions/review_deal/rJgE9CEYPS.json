{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper proposes discriminability distillation learning (DDL) for learning group representations. The core idea is to learn a discriminability weight for each instance which are a member of a group, set or sequence. The discriminability score is learned by first training a standard supervised base model and using the features from this model, computing class-centroids on a proxy set, and computing the iter and intra-class distances. A function of these distance computations are then used as supervision for a distillation style small network (DDNet) which may predict the discriminability score (DDR score). A group representation is then created through a combination of known instances, weighted using their DDR score. The method is validated on face recognition and action recognition.\n\nThis work initially received mixed scores, with two reviewers recommending acceptance and two recommending rejection. After reading all the reviews, rebuttals, and discussions, it seems that a key point of concern is low clarity of presentation. During the rebuttal period, the authors have revised their manuscript and interacted with reviewers. One reviewer has chosen to update their recommendation to weak acceptance in response. The main unresolved issues are related to novelty and experimental evaluation. Namely, for novelty comparison and discussion against attention based approaches and other metric learning based approaches would benefit the work, though the proposed solution does present some novelty. For the experiments there was a suggestion to evaluate the model on more complex datasets where performance is not already maxed out. The authors have provided such experiments during the rebuttal period.\n\nDespite the slight positive leanings post rebuttal, the ACs have discussed this case and determine the paper is not ready for publication.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "In this paper, the authors proposed a discriminability distillation learning (DDL) method for the group representation learning, such as action recognition recognition and face recognition. The main insight of DDL is to explicitly design the discrimiability using embedded class centroids on a proxy set, and show the discrimiability distribution w.r.t. the element space can be distilled by a light-weight auxiliary distillation network. The experimental results on the action recognition task and face recognition task show that the proposed method appears to be effective compared with some related methods. The detailed comments are listed as follows, \n\nThere are many grammar errors and typos in the current manuscript, such as \n-\tOur key insight is to explicitly design the discrimiability using embedded class centroids on a proxy set…\n\nThe authors proposed DDL based on the principle of the intra-class distance and inter-class distance. How to avoid the imbalance of the dataset, namely some classes have the insufficient data?\n\nIn Eq4, the authors adopt a normalization method. How about the influence of the model if we ignore this normalization? Some ablation study whether or not the normalization is missing.\n\nThe implementation details of the proposed framework are unclear. For example, how to fine tune the network?\n\n"
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper studies how to aggregate features from group inputs. The paper proposes  Discriminability Distillation Learning (DDL) to compute the aggregation coefficients. The method assumes that each sample has a discriminability property that is directly related to the task. The authors define this property and propose to learn such property by an auxiliary network. Such a network can be used in many models without affecting their original training procedure and is able to improve the performances on many tasks, including set-to-set face recognition and action recognition. The experimental results are comprehensive and convincing.\n\nThe idea is simple yet interesting and the results are good, so I tend to give a positive rating.\n\nBut overall, the paper is not well-written, and there are some questions:\n\n1. The paper needs more proofreadings. For example,\n    a. only frames **will** high scores will be weighted and aggregated\n    b. As shown in table ??\n2. It seems that the proposed method is limited to tasks that have the concept of “centroids”. Many tasks may not have well-defined centroids.\n3. Discriminability is also a kind of quality in some ways, and it is used in a similar way to the previous methods. The authors are encouraged to discuss more the differences to highlight the novelty and contributions. Especially after viewing Fig. 3 and 4, their boundaries become less clear.\n4. I might be wrong but I didn’t see any figures referenced in the main body. Please add references and organize them better.\n5. The discriminability is used only once. I’m just wondering if the authors have considered cascade training, i.e., use the discriminability information to train better centroids, which then will define discriminability better.\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposed a post-processing method for improving group-based recognition tasks. Several manually designed features based on the pretrained networks are supervised trained on a light-weighted network like the teacher-student module. \n\nThis paper should be rejected because (1) the novelty of the algorithm is limited: only using the well-known intra-class distance and inter-class distance as features. Besides, the superiority of such features should be better explained; (2) Similarly, the discriminability of testing image is too complicated, such as Eq. (9, 10). Why these params are designed in such ways? Explain them; (3) Why don’t you learn the discriminability by directly operating on the extracted pretrained features? The used two distances certainly are not the best choices compared with learning methods. You should compare the performance with your methods of training under the manually-designed features. (4) The written is poor, such as Figure 6: “table ??”; Table 2: “avgerage”. \n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes a discriminability indicator using embedded class centroids on a proxy set, and show the discriminability distribution w.r.t. the element space distilled by a light-weight auxiliary distillation network, which is called discriminability distillation learning (DDL).\nThis methodology was tested on a selection of datasets addressing set-to-set face recognition and action recognition. I have the following concerns, which made me to suggest rejecting this paper.\n\n1) The methodology explained in Section 3 should be improved. In the way it is presented, it is not clear and reproducible. In detail,\n1.1)  It is better to describe the pipeline together with Figure 1.\n1.2) Contribution of the top part of Figure 1 in proposed pipeline is not clear. More descriptive caption should be added.\n1.3) In section 1, where you ask reader to observe the feature embedding of elements which lie close to the centroid… Which section or figure are you referring to?\n1.4) In subsection 2.3, clearly discuss how proposed approach is different than traditional distillation methods. Also, explain your modifications and discuss why new structure is better than default ResNet-18. \n1.5) Subsections 3.2-3.4 do not contain enough explanation to support equation of proposed method. \n1.6) It is not clear why authors use cosine distance, because it is simple? \n1.7) The quality scores generated by DDL is very hard to interpret, which to me the one of the biggest problem of the proposed methodology.\n\n2) The related work section should include studies more related to the motivation behind DDL (“….to select represent samples from the whole set efficiently for group understanding.”). For instance, attention models, saliency detection, key-frame detection methods, outlier detection methods, quality aware networks, etc. should be discussed and compared with DDL. Instead, authors more focused on face recognition and action recognition tasks themselves. Therefore, many related works are missing. Especially, Section 2.3., should not be a part of related work but should be integrated either to Section 1 (Introduction) or Section 3.\n\n3) Experimental analysis: \n3.1 ) It is not possible to figure out if the proposed method is really performing better than SOA. In other words, the experimental analysis should be extended. One thing authors should consider is including more datasets, especially more challenging datasets i.e., the ones not already saturated. Some examples can be: iLIDS-VID, PRID2011, YouTube Face, IJB-A benchmark.\n3.2) Is there any reason to mainly focus on face recognition and action recognition?\n3.3) “For face recognition, DDL can easily improve the performance by concentrating the discriminative information and for video action recognition, DDL can further accelerate the pipeline by eliminating the frames with insufficient information.” This sounds like DDL behaves differently depends on the task, but perhaps the conclusion driven by the authors cannot be fully correct given that the number of used datasets are limited to make such a general statement. I suggest authors to re-write this sentence.\n3.4) The experimental analysis should include comparisons with methodologies such as quality learning via attention mechanism, etc. to better understand the necessity and effectiveness of proposed DDL. However, only for one dataset such a comparison was performed. It is strange why for other datasets the same comparison was not done.\n3.5) Experimental analyses so much focuses on to justifying the performance improvements of DDL is independent to the base model selected (e.g. mainly Table 3,  but also Table 4, 5 and 6 include). However, to me this is a supporting experiment and it is more important to show the real necessity of the proposed method by comparing it with SOTA methods.\n3.6) I do not find using Youtube Face benchmark suitable as it is already saturated, i.e. many existing models perform around 97%, which does not allow to show whether DDL can significantly contribute to the task or not. From the corresponding results, it looks like DDL does not provide any significant improvement.\n3.7) In Table 3, it is hard to observe the contribution of DDL in terms of the performance. The improvements are in the level of 1%. More discussion is needed about that table.\n3.8) “The discriminability distillation learning is more practical to untrimmed video action recognition since there are more diversity videos chip with ambiguous content and visual blur problem”  This means that DDL should not be used in some tasks, it is not generalizable, task-specific? Please elaborate it more clearly.\n3.9) Table 2 is hard to interpret, improve the discussions regarding it.\n3.10) Table 1 and table 2 were not referred in the text. What does DATA refer to in Table 1, why they are different?, if they are really different i.e. it is not me who misinterpret, then is not it unfair to compare the results?\n\n\n4) Other suggestions:\n4.1) Support your statements with references and appropriate experimental analysis. \n4.2) In Section 4, only YTF dataset is mentioned but authors also use IQIYI-VID-FACE challenge dataset.\n4.4) Section 4.2. is not clear at all, and should be re-written.\n4.5) Some references to the tables are wrong or some are missing, pls. check them all. E.g., in section 4.2., paragraph two, table 3 should be table 2.\n4.6) There is no reference to the any figures in the text.\n4.7) Paper contains several typos and grammatical mistakes. Also, most of the points were not explained well. "
        }
    ]
}