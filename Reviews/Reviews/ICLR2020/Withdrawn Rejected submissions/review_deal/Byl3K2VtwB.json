{
    "Decision": {
        "decision": "Reject",
        "comment": "The authors present an approach to learn node embeddings by minimising the mincut loss which ensures that the network simultaneously learns node representations and communities. To ensure scalability, the authors also propose an iterative process using mini-batches. \n\nI think this is a good paper with interesting results.  However, I would suggest that the authors try to make it more accessible to a larger audience (2 reviewers have indicated that they had difficulty in following the paper). For example, while Theorem 1 and Theorem 2 are interesting they could have been completely pushed to the Appendix and it would have sufficed to say that your work/results are grounded in well-proven theorems as mentioned in 1 and 2. \n\nI agree that the authors have done a good job of responding to reviewers' queries and addressed the main concerns. However, since the reviewers have unanimously given a low rating to this paper, I do not feel confident about overriding their rating and accepting this paper. Hence, at this point I will have to recommend that this paper cannot be accepted. This paper has good potential and the authors should submit it to another suitable venue soon.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review": "This work proposes a neural netowrk approach to minimize mincutloss, thus achieving embedding nodes and find communities at the same time. However, it is difficult for me to understand the paper and I feel that it is not clearly written.\n\n1. The algorithm is not written in a box as in Algorithm 1. At first I thought algorithm 1 is the main method, but only after reading it I realized that it is one step of the algorithm. I would appreciate it if the complete algorithm (including input, output, parameters) can be summerized clearly.\n\n2. I am confused about the claim \"spectral approach underperforms significantly on the bibliographic datasets as it only uses the structure information in the graph.\" I thought the input of all methods are the adjencency matrix A.\n\n3. In table 2 and table 4, why does the paper compare different methods with different measures? Is it possible to compare all methods using all measures?"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Although this paper seems to only combine existing techniques in community detection and node embedding into a co-train process. The idea is simple and easy understood and the paper is well-written. Theoretical analysis is provided for the approximation error for the sampling strategy. However, major concerns are:\n\n1. Experimental results show that co-training node embedding and community detection can improve the performance for node classification. The improvements may result from the assumption that papers with the same class label are associated with the same community in the citation graph. However, in the dataset, there are many cases that there are not dense connections among the same labeled papers. The authors should check the correlation between the detected communities and the original paper labels.\n\n2. No comparison with other community-preserving node embedding methods, such as \"Community Preserving Network Embedding\" in AAAI17\n\n3. Since this paper aims to combine community detection and node embedding process, a set of baseline should be considered. For example, if considering the downstream node classification of node embedding as an evaluation task, then how about the performance of the following two-step method. We can first detect communities based on the node features then do graph node embedding by considering the communities' membership and node features together (e.g. simply concatenating both community membership features and node features).\n\n4. Efficiency and scalability evaluations are needed. Spectral clustering has a scalability issue when meeting big graphs. Since the spectral process is also applied in the proposed method, efficiency and scalability evaluations are encouraged to provide, especially for big graphs which are not covered in the selected datasets in this paper.\n\n5. In Sec 5.3 and Fig 2, it's mentioned that trends of the three datasets are different. For the increasing trend, how about the performance for an extreme case where all nodes are considered in one batch. On the other hand, adding more nodes in one minibatch could provide more information, but why there exists a decreasing trend? Though the authors provide a reason in Sec 5.3, it's better to analyze the reason directly from the datasets."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper is reporting an unsupervised approach to learn node embeddings and communities simultaneously by minimizing the mincut loss function. This approach programs the data through encoder to generate membership likehood matrix H, and then generates corresponding membership matrix P using node selection. The matrix P and adjacency matrix are coupled to generate community adjacency matrix to minimize the cutting. However, despite such attractive points, the novelty and strength of this study is not outstanding enough for publication in ICLR. Details comments are as follows,\n1. Similar work such as the methods of transferring matrix E to H then to P have already been published , which reduce the novelty of this study.\n2. Though there is a schematic, the learning embedding process is still not described clearly. More details of the algorithms need to be discussed to such as how to get the node embedding matrix E."
        }
    ]
}