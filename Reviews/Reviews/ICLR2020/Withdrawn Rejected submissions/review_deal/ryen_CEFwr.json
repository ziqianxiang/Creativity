{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper proposes an approach for unsupervised learning of keypoint landmarks from images and videos by decomposing them into the foreground and static background. The technical approach builds upon related prior works such as Lorenz et al. 2019 and Jakab et al. 2018 by extending them with foreground/background separation. The proposed method works well for static background achieving strong pose prediction results. The weaknesses of the paper are that (1) the proposed method is a fairly reasonable but incremental extension of existing techniques; (2) it relies on a strong assumption on the property of static backgrounds; (3) video prediction results are of limited significance and scope. In particular, the proposed method may work for simple data like KTH but is very limited for modeling videos as it is not well-suited to handle moving backgrounds, interactions between objects (e.g., robot arm in the foreground and objects in the background), and stochasticity. ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The paper presents an unsupervised method to get disentanglement of pose, appearance, background from both images domain and video domain. 5 sub-network are used to model pose, appearance, foreground, background, and decoders.  Their methods let the network focus more on the foreground to regress the landmark and improve state-of-the-art performance on landmark regression (unsupervised.), video prediction and image reconstruction. \nHowever, there are still lots of details missing for the training of the whole network even with the supplementary.  \n1. what are the details of the color jitter process? how do you know it is foreground and only colorizing this part?\n2. why the video prediction only on KTH. H36M is also a video-based dataset.\n3. what is the thin-plate-spline warped image?\n4. how do you generate T_temp(x) for image-based dataset?\n5. are the learned landmark all unimodal? as for 2d pose estimation, even we give them unimodal gt, sometimes the prediction is bimodal.\n6. how do you make the covariance as learned?"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper presents an unsupervised approach for learning landmarks in images or videos with single objects by separating the representation of the image into foreground and background and factorizing the representation of the foreground into pose and appearance. It builds upon previous work [Jakab 2018, Lorenz 2019] who proposed to train by reconstructing the original image from one version of the image with perturbed appearance and another with perturbed pose. It extends this approach by introducing an additional separation of foreground and background in the image. \n\nStrengths:\n+ Nicely motivates the approach of separating foreground and background\n+ Fewer landmarks are needed than in previous work\n+ Approach seems beneficial for video prediction\n+ Clear and well written\n+ Detailed description of architecture and training\n \nWeaknesses:\n- The changes and improvements feel somewhat incremental\n- Some uncertainty about the solidity of the evaluation/comparability with baselines\nResults on CelebA somewhat weak\n\nOverall the paper is well written, easy to follow, presents a straightforward extension of previous work and appears to show an improvement. I’m thus generally supportive of the paper.\n\nOne question I’d like to see addressed in the response is about the evaluation: as you state, the details about cropping are not known for previous work, introducing some uncertainty into the external comparisons. It would be great if you could provide some more details about the steps you took to verify that your internal baseline is indeed comparable to previous work (e.g. Lorenz 2019). For instance, on CelebA your baseline seems to fall short of Lorenz 2019, which may suggest that your substantial looking improvement on BBC Pose is indeed due to more favorable cropping.\n\nThe second concern is about the results on CelebA presented in Fig. 6 in the Appendix: It looks like the background net reconstructs almost the entire image. I would have expected that hair style, shape of ears or existence of a beard would equally warrant landmarks and appearance. It seems a bit odd that the foreground is so focused on the central part of the face. Do you have an explanation for that?\n\nMinor comments:\n- Test in Fig. 1 too small and not readable when printed\n- Fig. 1 seems to be missing an arrow pointing from image to appearance encoder\n- Why are there more than 8 points in Fig. 2 for “Ours8” (and more than 12 for “Ours12”)?\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "In this paper, authors propose to design an unsupervised learning framework, which can capture pose representation by reconstructing images or videos. \n\nThe paper is not written well. Too much components in the design make this work hard to follow. The novelty is also relatively limited, since a large part of this work has been done in Lorenz et al. (2019). Moreover, the only supervision is the reconstruction loss. I am just curious how the neural network can learn the semantics representation (such as foreground and background), without any guidance in the corresponding modules? \n"
        }
    ]
}