{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper provides a data-driven approach that learns to improve the accuracy of numerical solvers. It solves an important problem and provides some promising direction. However, the presented paper is not novel in terms of ML methodology. The presentation can be significantly improved for ML audience (e.g., it would be preferred to explicitly state the problem setting in the beginning of Section 3).",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review": "Numerical solvers for partial differential equations take a lot of time to get high resolution results since they have to explore high dimensional grid in function domain. Thus, it is important to interpolate between grids to get high resolution results. In this paper, the authors propose the model that assists PDE solver by correcting residuals in a data-driven way. Specifically, they try to approximate NN to correction function in supervised and unsupervised manners. They also propose a temporal regularization method that smooths behavior of fluid between times. As a result, proposed method can generate high resolution results in efficient way with smoke rising simulation dataset.\n\nSignificance\n- The field that the paper target is too narrow so that it may not be significant to general machine learning community.\n\nNovelty\n- I think this approach is somewhat novel since it introduces new direction in the field where the model assists PDE solver to improve performance with learned correction function.\n\nClarity\n- I think this paper is well written in most places, but the paper is not intended to make it easy for general machine learning researchers to understand and follow the problem thoroughly.\n\nPros\n- The proposed method is orthogonal to other methods such as super-resolution and may be complemented to other existing approaches.\n\nCons\nMy main concern is that the evaluation of proposed method is quite limited in the sense that- The method is evaluated with only single dataset.- Only basic model is used to compare to proposed model. What about other baseline models use similar deep learning approaches?\n- There should be various PDE problems other than Navier-Stokes to evaluate the general effectiveness of the proposed model.\n- I think time comparison/analysis should be provided since the paper targets to get efficient approximation (using NN) in numerical analysis field.\n\nQuestions and comments\n- I wonder the affect of hyper-parameter in temporal regularization.\n- I wonder performance comparison to existing NN based approaches."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposes learning NN to correct for inaccuracies in numerical solvers of PDEs, with experimental focus on fluid flow simulation. It lists two approaches: (1) compute correction in high resolution simulation from reference states, convert to low-resolution correction, and train NN to predict low-res correction (optionally with temporal regularization, and (2) directly simulate forward using correction prediction and differentiable PDE solver and optimize to match the given reference states. It shows empirical results on better approximating fluid flow simulation. \n\nThe paper tackles an important problem of using NN to speed up expensive simulation computations. The main limitation appears to be the significance of machine learning approaches. Approach (1) is a naive prediction using NN, and approach (2) involves interesting differentiation through PDEs, but that’s directly borrowed from another concurrent anonymized submission. This paper alone does not seem to have enough novel ML contributions for acceptance. \n\nThe writing can benefit from more clarity and better structure. For example,\n- Write prediction as \\hat{c}_L(s) to show what is input for the NN\n- Put definition for c_H in Section 3.1. It seems to be based on v_R and v_B but would benefit from being explicit. \n- If beta=0 is used, why do you need Section 3.2? Is it a typo?\n- In Section 3.3, I am unsure if it should be called unsupervised, as you are given reference state s_H. How is the assumption different from Sections 3.1 and 3.2? Also, a relevant reference [1]\n\n[1] Bengio, Samy, et al. \"Scheduled sampling for sequence prediction with recurrent neural networks.\" Advances in Neural Information Processing Systems. 2015.\n\n"
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The authors aim at improving the accuracy of numerical solvers (e.g. for simulations of partial differential equations) by training a neural network on simulated reference data. The neural network is used to correct the numerical solver. For different tasks they set up an approximation scheme via minimizing a square loss plus a task specific regularization (e.g. volume preservation in the Navier-Stokes equation example). This is then trained in a supervised manner. They also explore an unsupervised version by back-progagating through a differentiable numberical solver.\nThe proposed method seems straight forward, but effective as the simulations seem to indicate."
        }
    ]
}