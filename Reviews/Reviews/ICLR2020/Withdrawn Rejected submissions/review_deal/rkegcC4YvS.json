{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper introduces a method for removing what they call representation error and apply the method to super resolution and compressive sensing. \n\nThe reviewers have provided constructive feedback. The reviewers like aspects of the paper but are also concerned with various shortcomings. The consensus is that the paper is not ready for publication as it stands.\n\nRejection is therefore recommended with strong encouragement to keep working on the method and submit elsewhere.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper presents a method for reducing the representation error generative convolutional neural networks by combining them with untrained deep decoder. The method is evaluated on compressive sensing and super-resolution, where a better performance than the isolated use of Deep Decoders and GAN priors. The main contribution of the paper is not the performance, but the simplicity of this approach.\n\n\n\nFor the title, I would suggest to replace the word Removing with Reducing.\nFurthermore, the clarification of \"GAN prior\" is very nice in the introduction, maybe you could already clarify it in the abstract.\n\nYou should perform a critical grammar check. There are too many commas, for example:\n\"At sufficiently difficult superresolution problems, the Hybrid model outperforms, the Deep\nDecoder, Bicubic upsampling, the BEGAN prior, and the BEGAN as DIP prior.\" -> there should be no comma after \"outperforms\"\nThe sentence from Page 3 to 4 reads strangely, probably a word is missing after \"For our GAN prior, we use the BEGAN architecture, and we demonstrate similar results\"\n\"Philosophically, they hybrid\" -> \"Philosophically, the hybrid\"\n\nFig 6 caption - shouldn't it be 49152 instead of 49512?\n\nYou perform various very good analysis experiments, which is well appreciated. Still, it would be good to think about some more experiments (and include at least one of them in the paper):\n1. You compare to IGAN and show that you achieve similar performance. You describe that a state-of-the-art approach are invertible generative models and that they are very time consuming (e.g., 15 minutes for a 64x64 image). How good would the invertible models be in terms of performance? Could you perform tests as well?\n2. It would be great if you report the runtime of all experiments as well - maybe also the memory usage."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "Summary: This paper proposes to use a combination of a pretrained GAN and an untrained deep decoder as the image prior for image restoration problem. The combined model jointly infers the latent code for the trained GAN and the parameters in the untrained deep decoder. It also jointly infers the mixing coefficient alpha and beta during test time for each image, thus learning how much we should rely on GAN. The proposed hybrid model is helpful on compressed sensing experiments on the CelebA dataset; however, it is only marginally better than deep decoder on image super resolution and out-of-distribution compressed sensing.\n\nDetailed comments:\n-\tThe writing is clear and I was able to understand the model part of the paper. The algorithm box is helpful. However, I would still appreciate if the authors can provide an overall model figure in the model section to help understanding. \n-\tJointly learning the mixing coefficient is an interesting part of the model.\n-\tThe motivation in the abstract and intro could be strengthened. A smaller version of Figure 1 can be probably moved to the beginning of the paper to illustrate the problem of GAN. But even with the help of Figure 1, it is still unclear what is the fundamental problem for GAN. Simply combining a GAN with an untrained decoder model doesn’t help elucidate the source of the problem. \n-\tThe proposed Hybrid model seems to help on compressed sensing experiments on CelebA. However, it doesn’t help much on out-of-distribution experiments. Moreover, in the super-resolution task, as shown in Figure 5, the improvement over deep decoder is also not significant.\n-\tThe out-of-distribution experiments seems lack of thorough study. In particular, the paper only studies the transfer between CelebA -> Caltech-UCSD Bird dataset. It would be better if the paper can study a variety of other image datasets as well. Also some visualization on the Bird dataset should also be included.\n-\tEffect of n_pre needs to be further investigated. Why not directly train both models together? It would be good if the authors could comment on how sensitive the n_pre is and what is the intuition.\n-\tFor figures, I would recommend rename “Hybrid” to “Hybrid (Ours)” to highlight the paper’s contribution, and use a brighter color.\n-\tFigure 5 should be renamed as a Table. \n-\tHyperparameter details should be moved to the Experiment section.\n\nConclusion:\nThe paper proposes a simple combination of a trained GAN and an untrained decoder model for the task of image restoration. Although the method is clear and straightforward, in the experiments, the influence of the new model component seems marginal. Moreover, the motivation is not strong enough. Therefore, I recommend weak reject."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #1",
            "review": "[Update after rebuttal period]\nI am sorry that the response cannot address my confusion. I still doubt the motivation of this paper and the actual experimental performance compared with state-of-the-art methods are still ignored. Thus I decrease my score.\n\n[Original reviews]\nThis paper proposed to modeling image as the combination of a GAN with a Deep Decoder, to remove the representation error of a GAN when used as a prior in inverse problems. The proposed methods are evaluated on two image restoration tasks, including compressive sensing and image super-resolution. The effectiveness of the combination is also presented.\n\nAuthors devote themselves to remove the representation error of the GAN image prior. Intuitively, the manner of the proposed linear combination model is rough and less reasonable. In Alg.1, the detailed algorithmic process is presented, it is clear that authors need to pre-train the used GAN and Deep Decoder, then combine them to train one network. If the motivation of this paper is to remove the representation error of GAN, GAN should be viewed as the main body. However, the authors view GAN and Deep Decoder as the same position against the original intention.\n\nAdditionally, in the experimental part, the ablation studies indeed reflect the effectiveness of the proposed algorithm, but it looks like the Deep Decoder plays a key role in all cases. In other words, the GAN image prior just plays a supporting role. This is also far away from motivation.\n\nMore importantly, I cannot see the surprising results because of this work only compare themselves with some basic version or naïve methods. All state-of-the-art approaches to different tasks are ignored, which is the other big disadvantage. \n\nIn Table 2, what is the meaning of ‘CSGM’？ The authors should describe it.\n\nIn a word, from the algorithmic and experimental perspective, this paper cannot achieve satisfying performance.\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        }
    ]
}