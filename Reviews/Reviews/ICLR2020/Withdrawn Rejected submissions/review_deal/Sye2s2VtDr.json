{
    "Decision": {
        "decision": "Reject",
        "comment": "The authors propose a simple but effective method for feature crossing using interpretation inconsistency (as defined by the authors).\n\nI think this is a good work and the authors as well as the reviewers participated well in the discussions. However, there is still disagreement about the positioning of the paper. In particular, all the reviewers  felt that additional baselines should be tried. While the authors have strongly rebutted the necessity of these baselines the reviewers are not convinced about it. Given the strong reservations of the all the 3 reviewers at this point I cannot recommend the acceptance of this paper. I strongly suggest that in subsequent submissions the authors should position their work better and perhaps compare with some of the related works recommended by the reviewers.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "title": "Official Blind Review #3",
            "review": "In the paper, the authors proposed CrossGO, an algorithm for finding crossing features useful for prediction.\nIn CrossGO, one trains a neural network that captures feature crossing implicitly.\nThen, possible crossing features are estimated using the gradient-based saliency.\nThe idea here is that, if a feature has a crossing with some other features, its contribution in the saliency can vary across different inputs.\nThus, by looking at the variation of the saliency, one can find candidates features for feature crossing.\nCrossGO greedily selects candidate crossings based on the idea above.\nIn the last step, a simple logistic regression is trained using the candidate crossings, and the effective crossings are selected using a forward greedy feature selection.\n\nI found the paper well-written and the idea is easy to follow.\nMy concern, however, is the lack of Factorization Machines (FM) in the experiments.\nIn Introduction, the authors mention to the deep version of FM and stated \"(deep FMs are) not able to generate interpretable cross features\".\nBut, as the authors are aware of, non-deep FMs are able to handle feature crossings in a interpretable way.\nThus, it would be essential to adopt non-deep FMs as the baseline in the experiments.\nBecause the important baseline is missing, I found the results are not convincing enough to claim the effectiveness of the proposed method.\n\n\n### Updated after author response ###\nThe authors have partially addressed my concern by adding FM/HOFMs as the experiment baselines, which I greatly appreciate.\nHowever, I found the current paper misses some other possible baselines for high-order interaction models [Ref1,2].\nAs the authors mentioned in the response, FMs find the feature crossing as a kind of embedded representations, which may not be suitable for modeling sparse interactions.\nThus, the sparse interaction models need to be taken into consideration as well.\n\n[Ref1] Safe Feature Pruning for Sparse High-Order Interaction Models\n[Ref2] Selective Inference for Sparse High-Order Interaction Models",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "\nThe paper presents a scheme to generate new features as cross-product\nof binary features to improve the performance of linear models while\nobtaining interpretable models. The candidate set of cross-features\ncan be exponential and is handled by the proposed scheme by utilizing\nthe gradient-based importances of the features in a (deep) neural\nnetwork. Features with large discrepancies in their local and global\ninterpretations are used as the seed set of candidate features for\ngenerating new cross-features, and the final step performs a feature\nselection to further reduce the final set of cross-features. The\nempirical evaluation demonstrates the utility of the proposed scheme\non 8 datasets. \n\nWhile the proposed scheme does present a way to improve the accuracy\nof interpretable models, I am currently recommending a reject for the\nfollowing reasons (given the higher standard recommended for papers\nover 8 pages):\n\n- While this paper does consider some baselines, it seems to be\n  missing some crucial baselines that address the same (or very\n  similar) problem. There are some papers [2,3] that learn boolean\n  conjunctions (that can be seen as cross-features) to generate\n  accurate interpretable models. Moreover, there are some search based\n  feature generation schemes [1,4] that significantly improve upon the\n  exhaustive feature generation scheme of Kanter & Veeramacheneni,\n  2015. This technique can easily be applicable in learning boolean\n  cross features with binary features. At the very least, it is important to \n  understand where this proposed scheme is positioned relative to the \n  aforementioned literature and why a comparison is not required.\n- It is very unintuitive (at least to me) to tie the candidate\n  generation scheme to a neural network especially given the\n  sensitivity of neural network training to different initializations\n  and other factors. For the same data and neural network, the local\n  vs. global discrepancies can change significantly, thereby changing\n  the candidate set of cross features. This can potentially make the\n  proposed feature generation scheme somewhat unstable, and the\n  interpretations from the subsequent models might not be as\n  interpretable as they seem. It would be good to understand what I am\n  missing here and why being tied to a neural network model is\n  essential and not an issue here. \n\n\nClarification:\n\n- Lines 8-10 in Algorithm 1 is not clearly explained.\n- The experiment to motivate Assumption 1 needs to be better\n  explained.\n\n\nMinor:\n\n- The notation in equation (1) needs to be clarified better.\n\n\n[1] Khurana, Udayan, et al. \"Cognito: Automated feature engineering\nfor supervised learning.\" 2016 IEEE 16th International Conference on\nData Mining Workshops (ICDMW). IEEE, 2016. \n[2] Dash, Sanjeeb, Oktay Gunluk, and Dennis Wei. \"Boolean decision\nrules via column generation.\" Advances in Neural Information\nProcessing Systems. 2018. \n[3] Wei, Dennis, et al. \"Generalized Linear Rule Models.\" Proceedings\nof the 36th International Conference on Machine Learning. 2019.\n[4] Khurana, Udayan, Horst Samulowitz, and Deepak Turaga. \"Feature\nengineering for predictive modeling using reinforcement learning.\"\nThirty-Second AAAI Conference on Artificial Intelligence. 2018. \n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper attempts to solve the cross feature generation problem efficiently. The state-of-the-art method AutoCross cannot control the size of the searching set of the candidates of cross feature fields. To narrow down this set, the authors provides a measurement called Interpretation Inconsistency. With an easy toy experiment, the authors conjecture that features with large Interpretation Inconsistency tend to interact with other features in the hidden layers of DNN. Therefore, based on this conjecture, the authors design an effective algorithm to discard those cross features with small Interpretation Inconsistency value, which finally narrows the set of cross features. With this narrowed set, the whole procedure can be accelerated largely. \n\nPros:\nThis work can be regarded as an accelerated version of AutoCross. By incorporating Interpretation Inconsistency, the set of cross features can be effectively narrowed. Although this is an incremental work, this idea is relatively novel. \n\nCons:\n1.\tThe setting of the threshold for filtering feature fields is somewhat heuristic. The authors should provide some explanations on its setting. If not, we cannot trust it and doubt that it may cause some unexpected results and thus will not be robust.\n2.\tThe experiments are somewhat not convincing. The main contribution is to accelerate AutoCross. Thus, I expect to see the time complexity comparison between them. However, I do not find it in this paper. Although the authors mention that on wide datasets, AutoCross simply cannot work, on narrow datasets, a time complexity comparison should be provided.\n3.\tIn Table 5, only the numbers of cross feature fields of the proposed method are provided. A comparison with baseline methods on the number would be better to show the advantage of the proposed method.\n\nMinor: In Section 2.1, the double quotation marks should be revised."
        }
    ]
}