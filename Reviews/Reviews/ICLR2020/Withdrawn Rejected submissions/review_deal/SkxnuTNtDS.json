{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #2",
            "review": "The paper proposes a simple modification to existing graph NN methods for classifying the entire graph of possibly variable size. The problem is of interest. The proposed method is on the other hand fairly simple and straightforward, as shown in Fig.1 and eq(4), as a simple function of the adjacency matrix A that incorporate the entire graph structure. The results are verified on four datasets with promising results. I have a number of concerns with the paper:\n*The presentation: The paper seems to come out in a rush, with many critical details missing. For example, the main method, which is the main technical contribution, is described within less 1-page length. The figure 1 is also not very helpful in understanding the details of the method. In experiment section, four datasets are presented, where many of them are introduced without any info about the dataset size, graph size, etc. The comparison methods used in Table 1 are also minimal (only 1 method is compared with in each dataset), and many of the methods are decade old. Some of the comparison methods are even without any formal reference so there is literally no precise info about where the methods are exactly from. Overall it is very difficult for an average reader to be fully convinced of the significance and professionalism of the work.\n**empirical evaluation: As aforementioned, the experiments are not compared with the recent work and detailed info is critically missing.\n**algorithmic contribution: this is also a question mark. \n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "Summary\n\nThis paper combine GCN with KG methods (quadratic kernel) to predict the class of graph-structured data, e.g. protein structures, chemical compounds, etc.\n\nStrength\n\nThe paper proposes an extension of GCN for graph classification, which is an interesting problem.\n\nWeakness\n\nThe use of GCN for graph classification isn’t well motivated. GCN works well for node classification which is a lot different from graph classification and the paper failed to point out why GCN should help? Paragraph 4 of section 2 provides some previous works that also extend GCN for graph classification but still, the motivation of this work should be clearly stated in the introduction. Furthermore, what’s the intuition for using the quadratic layer? How is it better than DIFFPOOL?\n\nRegarding the experimental results, it would be better to provide more convincing evidence as well as more information about the datasets being used, e.g., size, number of classes. Also, it isn’t clear if the results in table 1 are binary or multi-class? \n\nThe paper somewhat readable, but need serious revision of the flow as well as figures, result tables, etc. For example, it’s not necessary to use up entire of page 4 for figure 1 (which also doesn’t provide much information)\n\nOverall impression suggests that the paper wasn’t completed and should be carefully revised before submitting to another conference.\n"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "Strength\n-- Learning representation of entire graphs is a very important problem.\n\nWeakness\n-- The novelty  of the proposed approach is very marginal\n-- It is unclear why the proposed approach is working\n-- The experiments are very weak. \n\nThis paper studied supervised graph representation learning and proposed to use a quadratic layer for pooling. Experimental results on a few data sets prove the effectiveness of the proposed approach. \n\nOverall, the paper is easy to follow. However, the novelty of the proposed approach is very marginal. The pooling layer is directly taken from another paper. And it is really not clear why the quadratic layer is a good approach for summarizing the node representations. The experiments are very weak as well. The proposed approach only works better on one data set and is much more worse than existing methods on the other three data sets. "
        }
    ]
}