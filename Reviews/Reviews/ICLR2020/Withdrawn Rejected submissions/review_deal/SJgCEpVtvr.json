{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper is develops a self-training framework for graph convolutional networks where we have partially labeled graphs with a limited amount of labeled nodes. The reviewers found the paper interesting. One reviewer notes the ability to better exploit available information and raised questions of computational costs. Another reviewer felt the difference from previous work was limited, but that the good results speak for themselves. The final reviewer raised concerns on novelty and limited improvement in results. The authors provided detailed responses to these queries, providing additional results.\n\nThe paper has improved over the course of the review, but due to a large number of stronger papers, was not accepted at this time.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "#Summary\n\nThis paper proposes a generalised self-training framework to build a Graph Neural Network to label graphs.  Of importance is the dynamic nature of the self-training. The authors do not change the GCN but extend the self-training portion as per the prior GCN paper by introducing Dynamic Self-Training that keeps a confidence score of labels predicted for unlabelled nodes.\n\n# Comments\n\nThis is a very interesting paper in terms of looking at the effects of changing the self-training framework to better utilise the underlying structure. As such we can exploit information from other nodes that are yet to be labelled.\n\n1. As the self-training is going on, are there different computational costs or are they about the same?\n2. For CiteSeer 20 and 50, why does \\beta = 0.45 switch from the other experiments?\n3. Will such self-training be useful for general NN self-training procedures\n4. If we had soft-labelling or uncertainty on which label each node has, how would the dynamic self-training be changed?\n\n#Other notes\nPlease remove the \n\nAn appendix\nYou may include other additional sections here"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The paper proposes an approach for learning graph convolutional networks for inferring labels on the nodes of a partially labeled graph  when only limited amount of labeled nodes are available.\n\nThe proposal is inspired from Graph convolution Networks with the idea of overcoming the major drawback of these models that lies of their behavior in case of limited coverage of the labeled nodes, which implies using deeper versions of the model leading at the price of what the authors call the over-smoothing problem.  \n\nThe main idea here consists in relying on self training to get a better coverage of labeled nodes enabling learning with less deep models, this translates to a simple and intuitive algorithm. Using self training is not new in GCN but the way it is used here, computing adaptively a threshold for incorporating pseudo labels and using weights according to the confidence off predictions is new.\n\nExperimental results are reported on citation datasets and compared with many baselines show similar results as baselines when the coverage increases up to 50 labeled nodes /class, but the method brings significant improvements when the coverage is low (e.g. only few, <20, labels /class). \n\nAlthough the difference with previous approaches do not look like a huge step, the method seems to be quite justified empirically and achieve real good results wrt state of the art."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper propose to modify the existing work [1] of self-training framework for graph convolutional networks. It tracks three limitations of [1] and propose three  use a threshold-based rule to insert new pseudo-labels and dynamic change the pseudo-label set. Moreover personalized weight are assigned to each activate pseudo-label proportional to its current classification margin. Evaluation of the proposed framework is performed on four networks for semi-supervised node classification task with varying label rates.\nPros:\n1. This work tracks and addresses the limitations of existing work.\n2. Authors conduct experiments on multiple dataset with varying 2-hop coverage ratio. \n3. The overall paper is well written, except some typos, e.g. in page 6, section 5.1 \"Each of three dataset is ......\". Should \"three\" be \"four\".  \nCons:\n1. The proposed framework makes modification on the existing work, which is a good extension but the novelty is limited.\n2. The gap of the experiment results between the proposed method and the baseline methods are quite small.\n3. Only GCN instantiation are provided, it is suggested to evaluate the effectiveness on the other GNN variants, such as GraphSage, GAT and MoNet.\n[1] Li et al. Deeper insights into graph convolutional networks for semi-supervised learning."
        }
    ]
}