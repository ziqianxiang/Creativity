{
    "Decision": "",
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper presents a user-specific decision tree method for building explainable recommendation systems. A regression function is built to map training samples to a decision rule at each node and a second network is similarly developed to learn the value at the leaf nodes. They are trained end-to-end with a data loss on the target values with a sparsity term. Experiments show competitive performance which however is worse than the latest state of the art results. \n\nPros:\nGenerally, the paper is technically justified and clearly written.\n\nCons:\n1-\tA further discussion is needed about the exact advantage of the proposed regression networks in comparison with the similar works.\n2-\tThe experimental comparison seems to be insufficient. Only four state-of-the-art methods are compared and in table 1 about the missing results, a reasonable explanation is needed.   \n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "Very well written paper.  A very easy read. Usually authors leave the references riddled with minor formatting errors, which you didn't.\n\nVery nice method.  Well constructed cost function (Sct 3.2), clear, simple approach (Alg. 1), and a technique for converting regression trees to decision trees (with tests on single variables) that surprised me with its simplicity and effectiveness.\nNote in a sense you are using amortised inference methods (the functions g() and h()), which makes the local trees work.  Suggest you make this connection in the Related Work.  Its definitely an important characteristic of recent algorithms.\n\nExperimental work is convincing enough.  Thanks for doing the ablation studies.  I think this should be an essential part of all machine learning algorithm papers.  The most important part of the paper is the discussion on white-box introspection.  This is what makes the algorithm worth something.  Without this discussion, you just have yet another reasonable RS method.  I wonder how this sort of evaluation can be made more \"scientific\", more \"objected\" and \"measured\".  Please think about this and read papers from your colleagues doing explainable systems to see what they have done.  I'd think a user study would help, though this adds a level of complexity machine learning folks have not been trained to do.\n\nNot much to say because, well, its surprisingly simple but effective, and well written.\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposes an approach to generate explanations for recommendation\nsystems based on decision trees. The authors describe their approach and\nevaluate it empirically, comparing the achieved accuracy to other approaches.\n\nThe main drawback of the paper is that the approach is not evaluated in terms of\nexplainability of the generated trees. I realize that this is difficult, but\nsome proxy measure like the average height of a tree could have been computed to\ngive some evidence that the trees are human-understandable.\n\nThe authors do present samples of trees in Figure 4, but it is unclear how\nrepresentative those trees are, and some of the trees (e.g. a) purely bin\nratings, which presumably makes for explanations that are not very satisfying\nand counter-intuitive (e.g. \"the average rating is 10, therefore you will rate\nit 3.075\" but \"the average rating is 3.9, therefore you will rate it 3.836\").\n\nThe learned embedding function h seems counter-intuitive for providing\nexplanations as it is a complete black box that doesn't easily reveal the\nlearned relationships. The authors do not motivate why it is necessary.\n\nSection 3.3 describes how a partly-explainable tree is turned into a tree by\nreplacing nodes with decision stumps. It is unclear why this step is necessary\nand an explainable tree is not constructed in the first place.\n"
        }
    ]
}