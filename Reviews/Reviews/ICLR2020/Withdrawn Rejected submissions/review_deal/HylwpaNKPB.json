{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper studied the problem of aggregating high-order neighbor in GCN model. It first showed that stacking multiple layers with one-hop message propagation does not yield an advantage to learn node embedding from higher-order neighbors. Then it presents a solution based on learnable kth-order weight matrix, which can aggregate high-order neighbors in a more flexible and reasonable way. The approach itself is interesting. However, there are the following concerns:\n1)\tThe computational complexity. Although authors didn’t provide complexity analysis, it is definitely costly to run the proposed model on large graph. That’s also the reason why evaluation on Pubmed dataset was done on a sampled subset.  \n2)\tNo significant improvement over other baselines on graph embedding results, as shown inn Table 4 and 5. \n3)\tAuthors are suggested to read “Simplifying graph convolutional networks” in ICML 2019, which also studied the neighborhood aggregation issue and presents a simplified GCN model. \n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper proposes a high-order weighted variant of GCN. The key idea is to learn an adjacency weight matrix which obeys the topological constraints (e.g., if there exists k-length shortest path between any pair of nodes, then the corresponding entry of power-k weight matrix could have a non-negative value) from a lasso-type reconstruction loss. Experiments on 3 small citation networks are reported.\n\nOverall, I have a few concerns as below on the model and the experiment which prevent me from accepting the paper.\n\nPros:\n\n1, The topic of the paper, i.e., incorporating high-order information, is very important for learning better graph representations with GNNs.\n\n2, The paper is clearly written.\n\nCons:\n\n1, My main concern is on the objective of the proposed adjacency weight learning. It is not clear to me why the unsupervised reconstruction type of objective would produce weight matrix W that helps the downstream supervised tasks? Or more concretely, why W obtained by solving (8) would be useful for learning better representation for node classification? Moreover, there are many other ways which enable the model to directly learn weights on the graph, e.g., learnable spectral filters which take eigenvalues as input, learnable message functions in GNN, attention weights in GAT. All the learnable parts in above competitors are well aligned with the supervised learning objective. What do you think makes the proposed model superior to these competitors?\n\n2, I have another concern on the efficiency of the proposed method. An optimization needs to be done during inference which is problematic for moderately large graphs. It would be great to report the run-time of the proposed method.\n\n3, Experimental results are less convincing. (1) Only results on three small citation networks are reported. I suggest authors to try larger datasets to fully verify the effectiveness of the proposed model, e.g., reddit, PPI, quantum chemistry, etc. (2) It would be great to also report the standard deviation in Table 4.\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "In this paper, the authors propose a variant of GCN referred to as HWGCN to consider convolution beyond 1-step neighbors. The authors first construct a high-order adjacency matrix based on feature similarity and graph structure using LASSO method. Then the high-order adjacency matrix is used in the GCN instead of the original adjacency matrix. The authors carry out experiments on three datasets for node classification. Comparison to several state-of-the-art methods demonstrate comparable or better accuracy.\n\nStrength:\n1. The idea of utilizing high-order neighbors in GCN is interesting given the recent results of worse performance with added depth in GCN.\n2. The authors carry out thorough comparison to state-of-the-art methods across GCN, node embedding and also label propagation.\n\nWeakness:\n1. The major concern is whether the improvement of accuracy can justify the added complexity in model and training. Table 5 shows that the proposed method only has comparable but not superior performance to the baseline methods. However, the proposed method has added complexity in: (1) The time required to find shortest paths between nodes in the graph; (2) The time used in LASSO training to find high-order similarity; (3) The increased density of the graph which leads to higher cost for each graph convolution operation.\n2. The authors only provide evaluation on the accuracy of the proposed method. On the contrary, no running time comparison is provided. The authors should provide running time for (1) pre-processing of the high-order similarity including shortest path finding and LASSO training; (2) the time cost for the graph convolution ops with and without the high-order interaction.\n3. It would be interesting if the authors could provide more analysis and insight into the learned high-order interaction. For example, how level of sparsity is achieved via the LASSO learning? How different is the learned high-order interaction differs from direct similarity between node features and A^p.\n\nDetailed comments:\n1. In equation (5), the authors use the average among neighbors to compute the high-order computation. What will be performance differ if for example just use x_j? \n"
        }
    ]
}