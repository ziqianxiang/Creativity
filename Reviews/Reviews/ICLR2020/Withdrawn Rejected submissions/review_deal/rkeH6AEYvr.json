{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "\nSummary:\n\nPaper presents a progressive attention mechanism for multi-scale image classification. The network contains a module that prunes non-important regions progressively by a factor of 2, then extract the features through a CNN. After all level features are extracted, the network later aggregates them and produce a final prediction. Since Bernoulli sampling is used to binarize the region mask, REINFORCE algorithm is used to update the region network. The paper shows slight improvements on top of a simple CNN (with only 4 layers), on a synthetic MNIST and ImageNet, with some visualization examples of proposed region network.\n\nThis idea to use a region pruning seems interesting. However, as detailed later, the motivation and experiments are not sufficient to show that it brings new insight to the classification. Lacking proper comparisons with earlier methods also undercuts the effectiveness. It is unfortunate but I could not recommend this paper to be accepted in the current version.\n\nStrength\n\n+ Informative graphics to help understand the method\n+ Detailed methodology and discussion on experiments\n\nWeakness\n- Question about the motivation\nIn the second paragraph of the introduction, the paper claims \"problem is that computational resources are allocated uniformly to all image regions, no matter how important they are for the task at hand.\" Will this actually be a problem in training CNN nowadays? It is safe to assume the different regions could be described by some statistics, and the reason why CNN successes in the past years is its capability to capture such statistics during the training with gradient descent. Could the author provide more justification for this motivation?\n\n\n- Experiments are not sufficient\nAs the paper indicated in related work \"multi-scale representations\", this work belongs to the image pyramid method category. However, there is no empirical comparison shown.\nIn addition, the paper only tests its proposed method on top of a simple CNN, with 4 convolutional layers as in Table 4, and the top-1 accuracy on ImageNet is merely 40%. I suggest the author deploy their method to at least VGG-16 and ResNet-50 to further strengthen its impact. Otherwise, it is hard to convince people this method can generalize to CNN models.\nI suggest authors to conduct additional experiments in their future submission.\n\n- Localization metrics\nSince the key contribution of this method is the network learns to prune those not useful regions, should the author provide some numerical results, e.g. the mean intersection of union between the proposed method's region prediction and the ground-truth bounding box? This data should be available in your synthetic MNIST and the ImageNet one. Only showing some example in Figure 7 is not that convincing.\n\n\nMinor comments:\n\n1. What's the number in Figure 4, 6, next to the marks in Figure?\n2. While this KFLOPS per image is informative, should the author consider to put their results in a table, indicates by the level 1,2,3 for a better visualization? The current Figure 4 and Figure 6 are not straight-forward to grasp in the beginning."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper proposes a multiscale CNN variant that processes images in a coarse-to-fine setting (low to high resolution).  At each resolution, the network both extracts features and computes an attention map to use in processing the next higher resolution.  Features extracted from all resolutions are merged together and used in the classification decision.  Experiments show results of the attention mechanism on an MNIST-based synthetic dataset, and show classification accuracy on ImageNet.\n\nUnfortunately, the paper has major shortcomings.\n\nExperimental results are simply not convincing as ImageNet classification performance is far below modern baselines.  Figure 6 reports Top-1 accuracy on ImageNet in the 50-55% range.  Modern CNN baselines such as VGG [Simonyan and Zisserman, Very Deep Convolutional Networks for Large-Scale Image Recognition, 2014] or residual networks [He et al, Deep Residual Learning for Image Recognition, 2015] achieve Top-1 accuracy in the 70-80% range.  This is an enormous performance gap.\n\nThe paper should be using a modern network architecture as a baseline and modifying it to include the proposed multiscale feature extraction, location, aggregation, and merging modules.  Then test if those modifications improve ImageNet classification performance.  The baseline CNN architecture currently used is too impoverished to allow comparison to recent results in other work.\n\nFurthermore, this is not the first paper to propose multiscale methods or adaptive computation.  Though some work is cited, experimental comparison to competing methods in both of these areas is entirely lacking.  This alone is sufficient cause for rejection.\n\nFor example, how does the proposed attention mechanism compare to Autofocus [Najibi et al]?  How does the multiscale approach compare to Feature Pyramid Networks [Lin et al] or Multi-scale Dense Networks [Huang et al]?\n\nThere is also highly relevant work that is not cited by the paper, including:\n\n(1) SBNet: Sparse Blocks Network for Fast Inference\n    Mengye Ren, Andrei Pokrovsky, Bin Yang, Raquel Urtasun\n    CVPR 2018\n\nThis paper proposes an architecture with internal dynamic attention masks to reduce computation at inference.\n\n(2) Multigrid Neural Architectures\n    Tsung-Wei Ke, Michael Maire, Stella X. Yu\n    CVPR 2017\n\nThis paper present a multiscale network design that processes all scales simultaneously (an alternative to the proposed coarse-to-fine approach), yielding improved results on ImageNet.  It also conducts experiments on a synthetic MNIST dataset to demonstrate implicit attentional capabilities of its network architecture.\n\nBoth of these recent papers highly overlap the central themes (multiscale, attention) in the submitted work and should likely be included in citation, discussion, and experimental comparison.\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "In this paper, a coarse-to-fine pyramidal scheme, along with learned attention/routing mechanism, is proposed to handle classification in large images, whereby the receptive field of attends to a much smaller part of the image than would be useful for classification. To overcome this problem, the authors propose a mechanism by which attention mechanisms are propagated from coarse to fine levels. A few experiments are provided to show the benefits of the proposed mechanism over convolutional network baselines, especially in situations where the input size is relatively large compared to the effective receptive field. The paper is written in a straightforward manner and is mostly easy to read. \n\nWhile the overall idea is interesting, the authors seem to have completely missed reference [1] from CVPR 2017, which provides a very similar set of ideas but in a more formal and potentially more powerful setting of multigrid networks, incorporating both multiscale and attention mechanisms. \n\nFurthermore the experiments on ImageNet have extremely weak baselines; if I understand correctly, the top-1 accuracy is not even 55% for the best model, which is a far cry from modern architectures and baselines. It is well known that results on toy models hardly translate to real-world networks, and this makes me wonder about how applicable the results of this paper would be for large scale ResNet networks. It would have been much more convincing if the authors would have taken modern baselines and then shown that using their top-down approach allows scaling to even larger images, for example. As it is, the largest image size considered is 256x256, which is exactly what can already be well handled by modern ResNet's. For these very weak empirical results, I feel that the paper is not yet ready.\n\nSome specific questions:\n\n1. What interpolation/downsampling algorithm was used to create the coarser resolutions? Is the performance sensitive to this algorithm?\n\n2. For Figure 4, please provide the details about the figures in the caption itself, to avoid needing to scroll back and forth between the text and the figure. I found Figure 4 quite confusing to parse. Similarly for Figure 6. Fixing these would be very helpful.\n\n[1] Multigrid Neural Architectures (http://openaccess.thecvf.com/content_cvpr_2017/papers/Ke_Multigrid_Neural_Architectures_CVPR_2017_paper.pdf)"
        }
    ]
}