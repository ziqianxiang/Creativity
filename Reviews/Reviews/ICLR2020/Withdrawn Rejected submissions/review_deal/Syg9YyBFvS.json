{
    "Decision": "",
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "About the problem: I consider the problem tackled of very significant importance. As the paper rightfully argues, (boosted) DTs lead competitions in \"tabular\" data while deep learning excels on data with topological relationships between its features, yet we are short of providing the classification efficiency of DTs to DL over tabular data -- or -- explaining why it is worthless.\n\nThe solution adopted by the paper consists in reimplementing the classification algorithm of decision trees (Boolean algebra) using the DL algebra (essentially vector spaces).\n\nFirst, the name DNF needs to be changed. In Boolean formulas, it means Disjunctive Normal Form formulas, which could misleading given the paper's purpose. \n\nSecond, I see no difference between the OR and AND in (unnumbered formula in pg 3). \n\nThird, the architecture looks like it approximate a DNF (Boolean) rather than a DT. This is crucial: in a DT, the set of rules that can be derived from the tree are mutually exclusive. I do not (clearly) see this in the models learned.  This is important if the name Deep Neural *Forests* is to be used. \n\nFourth, I do not see any attempt to bring interpretability in addition to classification efficiency using DL on tabular data. Have the authors considered this as well ?\n\nFifth, the authors have used XGBoost even for small low dimensional datasets (Section 4) -- as far as I remember, XGBoost is heavily optimised for processing huge datasets, and accepts the price of approximations in the classical boosting framework to learn DTs (for ex on the splitting criterion used). Have the authors tried a more conventional but exact alternative for such simple datasets ? If so, what did the curves in Fig 2 look like ?\n\nSixth, the authors provide no statistical comparison to the results in Table 1. I assume the data after the +- are standard deviations (correct the \"Standard error\" in Fig 2). If so, I am quite sure that almost no bold result in the table is significant.\n\nSeventh, the experimental results are interesting, but apart from Section 6, I see no real advocacy to tweak DL to be more tabular -- compared e.g. to tweaking DTs to be more topological. Do the authors think that the paper answers by the affirmative to the question \"is it worth tweaking DL for tabular data ?\". A theoretical section would have been much welcomed, everywhere but in the conclusion... \n\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper tackles the general problem of training deep models for tabular data. Motivated by the success of decision trees in this field, the author proposed a novel neural network architecture that mimics how decision forests work. Specifically, it proposed a novel neural decision tree module and stacked these models through densely connections; localization and feature selection is used to build ensemble models, referred to as deep neural forests. Experiments on a toy checkerboard dataset, several real-world tabular datasets, and a multi-modal dataset suggest the effectiveness of the proposed model, showcasing that the proposed end-to-end learnable model is on par with GBDT. \n\nPros:\n- Novel/original idea\n- End-to-end learnable, allowing to utilize SGD, which better fits for the large-scale dataset and multi-modal dataset\n- Well written and easy to follow \n- Competitive results over GBDT, which is commonly used in relevant tasks.\n\n\nWeakness: \n- The neural network competing algorithms are too weak; there is one important baseline/ablation missing to justify the proposed architecture. \n- Some of the choices are not justified either theoretically or empirically.\n- Important details are missing\n- Motivation and the proposed approach is a bit dis-connected\n- Potential overhead. Runtime is missing so difficult to judge here. \n\n\nDetailed comments:\n\nI can understand the author wants to mimic decision tree behavior motivated by the fact that the decision tree can be considered as a disjunctive normal form formula. However, it’s not clear to me why this specific architecture of NT module is chosen. There seems no evidence to support that through this specific module we can capture the inductive bias over tabular data better. \n\nIt’s not clear to me if the benefits come from the ensemble or the NDT model proposed. Have you tried the same feature selection and localization trick to ensemble a few FCN models? This would be an important baseline to justify your contribution in Sec. 3.1. Moreover, it should be compared against several other approaches that try to combine the strength of neural network and decision trees, e.g. TabNN. \n\nAt least several key technical choices should be justified empirically through ablation study:\n+/- Orthogonal constraints\n+/- Ensemble (localization / feature selection)\n+/- Dense residual connections\n\nFrom the intro, we can see the paper is motivated by the success of decision tree models, specifically, gradient boosting trees. The comparison is also targeting GBDT. However, the architecture and ensemble scheme is mainly based on the bagging, which is commonly used in random forests. I would suggest the author modify the intro slightly to \n\nMissing details:\n- How each subgroup is decided? Do different choices matter a lot?\n- Why you use elastic net regularization instead of standard l1? Is this choice grounded by any empirical findings?\n\nMinor:\n- You should cite the straight-through estimator for the differentiable sign function. Otherwise, it might make readers think this is original in this paper. \n- Handling multi-modal input data is a bit beyond the scope of tabular data, which is the main focus of this paper. This raises some concerns since in this field there are much more comprehensive neural network models to be considered to compare against than simply combining FCN and CNN. \n\nFinal Remarks:\nOverall I think the paper is still slightly below the bar. I am expecting to see a thorough ablation and comparison to justify the technical contributions."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposes deep neural forest (DNF), which targets tabular data and integrating strong points of gradient boosting of decision trees (GBDT). The algorithm is composed by: (i) a neural tree (NT), which is constructed using soft binary OR and AND gates (multi-layered), (ii) a deep neural tree (DNT), which is a stack of layers of NBs with dense residual connections, and (iii) deep neural forest (DNF), which is a weighted ensemble of DNTs. A synthetic checkboard game (which is an extension of XOR problem) is used for illustration of the algorithm strength. Nine Kaggle datasets are used for experiments with comparison to XGBoost and FCN, and in about a half datasets, DNF outperforms them. Lastly, multi-modal task HRI-DD is used to show the integration ability of DNF with deep models.\nThe motivation of the paper is good: we need some systematic approach to apply deep neural networks to tabular data. How to incorporate specific inductive bias is a key. However, the paper is not enough convincing. Although AND and OR construction seems valid, there may be many different variants to incorporate the bias. More detailed comparison with other settings are needed. For example, I don’t understand how much the dense residual connection contributes to the performance. Besides, the rationale to select the dataset used in the experiment should be explained. There are various kinds of datasets and why do the authors pick some? Is it because they are appropriate for AND-OR feature construction? Or is it just random? More elaborate experiments may improve the paper a lot.\n"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposed a new model architecture, deep neural forest for tabular data. My first question is that it seems that the deep neural tree structure is just a special case of a fully connected neural network. Consider the AND() and OR() functions, they are a linear transformation with a tanh, which is equivalent to a one-layer neural network with tanh activations. Consequently, the NB() function is a two-layer neural network; NT() is a three-layer neural network and DNT is an N-layer (densely connected) neural network. I think the only difference is that DNT is a neural network with some weights fixed as 1 or 0 and in training, an orthonormality constraint is applied. Orthonormality constraint is also used in neural network training [1]. Hence, instead of a completely new model, I would rather consider DNT as a neural network with a special regularization. Then I would recommend an ablation test to study which part really contributes to the model's performance. For example, can a regular neural network ensemble trained with orthonormality constraint achieve a similar result as DNF?\n\nI did not get the intuition why the author multiplies a Gaussian probability density. It seems that this formulation is not from Meir et al. (2000), so more explanation and discussion on this would be welcomed. Is there a Bayesian intuition behind this?\n\n[1] Bansal, Nitin, Xiaohan Chen, and Zhangyang Wang. \"Can we gain more from orthogonality regularizations in training deep networks?.\" Advances in Neural Information Processing Systems. 2018."
        }
    ]
}