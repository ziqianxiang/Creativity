{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper tackles the problem of how to adapt a model from a source to a target domain when both data is not available simultaneously (even unlabeled) to a single learner. This is of relevance for certain privacy preserving applications where one setting would like to benefit from information learned in a related setting but due to various factors may not be willing to directly share data. The proposed solution is a transfer alignment network (TAN) which consists of two autoencoders (each trained independently on the source and the target) and an aligner which has the task of mapping the latent codes of one domain to the other. \n\nAll three reviewers expressed concerns for this submission. Of greatest concern was the experimental setting. The datasets chosen were non-standard and there was no prior work to compare against directly so the results presented are difficult to contextualize. The authors have responded to this concern by specifying the existing domain adaptation benchmarks are more challenging and require more complex architectures to handle the “more complex data manifolds”. The fact that existing benchmark datasets may be more complex the the dataset explored in this work is a concern. The authors should take care to clarify whether their proposed solution may only be applicable to specific types of data. In addition, the authors claim to address a new problem setting and therefore cannot compare directly to existing work. One suggestion is if using new data, report performance of existing work under the standard setting to give readers some grounding for the privacy preserving setting. Another option would be to provide scaffold results in the standard UDA setting but with frozen feature spaces. Another option would be to ablate the choice of L2 loss for learning the transformer and instead train using an adversarial loss, L1 loss etc. There are many ways the authors could both explore a new problem statement and provide convincing experimental evidence for their solution. The AC encourages the authors to revise their manuscript, paying special attention to clarity and experimental details in order to further justify their proposed work. ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "In this paper, the authors claimed to address a new domain adaptation setting under double blind constraint, to meet the privacy requirement. Though the problem itself seems real and interesting, the solution in this work makes the problem quite trivial. In fact, any other domain adaptation method can be applied to address the problem, while the authors even did not compare with existing UDA methods which can be intuitively adapted.\n\nPros:\n-\tThe problem that this work aims to address, i.e., domain adaptation under privacy constraint, seems reasonable and important.\n\nCons:\n-\tThe authors proposed a quite trivial solution to solve this problem, which in turn makes all existing UDA adaptation methods off-the-shelf. For example, the most widely accepted DA algorithms, such as MMD and DANN, can be adapted to minimize the distance between the target encoder and the source encoder by training the weights for the target encoder. In this case, the aligner introducing more parameters is not even necessary. \n-\tThe results are not promising and inspiring. S(UL), directly applying a model trained on a source dataset, has already achieved as competent results as TAN. \n-\tThe datasets used are at a toy level from UCI. More profound discoveries are expected on DA benchmarks. \n-\tThe paper needs significant proof-reading, as there are many grammatical errors and typos.\n"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper proposes a TAN model for double blind UDA problem, which supposes that partial data drawn from source domain is unlabeled and the target domain is completely unlabeled.\n\nActually, blind domain adaptation has been proposed several years ago. The double blind domain adaptation has no signficant difference.\n\nFrom the model, I could not observe the technical novelty, although the authors focus on the \"Aligner\". Actually, autoencoder based domain adaptation has also been proposed for several years.\n\nThe aligner can actually be removed, by jointly training a domain-shared encoder in Step 3 when the unlabeled target data is used for training.\nIn other words, step 4 can be removed and in test stage, the output of encoder means the domain aligned feature representation. \n\nAdditionally, the source classifier is trained independently from the unlabeled target data. Although the domain aligned feature representation can be learned, it is still risky to directly apply the source classifier for unlabeled target data. Therefore, I suggest a safe strategy to train the source classifier and the domain aligned feature represenation module by jointly feeding the labeled source and unlabeled target data into the Step 2. That is, the step 3 can be integrated into step 2 for safer training.\n\nI also have concerns on the experimental datasets. Why not use the benchmark visual datasets?\n\nThe proposed model lacks of comparisons with many state-of-the-art models.\n"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "N/A",
            "review": "\n\n###Summary###\n\nThis paper tackles the transfer learning problem with the double-blind unsupervised domain adaptation, where either the source or the target domain cannot observe the data in the other domain, but data from both domains are used for training. The high-level intuition of this paper is based on the observation that in some practical settings, the transferring source data to the target domain is restricted due to the privacy policy. The goal is to learn a classifier which performs well in target classification task under double-blind constraint. \n\nThe setting of this paper is slightly different from the conventional domain adaptation. In this paper, the source domain has abundant unlabeled data and a small number of labeled data. The target domain only contains a limited number of unlabeled data.\n\nThe paper proposes a transfer alignment network (TAN) which comprises two autoencoders, one trained on the source domain and one trained on the target domain. In the domain adaptation phase, the model leverages an aligner to transfer the output of the target encoder to an aligned latent variable.  The aligner is trained to map the target code to source code on the target unlabeled data. The objective function is L2 distance between the source code and the mapped target code. \n\nThe whole pipeline is trained with four steps:\n1) The source encoder and source decoder are trained with L2 reconstruction loss.\n2) The source encoder and source classifier are trained with cross-entropy classification loss.\n3) The target encoder and target decoder are trained with L2 reconstruction loss.\n4) Train the aligner to map target code to source code on target unlabeled data with L2 distance loss.\n\nThe paper proposes to compare the TAN with three baselines: S(UL):  a stack of encoder and a neural network classifier trained using source data and tested on target data without finetuning. S(UL)-T(U): a model retrains the S(UL) with the target unlabeled data. S(UL)-T(U)-Large: a model which is similar to S(UL)-T(U) but contains more layers and parameters in MLP.\n\nThe experiments are performed on five multivariate datasets: HIGGS, HEPMASS, SUSY, Sensorless, and Gas. \n\n\n### Novelty ###\n\nThe experimental setting proposed in this paper is interesting. However, the proposed model is trivial. The TAN model is composed of autoencoders and aligner. The training losses in the framework are L2 reconstruction loss and L2 distance loss. Thus, the novelty of this paper is incremental.\n\nThe experimental results in this paper are weak. First of all, the datasets used in this paper are not standard benchmarks. Secondly, the baselines in this paper are too trivial.   \n\n\n###Clarity###\n\nOverall, the paper is well organized and logically clear. The images are well-presented and well-explained by the captions and the text. \n\n###Pros###\n\n1) The paper proposes an interesting transfer learning framework where either the source or the target domain cannot observe the data in the other domain. \n\n2) The paper is applicable to many practical scenarios since the data privacy in the real-world application is critical. \n\n3) The paper is overall well-organized. The claims of the paper are verified by the experimental results.\n\n###Cons###\n\n1) The paper proposes double-blind unsupervised domain adaptation as accessing the source and target domains is restricted in some practical settings. However, the source and target domain share the models trained on themselves, as well as the features extracted from the source domain and target domain data. The information about the original data can be recovered with the shared features and weights, which violates the settings proposed in this paper. \n\n2) The main issue of this paper is the novelty is incremental. The proposed model is trivial as it only contains the auto-encoders and L2 loss. \n\n3) The experimental part of this paper is weak. The datasets used in this paper are not the standard domain adaptation benchmark. It would be nice to see how does the proposed model work on standard domain adaptation benchmarks such as Office31, VisDA, Office-Home, DomainNet, etc.\n\nVisDA: The Visual Domain Adaptation Challenge\nhttps://arxiv.org/pdf/1710.06924.pdf\nOffice-Home : Deep Hashing Network for Unsupervised Domain Adaptation\nhttp://hemanthdv.org/OfficeHome-Dataset/\n\nThe baselines used in this paper is also trivial. It is desirable to compare the proposed method with state-of-the-art domain adaptation methods.\n\nBased on the summary, cons, and pros, the current rating I am giving now is \"reject\". I would like to discuss the final rating with other reviewers, ACs.\n\n"
        }
    ]
}