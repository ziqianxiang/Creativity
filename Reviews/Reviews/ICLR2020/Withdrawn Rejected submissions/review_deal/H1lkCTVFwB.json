{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "\nThis paper reports experimental results on global feature pooling for fine-grained visual categorization. The main experiments are (1) Comparison of features learned by average pooling and max pooling. (2) Comparison of nine pooling methods (3) Combination of two different pooling schemes. \n\nThe finding on the features learned by average pooling and max pooling is interesting. \nHowever, this paper is not suitable for publication because the experimental comparison of two different pooling schemes lacks details and does not support a significant contribution. \n\nThe hypothesis of the little improvement of a conventional combination of two different pooling is claimed that lower layers' filters become confused by gradient signals coming from the two different pooling schemes. However, such a high-level explanation is not convincing well. The hypothesis should be verified by equations and/or experiments. \n\nThe detail of “channel split“ is unclear. How is the feature map split into different splits? \n\nThe detail of the “freeze-and-train” trick is unclear. Does “a new linear layer with global max pooling” means that a linear layer is added after or before the pooling? \n\np.10, the authors wrote that “This trick guarantees that …”. Why the training of a new linear layer before training whole network can guarantee that final performance becomes not worse? \n\nThis paper also proposed post-global batch normalization for achieving performance improvement and faster convergence. However, all experiments are conducted using this normalization; thus, the effects of this normalization cannot be confirmed.\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "Summary:\n\nThe paper proposes to evaluate 9 different pooling function to replace the global average pooling in the fine-grained classification domain, and reveals that max-pooling out-performs average pooling.\n\nThe technical novelty of this paper is trivial. By using the known pooling function. However, it is uncertain to me if the survey paper is necessary in this domain, since the best results achieving via their study, is inferior to the state-of-the-arts bilinear pooling. Paper is composed in a poor, informal, oral-spoken manner. Related work is heavily mixed with introduction and make decipher the core contribution hard.\n\nThe major concern about this paper is lacking novelty and impact on this field. Only evaluating some known operations on some datasets is insufficient for a conference paper. In addition, recent work based on bilinear pooling [1] yields 88.0% accuracy with ResNet-50, which is significantly higher than the ones in Table 1. \n\nThe only interesting is about the visualization in Figure 1, showing max-pooling focus more on the local details on one given example. However, only one qualitative example is not enough, CUB dataset includes the partial bounding box, I suggest author further compute some numerical metrics based on the location information and extend to all the state-of-the-art global pooling methods. \n\n\nStrength:\n+ Good visualization in Figure 1.\n+ Discrete entropy is reasonable.\n\nWeakness:\n- Trivial technical novelty.\n- 9 evaluated methods are not the current interest in the research field. best results are much lower than the state-of-the-art. \n- Writing is not in good shape and hindering to grasp the main contribution.\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper conducted thorough studies of the pooling layer types on fine-grained classification tasks. It validated that the maxpooling would encourage sparser final-conv layer feature maps than avgpooling by both qualitative results and quantitative results with two proposed reasonable metrics. Also, the experimental results show that models with the global maxpooling layer would outperform models with the global avgpooling layer for fine-trained classification tasks. Related work is listed in detail.\n\n\nHere I have several concerns:\n\nWill the global pooling encourages object-level features and thus bring benefits for coarse-grained classification tasks? These results will complement the argument proposed in the paper and should not include it in future work. We can also validate the effectiveness of post-global batch normalization in the coarse-grained classification setting.\n\nAlthough the author has discussed the differences between training from scratch and finetuning, I think it is still required to conduct the training from scratch experiments and compare the final scores for different methods, especially for the Table 2. Will the results align with the current version? If not, the proposed 'freeze-and-train' trick is not much solid.\n\nFor the discussions about learnable generalized pooling, we cannot directly draw the conclusion from the phenomena shown in Figure3. Because the learnable generalized pooling will dynamically change its type according to the specific input image which is quite different from the fixed type.\n"
        }
    ]
}