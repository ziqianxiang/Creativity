{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #4",
            "review": "The paper proposes an end-to-end solution to accurately perform multi-person pose estimation. Existing approaches can be characterised as being either 'bottom-up' (parts localisation then person localisation) or 'top-down' (the opposite direction). In particular, existing techniques in the bottom-up regime use greedy heuristics to refine the predictions, which makes the overall optimisation process unclear. The proposed technique performs both parts jointly through the proposal of an end-to-end differentiable model (a CNN-LSTM on top of an image's extracted features) to perform multi-person pose estimation.\n\n- I found the paper quite difficult to follow in some parts. For instance, it disrupts the flow of the paper by having related works / lit review while describing the model (you should put this in a separate section). It would have also been nice to have more equations complementing the text.\n- Many of your citations need to be in parentheses (i.e. use \\citep).\n- Figure 3 should be moved up to be closer to the text which explains the training procedure, right now it's too far down.\n- You should also show LSTM2 in the figure, or have it in its own figure\n- If the final output of the LSTM are the confidence maps for each person, you should make this clear in the diagram, e.g. drawing arrows from each of the z time steps (since each of the z time steps corresponds to heat map predictions for one person).\n- Refer to Algorithm 1 in the text. What is this algorithm referring to? LSTM2?\n- Center table captions\n- I am confused about how LSTM1 and LSTM2 interact. When I first read the paper I thought that the LSTM in Figure 3 was 'LSTM1' and that you were replacing this by an 'LSTM2'.\n- It says in the training procedure that \\tilde{z} poses are predicted (or more technically, 2x that amount +1 because of the refinement loop). This to me implies that \\tilde{z} can change for each input over the course of training. You also have a fully-connected network which predicts the ground truth stopping vector p (whose length is determined by max(z,\\tilde{z}+1) and therefore appears to be of variable length), but because this is a fully-connected network how can p be variable length? It doesn't seem clear from the writing. Perhaps I can suggest how I would have implemented this:\n- Run the LSTM for T=z+1 iterations, where z is the ground truth number of people in the image. The input to the LSTM at each iteration is simply the input x from the AE concatenated with the output heat map from previous timestep (like LSTM2). The output at each iteration t will be a tuple (\\tilde{H}_t, \\tilde{p}_t}), where \\tilde{p}_t \\in [0,1] is the probability that we halt the LSTM. For iterations 1..z, the GT value for \\tilde{p}_t will be 0 and for iteration z+1 it will be 1. This would not require a refinement network nor a separate network to estimate stopping probabilities.\n- I find the ordering issue to be an interesting problem. Unfortunately, as you have mentioned in Section 3.1.2, it still requires one to define permutations of the poses during training. Perhaps future work could somehow utilize permutation-invariant modules (e.g. DeepSets).",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper has proposed a bottom-up approach for multi-person pose estimation. This method integrates the part detection and association stages together to form a differentiable model. The memory footprint while training the model is kept low by constraining the back-propagation steps within a small number of time steps. \n\nWhile the proposed method Doesn’t seem to show a big improvement on the COCO dataset, the authors gave a convincing reason that there are fewer occlusions in the COCO dataset, and in the harder task of OCHuman where only the harder poses are present, the proposed approach has shown its advantage over other models.\n\nAs for the multi-scale setting, could the author provide some more recent baselines? Newell et al. was proposed in 2016-2017, which is almost 3 years old. And the proposed method doesn’t seem to have anything preventing it from being applied on newer bottom-up models. \n\nThe authors pointed out in the motivation that the thresholding process causes problems in deciding if a new person is detected. However in the Stop criteria proposed by the authors (Page 4), they are still using a threshold. \n\nThe writing of the paper needs to be significantly improved. The paper seems to be submitted in rush. There are a lot of places with typos or vague descriptions that significantly impedes understanding of the paper, for example:\n\n1. Page 2, “bottom-down approach” -> bottom-up approach\n2. Page 3, “Bests fits” -> best fits\n3. Figure 1, “first raw” -> first row\n4. Page 3, “Convolutional (Long) Short-Term Memory”\n5. Figure 5, some scripts need to be removed here.\n6. The heat maps in all the figures are too small to decipher. I can’t see the poses clearly. \n7. Section 3.1.2, The authors are introducing related works while describing their model.\n8. While motivating the learning-based model (Section 2.2) It seems to be hard to follow the long paragraph, and many terminologies are not consistent.  \n9. In the training procedures section, there are still descriptions of the model structure. "
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "The paper proposes a method to solve the multi-person pose estimation problem. The authors design a bottom-up method and demonstrate that this bottom-up method performs better, especially under the circumstances where subjects have severe occlusions.\n\nIn particular, the authors utilize ConvLSTM to estimate the pose of one subject at each iteration. The choice of the recurrent network for the multiple person pose estimation is relatively novel. Designing a separate branch to determine the stop criteria is also well done under the proposed architecture. Especially I like the discussion and experiments on the ordering part, which solves the most critical problem applying the ordinal prediction method, i.e., LSTM, to this problem where the order does not really matter. The authors also come up with  new optimization tricks to deal with the limited GPU memory. The experiments are also reasonable: the proposed method achieves the best results among bottom-up methods on COCO and the overall best result on OCHuman.\n\nOverall, I believe this could be a good paper if the authors can address some of my concerns here:\n1. the motivation of the loop in the first LSTM is not quite clear to me. The authors demonstrate the feedback loop is important in the experiment and text, but the motivation is unclear. Moreover, if this loop is very useful in LSTM1, wouldn't it be natural to also include the feedback loop in LSTM2?\n2. based on what is claimed in Table 3, the optimal order is the learnt order, that is, u in Eq. 4 should be the same order as the order in Eq. 2. Then the overall architecture of the network consists of two consecutive LSTMs with intermediate supervision, which is intrinsically similar to stacked hourglass used in Newell’17. Therefore, can we expect better performance if we stack another LSTM on the proposed network?\n3. since the optimal order is the learnt order, have the authors trained the model multiple times to see if the learnt orders are the same? If they are different, can we still draw any conclusions?\n4. the performance on the COCO dataset is not so significant compared to the top-down methods. Though the authors claim that the COCO contains too many easy cases, there is no analysis about how the proposed method fails at these cases.\n5. missing literature.\nJin, Sheng, Wentao Liu, Wanli Ouyang, and Chen Qian. \"Multi-person Articulated Tracking with Spatial and Temporal Embeddings.\" CVPR 2019\nThis is also a fully differentiable bottom-up method. They achieved 0.68 AP on COCO.\nZhou, Xingyi, Xiao Sun, Wei Zhang, Shuang Liang, and Yichen Wei. \"Deep kinematic pose regression.\" ECCV workshop 2016\nSun, Xiao, Jiaxiang Shang, Shuang Liang, and Yichen Wei. \"Compositional human pose regression.\" ICCV 2017\nThese two methods work on single person pose estimation. They are bottom-up methods but they also consider the joint detection and association (bones) together as either a kinematic model or compositional model.\nIt would be great if the authors can also discuss these previous works.\n\nMinor comments:\nP in Eq. 1 should be \\textit{p}\nOn page 5 when HM is first time mentioned, it is not clear that HM abbreviates HeatMap\nOn page 7, “Coco” should be “COCO”"
        }
    ]
}