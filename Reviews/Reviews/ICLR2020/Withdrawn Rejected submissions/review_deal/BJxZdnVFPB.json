{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "Summary:\nThis paper aims at classifying visual attributes. To overcome the performance dropping of training multiple attributes in one model since different attributes focus on different kinds of features, they propose to independently classify each attribute and leverage such \"negative\" attributes to boost the invariance of features for the target attribute. Specifically, the classifier should accurately classify for the target attribute, but cannot decide the right labels for its negative attributes, which resembles an adversarial learning manner. To this end, they turn to the reversal gradient technique proposed in domain adaptation area. \n\n+Strengths:\n1. The writing is easy to understand. Motivations, related works and techniques are clearly introduced. The Fig.1 of the method is also informative and clear.\n2. The idea of leveraging negative attributes to learn robust attributes is interesting and may give insights to other multi-task learning problems.\n\n-Weaknesses:\n1. My biggest concern is the performance of their method. They conduct experiments on the relatively easy solved face attributes and pedestrian attributes. We can find that the performance differences between baselines and SOTA are quite slight, which cannot draw convincing conclusions to support their claims in the paper. They'd better to do these on other more challenging attribute datasets, such as AwA dataset. Considering that the performance gain is quite slight while the training time and storage cost is increased obviously compared with multi-task training and traditional single task training, the value of this method is not high to this task. \n2. The first sentence in the Abstract is not idiomatic. Please make a verification. \n3. This paper seems not have obvious technical contributions. The significant component reversal gradient has been studied in the related domain adaptation works.\n4. The procedures to obtain the most negative attribute are not scalable and efficient when large scale of attributes need to be classified."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "Summary：\nAuthors proposed adversarial attribute learning (AAL) that can directly exploit the attributes with negative transfer to improve the attribute prediction. The gradient reversal technique is adopted to solve the adversarial training problem. Experimental results reveal that AAL benefits from the negative transferred attributes.\n\n\nComments:\n1.\tWhy is the learned CNN representation, which is invariant to auxiliary attributes, more suitable for classifying the main attribute? The improvement of adversarial attribute learning compared to the single task attribute training is not significant (92.46% vs 92.33%).\n\n2.\tThe ablation experiments are conducted on the validation set. The authors should give the results on the test dataset.\n\n3.\tThe result of the multi-task is better than the single task, which means that some attributes are positively transferred. Thus, can these positive transferred attributes be exploited?\n\n4.\tIn the ablation study of “Multiple adversarial attributes”, it can be observed that the result of using all the negative attributes is worse than that only uses the most negative attribute. This result seems inconsistent with the assumption that negative attributes are helpful in the proposed AAL model. The authors should give a more detailed interpretation.\n\n5.\tIs the most negative attribute the most suitable for training the attribute learning model? The authors should verify this point.\n\n6.\tThe idea of the proposed adversarial attribute learning model is interesting and practical. While how to find the most suitable auxiliary attribute set is also important and can make this work more solid.\n\n7.\tSome writing issues should be improved.\n\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper proposes an interesting idea: given that multi-task training of two tasks leads to poorer performance for the first task, one can perform multi-task training with the *inverted* gradients of the second task instead and obtain improved performance for the first task. This is motivated as follows: if features required for the second task induce worse performance for the first task, then becoming invariant to the labels of second task may induce better performance of the first task. This is applied to attribute learning settings.\n\nThe paper reports initial experimental findings indicating minor advantages to this approach: mean performance across attributes improves from 92.34% with single task training to 92.46% with the proposed approach on CelebA and from 92.19 to 92.32% mean accuracy on a recent person attribute dataset.\n\nI would find the empirical phenomenon interesting if confirmed more thoroughly, and worthy of closer study. However, as things stand, the findings are at best preliminary. Both negative transfer itself, and the gains from the proposed approach to exploit it to improve performance are very marginal at best, and no error bars are shown, leaving open the possibility of statistical insignificance.\n\nConceptually, the connection to Jayaraman et al 2014, which proposes to use different features to predict different semantic attribute groups, is not explained.\n\nI would be interested in a study of the various positive and negative task transfer groupings that emerge, in the spirit of work like Zamir et al, \"Taskonomy ...\".  Do these groupings have anything to do with semantic meanings and groupings of attributes?\n\nIn general, it feels like this work scratches the surface of some interesting empirical phenomena, but falls short of either providing conclusive evidence for them or of providing theoretical insight into them."
        }
    ]
}