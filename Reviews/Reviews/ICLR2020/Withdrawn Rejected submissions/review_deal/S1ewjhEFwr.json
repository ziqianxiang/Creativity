{
    "Decision": {
        "decision": "Reject",
        "comment": "Main content: Proposes a deep RL unified framework to manage the trade-off between static pruning to decrease storage requirements and network flexibility for dynamic pruning to decrease runtime costs\nSummary of discussion:\nreviewer1: Reviewer likes the proposed DRL approach, but writing and algorithmic details are lacking\nreviewer2: Pruning methods are certainly imortant, but there are details missing wrt the algorithm in the paper. \nreviewer3: Presents a novel RL algorithm, showing good results on CIFAR10 and ISLVRC2012. Algorithmic details and parameters are not clearly explained. \nRecommendation: All reviewers liked the work but the writing/algorithmic details are lacking. I recommend Reject. ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This work introduces a Reinforcement Learning based framework that simultaneously learns both a static and dynamic pruning strategy. The combination allows the static pruner to decrease the required storage while the dynamic pruning can optimize the required compute using input-dependent pruned weights. The RL agent can dynamically learn the optimal sparsity distribution among the different layer of the networks while staying under a resource constraint as opposed to other methods which often enforce a layer level sparsity ratio. It demonstrates the efficacy of the algorithm on CIFAR10 and ILSVRC2012 and showed the effect of the tradeoff between static and dynamic pruning.\n\nOverall I believe this paper is a borderline accept. It proposes a unified framework to manage the trade-off between static pruning to decrease storage requirements and network flexibility for dynamic pruning to decrease runtime costs. The empirical results demonstrate the capability of the framework but would benefit from some clarification and additional ablations.\n\nPros:\nProposed an RL formulation of a unified framework for static and dynamic channel pruning.\n\nThe empirical results demonstrate the ability of the model to achieve high accuracy while sparsifying the compute and balancing storage consumption and accuracy. Strong results are shown for CIFAR10 and ILSVRC2012.\n\nDemonstrated a tradeoff between static pruning and runtime-pruning through ablation of R_r.\n\nCons:\nIt is unclear how speed-up calculated. Is it wall clock and benchmarked on what device? What was the cost of running the RL agent during runtime?\nIf you are computing MACs, that should be reported as such unless a strong correlation can be proven with the particular pruning scheme. MAC reduction does not translate directly to speedup in hardware.\n\nIt could be clearer if the ablation of R_r also demonstrated a storage/accuracy tradeoff.\n \nIt is unclear if similar results may be achieved by first running a static pruning and then separately training a dynamic pruning algorithm on the already statically pruned network?\nIt might benefit from an ablation study with and without simultaneously training static pruning?\n\nSome of the algorithmic details could benefit from some clarification.\nIn section 3.2, it is unclear to me the effect of R_r during training. It seems that the agent could learn to over select channels to prune to adapt to R_r. Section 3.4 seems to lack inclusion of R_r in the number of statically pruned values. The treatment of M_0 in section 3.2 separate from  M_r and M_s seems to make the number of statically pruned filters during training depend on the layers chosen by dynamic pruning. It seems like it may cause differing sparsity between training and inference time."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This paper proposes to learn static and dynamic channel pruning policies for convolutional neural networks. Static pruning depends only on the training dataset and is computed once before the model is deployed. Dynamic pruning is input-dependent. The policies are obtained with deep reinforcement learning on the training dataset using a combination of the loss function and storage/computation resource budgets as a reward signal. The key novelty in this paper is to combine static and dynamic pruning which can obtain the benefits from both worlds. Experimentally, the learned pruning policies are competitive with recent dynamic pruning approaches on CIFAR-10 and ILSVRC2012, in terms of both final test accuracy and number of parameters/inference time.\n\nOverall, I do like the idea of combining static and dynamic pruning, the DRL approach is reasonable and it seems to do well in practice. However, there are some key issues that must be addressed by the authors. In summary, these are:\n\n1- Additional baseline methods: why not compare against a simple combination of the best published static pruning method, and one of the best published dynamic pruning methods (e.g. FBS or RNP)? I'd like to understand what the added value of jointly learning the static and dynamic pruning policies is. If a simple combination of existing static and dynamic methods works well, you will need to justify the need for the more complicated DRL approach you propose in this paper.\n\n2- Writing: it has to be substantially improved; please see the sections Writing and Minor below.\n\n3- Training cost: how stable is the training process described in Section 4.1? Does it much longer to train compared to pure dynamic pruning methods? \n\nRelated work:\n- Discuss connections to routing networks which adaptively route layer outputs to the next layer's modules: Rosenbaum, Clemens, Tim Klinger, and Matthew Riemer. \"Routing networks: Adaptive selection of non-linear functions for multi-task learning.\" arXiv preprint arXiv:1711.01239 (2017).\n\nWriting:\n- Sections 3.3 up to Section 5 need lots of rewriting; I suggest some changes in \"Minor\" below but please make a full pass as the paper is difficult to read at the moment.\n- Section 4.1 is extremely difficult to read and so I don't really understand how you train the pruning policies. Please improve the writing and summarize the process in pseudocode or illustrate it. Also, I believe 4.1 should be a section of 3 rather than in experiments. It is extremely important to understand how the network+DRL agents are trained!\n\nClarification:\n- Number of pruned channels, runtime vs static: \\ceil{d_r C} vs (C - \\ceil{d_s C}); why are these different in form? Seems like the static formula prunes \\ceil{(1-d_s) C}. Why is that?\n- Tables 1-2: what is the \"Baseline acc.\" and why is it different for each method? Isn't this the accuracy of the same network before any pruning?\n\nMinor:\n- Title is too long: particularly the expression \"DYNAMIC FLEXIBLE RUNTIME CHANNEL\". Perhaps you can think of shorter titles.\n- \"We consider a standard form of reinforcement learning an agent\" --> \"We consider a standard form of reinforcement learning: an agent\"\n- \"are the the number of channels\" --> \"are the number of channels\"\n- \"output feature F_out u_r is predicted\" --> \"output feature F_out, u_r, is predicted\"\n- \"many existed dynamic\" --> \"many existing dynamic\"\n- \"Since C_in is various among layers\" --> \"Since C_in varies among layers\"\n- \"To avoid over-prune the filters and crashed in training, we set a minimum sparsity ratio +α, then the action space change to a_t^r ∈ (+α, 1].\" --> \"To avoid over-pruning the filters and crashing the training, we set a minimum sparsity ratio +α, such that the action space becomes a_t^r ∈ (+α, 1].\"\n- \"The reward function is proposed to consider both of network accuracy and computation budget.\" --> \"The reward function is considers both the network accuracy and computation budget.\"\n- \"and it may be various in scale\" --> \"and it may vary in scale\"\n- \"large at begin of training and small near converge\" --> \"large at the beginning of training and small near convergence\"\n- \"which filters can be to prune permanently\" --> \"which filters can be pruned permanently\"\n- \"on two popular dataset\" --> \"on two popular datasets\"\n- \"4.1 IMPLEMENT DETAILS\" --> 4.1 IMPLEMENTATION DETAILS\n- \"For CNN fintuning\" --> \"For CNN finetuning\"\n- \"Noted that for fair\" --> \"Note that for fair\"\n- Tables 1-2: \"Compare to state-of-the-art\" --> \"Comparison to state-of-the-art\"\n- \"Our methods has\" --> \"Our method has\""
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper presents an offline and online pruning method for CNNs where RL is used for tuning the sparsity.\n\nPruning methods are important for real-time applications of CNNs on low resourced devices, so the paper addresses a genuine need. However, the paper is poorly written and the experimental results are not as convincing.\n\n1) Majority of the description of the models and architecture is written in text and is very difficult to parse, while this could've been avoided by usage of mathematical notations for operations. This is specifically evident for early parts of sec 3 which makes parsing and reading very difficult.\n\n2) It's not clear why the baseline performances in the experimental section are different across different methods. If I understand correctly, all the original non-pruned models should be the same for this experiment to make sense. This is specially important for Tab 2 where the closest competing algorithms (FBS and CGNN). Due to using different baselines, the numbers are not comparable.\n\n3) One thing that is not clear in the text is the computation taken by the runtime pruner architecture. Are these rolled in the estimations on the speedup?"
        }
    ]
}