{
    "Decision": {
        "decision": "Reject",
        "comment": "The paper proposed a method to evaluate latent variable based generative models by estimating the compression in the latents (rate) and the distortion in the resulting reconstructions. While reviewers have clearly appreciated the theoretical novelty in using AIS to get an upper bound on the rate, there are concerns on missing empirical comparison with other related metrics (precision-recall) and limited practical applicability of the method due to large computational cost. Authors should consider comparing with PR metric and discuss some directions that can make the method practically as relevant as other related metrics. ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #1",
            "review": "This paper presents a method for evaluating latent-variable generative models in terms of the rate-distortion curve that compares the number of bits needed to encode the representation with how well you can reconstruct an input under some distortion measure. To estimate this curve, the author’s use AIS and show how intermediate distributions in AIS can be used to bound and estimate rate and distortion. They apply their evaluation to GANs, VAEs, and AAEs trained on MNIST and CIFAR-10.\n\nI found this paper well written, with a number of interesting technical contributions, particularly how to leverage AIS to compute R-D curves for an individual model. However, the utility and interpretation of these R-D curves for single models remains confusing to me, and there is insufficient discussion and comparison to other joint diversity/sample quality metrics proposed in the GAN literature. The compute time required for evaluation may also limit the applicability: 4-7 hours for 50 images on MNIST, and 7 days for CIFAR-10. \n \nMajor comments:\n* How should we interpret rate-prior distortion for an individual model vs. rate-distortion where models are optimized for each rate? Past work in learned compression and generative models (Theis et al. 2016, Balle et al. 2016, Alemi et al., 2018) show that models must adjust their decoder (and prior) as a function of rate to be optimal in terms of distortion. For a fixed decoder, optimizing the prior may still be required to achieve low rate. Given that many of the models you compare are trained to do well at one point on the R-D curve, why does it make sense to evaluate them at other points? Additionally, you only evaluate models with deterministic decoders and many of the experimental conclusions are highly specific to this setting but not noted. \n* As you focus on general distortion metrics instead of NLL alone, it'd be interesting to compare curves under different distortion measures, e.g. MS-SSIM for images or L1 vs. L2. Right now there's not much experimental novelty vs. prior work that looked at rate-distortion curves with NLL distortion and Gaussian observation models.\n* It’d be useful to include experiments comparing Rate-Prior distortion curves and Rate-distortion curves where you a) optimize over the prior, b) optimize the decoder, fixing the prior, and c) optimize both the prior and decoder. \n* There’s no comparison of other approaches to generate the rate-prior distortion curve. For example, you could just use an amortized inference network like in VAE w/ a flexible variational family and anneal beta over time.\n* There are several related papers which should be discussed and contrasted, in particular https://arxiv.org/abs/1901.07821 which looks at rate-distortion-perception tradeoffs, and https://arxiv.org/abs/1806.00035 which presents precision-recall curves for diversity/quality metrics applied to implicit models. How do the insights gained from the rate-distortion curves relate to precision/recall and why should one be preferred over the other? https://arxiv.org/abs/1611.02163 also looked at distortion as a metric for GANs (equivalent to beta -> infinity in your framework).\n\nMinor comments:\n* Missing discussion of several related works: that presents a complexity measure for the latent space of GANs: https://arxiv.org/abs/1802.04874\n* “Wasserstein distance remains difficult to approximate…” - see https://openreview.net/forum?id=HkxKH2AcFm that advocates for evaluation with Wasserstein\n* Tightness of bound on simulated data (what BDMC provides) may not correspond to tightness of bound on real data (what you care about in practice). \n* The treatment of VAEs as implicit models only makes sense with location scale family p(x|z), thus the entire framework proposed here doesn’t make sense with e.g. autoregressive p(x|z), as used in PixelVAE and others.\n* Why focus on fixed prior p(z)? An alternative would be to optimize p(z), q(z|x) and fix p(x|z). How would this change the resulting rate-prior distortion curves?\n* “We can compute the R-D curve by sweeping over \\beta rather than by sweeping over D” - this is not the case when the R-D curve has linear segments, see e.g. Rezende & Viola 2018\n* Many of the properties and discussion around rate-prior distortion functions (especially w/NLL distortion) are also in Alemi et al. 2018 as their definition of “rate” is identical to your definition of “rate-prior”. Also many of these properties are specific to continuous latents which isn’t noted.\n* Should clarify that q_k(z|x) correspond to points along R_p(D)\n* The results in Eqn 14-17 showing you can tractably estimate distortion and get an upper bound on rate using the AIS-derived distributions are very cool!\n* “AIS variance is proportional to 1/MK” - this is for variance in the partition function? How does this translate to variance in estimates of rate/distortion?\n* “In the case of probabilistic decoders, …” -> need the caveat this is with NLL distortion\n* Validation on the linear VAE is great!It looks like some of the points for AIS at low distortion are below the analytic rate, but the proofs indicate the estimated rate should be greater than the analytic rate. Is this just noise?\n* Fig 4 and 5: hard to see difference between the dashed lines\n* VAE results would change drastically if you targeted them to different regimes (e.g. beta-VAE or constrained optimization like GECO)\n* Statements like “VAE is trained with the ELBO objective, which encourages good reconstructions” only make sense when the decoder is location-scale. VAEs w/rich autoregressive decoders typically do a horrible job reconstructing.\n* How robust are model differences across random initialization? It’d be great to add error bars to all these plots, especially given that GAN training can stochastically succeed.\n* Eqn 18/Fig6a: depending on the dataset, you could easily notice the difference of 4.6 nats and log-likelihood could still tell these two models apart. It’d be useful to add a line at beta=1 to show that the likelihood would be the same but the R-D curves are different.\n\n========================\nUpdate after rebuttal\n\nThank you to the authors for addressing a number of my concerns, adding additional text and experiments. However, my main concern remains: if rate-distortion in an individual model is a useful method for evaluating generative models, you should compare it empirically with other metrics that have been proposed for this purpose (e.g. precision-recall). Additionally, while the theoretical novelty of getting the full R-D curve from a single AIS run is very cool, I'm skeptical of the practical utility as a metric for generative models due to the computational costs of AIS (4-7 hours for 50 images on MNIST). The simple baseline I suggested of training an amortized inference network with beta annealed over time would not require training a separate encoder for each point in R-D, you could just start beta large, and anneal beta in steps to 0 over time, tracing out an R-D curve. Given the current experiments, it's not obvious if the win of AIS in terms of accurate posterior inference is worth the increased computational cost over a simple VI baseline.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper considers the rate-distortion tradeoffs of deep generative models such as variational autoencoders (VAEs) and generative adversarial networks (GANs).\nThe authors propose an annealed importance sampling (AIS) method to compute the rate-distortion curve efficiently. In experiments, the authors compare the rate-distortion curves for VAEs and GANs and discuss the properties of rate-distortion curves.\n\nThe method for computing the rate-distortion curves of deep generative models is interesting and the rate-prior distortion curve is promising as a performance measure. However, the main technical contribution of this work is the estimated AIS rate-prior distortion curve and it is based on a straight-forward application of AIS. \n\nIn fact, Sections 2 and 3 discuss already known result in literature although summarizing them in a paper is nice for readers.\n\nAlthough the findings in the experiments are interesting and insightful, they are still preliminary and further investigations are desirable.\n\nIn Section 5, the authors mention the consistency of their framework with Shannon’s rate distortion theorem. This seems to be a little overstatement because the authors discuss little about the optimization of the prior p(z).\n\n"
        },
        {
            "rating": "8: Accept",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "Summary:\n\nThe paper proposes a new way to evaluate generative models that don't have tractable likelihoods, such as VAEs or GANs. Such generative models are composed of a prior over latent variables and a decoder that maps latent variables to data. The idea is to evaluate a trained model in terms of the best (lossy) compression rate that can be achieved by encoding a datapoint (e.g. an image) into the latent space, as a function of a permitted distortion between the datapoint and its reconstruction after decoding. The paper describes a method that estimates an upper bound on this rate-distortion curve using annealed importance sampling. The method is applied in evaluating and comparing a few VAE, GAN and AAE architectures on images (MNIST and CIFAR-10).\n\nOverall evaluation:\n\nThis is a very good paper, and I'm happy to recommend it for acceptance.\n\nThe problem considered (evaluating generative models with intractable likelihoods) is an interesting and important one. In general, such models are hard to evaluate and compare with each other. The paper proposes a new method for evaluating them, which can also improve our understanding of these models and potentially diagnose them in practice.\n\nThe method is well-motivated and backed by theoretical results. One clever aspect of the method is the way annealed importance sampling is used to approximate the rate-distortion curve: instead of sampling separately the rate for each distortion level with a different AIS run, a single AIS run is used to approximate the whole curve. This is done by taking the various points on the curve to correspond to intermediate distributions in AIS, which is quite clever.\n\nThe paper is well written, precise, and contains sufficient theoretical background to motivate the method.\n\nThe experiments are done carefully, and the results are interesting. I found particularly interesting the fact that VAEs behave differently to GANs (in terms of their rate-distortion tradeoff) when the dimensionality of the latent space is increased.\n\nSome discussion and critical feedback:\n\nI found the paper too long (10 full pages). I appreciate the detail, precision and depth of explanation, but I think it would be good to reduce the amount of text if possible.\n\nI though that the introduction was too specific to VAEs/GANs and to image modelling, which may give the impression that these are the main models/tasks of interest. I understand that these are the models and tasks that the paper is interested in, but I think it would be better if the introduction acknowledged the existence of other types of generative models (e.g. likelihood-based models such as autoregressive models and normalizing flows) and were less specific to image applications.\n\nProposition 3 is true almost by definition, since R_p is defined to be the minimum of all rate-distortion curves. I wonder if something more informative can be shown here. For example, my understanding is that the reason R^{AIS}_p is not optimal is due to the bias of the importance-sampling estimator in eq. (12). Since this bias asymptotically goes to zero, I suspect that R^{AIS}_p may become equal to R_p for M -> infinity, and perhaps the bound improves monotonically as M increases.\n\nIf my understanding is correct, the reason for the inequality in proposition 4 is that log\\hat{Z} is a biased estimate of logZ (due to Jensen's inequality) despite \\hat{Z} being an unbiased estimate of Z. If that's all there is to it, the proof in the appendix, although precise, is a bit of an overkill. It also seems to me that the log\\hat{Z} bias also approaches zero as M -> infinity, so this inequality maybe also becomes an equality asymptotically.\n\nIn future work, it would be interesting to also evaluate flow-based models (such as Glow). Since these models give exact likelihoods, it may be good to observe how the evaluation based on rate-distortion curves compares with a likelihood-based evaluation.\n\nSection 6 attributes the performance drop of VAEs in the low-rate regime to the \"holes problem\". If that's true, then I would expect the situation to be improved with more flexible prior / posterior models. What prior / posterior models were used in the experiments? If only diagonal Gaussians were used, then it would be interesting to see whether more flexible priors / posteriors such as normalizing flows would change the results.\n\nMinor corrections and suggestions for improvement:\n\n\"For continuous inputs, the metric is often dominated by the fine-grained distribution over pixels rather than the high-level structure\"\nThis statement is specific to images, not continuous inputs in general.\n\nOn the quantitative analysis of deep belief networks, https://dl.acm.org/citation.cfm?id=1390266\nis an older example of AIS used to evaluate generative models that could be cited.\n\nI think it would be better to drop z_0 and T_0 in equations (1) and (2), and have z_1 sampled from p_0 directly, to make the equations consistent with the equations that follow afterwards.\n\n\"using a latent variable z with a fixed prior distribution\"\nIn VAEs the prior can also be learned, it doesn't have to be fixed (this may in fact help alleviate the holes problem).\n\nIt could be mentioned that the objective in Eq. (9) has the same form as a generalized VAE objective, such as the one used by beta-VAE, https://openreview.net/forum?id=Sy2fzU9gl\n\nAt the bottom of page 4 and page 5, R_p(D) uses a different font for R than the rest of the paper.\n\nFig. 1 is too small to read on paper, I had to zoom in using the pdf in order to see it properly.\n\nLast paragraph of section 4 specifically mentions images, even though it doesn't need to (datapoints don't have to be images).\n\nThe last two paragraphs of page 7 contain a few grammatical mistakes:\n- fixing the architecture of neural network --> fixing the architecture of the neural network\n- as the result --> as a result\n- there exist a rate distortion code for any rate distortion pairs  -->  there exists a rate distortion code for any rate distortion pair\n- While in our definition of rate distortion -->Whereas, in out definition of rate distortion\n\nTop of page 8, use \\citet instead of \\citep where appropriate.\n\nCapitalize names and acronyms in references, such as ELBO, GAN, MMD, VAE, Bayes, Monte Carlo, etc."
        }
    ]
}