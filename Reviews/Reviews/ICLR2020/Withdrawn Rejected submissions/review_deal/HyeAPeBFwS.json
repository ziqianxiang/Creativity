{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper suggests a Bayesian approach to make inference about latent variables for image inference tasks. While the idea in the paper seems elegant and simple, reviewers pointed out a few concerns, including lack of comparisons, missing references, and requested for more extensive validations. While a few comments might have been misunderstandings (eg lack of quantification - seems to be resolved by author’s comments), other comments are not (eg equation (8) needs further justification even if the final results don’t use it). We encourage authors to carefully review comments and edit the manuscript (perhaps some appendix items should be in the main to reduce confusion) for resubmitting to future conferences. ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes to use a trained GAN model as the prior distribution for Bayesian inference to quantify the uncertainty. As for me, the best application of this paper is to restore a corrupted image, which shares a lot of common properties in image restoration, denoising and image reconstruction. I do like the extension of applying the idea in physics problems. And the results demonstrate at some extent, the proposed method could evaluate some uncertainty. \n\nThe idea is pretty simple and the paper is easy to read.  Nonetheless, there are some issues:\n\nA big issue of this paper is the deviation of purpose and method. As the paper claims to quantify the uncertainty, the paper is supposed to give specific quantitative metric or values to probe the uncertainty. However, the paper demonstrates to us only the ability, not exactly “quantification”. I’d like to see a specific metric of uncertainty that could only be calculated through the proposed method. \n\nThere are some grammar issues in the paper. For example. “…we the MAP…” in the 7th page.\n\nGiven my major issue seems to be quite problematic, I currently would weakly reject this paper. But I don’t have a full picture over this area, I’ll read the rebuttal and see if I could raise the score."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "The paper studies the Bayesian inferences with the generative adversarial network (GAN). In the first half of the paper, the general framework of the Bayes estimation is introduced. Then, The authors proposed how to incorporate GAN to the Bayesian inference. Some computational methods for calculating the mean of the statistic under the posterior distribution are described. Then, numerical experiments using MNIST and Celeb-A datasets are presented. \n\nThough the Bayesian inference using GAN is a natural idea, learning algorithms proposed in this paper are simple and are not intensively developed. In numerical experiments, there is no comparison with major competitors besides random sampling in the active learning setup. Hence, the effectiveness and advantage of the proposed methods are not clear.\n- In active learning, the proposed method should be compared with other methods such as Bayesian DNN using dropout, etc. \n- How does the estimation accuracy of GAN relate to the estimation accuracy of the proposed method? Showing a quantitative description would be nice.\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "Summary of the paper:\n  \n        The paper proposes a Bayesian approach to make inference about latent variables such as un-corrupted images. The prior distribution plays a key role in this task. The authors use a GAN to estimate this prior distribution. Then, standard Bayesian techniques such a Hamilton Monte Carlo are used to make inference about the latent variables.\n\nDetailed comments:\n\nEq. (8) is expected to give very bad results. The reason is that it is very unlikely to sample from the prior configurations for z that are compatible with y.\n\nThe paper does not address learning any model parameters. e.g. the amount of noise.\n\nA more principled approach would be to estimate the prior parameters using maximum likelihood estimation. That has already been done in the case of the\nvariational autoencoder.\n\nThe variational autoencoder is an already known method that can be used to solve the problem formulated by the authors. It also automatically proposes\nan inference network that can be used for recognition. If the likelihood is Gaussian and p(x|z) is also Gaussian, one can directly marginalize x and work\nwith p(y|z) and p(z). The authors should at leas discuss the potential use of this method alongside with the BIGAN model which also provides a recognition model.\n\nIt is not clear how the HMC parameters are fixed.\n\nThe experiments do not have error bars (Figure 4.) This questions the significance of the results.\n\nMy overall impression is that there is little novelty in the proposed approach. Namely, using a GAN to learn the prior distribution, and then very well known\ntechniques to infer the original input image.\n\nI have missed some references to related work on inverse problems. An example is:\n\nhttps://arxiv.org/pdf/1712.03353.pdf\n\n\nIs the original figure contained in the training set used to infer the GAN. If so that can lead to biased results.\n\nI have missed a simple baseline in which one simply finds the training image that is closest to the corrupted observed or partially observed image.\n\nMy overall impression is that there is not much novelty in the paper as it is simply a combination of well known techniques. E.g. GANs and Bayesian inference with Monte Carlo methods.\n\n"
        }
    ]
}