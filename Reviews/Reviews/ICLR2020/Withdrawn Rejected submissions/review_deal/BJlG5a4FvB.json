{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Differentially private (DP) algorithms give provable privacy guarantees at the cost of a non-negligible loss in terms of utility. Motivated by such empirical observations, this paper proposes to lift the utility of the DP-SGD algorithm that is used to train differentially private DNNs by a mechanism called Laplacian smoothing. The authors claim that under the same privacy budget, the proposed methods enjoys better utility guarantees, measured in terms of optimality gap (convex cases) and stationary gap (norm of the gradient, nonconvex cases). \n\nOverall, the paper is well-written and easy to follow. However, I am not very convinced by the claim that the proposed DP-LSSGD algorithm enjoys better utility guarantees under the same privacy budget. Specifically, if we check the results in both convex and nonconvex cases in Table 1, it turns out the convergence rates (optimality/stationary gap) in terms of d, n and \\epsilon are exactly the same between the classic DP-SGD and the proposed DP-LSSGD. The only difference lies in the constants, which are fixed and do not matter too much. If we check the results more carefully, it is even not clear in the convex case the constant $\\gamma\\cdot D_\\sigma$ is smaller than $D_0$. From this perspective it is not clear to me what's the essential improvement here? \n\nThe main idea of the Laplacian smoothing is to precondition the original gradient descent by a fixed matrix $A_\\sigma$. The authors claim that the LS method could help to avoid spurious minima and reduce the variance of SGD. I am not sure about this point, since in the literature there are many data-dependent preconditioning methods, including AdaGrad, Adam, AdaReg, etc., but none of them is free of the local-minima problem. So it's not clear to me why a fixed preconditioning matrix will help here? The final DP-LSSGD algorithm is a combination of the original DPSGD algorithm with a preconditioning matrix given by $A_\\sigma$, similar to what is done in LSSGD. \n\nThe main contribution of this manuscript lies in Section 3, i.e., the theoretical analysis of the convergence rate of the proposed algorithm in both convex and nonconvex settings. The results (in terms of convergence rate) are the same as the ones in the non-private settings. Just a comment, with further assumptions, e.g., strong convexity in the convex case, the authors could potentially improve the $O(1/\\epsilon)$ rate to linear convergence of $O(\\log(1/\\epsilon))$. So the main take-home message here is that privacy does not sacrifice convergence speed, which is already known in the literature. \n\nExperiments comparing DP-LSSGD versus other DP variants are conducted. In Figure 5, it is shown that DP-LSSGD is indeed better than DP-SGD in terms of accuracy, but is slightly worse than DP-Adam. A combination of the Laplacian smoothing with DP-Adam gives the best result in terms of accuracy in most of the cases, which is a plus.\n\nOverall, I think there is indeed some novel contribution in this paper, but I feel it's quite incremental in nature, in terms of both theoretical analysis and empirical results. Hence I vote for a weak reject. \n\n\n\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes an algorithm called DP-LSSGD, which can improve upon DPSGD in terms of utility with Laplacian smoothing. The authors provide convergence guarantee and experimental evaluations demonstrating the advantage of the proposed algorithm over DPSGD and DPAdam.\n\nThe proposed method seems like a good method to have for improving the gradient-based DP learning algorithms. I have some more comments/questions:\n1. It seems to me that the experiments mainly considers high privacy (epsilon < 1) regime. This might be a bit too strict in practice. Given that Figure 5 seems to suggest that the advantage of the proposed method is less significant in the higher epsilon regime (though still pretty low to me), I think the authors might consider comment more on this matter. Maybe adding a plot showing final accuracy vs. epsilon (for epsilon going all the way up to 5 or 10) can also help.\n2. You mentioned that the accuracy of DPSGD decreases after some epoch. Can this possibly be fixed by a brief hyperparameter selection? I feel like experiments from related work don’t usually have such a problem. Maybe it would look fairer if the best parameter is used for everyone. Besides, since DPSGD seems to work better in the beginning, would you consider using DPSGD first and then change to DPLSSGD or increasing sigma gradually?\n3. I’m not very familiar with the field but I guess there might be other existing denoising methods for SGD or other gradient descent method. If so, why did you pick the LSSGD algorithm and do you think other denoising methods can be equally helpful for DP training? "
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper introduces LSSGD [1] in the privacy-preserving empirical risk minimization to improve the utility upper bound under the same privacy budget. The experiments show that the proposed method called DP-LSSGD outperforms the baseline method--DP-SGD [2].\n\nMy major concerns are as follows.\n1. The improvement of the utility upper bound is insignificant. Table 1 shows that the utility upper bounds of DP-LSSGD and DP-SGD have the same order.\n2. The novelty is incremental. The key method in this paper--LSSGD--was proposed in [1].\n3. Table 2 in [3] shows that DP-SVRG [3] outperforms the baseline method--DP-SGD. The authors may want to conduct more experiments to compare DP-LSSGD with other related work including DP-SVRG.\n4. The authors may want to provide the problem setup of the privacy-preserving empirical risk minimization in detail.\n\n\n[1] S. Osher, B. Wang, P. Yin, X. Luo, M. Pham, and A. Lin. Laplacian Smoothing Gradient Descent. ArXiv:1806.06317, 2018.\n[2] R. Bassily, A. Smith, and A. Thakurta. Private Empirical Risk Minimization: Efficient Algorithms and Tight Error Bounds. In 55th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2014) , 2014.\n[3] D. Wang, M. Ye, and J. Xu. Differentially Private Empirical Risk Minimization Revisited: Faster and More General. In Advances in Neural Information Processing Systems (NIPS 2017), 2017."
        }
    ]
}