{
    "Decision": "",
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The title of this paper is rather misleading that I thought it was an empirical study of learned priors in deep latent variable models. But in fact this is a methodology paper that proposes a new learning objective for these models. The objective is new in that I haven't seen it anywhere else but the contribution is quite incremental given a closely-related objective is studied in wasserstein autoencoders. Despite that it might look surprising to people familiar with variational autoencoders, removing the KL regularization term and match aggregated posterior and prior is already justified in the wasserstein ae paper.\n\nMore empirical evidences are needed to show the strengths of the proposed method over methods with similar motivations, such as WAE, resampled prior VAE (Baur & Mnih, 2018), 2-stage VAE (Dai & Wipf).\n\nMore concerns are summarized below\n* There are many claims in the main text that is unclear to me. For example, on page 4, \"in doing so it is easy to see that the issue of posterior overlap can be mitigated\", how?\n* FID is not a meaningful metric for generalization. There is no evaluation of test log likelihoods.\n* The learned deep generative model may generate pretty images. But I suspect it will be outperformed by WAEs in terms of representation learning (because no regularization ever happens in the objective).\n* Did you apply VGG19 perceptual loss to all models or only models using the proposed method?"
        },
        {
            "rating": "1: Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review": "In this paper, the authors study VAEs which are trained with a loss that does not contain the typical KL divergence term.  Additionally, the authors focus on the case where the prior (latent) distribution is learned via a normalizing flow.  The authors empirically show that higher quality samples can be generated by VAEs without the KL divergence (than in comparison to those with the term) in this context; that the linear separability of the latent representations increases without the KL term, and that greater diversity can be obtained by conditional sampling.  \n\nThe observation that the authors report is intriguing and definitely worth further inquiry, but I feel that the paper in its current form does not present a coherent picture that other researchers can easily grasp and build upon.  The quality of the writing is a significant barrier toward understanding the deeper meaning of the paper.  As a result, I recommend declining this paper for publication in ICLR.  \n\n(1) The paper needs a much clearer focus.  For example, the title of \"empirical observations pertaining to ...\" should be replaced by something related to the actual claim of the paper\n(2) The abstract is too vague for experts or non-experts to get a clear indication of what is in the paper\n(3) Where does this work leave the relative performance levels of VAEs versus other generative models? \n(4) How broadly should the results be interpreted for VAEs?  Does it only apply to flow-based priors?  Or is it making a claim for a broader set of learnable priors?  This will also affect what is in the title and abstract.  Is it only being claimed for L2 loss (which then admits a 2-Wasserstein distance problem) or is it being claimed about a broader category of losses?  If so, what is the principle under which removing the KL terms is reasonable when it doesn't lead to a 2-Wasserstein problem?\n(5) Individual sentences of the paper are adequately written, but the writing of the paper currently feels like a long list of facts and details, which makes extracting the deep takeaway much harder.  It is unclear after reading this paper what I would tell another researcher or a student, though I feel that with a substantial revision there could be some very interesting things that could be told based a continuation by the authors of this work."
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The paper explores the idea of removing the prior regularization, such as the KL regularization in variational autoencoders. In order to allow sampling from the generative model, the prior distribution is parameterized by a normalizing flow that is fit to minimize the cross-entropy between the marginal posterior distribution and the prior. I find the idea to be interesting. However, the paper, especially the experimental section, is in a very rough state, making assessing the contribution hard. I recommend rejection of the paper in the current state, but encourage the authors to finalize the paper.\n\nPros:\n1. The paper proposes a fairly radical change to the VAE setup.\n2. The results look sensible and in some aspects better than the results of VAEs and GANs.\n\nCons:\n1. As mentioned above, the paper is clearly unfinished. There are many formatting issues (too small figures; \\citet and \\citep being used incorrectly). Most importantly, the text is unnecessarily verbose. As an example, autoregressive flows are discussed in detail, yet not used in the experiments.\n2. Despite the verbosity, there is no discussion of the downsides of the removal of the regularization. For instance, I would expect the log-likelihood of the proposed model to be arbitrarily poor. Furthermore, it seems that the optimal encoder distribution in this setup is a delta-function, which makes the aggregate posterior a mixture of delta-functions and can lead to issues when fitting a prior distribution.\n3. Iâ€™ve found the disentanglement results confusing. Beta-VAE usually requires beta > 1 for disentanglement, but this paper achieves better disentanglement for beta = 0 than for beta = 1"
        }
    ]
}