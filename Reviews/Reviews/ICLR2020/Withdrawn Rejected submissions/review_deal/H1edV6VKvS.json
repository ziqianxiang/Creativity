{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The authors of this paper introduce the concept of proximal mapping from sparse representation  to supervised and unsupervised structures, aiming at learning structured representations. It generalize dropout and invariant kernel warping, and applied in multiview learning and sequence modelling. Generally speaking, without sufficient background knowledge, it is difficult for a reader to understand the major contributions of this paper, due to unexplained terms and notations. For example in the second paragraph of Section 2, I think x in activation functions should correspond to z in Equation (1) in some places. Thus, the authors are suggested to improve writing to clearly show the idea without too much mingling with specific techniques. Visual examples, such as Figure 2, do help.  Moreover, it is unclear how structured representation is defined, and how structured representation is learned by prox-map.  Finally, experimental results do support that the introducing prox-map in various neural networks improves performance. "
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposes looking at many existing and some new layers on neural networks as proximal operations  (where a proximal operator is defined as  P_f(z) = argmin_{x\\in C} f(x) + 1/2 ||x-z||^2). Trivially many existing layers can be written in this way, but the model can be applied to novel fairly interesting setups. \n\nThe analogies and extensions of existing methods are overall very dense and hard to follow, specially with the amount of liberties and approximations spread throughout the paper. For example, at one point when talking about kernel spaces the paper suggests that a proximal operator computes X^-1 y and draws a close analogy to X y, \"modulo the exponent in X\", when in fact multiplying something by a matrix or its inverse tend to have quite the opposite effect (unless the matrix is its own inverse, which does not seem to be the case here). Similarly in the dropout section a b^2 is treated as the same as (a+lambda)^2 b^2, which again has quite different behavior (and IIUC the algorithm does not work with lambda=0).\n\nOverall it's very hard to believe that the proximal methods which claim to approximate and extend existing methods do indeed approximate and extend those methods, at least from reading the mathematics of the paper.\n\nThe experimental section does show that the methods perform reasonably well, and the two particular variants evaluated in the paper body proper are two of the better-justified one. I would strongly encourage the authors to substantially rework the paper to remove the more dubious equivalence claims (or, instead, strengthen them) and focus on simplifying the explanation and derivation of the things which do perform well.\n\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes using proximal steps as a replacement both for traditional operations in neural networks as well as strategy for expressing more exotic computations that are carried out in learning. Since proximal steps are the solution to a (usually simple) minimization problem, argmin differentiation techniques provide a general strategy for computing gradients with respect to their inputs.\n\nIn general, the techniques proposed in this paper are interesting and well motivated. The techniques provide strategies for deriving new and principled unsupervised learning objectives (deep CCA), reconceiving of and analyzing existing techniques (dropout), and support working with kernelized representations. Empirical evaluation on fairly small scale experiments demonstrates these techniques can productively be employed to develop new and powerful models\n\nConcerns:\nthere is, in my opinion, rather too much content for a conference paper of 8 pages. Fpr instance, the kernelization that the authors propose is rather orthogonal to the general techniques proposed, and its affordances are not analyzed empirically\nSome of the mathematical claims are too tersely described for most readers (keep your audience in mind!). One example occurs at the bottom of page three when discussing kernel warping; this relies heavily on previously published work, but adequate space does not exist to make the connections to the novelty of this work clear. This again suggests that a journal publication which offers authors and reviewers a more careful back-and-forth might be more appropriate.\n\nA claim and some missing citations:\n\n“but surprisingly underutilized in modeling deep neural networks” - there has been a small amount of work, but it’s not completely unsurprising since the theory of proximal mappings only really makes sense in the context of convex problems. Like many things in deep learning, it may turn out to be the sort of thing where we can ignore the conventional theory, but that’s not a foregone conclusion. However, there are some other antecedents in the literature which do suggest that proximal-like operators do play an important role in the development of techniques in deep learning. Some relevant related material are the so-called “sparsemax” and “sparsemap” operations, which conceive of softmax (and marginal inference) in terms of a dual optimization problem. However, this work alters the dual form to recover sparsity inducing optimization problem; however, the techniques for deriving derivatives are the same and speak to the general flexibility of viewing the building blocks of neural networks as solutions to optimization problems rather than as less analyzable functions. Two relevant papers are: Martins and Astudillo (2016 ICML) and Niculae et al (2018 ICML).\n"
        }
    ]
}