{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review": "The authors present a new neural network method for generating image embeddings which can be used for image classification and instance retrieval. It seems to be implemented using a combination of existing techniques such as CNNs and generalized mean pooling. The model has to linear heads to do classification and image retrieval. The authors obtain new state of the art results on classification when compared to previous results obtained with similar architectures.\n\nNovelty:\n\nI believe this is the main limitation of this work. It seems the proposed method does not have significant innovations and it is obtained from combining previous methodologies.\n\nQuality and significance:\n\nThe experiments seem to indicate that the proposed method could be useful in practice. However, the lack of new methodological contributions reduces the quality and significance of this work.\n\nClarity:\n\nThe paper seems to be clearly written and is easy to read."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The paper proposes to jointy train a deep neural net for image classification, instance and copy recognition. This is achieved by i) combining a classification (cross-entropy) loss with a retrieval loss based on multiple copies/augmentations of the training image, and ii) a generalized mean pooling (GeM) layer allowing to interpolate between average and max pooling. The network obtains improved image classification accuracy on ImageNet over the same model trained without additional losses, and retrieval results competitive with the state of the art.\n\nThe paper is well-written and the different components are well explained. The improvements obtained on ImageNet are considerable, and I like the idea of using the GeM layer pooling exponent to adapt the network to higher resolutions. Also, it is desirable to have models that work well on multiple tasks e.g. for deployment on mobile devices.\n\nI have several questions and concerns:\n\n- Repeated augmentation together with a retrieval loss as the one presented in (2) is a known supervised learning technique called exemplar [1], which was originally proposed with a classification loss but recently extended to a to a triplet loss as the one in (2) in [2]. The same loss was also used together with labels for semi-supervised learning in [3], and similar improvements in image classification accuracy as in the proposed paper were observed for training a rotation-based self-supervised loss with all labels (the MOAM model in [3]). I think the paper would benefit from a review of recent work on self-supervised learning.\n\n- It was previously observed that increasing the resolution can improve image classification accuracy, see, e.g. in [5, 4]. It is also to be expected that adding AutoAugment to the mix will help.\n\n- It would be interesting to see a simple ImageNet pretrained retrieval baseline without bells and whistles in the retrieval experiments. I’m not a retrieval expert, but it seems that retrieval networks are typically trained on other data sets and do additional tricks than just using a pretrained ImageNet embedding.\n\nAll in all I think the paper is solid and presents good results, but a very similar method was previously proposed by [3]. I’m therefore not convinced that the paper presents enough novelty.\n\nMinor comment:\n-Using a different letter for the supervised labels y_j and the pairwise labels y_ij might improve readability.\n\n\n[1] Dosovitskiy A, Springenberg JT, Riedmiller M, Brox T. Discriminative unsupervised feature learning with convolutional neural networks. In Advances in Neural Information Processing Systems 2014 (pp. 766-774).\n[2] Kolesnikov A, Zhai X, Beyer L. Revisiting Self-Supervised Visual Representation Learning. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2019 (pp. 1920-1929).\n[3] Zhai X, Oliver A, Kolesnikov A, Beyer L. S4L: Self-Supervised Semi-Supervised Learning. arXiv preprint arXiv:1905.03670. 2019 May 9.\n[4] Tan M, Le QV. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. arXiv preprint arXiv:1905.11946. 2019 May 28.\n[5] Touvron H, Vedaldi A, Douze M, Jégou H. Fixing the train-test resolution discrepancy. arXiv preprint arXiv:1906.06423. 2019 Jun 14.\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "Main comments:\nThis paper proposes a unified embedding for image classification and instance retrieval. The objectives for both classification and retrieval are jointly optimized. To bridge the gap between image classification and instance retrieval, the generalized mean pooling layer with exponent p is proposed. A repeated batch sampling augmentation is introduced to enhance the performance for both tasks.\n\nThose schemes proposed in this paper are shown to be effective through extensive experiments. However, those schemes are more like good techniques to improve the performance instead of bridging the gap between two tasks, rather than principled algorithm designs.\n\nOverall, this paper proposes several schemes including self-supervision, generalized mean pooling, and repeated augmentation to improve the performance of two tasks. The experimental results demonstrate the effectiveness of those schemes. However, those schemes are more like techniques to improve the performance instead of bridging the gap between two tasks. Another possible explanation is the gap between image classification and instance retrieval is not as large as stated. It is important to justify the claims how those schemes bridge the gap between image classification and instance retrieval in a principle manner (rather than good techniques or tricks).\n\nThe p in the proposed GeM seems has limited influence on both classification and retrieval. AAs shown in Fig.2, except for p=1, the performance of p with other values are similar. The authors mentioned that the GeM is a trade-off for between average pooling and max pooling, why not just use two different pooling ops for two tasks. Maybe GeM is a trick for preserving more local information, but I cannot tell its advantage for balancing two tasks. And the optimal p in GeM is obtained by grid search, which makes me double the real value of GeM.\n\nThe authors mentioned that image resolution used for classification and retrieval is quite different. It is not clear whether the gap between those two tasks is mainly because that the backbone network is not capable of capturing details. This needs to be addressed. In addition, there have been several methods that aim to capture both details and global features [1-3] by designing backbone networks with multi-scale ability\n\n[1] Big-little net: An efficient multi-scale feature representation for visual and speech recognition\n[2] Res2Net: A New Multi-scale Backbone Architecture\n[3] Deep High-Resolution Representation Learning for Visual Recognition\n\nThe authors need to put this work in proper context and discuss the differences. It is also better to add more experimental evaluations against these methods to clearly demonstrate the merits of this work.\n"
        }
    ]
}