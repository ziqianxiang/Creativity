{
    "Decision": {
        "decision": "Reject",
        "comment": "The problem of introducing interpretability into sepsis prediction frameworks is one that I find a very important contribution, and I personally like the ideas presented in this paper. However, there are two reviewers, who have experience at the boundary of ML and HC, who are flagging this paper as currently not focusing on the technical novelty, and explaining the HC application enough to be appreciated by the ICLR audience. As such my recommendation is to edit the exposition so that it more appropriate for a general ML audience, or to submit it to an ML for HC meeting. Great work, and I hope it finds the right audience/focus soon. ",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The authors consider a combination of an Gaussian model and neural network learned together to be able to find specific Gaussian features that would predict sepsis in a more intuitive, interpretable way for a medical experts. Also, they have provided a new labelling for the MIMIC-III dataset, which is of great value.\n\nUsually constraining the feature space reduces the accuracy, as one tends to miss important features. However, here, one is using a Gaussian model to generate a feature space that is easier to train with a neural network (by filling the sparse data by Gaussian process interpolation) but also augment the dataset.\n\nThe author report that his improves prediction. Unfortunately, I did not find tables of solutions where one could the actual impact. The authors should include a numerical table of their result comparison results.  Now there is only a narrative in section 5.3 and an image showing that at different covariance times, different feature groups starts to interpret the results. Obviously, a question arises if the model would perform even better with a combination of covariance times, or is there some covariance time range that is missing that would improve the result even more.\n\nThe Gaussian model creates smooth interpolation of data spaces and also forces the training to look at corresponding smoothened features - that are very good for human eyes. However, there are situations (like the detecting heart beat from a video from a head moving with a recoil from the blood rushing to the brain) in where the signal is too weak for human to see, but is definitely there for a computer.  I would state that this as interpretable,  as an explicitly visible signal would be. Even  shorter time constant signal might be valuable as well, but it would not be visible here...  It seems that in sepsis, it was a good idea, as it improves the result compared to the situation of not using the Gaussian model. \n\nOne has to be careful to state that this would address the interpretability of the results. Gaussian process by itself is not giving understanding nor interpretability as it is too general. But it can make the provided solution \"teachable\" to a human expert by showing what visible features one can track.\n\nCompare this to a situation where one is using physical model to regularize detection. It has the analogous two model structure like the one in the manuscript. In https://xbpeng.github.io/projects/SFV/index.html the authors of the paper report that that one can achieve a better pose estimation by constraining the pose to only those that are achievable by a physical model based policy trained by reinforcement learning. This one is able to \"interpret\" the pose.\n\nAs a summary, the authors have done solid and valuable work in improving the accuracy detection. They should have a more formal way to present the results and baseline comparisions as tables. On the explainability and interpretability, there remains a lot of interpretations and one has lots of explaining to do, even after this manuscript.\n\n\n\n\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The authors present a Sepsis-3 compliant labeling of the MIMIC-III dataset and a sepsis-prediction model largely based on MGP-TCN that uses attention mechanisms to enable explainability.\n\nIt is not entirely clear what the authors mean by MC samples from Y_MGP, are these simply samples from the posterior in (6)?\n\nIf z_j and z'_j are M-dimensional, how does one apply (8) and (9) for W_{\\alpha,0}, W_{\\alpha,1} being (M+Q)-dimensional or W_{\\beta,0}, W_{\\beta,1} being matrices?\n\nThe labelling of the data, largely following Johnson & Pollard (2018) and Moor et al (2019), is only different to Moor et al (2019) in the assumption that in the SOFA calculation missing values have zero contribution. Unless the authors provide evidence that this is reasonable, it is not necessarily clear whether labels resulting from the proposed scheme will be biased and affected by differences in clinical practice at different sites or data collection practices. That being said, it is not clear whether the proposed labeling is a contribution from the work.\n\nThe fact that the proposed labels are harder to fit does not imply that the proposed labels are better or more reasonable. This provided that is difficult to know (without ground truth) whether the difficulty originates from a broader use case (not as easy as Moor et al (2019)) or labels being noisy, imperfect proxies for sepsis diagnosis. I understand the author's motivation for doing it, however, their approach is not sufficiently justified. I also agree that predicting sepsis in a realistic setting is harder than suggested in prior work, however, the proposed labeling does not necessarily yields evidence of that being the case.\n\nThe interpretation of the covariance matrices of the MGP is interesting, though not surprising considering that covariates in green are measured regularly while blue covariates are ordered sparingly.\n\nFigure 5 is interesting, though raises questions about of interpretability of the model. How should unobserved covariates be interpreted (INR in Figure 5)?\n\nIn summary, the contributions of the present work are not sufficiently justified (labeling), the novelty of the proposed model is minor, relative to MGP-TCN, and the added value of the attention mechanism as a means to interpret predictions in terms of the journey of a patient is not clear.\n\nMinor:\n- Figure 1 needs a better caption. Being in page 2 makes it very difficult to understand.\n- TCN is used before being defined.\n- In (1) it should be t_{p,i,k} not t_{p,k,i}"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #1",
            "review": "I've read the rebuttal and I'd like to keep my score as is. My main concern is the questionable role of attention in making the model more interpretable (which is the main contribution of the paper).\n\n###########################\n\nThe paper proposes a new model for automated sepsis detection using multitask GP and attention-based GP. The sepsis detection problem is of paramount importance in the clinical domain and the authors rightly emphasized that point. Also the paper tries to combine interpretability with prediction accuracy by using attention mechanism. \n\nThe paper is generally well written and well motivated; however, in terms of technical novelty and empirical evidence the paper can be further improved. \n\nThe MGP-AttnTCN model is mostly a minor modification of the model proposed by Moor et al. 2019 and has the additional attention element to be more interpretable. Unfortunately, it’s not easy for an ICLR reader without any medical background to evaluate the validity of the interpretability results provided in the paper. Furthermore, the recent works in NLP have agued against the value of attention for interpretability (see for instance “Attention is not Explanation” by Jain & Wallace 2019). That said, I believe the paper is probably a better fit for a machine learning in healthcare venue (such as MLHC). \n\nIn terms of empirical evidence of the prediction accuracy the paper only compares with Moor et al 2019 (which does not show a significant improvement in the realistic setting) and a much older InSight paper (2016). This would have been typically enough for a paper with major technical novelty; however, for this paper, I believe adding more recent baselines and discussing the advantages of the method over these baselines would be necessary. \n\nMinor:\nCaption in Figure 1 can be more informative and useful for the reader if you add more details on different parts of the model. \n“Graphically, once can observe” should be “one can observe” . ",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        }
    ]
}