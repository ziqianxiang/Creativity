{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper studies the effect of training image classifier with masked images to exclude distraction regions in the image and avoid formation of spurious correlation between them and predicted labels. The paper proposes actdiff regularizer and demonstrates that it prevents such overfitting phenomenon on synthetic data.  However, there was no success on real data. This is important as it shows that the improvement reported in some saliency-map based approaches in the literature may be due to other regularization effects such as cutout.\n\nThis was a unique submission in my batch, as it embraces its negative results. Among our internal discussions, all reviewers that and we all believe that negative results are important and should be encouraged. However, in order for the negative results to be sufficiently insightful for the entire community, they need to be examined under well-organized experiments. This is the aspect that the reviewers think the paper needs to improve on.  In particular, R2 believes the paper could consider a larger set of possible regularizations as well as a broader range of  applications. The insights in such setting may then lead to solid insights on why the current approaches are not very helpful, and in which direction the follow-up researches should focus on.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "\nSummary\n---\n\n(motivation)\nCNN image classifiers tend to overfit to distractor patterns.\nPerhaps these patterns are spatially local, such that in most images signal is at one\nlocation while the noise models tend to overfit to is somewhere else.\nIf so, then generalization should improve if models are given additional\nsupervision (i.e., a mask identifying salient regions) that specifies where the signal is and is not.\nThis paper designs the Actdiff loss to realize this intuition.\n\n(approach)\nActdiff:\n1) The Actdiff loss requires a mask that highlights areas of the input\nimage which have signal and not distractor regions. It extracts features from\nthe original input image and its masked version then encourages the two features\nto be similar at every layer of the CNN using an L2 loss.\n\nActdiff is compared to 5 other methods including a reconstruction loss and Gradmask (previous work).\n\n(evaluation - synthetic dataset)\nA synthetic dataset is constructed for a simple binary classification task based on the presence of simple shapes.\nTwo patterns can predict the correct class at train time, but one of the patterns is removed at test time so additional information (masks in this case)\nis required to specify which pattern the classifier should use.\nAll the losses except Actdiff achieve at best 50% accuracy on the val set, but Actdiff gets 80% or more accuracy on 3 of 4 tested model variations.\nThis shows that Actdiff can effectively introduce the relevant masking information.\n\n(evaluation - Medical Segmentation Decathalon)\nThis dataset provides 3 segmentation tasks (Liver, Cardiac, Pancreas), including ground truth masks for those images.\nAll 6 methods outperform all the others at least some of the time.\nThe conclusion is that adding mask information using Actdiff doesn't improve segmentation performance.\n\n(evaluation - Multi-Site dataset)\nA final task tries to construct another synthetic dataset out of real X-ray images\ncollected at two different places.\nThe train set is largely from one place and the test set is mostly from the other place, and masks are constructed so Actdiff can try to eliminate this bias.\nActdiff causes a negligible increase in performance.\n\nThe paper concludes that signals CNNs tend to fit to in this type of data are not very spatially distinct.\n\n\nStrengths\n---\n\nThere is some novelty in the approach. The actdiff loss makes sense and masking + activation mapping have not been tried together before to my knowledge.\n\nExperiments follow a logical progression, starting by verifying the idea on a synthetic dataset, then moving to real data, and then evaluating on a half-synthetic dataset designed to debug the approach.\n\nExperiments average over many random initializations.\n\nThe paper embraces its negative result.\n\n\nWeaknesses\n---\n\nThe approach is not very compelling to me:\n* Implicit in this paper is that any information outside the mask is a distractor and any information inside is not a distractor. Why should the particular masks chosen for the experiments have this property? How can an expert know which features a model will find useful?\n\nThe paper's novelty is somewhat limited. The idea of regularizing using saliency maps has been explored and even applied to medical data like the MSD used here in Gradmask (one of the strong baselines this paper compares to). Activation matching is also common (e.g. [1]), though it has not been combined with masking before.\n\nWhile the weights applied to the various losses are provided, it's not clear how they were tuned. In this case there may be lots of competing losses, so it's important to tune the weights somehow to ensure the tradeoff between losses is optimal.\n\nThe results (and the conclusions) suggest Actdiff is not very effective at increasing generalization. Table 2 reports test results on all datasets. In that table, each loss outperforms all the other losses in at least two cases (a case is a model-dataset pair).\n\n[1]: Gatys, Leon A. et al. “A Neural Algorithm of Artistic Style.” ArXiv abs/1508.06576 (2015): n. pag.\n\n\nMissing experiments:\n\n* In the Multi-Site experiment, compare to what happens when the circular mask is applied to all images and not just those from one site. This is a necessary control to be sure that any benefits from masking are due to domain transfer and not other regularization effects. Either conclusion could be useful, but it would be nice to know.\n\nPresentation weaknesses:\n\n* In the synthetic dataset the model cannot tell the difference between correct and incorrect signals at train time. Therefore, I think there's no way for some of the baselines (plain classifier, autoencoder) to generalize correctly. Is that right? If so, it should be clear that comparisons to these baselines are not fair when discussing the synthetic evaluation in section 4.\n\nMissing details / points of clarification:\n\n* What is the Conv AE? I assume it is a CNN based autoencoder of some sort. A detailed description of the non-standard architectures would be useful for reproducibility, though probably only in the appendix.\n\n* What are the lambda hyperparameters? I assume these are weights on the corresponding loss terms, but this is never made explicit.\n\n* How does f(.) relate to the function o_l(.)? Is o_l(.) an intermediate step in f(.)?\n\n* The MSD dataset is not clearly described. Is this a classification dataset where classes are different diseases? What do the ground truth masks capture?\n\n* I think only Conv AE and UNet contain reconstruction losses. This presentation is a bit confusing since reconstruction loss was presented as another loss and it shows up in the tables implicitly based on the architecture being compared.\n\n\nSuggestions\n---\n\n* This paper would be a bit more convincing if it started with a concrete example of the problem illustrated on some dataset (e.g., maybe an example from Gradmask). That may also help drive intuitions later on in the paper.\n\n\nPreliminary Evaluation\n---\n\nClarity: The paper is fairly clear.\nQuality: Quality is mixed. Lots of relevant experiments are reported but they don't support clear conclusions and I'm not sure how well the models were tuned.\nOriginality: There is some novelty, but it is limited as discussed above.\nSignificance: I see limited significance.\n\nFor me this paper requires special scruitiny because it presents a negative result. Here are some factors that come to mind when thinking about whether to publish a negative result:\n* Is the approach compelling? - This approach is not very compelling (e.g., comments about limited novelty and lack of concrete examples to boost intuition).\n* Are the experiments thorough? - The experiments could be significantly more thorough (e.g., comments about tuning lambda).\n* Will readers learn something useful? - This paper may help researchers trying to leverage similar intuitions, but it won't be very useful outside this audience.\n* Does the paper present experiments that promote deeper understanding of why the approach failed? - This paper makes significant reasonable steps in that direction with sections 4 and 6, but I was still a bit dissapointed with the conclusions of these sections.\n* Does the paper discuss alternative approaches that were investigated? - Many alterantive approaches were considered and their performance reported.\n\nOverall I think this paper is close but fails to meet the bar because it does a bit worse than expected on most criteria above.\n"
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "N/A",
            "title": "Official Blind Review #3",
            "review": "This paper considers how we can train image classification models so that they can ignore task irrelevant features.\nFor this purpose, the authors considered a situation where task relevant parts of the images are annotated as masks by the human experts.\nThe authors then proposed using Actdiff loss, Reconstruction loss, and Gradmask loss that are designed to suppress the effect of irrelevant features. \n\nI think the problem considered in this paper is interesting and important.\nAs the authors pointed out, the medical images taken from different hospitals may contain hospital-specific features which is irrelevant to the targeting task.\nThus, we need a way to train image classifiers that can ignore such irrelevant features.\n\nMy major concern on this study is the experiments.\nThe authors mention that part of their methods sometimes did not work (see below).\nThis makes the effectiveness of the proposed losses a bit questionable.\nIf I understad correctly, in practice, the users need to tune the weights of several losses carefully until they can obtain a good model.\nIf this is the case, I am not very sure if the proposed losses are essential, or tuning a right weight can occasionally provide good models.\n\n* (Sec4) \"Gradmask proves to be too powerful a regularizer for this task, and never produces a model with good generalization performance.\"\n\n* (Sec5) \"For the Cardiac dataset, the best performing method was classification with gradmask for the Convolutional AutoEncoder and with actdiff for the UNet, and each achieve similar performance.\"\n\n* (Sec5) \"The gradmask and combination actdiff and gradmask models improved over baseline, but there is no clear reason why this would be true from the saliency maps.\"\n\n* (Sec6) \"Both actdiff and gradmask improve performance of the model, but only actdiff scores above chance, and performs similarly to a model trained with the areas outside of the mask completely removed.\"\n\n### Updated after author response ###\nThe authors have tried to address my concern by re-running the experiments, which I greatly appreciate.\nHowever, the effectiveness of the proposed approach is not convincing enough.\nI expect the authors to design the more effective experiments in the future version.\nIt would be great if the authors can clarify and demonstrate which regularization is helpful under which circumstances and why, and when it is not.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper attempts to tackle the overfitting problem due to the focusing on the distracting information. By utilizing the dataset with masks, the authors propose a simple method to ignore the distracting features. By designing actdiff loss and reconstruction loss, the authors demonstrate that classifiers are likely to predict using features unrelated to the task and their losses can mitigate this problem.\n\nPros:\nThis kind of study can make us understand deeply what is going on in deep learning and thus to make it better, which shows this work’s high significance.\n\nCons:\n1.\tThe presentation of this paper is not clear. For example, in Table 1, the experiment name is so confusing. The authors mention that “Conv AE Actdiff” is the one using both actdiff loss and reconstruction loss. Then what does “Conv AE Reconstruct Masked” mean? Does Conv AE means they implicitly contain reconstruction loss? The authors should elaborate them clearly. The corresponding double quotation marks should be revised. Figure 3 is also confusing. At first, I thought different lines represent different input data (one without mask and one with mask) and different columns represent different methods. However, this is not the case. Furthermore, the fourth column is more confusing. I do not see any red circles in the fourth column. Why the reconstruction of distractor is far away from the original one. Does the right top picture show the advantages of UNet Reconstruction or its drawbacks?\n2.\tIn fact, the training data with masking is not sufficient (may only available in some medical images). It is hard to utilize these data to generalize to various other tasks including large amounts of images without masking.\n3.\tFrom the experiments on real tasks, I barely see improvements by the proposed method, which makes the conclusion unconvincing.\n\n"
        }
    ]
}