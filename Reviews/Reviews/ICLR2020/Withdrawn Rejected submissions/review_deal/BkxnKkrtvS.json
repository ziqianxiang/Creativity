{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper treats the CRF-based NER tagger as the amortized variational posterior in a generative model of text given tags. In this manner, a VAE is defined that can be trained in a semi-supervised manner. Partially supervised learning (PSL) is also explored.\n\nThis paper is not well-written for the following reasons.\n\n1. This paper over-claims:  \"to our knowledge, we are the first to utilize VAEs for NER.\" \n\nThere are some works in applying VAEs to sequence labelling, even the harder seq2seq learning. For example,\n\n[a] Language as a latent variable: Discrete generative models for sentence compression, EMNLP 2016.\n[b] StructVAE: Tree-structured Latent Variable Models for Semi-supervised Semantic Parsing, ACL 2018.\n\nThe authors should concentrate on the novel elements of their proposed method. A straightforward of applying VAEs to NER for semi-supervised learning does not warrant an publication at ICLR.\n\n2. Unfortunately, the novel elements are not elaborated. It is difficult for the reader to tell which parts of the proposed method are novel.\nIf only looking at the technical development in the main paper (without the Appendices), the development seems to be weak, not substantial contribution from applying VAEs. The authors should make a better balance between the main content and the Appendices.\n\n3. The experimental results are also not well organized. Comparisons are here and there, without a main thread.\nMF, MT are used without definitions."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper considers the task of Named Entity Recognition and formulates it as a the task of segmenting a sequence of text tokens by a corresponding sequence of tags. This requires to use a special tag symbol which is labelling text parts that are not in any entity span. Consequently this special tag will never occur in partially annotated training examples. Moreover, the authors consider and explore a multitude of generative models whose decoders (conditional probability of the text sequence given the tag sequence) are beyond simple conditional independent models (as in standard HMMs). To learn such models from semi-supervised and partially labelled training data, the authors propose to use the VAE approach, assuming the encoder to be a linear CRF model (i.e. a conditional HMM). Implementing this program requires (i) to formulate the tasks for unlabelled and partially labelled training data, (2) to use an approximate but differentiable sampler for the encoder model and (3) to compute the KL-divergence for Markov chain models. The authors consider known options for each of these problems and then analyse the resulting approach for a multitude of generative models experimentally. \n\nIn my opinion the task formulation, the related models and considered learning tasks are highly interesting and conceptually relevant. Nevertheless, I would not recommend to publish the paper in its present state for the following reasons. The paper is in my view to much application oriented and cluttered with various application/implementation details, which are rather obscuring several interesting and relevant conceptual questions. The same holds in my view for the  unnecessary large number of considered model variants. The paper can be improved by moving the conceptual and technical explanations from appendices to the main body and delegating application details, details of some model variants etc. to the appendices. \n\nFurther questions/comments:\n- Why are you using a fully factorising prior for the tag sequences? Would it be possible to use a Markov chain model here?\n- Why and where from comes the log probability of the encoder (q) in the supervised loss?\n- The score function estimation and other similar approaches indeed suffer from high variance gradients. On the other hand, the proposed relaxed \"perturb and MAP\" approach is clearly an approximation. It is therefore not clear to me why the latter is to be preferred to the former."
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "This work applies CRF autoencoder to the task of semi-supervised named entity recognition. The latent variables are the discrete tag sequences; and to facilitate end-to-end training, an amortized variational objective is used. Different generative model (i.e., generating input tokens conditioning on the latent tags)   architectures are explored. Experiments with NER with the Ontonotes 5 dataset show that, with proper architectures and prior distribution, the proposed model outperforms strong baselines. \n\nOverall I find the paper clearly presented and well executed. However there is not much to learn from the technical part: most of the key components have been around for a while, and the paper does not seem to attempt to solve any key challenges.\n\nTo be more constructive, I think the paper can be improved by:\n\n- Evaluating the proposed method with other tagging tasks, and discuss whether the architecture and prior distribution choices for the generative model are task-dependent. \n\n- Discussing how the model (especially the generative part) translate to other structured latent variables, e.g., syntactic trees and semantic graphs.\n\n- More carefully evaluating the partially supervised learning objective, which seems interesting can could potentially benefit future research.\n\nI'm happy to adjust the score if the authors can justify the technical contribution and take the effort to improve the paper."
        }
    ]
}