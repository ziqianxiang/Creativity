{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper aims to solve the multi-domain multi-modal image to image translation problem by categorizing domains into hierarchies. The paper models each domain as a gaussian distribution that is a subset of its parent domain, which is also a gaussian distribution. Borrowing ideas from Athiwaratkun & Wilson (2018), it measures the difference in probability densities and optimizes a thresholded version of the KL divergence of two densities, so that if child *f* is nested in parent *g*, then KL(f||g) is small but KL(g||f) is big.  By comparing with StarGAN (multi-domain) and MUNIT(multi-modal) baselines, the paper shows comparable performance while taking the best of both worlds.\n\nAlthough it is attractive that the paper has one generator and one encoder for multiple domains and supports multi-modal outputs, there are some unanswered key parts that made me hesitant to accept the paper. \n1. How widely applicable is the hierarchical approach? e.g. Gender and hair color may not fit the assumption that one is another's subset. By putting gender as the top-most node, you treat dark haired men and dark haired women as two separate groups where we maximize their thresholded KL divergence. The resulting distribution may not be a faithful representation of the real world. \n2. From fig. 12 it seems that the choice of alpha can vary widely between 50 and 2000 and still have similar IS metrics. On the other hand the choice of m seems to have a clearer effect. Does that suggest KL(child||parent) does not matter as much compared to KL(parent||child)? \n3. It is unclear what hyperparameters was used to train the baseline models. Did you use the default hyperparameters in the paper or did you tune them? The MUNIT on CelebA (fig. 3) looks a bit unnatural. \n4. Were metrics other than KL considered? e.g. you mentioned it is hard to compute the KL between two mixed gaussian distributions. Perhaps sliced wasserstein distance (e.g. Deshpande et al. 2018) or some other measurement would be a good alternative? \n\nMinor points that did not affect the rating:\n1. In TLDR \"controled\" -> controlled\n2. In section 3.1 the paper states \"We further assume G and E are deterministic and mutually inverse\". This is inaccurate since neither Karras et al. (2018) nor Huang et al. (2018) gives G and E that are exact inverses of each other. It mislead me to think you used Glow from Kingma & Prafulla 2018."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes a method, Hierarchical image-to-image translation (HIT), enabling both multi-domain and multimodal image translation on multiple category domains. To this end, the proposed method utilizes the nested distributions based on a hierarchical structure that exists among image categories. (e.g., Dogs include Husky). The method attempts to model all category domains in a given hierarchy structure as nested Gaussian distributions in a common space. They perform qualitative and quantitative experiments on several categories and attributes for validation of the proposed method.\n\nThe idea of using the hierarchical structure among image categories is interesting. However, the technical novelty is marginal, considering that both the nested distribution loss and the hierarchical classification loss are based on previous studies [1,2].\n\nAdditionally, in Figure 4, the hierarchy on ImageNet dataset is reasonable, but in Figure 6, the hierarchy on CelebA dataset seems to be arbitrary and subjective. Also, the model performance may not be reliable nor robust against the hierarchy changes. In addition, the quality of generated images is somewhat low.  \n\nA few more questions include: \n1)\tFrom Figures 3 and 6, I think that this model mainly focuses on the skin and the hair color. I am curious about the results on other attributes. \n\n2)\tI think that the paper needs additional baselines to compare the proposed model against, e.g., [3] on ImageNet and CelebA datasets. \n\n3)\tIn order to check whether the inclusion relation has been properly learned, showing 2D embedding visualization of data items by t-SNE would make the paper convincing.\n\n\n[1] Choi et al., “StarGAN : Unified Generative Adversarial Networks for Muli-Domain Image-to-Image Translation.” CVPR’18\n[2] Ben et al., “Hierarchical Density Order Embeddings.” ICLR’18\n[3] Cho et al., “Image-to-Image Translation via Group-wise Deep Whitening-and-Coloring Transformation.” CVPR’19\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "This paper proposes a way to utilize the domain hierarchical structure information to help the general multimodal I2I (called joint multi-domain and multi-modal in the paper). The proposed method applies the hierarchy-regularized learning to learn the nested distributions which are reasonable for the data with a well-defined hierarchical structure.\n\nPros:\n1. The proposed method shows the ability to learn the nested distributions with the help of hierarchical structure information. It is a reasonable way to model the general multimodal I2I. I think the authors work in the correct direction.\n2. To model the partial order relation in the hierarchy, the authors borrow the thresholded divergence technique from the natural language processing field (Athiwaratkun & Wilson (2018)) and use the KL divergence considering its simple formulation for Gaussians. It sounds reasonable and may benefit other related CV tasks.\n\nCons:\n1. The detailed method description is very confusing to me. In section 3.1, it is mentioned that the proposed “method only contains one pair of encoder and decoder for multi-domain X^l_i”, which sounds like there are many pairs of encoder and decoder. While in the following description “using G to output the target image x^l_(i→j) = G(c_i , s^l_j )”, which sounds like use one shared generator.  I wonder if it is the case that there is one shared encoder, one shared decoder, but there are different branches for different sub-domains in the domain distributions modeling module?\n2. It is mentioned that the penalty between a negative pair should be greater than a margin m. While this important parameter as mentioned in A.2 is not described in the main paper.\n3. It is mentioned that “In the extreme case, every instance is a variation mode of the domain-specific information.” It is the case in the ICLR19 paper “Exemplar guided unsupervised image-to-image translation with semantic consistency” which uses one exemplar to achieve the general multi-modal I2I. I wonder what are the advantages and disadvantages of learning the distribution and using the exemplar directly. Besides, if there is no well-defined hierarchical structure, is there any way to apply the proposed method?\n4. As to the evaluation, although the authors provide quantitative results by different metrics, a user study evaluation would be good. \n5. As to the visualization results, there are still many noticeable artifacts in the results. Maybe the nested distributions are too complex to learn in this framework.\n\nMy initial rating is on the boardline."
        }
    ]
}