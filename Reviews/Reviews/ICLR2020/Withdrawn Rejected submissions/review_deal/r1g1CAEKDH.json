{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper adds a new model to the literature on representation learning from correlated variables with some common and some \"private\" dimensions, and takes a variational approach based on Wyner's common information.  The literature in this area includes models where both of the correlated variables are assumed to be available as input at all times, as well as models where only one of the two may be available; the proposed approach falls into the first category.  Pros:  The reviewers generally agree, as do I, that the motivation is very interesting and the resulting model is reasonable and produces solid results.  Cons:  The model is somewhat complex and the paper is lacking a careful ablation study on the components.  In addition, the results are not a clear \"win\" for the proposed model.  The authors have started to do an ablation study, and I think eventually an interesting story is likely to come out of that.  But at the moment the paper feels a bit too preliminary/inconclusive for publication.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #4",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "The paper proposes Wyner VAE, a variational autoencoder for a five-variable graphical model. The five variables consist of two observable views, X and Y, with a shared latent variable Z, while the two other latent variables U and V control the randomness of X and Y, respectively, independent of others. The overall objective is motivated by Wyner's mutual information minimization. Using a few common techniques to bound KL divergence, the paper arrives at a few terms that are reminiscent to the variational lower bounds, including terms that constraints the hidden variable to be similar to the prior, and two cross-modal reconstruction terms. The paper includes a comparison between similar models, both in terms of formulation and experiments. The results show that Wyner VAE has certain nice properties that is lacking in other models.\n\nI am giving a score of 6. The formulation and the lower bound for learning are the strengths of the paper. The lack of discussion on some of the common problems for VAEs and the experiments are the weakness of the paper.\n\nThe paper deserves credit to motivate the problem from Wyner's viewpoint. However, after the derivation, the framework falls back to common VAEs, and is not very different from VCCA-private. Comparing Wyner VAE and VCCA-private, I can see why it is hard to justify the difference of the two based on the formulations, but I also find it unconvincing from the experiments to conclude that one is better than the other, especially when there are many hyperparameters to tune. The paper should state this clearly when comparing the two.\n\nIn terms of the common problems for VAEs, the paper does not address a few degenerate cases. The first case is where all the information gets pushed to the shared latent variable Z, leaving little private information for U and V. The second case is that little information about both views gets pushed to the shared latent variable Z, while the decoders are doing all the heavy lifting to reconstruct the observables. To avoid these degenerate cases, more constraints might be needed for the models, such as the ones proposed in (Hsu et al., 2017). Finally, as with most VAE models, the paper does not discuss how well lower bounds approximates the likelihood and the resulting learned representation when the gap between the likelihood and the objective is large. \n\nThe experiments in the paper are somewhat lacking. Figure 7 is where the capability of the model is fully demonstrated: a clear distinction between the shared and the private views are shown. It would be great if the paper can include experiments on a real-world multi-view data set, such as images paired with texts, speech paired with images, speech paired with video, etc.\n\nUnsupervised learning of disentangled and interpretable representations from sequential data\nWei-Ning Hsu, Yu Zhang, James Glass\nNeurips, 2017\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper presents a method for learning latent-variable models of paired data that decomposes the latent representation into common and local representations. The approach is motivated by Wyner’s common information, and is made tractable through a variational formulation. On experiments with MoG, MNIST, SVHN, and CelebA, the paper shows that penalizing the complexity of the common representation can improve style-content disentanglement and conditional sampling.\n\nWhile I found the formulation and motivation from Wyner’s common information and Cuff’s channel synthesis interesting, the resulting model and experiments were unconvincing. There are many terms in the Wyner model proposed, and there are no ablations demonstrating which terms are important and which are not (e.g. do you need both L_xx and L_xy?). On the toy MoG experiment, the common information is known but trained models do not recover the right amount of information. For representation learning, accuracy decreases as the penalty on the common information increases, and for NLL, the joint and conditional NLL is often similar to existing work (CVAE and JVAE). The main win appears to be for style-content disentanglement, but the results there are qualitative and often change the content when only style is changed. It’s also puzzling as to why CVAE overfits so severely in a subset of the experiments. Without a more thorough evaluation of what terms in the loss matter, and showing that the technique recovers something like Wyner’s common information (by extracting the right information on a toy model), I cannot recommend this paper for acceptance.\n\nMinor comments:\n* Eqn 1: the constraint “Subject to X-Z-Y” is confusing. Do you mean X-Z-Y is a Markov network (undirected) and not a Markov chain (directed), in which case X -> Z <- Y does not correspond to X-Z-Y? (This is addressed in Eqn 3-4, but should be fixed here)\n* How is Wyner’s common information related to the multivaraite mutual information I(X; Z; Y)?\n* When describing distributed simulation, please include the variables and objective like you do for common information\n* s/Markovity condition/independence assumption?\n* Why are both losses in Eqn 4 and Eqn 5 needed? Couldn’t you use either to train q(z|x)?\n* Eqn 10 (and most of your objectives) are still intractable due to the q(x)/q(x,y) terms, you should note that it is constant and dropped from the objective\n* “Style control”: could you define what you mean by style in this context? Prior work could likely also do “style control” by e.g. interpolating subsets of dimensions.\n* Related work: https://openreview.net/forum?id=rkVOXhAqY7 (CEB) that may result in a similar objective as Wyner’s common info\n* When comparing to JVAE/JMVAE, it seems like the main difference is suing a latent-variable in the decoder, but the framework is still the same. It’d be useful to spend more time comparing/contrasting with this prior work.\n* Fig 4: would be useful to have a picture of the samples (right now they’re just in appendix)\n* Fig 4: in the data generating process, I believe I((X, Y); Z) = ln(5) = 1.6 nats, but none of your models converge to rates around there. Why not?\n* Unlike other approaches (JVAE, CVAE) you have additional terms in your loss for conditional prediction at training time. It seems like these may be giving you gains, and it’d be useful to perform ablations over the terms in Eqn 15 to figure out what is impacting performance in Fig 4. E.g. if you set \\alpha_{x -> y} and \\alpha{y -> x} to 0\n* Why do the CVAE models overfit? Have you tried optimizing the variational parameters on the test set if it’s due to amortization gap?\n* Fig 5b: what’s the variance you’re plotting? In representation learning, we often just care about downstream accuracy, and it looks like \\lam = 0  performs best there.\n* Table 3: isn’t this showing that \\lam = 0 works the best for joint NLL and close to best for conditional NLL on the MoG task? What’s the discrepancy with Fig 5 where conditional NLL is highly dependent on \\lambda for MNIST?\n* Fig 6 (a1-f1): for this MNIST add 1 dataset, the only common info should be the label. But it looks like the labels do change for non-zero values of lambda (b1 there’s a 2 -> 7), c1 1 -> 9)\n* Table 4: would be useful to train CVAE yourself, as the small differences in numbers could just be due to tuning / experimental setup. You also should bold everything that’s within stderr (i.e. \\lambda = 0 and \\lambda = 0.15 are equally good)\n* Fig 9: would be useful to include CVAE, and Wyner VAE in this plot, i.e. is it only using the mode information in the latent variable when doing conditional sampling?\n* CelebA results look interesting, but there’s been other work on generation from attributes that presents more visually compelling results, e.g. https://arxiv.org/abs/1706.00409"
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposed a variational autoencoder for a pair of correlated observation variables, motivated by Wyner's common information. An instantiation of the model using reverse KL divergence metric is also provided for model inference. Experimental results on simulated dataset and real image datasets show the effectiveness of the proposed generative model. The paper also provides a comprehensive appendix with technical and experimental details. Overall, the paper is technically sound and well supported by theory and experiments.\n\nHere are a few specific comments and questions about the technical content:\n1) For most of the data modeling tasks in real applications, we will most likely have one observational variable (speech segment, document or image). How would the proposed VAE model be applied when the two correlated variables are not explicitly observed or defined? It would be nice if the authors can provide some discussion on the general applicability of the  proposed model.\n\n2) A common challenge of information theoretic VAE is the analytical intractability of divergence measure. For example in Zhao et al. 2018, the maximum mean discrepancy measure is used to approximate the divergence. It is unclear to me whether the objective function in Section 2.3 (using the reverse KL divergence measure) is analytically tractable or not. If not, what kind of approximations (e.g., sampling) did the author used?\n\n3) In the experimental section, the authors showed that for joint and conditional distribution modeling tasks, the optimal regularization parameter might be different. This implies that for a specific task, the user is responsible to choose a proper  \\lambda value. I wonder whether the authors can provide some general guidelines on how to choose this important parameter in practice, as the results seem to be highly dependent on the choice."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper presents a variational auto-encoder approach for paired data variables, with a separate notion of common and individual randomness. On top of data reconstruction, Wyner's common information is added as a regularization term to promote the succinctness of the latent common representation in particular. Besides, KL divergence based constraints are proposed to encourage consistency of different modeling components. Although the consistency imposed by KL can be weak, this helps avoid making unrealistic assumptions.\n \nTo make the proposed objective function tractable, the authors make use of several standard techniques such as variational bounds and sampling-based approximations. The proposed approach can be tailored for multiple purposes, including joint/conditional generative modeling, two variable auto-encoding, style extraction and control, as illustrated in Figure 2 and Figure 3. It also supports the multi-stage training scheme, adding more flexibility. The authors did a great job in the literature review and experimental comparison. Table 1 and Table 2 demonstrate the position and distinctions of the proposed Wyner VAE approach. The comparison to the information bottleneck is also interesting.\n \nThe numerical studies are extensive. The authors demonstrate performance improvement quantitatively over several baseline competitors, although the margin is not big. With appropriate regularization, the qualitative results indeed look better subjectively.  The proposed approach stands out as a \"swiss army knife\" approach for two-variable VAE, which could support versatile needs. The shared and individual randomness are proved to be useful in style extraction and style control in the experiments. Overall, I feel the experiment evaluations and explanations are convincing and informative.\n \n\t• The Alice Bob example is helpful to understand the main purpose of this paper \n\t• The authors introduced the theoretical background of Wyner's common information --- the two contexts it arises. These texts are interesting to read, but I feel the connection to the following learning problem is weak. It would be nice to have more justifications on the choice in the context of VAE learning (optimality?), as opposed to other seemingly more natural choices. For example, the sum of mutual information I(X; Z)+I(Y; Z), or other forms of common information\n\t• Although the proposed approach involves many terms, in general, the presentation is good with clear notations. I am just confused about p_tilde (u,v|x,y,z) in (8). Is it simply p(u)p(v)? \n\t• There is a typo in (19) and (20)"
        }
    ]
}