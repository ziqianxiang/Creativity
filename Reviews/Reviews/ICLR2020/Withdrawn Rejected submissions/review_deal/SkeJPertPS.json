{
    "Decision": {
        "decision": "Reject",
        "comment": "This paper proposes new target objectives for training random forests for better cross-domain generalizability. \n\nAs reviewers mentioned, I think the idea of using random forests for domain adaptation is novel and interesting, while the proposed method has potential especially in the noisy settings. However, I think the paper can be much improved and is not ready to publish due to the following reviewers' comments:\n\n- This paper is not well-written and has too many unclear parts in the experiments and method section. The results are not guaranteed to be reproducible given the content of the paper. Also, the organization of the paper could be improved.\n\n- The open-set domain adaptation setting requires more elaboration. More carefully designed experiments should be presented. \n\n- It remains unclear how the feature extractors can be trained or fine-tuned in the DNN + tree architecture. Applying trees to high-dimensional features sacrifices the interpretability of the tree models, hampering the practical value of the approach.\n\nHence, I recommend rejection.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes an approach to building random forests that are\nbalanced in such a way as to facilitate domain adaptation. The authors\npropose to split nodes not only based on the Information Gain, but\nalso so that the sizes of each set passed to left and right children\nare equal. Another extension to the standard random forest training\nprocedure is the use of a collaborative term subtracted from the\ninformation gain over the source domain. This term encourages\nalignment of the source and target domains in the leaves of trees in\nthe forest. Experimental results are given on a range of standard\nand open-set domain adaptation datasets.\n\nThe paper has a number of issues:\n\n1. There are some problems with clarity, and the English is somewhat rough\n   throughout. These problems are not terribly distracting, but the\n   manuscript could use more polish.\n2. I don't see a detailed discussion anywhere about the\n   hyperparameters used for fitting the random forests. How many trees\n   are used? What is the max depth? These parameters should be\n   discussed and included in the ablations in order to appreciate the\n   complexity/performance tradeoffs.\n\nThis paper has some interesting ideas in it, and the experimental\nresults are excellent. I would encourage the authors to move salient\nmaterial from the supplementary material to the main article and to\nprovide a more thorough discussion of the complexity of the models\n(the structural parameters of the trees/forests)."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper proposes a new target objects for training random forests that has better generalizability across domains. The authors demonstrated that the proposed method outperforms existing adversarial learning based domain adaptation methods.\n\n\nStrength\n\nThe paper is clearly-written. The two objectives(balanced split and common split distribution between source and target domain) are well motivated and explained in the paper.\n\nThe authors show that empirically the proposed method outperform several existing adversarial learning based domain adaptation methods.\n\n\nWeakness\n\nOne of the main draw back of the method is that it relies on the features extracted from existing pre-trained neural networks, and cannot be used to update the representation of the neural networks. While the adversarial learning based method could do end to end training.\n\nIt would be great if the authors could clarify the setup of the baseline methods(e.g. Whether the baseline methods also take benefit of imagenet dataset, and is trained end to end).\n\nWhat will happen if you do not have the imagenet models and have to train all the models from scratch?\n\nOverall I think it is a borderline paper that might be interesting to some audiences in the conference.\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Summary:\nThis paper introduces a method for domain adaptation, where each domain has noisy examples. Their method is based on a decision tree in which the data at each node are split into equal sizes while maximizing the\ninformation gain.  They also proposed a way to reduce domain alignment. Their method is tested on several noisy domain adaptation settings and performs better than other baseline methods. \n\nPros:\nTheir idea to utilize a decision tree for domain adaptation sounds novel. \nExperiments indicate the effectiveness of their method.\n\nCons:\nThis paper is not well-written and has many unclear parts. \n1, The presentation of the problem set is unclear throughout this paper. In the abstract, they mentioned that they tackle the situation where both source and target domains contain noisy examples. However, they did not define the exact problem setting in any section. I could not understand what kind of problem setting motivated their method, which makes it hard to understand their method. \n2, How they actually optimized the model is also unclear. From Eq 1~4, it is hard to grasp how they trained the model. \n3, In open-set domain adaptation, simply minimizing domain-distance can harm the performance. How does the method avoid this issue? It was also unclear. \n4, Experimental setting seems to be wrong and unclear. In Openset1, they say that \"The labels from 1 to 10 of both source and target domains are marked as the known class, and all data with label 11∼20 in the source domain and label 21∼31 in the\ntarget domain are used as one unknown class\". However, Saito et al. (2018) used 21-31 classes in the target domain as one unknown class. In addition, \"According to Saito et al. (2018) the target data of the unknown class is not used in training, \", they used the 21-31 classes for training in an unsupervised way. How is this method used to detect unknown class? Is there any threshold value set for it?\n5, The experimental setting is unclear. In 4.4, \", we use only 10% of training samples\", does it mean 10 % training source examples or target examples? This setting is also unclear. \n\nFrom the cons written above, this paper has too many unclear parts in the experiments and method section. I cannot say the result is reproducible given the content of the paper and the result is a reliable one. They need to present more carefully designed experiments. \n"
        }
    ]
}