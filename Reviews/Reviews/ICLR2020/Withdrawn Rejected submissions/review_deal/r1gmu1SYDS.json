{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "The paper proposes to introduce the notion of Observed Mutual Information (OMI), that captures how easily a given model can extract information from the data, and show correlation between this measure and the performance of the model.\n\nHowever, the reason why the OMI score should be a good predictor of the model performance is not clearly justified in the paper, either formally or informally. In fact, I believe it is easy to construct examples where the OMI score can vary arbitrarily, while the difficulty of the learning task remains virtually unchanged. For example, let p(x) be the distribution of MNIST digits, to which arbitrary amount of noise is added to one corner of the image. This increases H(x) arbitrarily, and hence arbitrarily varies the OMI score. On the other hand, any network can easily learn to solve the task by just ignoring the noise in the (unused) corner. In general, it seems to me that for images the OMI score will depend almost entirely on the amount of noise or variability in the image, rather than from the actual difficulty of the task.\n\nThe idea that Shannon Mutual Information does not capture the actual complexity of extracting the information is also already well explored in the literature. For example, Kolmogorov (or Algorithmic) Mutual Information explicitly account for the complexity of the program extracting the representation, and will change based on how data is represented. Montanari (https://arxiv.org/abs/1409.3821) explores the computational implications of representing the data through a minimal sufficient statistic. Achille and Soatto (https://arxiv.org/abs/1905.12213) study the relation between complexity of the learning task, complexity of the DNN, and \"effective information\" contained in the activations.\n\nRegarding the bounds on entropy and mutual information described at page 3-5, they seem to be vacuous for most problems of interest, since H(x) will be very large in those cases (even for MNIST H(x) is estimated to be ~80 nats, which would require a very large number of samples to properly estimate mutual information using the given bound)."
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "In this paper, the authors proposed \"observed mutual information\", by dividing estimated mutual information by the entropy of X. They claimed that the estimated mutual information has an error which increases as the entropy of X increases.\n\nHowever, the authors made a fatal error by misunderstanding the Asymptotic Equipartition Property (AEP), in the proof of Lemma 2. In information theory, AEP tells us that asymptotically, the cardinality of \"typical set\" is bounded by 2^{H(x) + \\epsilon}.  The typical set A(n)_\\epsilon with respect to p(x) is the set of sequences (x1,x2,...,xn) ∈Xn with the property 2^{-n(H(X)+\\epsilon)} ≤ p(x1,x2,...,xn) ≤2^{−n(H(X)−\\epsilon)} (See Section 3.1. in Thomas&Cover's book). However, the authors made a mistake by saying the cardinality of X is bounded by 2^{H(X) + \\epsilon}, which is completely wrong. \n\nThe wrong Lemma 2 showed that the error of mutual information estimation is proportional to the entropy H(x), which is the motivation for proposing observed mutual information. Therefore, the definition of observed mutual information is meaningless, let alone the remaining sections. The paper can be rejected without reading the remaining sections. "
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The authors provide OMI score to understand the difficulty of a given learning task. They also evaluate their theoretical observations via several experiments.   \n1. Optimizers heavily influence the performance of a given learning problem in vision task. So, our question is that whether the optimizers or other hyperparameters could influence the computation of OMI scores.  \n2. Although the authors apply the bayesian hyperparameter optimization techniques to mitigate the bias that introduced by the hyperparameters,   the adopted bayesian hyperparameter optimization technique can not find the optimal parameters and different hyperparameter optimization techniques maybe provide different hyperparameters.  \n"
        }
    ]
}