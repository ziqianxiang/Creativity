{
    "Decision": {
        "decision": "Reject",
        "comment": "The submission proposes an architecture to learn a similarity metric for graph matching. The architecture uses node-graph information in order to learn a more expressive, multi-level similarity score. The hierarchical approach is empirically validated on a limited set of graphs for which pairwise matching information is available and is shown to outperform other methods for classification and regression tasks.\n\nThe reviewers were divided in their scores for this paper, but all noted that the approach was somewhat incremental and empirically motivated, without adequate analysis, theoretical justification, or extensive benchmark validation. \n\nAlthough the approach has value, more work is needed to support the method fully. Recommendation is to reject at this time.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper proposes an architecture for (supervised) learning a similarity score between graphs through a series of layers for node embedding, node-graph matching, aggregated graph embedding, and finally prediction.\n\nThe evidence for preferring this architecture over existing one is entirely empirical -- based on experiments on four datasets.  The properties of the graphs used in the experiments are not clear: How many edges do they have on average?What is the exponent of their degree distribution on average? How many triangles do they have?  How much does the graph structure contribute to learning?   What happens if one just trained on the features of nodes?  \n\nThe lack of any theoretical reasons for using this architecture over others (perhaps by linking it to the cut norm of the graphs) or insights as to when and on what types of graphs this architecture performs well reduces the significant of this paper.\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review": "In this paper, a hierarchical graph matching network, which considers both graph-graph interaction and node-graph interaction, is proposed. Specifically, the graph-graph interaction is modeled through graph level embeddings learned by GCN with pooling layers. While node-graph interaction is modeled using node embedding learned by GCN and attentive graph embedding aggregated from node embedding. \n\nSome concerns about the paper are as follows:\n\n1)\tThe novelty of the paper is incremental. The major contribution of the paper lies in the propose of multi-perspective matching function $f_m()$, which is somewhat similar to the Neural Tensor Networks proposed in [1] and utilized in [2] Although, in [2], the Neural Tensor Network is used to measure the similarity between graph-level embeddings.\n2)\tSome of the technical details of the paper is not clearly presented or well explained. \na.\tIn Eq. (7), attentive graph-level embeddings are calculated using weighted average of its node embeddings. However, it is not clear which node $i$ from the other graph should be used to calculate the weights (\\alpha_{I,j}, \\beta_{i,j}). Furthermore, it is also not clear why the attention score should solely base on a single node from the other graph rather than the information of the entire graph. \nb.\tIn Eq. (10), it would be better if the authors could provide more motivations about using Bi-LSTM aggregator. Especially, the embeddings to be aggregated are unordered. What are the two directions in Bi-LSTM in this case? What is the benefit of using Bi-LSTM as aggregator compared with LSTM aggregator or other aggregators? \n\nSome other questions to be clarified:\n1)\tWhy different similarity score functions are adopted for the classification task and the regression task? \n2)\tFor the classification task, the mean squared error loss is adopted. Why not using other more commonly used loss for classification task? \n\nSuggestions:\n\nIt would be better if the authors could empirically show the effectiveness of the Bi-LSTM aggregator.\n\nIt would be helpful if the authors could conduct some investigation on how the number of perspectives affect the performance of the model.\n\n[1] Reasoning With Neural Tensor Networks for Knowledge Base Completion\n[2] SimGNN: A Neural Network Approach to Fast Graph Similarity Computation\n\n\n\n"
        },
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The paper proposes a network learning similarity between graphs. In particular, the proposed method focuses on node-graph cross-level interaction which has not been considered by other neural net studies. The performance is evaluated by two datasets on classification and regression tasks respectively.\n\nOverall, the basic idea would be reasonable, and the architecture is clearly described. Any of my comments below are not critical concerns.\n\nThe network considers node-graph interaction, but in general, subgraph-graph interaction can be considered. Rationale that only focusing on node-graph interaction is not mentioned.\n\nThe authors repeatedly mention that the proposed method jointly learns representation and similarity. Is the learned representation can be used for any purpose? Since it depends on a counterpart of the input pair, the representation is seemingly difficult to use.\n\nThe experiments show superior performance of the proposed methods, but the datasets are only two for each tasks. In particular, since graph classification is a popular task, evaluation on a variety of benchmarks would be more convincing. \n\nA baseline with some graph kernel can be informative.\n\nShowing an example of graph pairs, in which cross-level interaction is indispensable to appropriately evaluate similarity, would be convincing.\n\nA related paper being missed would be \n'Yoshida, et al. Learning Interpretable Metric between Graphs: Convex Formulation and Computation with Graph Mining, SIGKDD 2019'. "
        }
    ]
}