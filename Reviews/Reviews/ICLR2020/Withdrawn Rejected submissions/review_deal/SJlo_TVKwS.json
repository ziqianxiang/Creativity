{
    "Decision": "",
    "Reviews": [
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper addresses the posterior collapse problem associated with the VAE for text modeling with a modified VAE architecture. \n\nThe paper motivates the problem (noted by several other works - e.g. Bowmman et al) by presenting the gradients for reconstruction and regularization terms in the VAE and the deterministic AE, and noting that the gradients in the case of the VAE tend to drop, as is evidenced in the case of the decoding signal with respect to the encoder. This points to the possibility that the decoder might be ignoring signal from the encoder. \n\nAn architecture is then presented to alleviate posterior collapse by coupling the VAE and DAE, with structure of the encoder and decoder in both networks being shared. By doing so, the authors (seem to) argue that signals arising from this structure are boosted and we therefore get better gradients being propagated. The decoder is encouraged to not ignore the encoder's codes with the extra signal.  \n\nResults are given for various datasets showing that the NLL is lower for their coupled approach, as is the perplexity. Various other models are also compared against. In addition, in order to show that the connection between the input x and the latent code z ~ Q(z|x), they calculate the mutual information between these two quantities (appendix E - interesting estimation). The result is that their model achieves higher MI.\n\nMy thoughts: \nThe paper reads well, and the results are convincing. Using the shared architecture + coupling loss - which adds extra signal, pushing the stochastic signal to match the deterministic one, but not the other way round - helps to overcome encoder/decoder incompatibility, presumably allowing the decoder to not bypass the encoder content. However, I don't get a clear sense of how this might happen. The theoretical case is limited,and using a coupled/shared architecture is also standard (see, for e.g. Unsupervised image to image translation - although the context in that work is very different). "
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "Idea description: \nIn order to solve the encoder-decoder incompatibility, which means little information are backpropogated from the decoder to the encoder, the authors proposed to combine a VAE and AE by weight sharing and hidden feature matching.\n\nThe idea is very intuitive and the experiments on the perplexity and KL indeed proved this intuition: adding AE term could help us to reconstruct a sentence easier and harm the KL divergence. To further prove the effectiveness of this method, the author could either do more experiments on image or do more text generation tasks, e.g. conditional generation, dialogue generation"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published one or two papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "Contributions:\n\nThe main contribution of this paper lies in the proposed Couple-VAE for text modeling. It is widely known that VAE designed for text modeling suffers from the posterior collapse problem, and in this paper, the authors shows that the training faces the challenges of encoder-decoder incompatibility. In order to alleviate this issue, the original VAE is accompanied with a deterministic network with the same structure as the VAE. The encoder of both the stochastic and deterministic networks is shared, while a coupling loss is proposed to push the stochastic decoding signals into the deterministic ones. Experiments demonstrate that the propose method is model-agnostic, and can be used to improve the performance of various models.  \n\nStrengths:\n\n(1) Writing and Clarity: This paper is well written. I enjoyed reading this paper. Every section is clearly presented. \n\n(2) Experiments: I appreciate that the authors provided comprehensive results like Table 1 & 2. This demonstrates that the proposed method can be used to improve performance of  a wide range of  current VAE models for text modeling. The experiments look carefully designed. \n\nWeaknesses:\n\n(1) Novelty: My biggest concern regarding this paper lies in its novelty. From my understanding, this paper contains two novelty points: (i) the identification of the so-called encoder-decoder incompatibility problem; and (ii) the proposed Couple-VAE model. In terms of the the first point, though the observation is interesting, and it seems no previous work has pointed out this problem clearly like in this paper, still, it looks kind of straightforward. In terms of the model design, i.e., Figure 3, its novelty is very limited. Basically, the model couples a VAE and an AE together, by sharing the encoder and decoder together, and adding an additional coupling loss. To me, this is not enough to support an ICLR paper.  \n\n(2) Questions:\n\nThe coupling loss is defined in Eqn. (5). Though the authors argued that using Euclidean space may not work well, it would still be interesting to report results of using a simple L2 norm for the couple loss to support this claim. Further, what is the model performance without using the couple loss? \n\nOverall, I think this paper is well written and well executed. However, due to the limited novelty of the method part, I lean to weak rejection of the paper. "
        }
    ]
}