{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper considers the problem of cross-lingual document classification with domain gap in source and target languages. In this setting, labeled data is only available in the source language, while the target language has in-domain unlabeled data. The aim of the paper is to tackle the domain and language mismatch problem simultaneously.  \n\nThe paper then proposes two simple methods to overcome this gap. The first method uses MLM training (a la BERT) while the second uses the unsupervised data augmentation technique to generate new examples through translation. \n\nThe technical contribution of the proposed approach seems modest. Also, the experimental analysis is limited to sentiment and document classification, relatively easier tasks than say, XNLI. With such limited experiments, its difficult to assess the utility of the method. The experimental comparison could also be extended to include other approaches for domain adaptation across languages, discussed in the related work section. \n \nQuestions:\n1. Are the reduction in error rates statistically significant?\n\n2. The discussion argues that less impact of self-training for MLDoc dataset owes to it not having enough unlabeled examples. How to determine what is \"enough unlabeled examples\" for self training?  \n\n\n"
        },
        {
            "experience_assessment": "I have published in this field for several years.",
            "rating": "3: Weak Reject",
            "review_assessment:_thoroughness_in_paper_reading": "N/A",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A",
            "review": "Summary:\nThis paper aims to tackle the domain shift problem for cross-lingual document classification by combining the masked language modeling (MLM) pre-training and unsupervised data augmentation (UDA) methods. Experimental results on multi-lingual Amazon and MLDoc datasets demonstrate the effectiveness of the proposed methods. The performances are superior. However, there exist some problems:\n1. The novelty and contributions are somewhat limited and weak. The techniques, i.e., MLM and UDA for addressing the domain gaps are widely used in transfer learning/domain adaptation problems. The combination of them to resolve the same domain shift problem in a new cross-lingual setting is somewhat straight-forward. So, compared with the previous domain adaptation problems, what’s the new things or differences for the domain mismatch in the XLDC task? \n2. For the experiments, the baselines are very simple and not competitive.\n3. Also, there exist some typos in the paper, e.g., in section 3.3 MLM“A standard practice is to to further pre-train”, etc. "
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This paper addresses the important problem of cross-lingual learning in text classification tasks (in this case: text and sentiment classification). The authors address the realistic setup where labeled data  exists in the source language and only unlabeled data is available in the target language. \n\nWhile the paper addresses a timely problem, there are two main reservations that make me recommend a weak reject:\n\n1. The methods proposed by the authors reflect a standard combination of existing ideas in the literature. I am aware that assessing the novelty of a proposed algorithm is subjective in nature, but I do not see here sufficient novelty that will impact the thinking on these problems.\n\n2. In this context I would like to note that more advanced algorithms that explicitly address language and domain gaps, have been proposed in the literature. One of these (Prettenhofer and Stein, 2010), which applies structural correspondence learning (SCL) to the problem, is mentioned by the authors. Another, which marries SCL with deep learning is:\n\nZiser, Yftah, and Roi Reichart. \"Deep Pivot-Based Modeling for Cross-language Cross-domain Transfer with Minimal Guidance.\" Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2018.‏\n\nThe last paper also addresses variants of the problem, such as training a cross-lingual model without knowing the target language at training time.  \n\nThe authors not only skip that work, but they also compare their methods only internally (i.e. to variants of their own methods that do not utilize all of their components). It is true that for one of the tasks they quot the state-of-the-art from a previous paper, but for cross-language sentiment analysis there is no comparison to previous work. The above two papers, and one or two additional papers experiment in the sentiment analysis setup of the existing paper, and should be compared with (particularly the EMNLP 2018 paper which claims sota on this task with a quite large margin).\n\nAn additional comment:\n\nThe appendix of the paper contains major staff that belongs to the main paper. If ablation studies make important observations then, IMO, they should not be external to the paper.\n\n\n"
        }
    ]
}