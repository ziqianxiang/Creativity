{
    "Decision": "",
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "1: Reject",
            "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.",
            "review_assessment:_checking_correctness_of_experiments": "N/A",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper shows a simple geometric proof for the necessity of depth in relu networks. In particular, there exists a set of functions such that bounded depth neural network needs exponential size to estimate, while linear depth neural network only requires bounded width.\n\nHowever, the contribution itself is not too significant in that the theorems are already known in literature in a more complete and general form. Showing an illustrating 2 dimensional example is definitely an interesting and more accessible results for education and better understanding, but not a significant contribution to the knowledge of deep learning theory. Also the theorem statement and proof need to be made rigorous in terms of definition, mathematical reasoning etc.\n"
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I have read many papers in this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "review": "This submission presents a simple proof for depth separation in deep neural networks. The authors claim their proof is simple, and can be easily followed by newcomers. The motivation of the paper is clear. \n\nI give an initial rating of weak reject is because: (1) the notations in this submission are inconsistent and confusing; (2) the contribution seems marginal compared to previous literature. I will illustrate more as below.\n\n1. The authors claim that their problem construction and lemma 3 are novel. However, I found similar formulation in Theorem 5.4 of \"Tropical Geometry of Deep Neural Networks\", ICML 2018.  Can authors clarify the difference and your contributions? \n\n2. Most of the proof follow reference \"On the expressive power of deep neural networks.\" ICML 2017, especially lemma 4. Basically, lemma 4 is a 2d simplification of the results in that reference. \n\n3. Notations are inconsistent. For example, authors use \"d\" as the number of hidden layers in introduction, and then use \"L\" as number of layers later. Actually I think \"m\" also has the meaning of number of layers because authors always refer to \"m\" as network depth. \n\n4. For equation 1 in section 3.2, what is the execution order of this equation? It seems from right to left. However, if we see the last equation in section 4.3, the execution order seems from left to right. This is inconsistent, correct me if I'm wrong.\n\nMinor:\nI only see Lemma 2,3 and 4. Where is Lemma 1? \n\nIn conclusion, if this submission focuses on simple proof and easy understanding, the notations should be kept consistent and use as few characters as needed. The writing needs improvement. "
        },
        {
            "rating": "3: Weak Reject",
            "experience_assessment": "I do not know much about this area.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "This paper presents a proof that deeper networks need less units than shallower ones for a family of problems.\nMore exactly, the authors exhibit a series of indexed problems f_i, such that:\n- for a given depth, there are problems that require a  exponential number of units to be approximated by a network, and\n- for any problem within the family, it is possible to approximate it with a \"reasonably-sized\" network.\n\nThe main advantage of the approach is that the proof is based on relatively simple geometric concepts.\n\nThe problems f_m are binary classification problems, where 1 class is inside a 2D polygon with m sides, inscribed in a circle of radius 1 centered on 0, and the other class is outside.\n\nFor a given m, the paper provides the architecture of the network approximating m as a composition of geometric transformation.\n\nI like the simplicity of the geometric proof. However, the family of functions sounds simple and not representative of the complexity of real problems. In particular, the positive region is a simple convex region. This makes the generalization of the conclusion of the proof to real problems not particularly convincing.\n\nFor a more minor comment:\nI would say that Paragraph \"Number of regions in a line-arrangement of n lines\" could be shorten as it is a pretty  standard math result (not just from deep learning). At least, Fig 5 could be removed.\n\nFor Paragraph \"A 1 hidden-layer ReLU network is a line arrangement\": I think this is also well known now, and could be shortened.\n\n\n\n\n\n"
        }
    ]
}