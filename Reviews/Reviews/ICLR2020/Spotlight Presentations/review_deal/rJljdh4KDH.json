{
    "Decision": {
        "decision": "Accept (Spotlight)",
        "comment": "This paper proposes to follow inspiration from NLP method that use position embeddings and adapt them to spatial analysis  that also makes use of both absolute and contextual information, and presents a representation learning approach called space2vec to capture absolute positions and spatial relationships of places. Experiments show promising results on real data compared to a number of existing approaches.\nReviewers recognize the promise of this approach and suggested a few additional experiments such as using this spatial encoding as part of other tasks such as image classification, as well as clarification and further explanations on many important points. Authors performed these experiments and incorporated the results in their revisions, further strengthening the submission. They also provided more analyses and explanations about the granularity of locality and motivation for their approach, which answered the main concerns of reviewers.\nOverall, the revised paper is solid and we recommend acceptance.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "rating": "6: Weak Accept",
            "experience_assessment": "I have published in this field for several years.",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review": "The paper presents a model that learns an embedding/representation for spatial points (POI's). There are two specific things the representations are trying to encode - location modeling and spatial context modeling and the model tries to do it in multi-scale manner to increase the information/granularity of the learnt representations.\n\nThe experiments are performed on Yelp Data challenge which has 21,830 POI's with 1191 POI types. In the location context experiments authors show that by going after a smaller grid size we can get much better results compared to other methods while other methods like tile, wrap and rbf have more parameters causing overfitting. Similarly, on spatial context modeling we see better results.\n\nOverall, the problem of learning vector representations for spatial points is interesting and useful and this paper has valuable contributions on how to do it. \n\nOne thing I would like to have seen to strengthen the paper further is the application of these representations in other tasks like image classification or recommendation systems or retrieval. The paper currently misses that. \n\nFor ex - https://arxiv.org/abs/1505.03873 uses location information to improve image classification, similarly can we use the representation learned through this method instead of positional coordinates and show that it helps the final task."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "title": "Official Blind Review #2",
            "review": "The paper introduces Space2Vec, a space representation learning model. The work is motivated by the biological grid cell’s multi-scale periodic representations and the success of representation learning of NLP. So, the key idea behind the model is two-fold. On one hand, utilize the position information and the context associated with the position. On the other hand, the authors build a multiscale point space encoder based on Theorem 1 (in the paper), which was previously proved by Gao et al. (2019).\nThe multi-scale point feature encoder is novel. The experimental results turn out that the whole model is good at predicting features using only location information but does not outperform the RBF kernel (on validation) in terms of using spatial context modeling.\nOne core selling point of this paper is dealing with location distributions with very different characteristics. This is very well motivated at the beginning. More analysis/statistics would help better understand how the model \"theory\" wins Table one. See comments on experiments.  \n\nI have some comments/questions about model architecture and also experimental results/analysis.\n\n1. Regarding Contextual Embedding\n-- The encoder of this paper is not doing much “contextual embedding”.  The encoder typically encodes features of each position independently thus lead to very local embedding. \n-- The location decoder would reconstruct the same (or similar) type of point features given embeddings of locations of the same type. As the distributions of different types of locations are very different, an encoder capable to deal with multi-scale data is crucial here. \n-- The Spatial context decoder, like a context-dependent language model, would reconstruct the current position features, given the neighboring information.\n-- Overall, unlike many existing pre-training models in NLP with deep encoders, the full model of this paper is with very local encoder, while the decoder does the most work of “gathering contextual information\". \nAs you claim your model to be \"a general-purpose space representation model\", can you describe/specify how you would use your model for other tasks? Will you take some intermediate output of decoders to be representations? Or will you fine-tune the whole encoder-decoder?\n\n2. For experiments:\na.\tI do not prefer saying your method outperforms RBF in the “spatial context modeling” task when you getting worse validation set performance. It is interesting that RBF is stronger in terms of validation.\nb.\tIs it possible for the authors to do some statistics on the different types of locations? For your first task “location modeling”, should we expect to see that your model does not have very bad performance on certain types of locations while other non-multi-scale approaches do? This is trying to provide better support to one of your core contributions.\nc.    Again, to claim the model can be widely applied, try more tasks?\n\n\nTo clarify my \"experience assessment\", I mean I read many related representation learning papers rather than specific papers related to GIS data.\nMy actual rating for the paper is between weak reject to weak accept (but the system does not have intermediate choices). I would like to hear the author's feedback to further revise the rating.\n\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        },
        {
            "experience_assessment": "I do not know much about this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #3",
            "review": "This paper presents a new method called \"Space2Vec\" to compute spatial embeddings of a pixel in a spatial data. The primary motivation of Space2Vec is to integrate representations of different spatial scales which could potentially make the spatial representations more informative and meaningful as features. Space2Vec is trained as a part of an encoder-decoder framework, where Space2Vec encodes the spatial features of all the points that are fed as input to the framework. \n\nThey conducted experiments on real world geographic data where they predict types of point of interests (POIs) at given positions based on their 1) locations (location-modeling) and 2) spatial neighborhood (spatial context modeling). They evaluated Space2Vec against other ML approaches for encoding spatial information including RBF kernels, multi-layer feed forward nets, and tile embedding approaches. Their results indicate that that Space2Vec approach performs  better (albeit marginally) than other ML methods. \n\nI am giving this paper a weak reject rating mainly because of weak results and lack of motivation for location modeling problem (where their approach performs significantly better than baselines).   I explain my concerns below under detailed comments.\n\nDetailed Comments: \n1) Motivation of location modeling problem does not sound compelling enough to me, especially in the context of Point of Interest(POI) classification approach. I could not imagine any scenario where access to information from spatial neighborhood will be denied. If authors could present strong motivating examples for this problem and demonstrate the utility of their proposed approach in that setting, that will make the paper much stronger.  \n2) In spatial context modeling problem, the improvements in the results (Table 2) appear to be marginal(0.185 against 0.181, 25.7 against 25.3). Authors should try out more datasets to convincingly justify the superiority of their approach over other methods.\n\nEDIT: AFTER RECEIVING AUTHOR'S RESPONSE\nI am satisfied with author's response to my comments. I am updating my rating to Weak Accept. \n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."
        }
    ]
}