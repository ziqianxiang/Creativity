{
    "Decision": {
        "decision": "Accept (Spotlight)",
        "comment": "This paper analyzes the weights associated with filters in CNNs and finds that they encode positional information (i.e. near the edges of the image).  A detailed discussion and analysis is performed, which shows where this positional information comes from.  \n\nThe reviewers were happy with your paper and found it to be quite interesting.  The reviewers felt your paper addressed an important (and surprising!) issue not previously recognized in CNNs.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "This paper studies whether and how position information is encoded in CNNs. On top of VGG and ResNet, it constructs an additional PosENet to recover position information. By analyzing how well PosENet recovers position information, this paper provides several interesting findings: CNNs indeeds encode position information and zero-padding is surprisingly important here.\n\n[Pros]\n\n1. I enjoy reading this paper: probing CNNs is not easy, but it designs experiments in an intuitive way and rigorously performs ablation studies and analysis.\n2. The observations and findings are interesting and helpful to the community.\n\n[Cons]\n\n1. A weakness of this paper is that it ignores the impact of training process while probing PosENet: In Table 1, VGG/ResNet perform much better than PosENet, but it could be because VGG/ResNet is easier to train (kind of fine-tuning PosENet only) than PosENet. Would be nice to show the training curve and train PosENet longer.\n2. Zero-padding seems to play a surprisingly important role in encoding position information (Table 5), but it is still unclear why it is so important and how it helps.\n\nOverall, I think this is a good paper.\n"
        },
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.",
            "title": "Official Blind Review #1",
            "review": "This paper studied the problem of the encoded position information in convolution neural networks. The hypothesis is that CNN can implicitly learn to encode the position information. The author tests the hypothesis with lots of experiments to show how and where the position information is encoded.\n\nClarity:\nThis paper is interesting for me. It tries to understand the encoded position information that is easily ignored by researchers. I like adequate experiments with learned position information and position illustrations.\n\nExperiments:\n1. The paper mainly discussed the zero-padding and found it is the source of position information. How about other padding modes like constant-padding, reflection-padding, and replication-padding?\n\n2. The partial convolution-based padding method [1] (padded regions are masked out) shows that its recognition accuracy is higher than the traditional zero-padding approach. Can you help investigate where the position information comes from for this case?\n\n[1] Partial Convolution based Padding, https://arxiv.org/pdf/1811.11718.pdf.\n\n\nSome of my concerns are well addressed by the author thus I upgrade my score.\n",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "The paper investigates to what degree Convolutional Neural Networks (CNNs) learn to encode positional information.\nRather interesting finding is the not only they do encode this information, but that it is to a large degree function of the padding commonly used in the CNN architectures.\n\nThe problem the paper is looking at is well motivated, the experiments are nicely designed and it includes comprehensive ablation study.\nPrevious and related work seems to be well referenced.\nThe main idea of introducing the PosENet to predict the gradient map is neat, and allows for interesting experiments (e.g. what layers most strongly encode the positional information).\n\nI really enjoyed the paper, the overall quality is high and does not seem to be rushed (no obvious typos or mistakes in the figures/tables).\nI believe this should be an accept.\n\nQ:\nI can understand why you removed the pooling layers, but did you try to run some of your experiments with these as well? How were the numbers effected?"
        }
    ]
}