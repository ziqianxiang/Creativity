{
    "Decision": {
        "decision": "Accept (Spotlight)",
        "comment": "The paper proposes a method to control dynamical systems described by a partial differential equations (PDE). The method uses a hierarchical predictor-corrector scheme that divides the problem into smaller and simpler temporal subproblems. They illustrate the performance of their method on 1D Burger’s PDE and 2D incompressible flow.\nThe reviewers are all positive about this paper and find it well-written and potentially impactful. Hence, I recommend acceptance of this paper.",
        "title": "Paper Decision"
    },
    "Reviews": [
        {
            "experience_assessment": "I have published one or two papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #2",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "[Summary]\n\nThis paper proposes to combine deep learning and a differentiable PDE solver for understanding and controlling complex nonlinear physical systems over a long time horizon. The method introduces a predictor-corrector scheme, which employs a hierarchical structure that temporally divides the problem into more manageable subproblems, and uses models specialized in different time scales to solve the subproblems recursively.\n\nFor dividing the problem into subproblems, they use an observation predictor network to predict the optimal center point between two states. To scale the scheme to sequences of arbitrary length, the number of models scales with O(log N). For each subproblem, the authors propose to use a corrector network to estimate the control force to follow the planned trajectory as close as possible. \n\nThey have compared their method with several baselines and demonstrated that the proposed approach is both more effective and efficient in several challenging PDEs, including the incompressible Navier-Stokes equations.\n\n[Major Comments]\n\nPredicting the middle point between two states for modeling the dynamics via deep neural networks is not new, but I did not know any other works that use this idea for controlling PDEs.\n\nI like the idea of splitting the control problem into a prediction and a correction phase, which leverages the power of deep neural networks and also incorporates our understanding of physics. The introduction of the hierarchical structure alleviates the problem of accumulating error in single-step forwarding models and significantly improves the efficiency of the proposed method. The videos for fluid control in the supplement materials also convincingly demonstrate the effectiveness of the technique.\n\nI still have a few questions regarding the applicability and the presentation of the paper. Please see the following detailed comments.\n\n[Detailed Comments]\n\nIn Section 3, the authors claim that their model \"is conditioned only on these observables\" and \"does not have access to the full state.\" However, the model requires a differentiable PDE solver to provide the gradient of how interactions affect the outcome. These seem to contradict each other. Doesn't the solver require full-state information to predict the behavior of the system?\n\nRelated to the previous question, how can we make use of the differentiable PDE solver if we are uncertain or unknown of the underlying physics, i.e., partially observable scenarios.\n\nThe algorithm described in Section 5 seems to be the core contribution of this work. Instead of describing the algorithm in words, I think it would make it more clear if the authors can add an algorithm block in the main paper. It would also be better if the authors can include a few sentences describing the algorithm in the abstract to inform the readers of what to expect.\n\nFigure 4 is a bit confusing, and it would be better if the authors can include the label for the x-axis. Besides, in the caption, the authors said that they show \"the target state in blue.\" However, there are a lot of blue lines in the figure, and it is hard to know, at first glance, which one of them is the target.\n\nIn Table 1, the bottom two methods are using the same execution scheme and training loss, but the results are different. Is there a typo? Also, it would be better to bold the number that has the best performance."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "8: Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #3",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "## Summary\n\nThe authors propose a method for training physical systems whose behavior is governed by partial differential equations. They consider situations where only partial observations available, and where control is indirect.\n\nIndirectly controlling physical systems is a very important problem with applications throughout engineering. In fact, much of the field of robotics can be described in these terms. The authors employ a number of interesting methods, including a predictor-corrector framework and the adjoint sensitivity method for differentiating through differential equation solvers.\n\nThe paper is generally very clear, organized and well written. There are only a few places where I think clarification is needed (see detailed comments below). I also have a few questions about the losses and training procedure. On the whole, I think the paper is inventive, well-written and potentially very impactful. I think it would be a great addition to ICLR.\n\n\n## Clarifications\n\n* Page 4: I found the statement \"an agent trained in supervised fashion will then learn to average over the modes instead of picking one of them\" a little confusing. Could you clarify the reasoning here?\n* Page 5: I think the description of predictor-corrector could be clearer. In particular, I found the phrase \"the correction uses o(t + ∆t) to obtain o(t + ∆t)\" unclear.\n* Page 8: Could you add a description of what is observable to the body of the paper (I see it is included in the supplement)?\n* Page 8: I think ∇p needs to be divided by density in your NS equation, right?\n* Page 8 - 9: Is there a limit on the size of the force that can be applied at any point? I know the total force is penalized, but what about the maximum force applied at any point?\n\n\n## Losses and Training\n\n* I think \"differentiable physics\" losses need a more detailed explanation in the body of the paper.\n* In the supplement, it is defined using B_r, but I don't think B_r is defined.\n* It seems like the differential physics loss requires a differential solver (in this case, for Burger/Navier-Stokes). If I have understood this correctly, I think this needs to be discussed in the body of the paper. In particular, it would be nice to discuss what happens when the physics is a black box (i.e. we can interact with the system by applying control and observing, but we don't know the rules governing the physical system). Is this exactly when we are restricted to the \"supervised\" loss? Is there some middle ground? What if we had black box access to the exact physics, along with an approximate differentiable solver? This seems like a realistic scenario for e.g. large fluid flow scenarios."
        },
        {
            "experience_assessment": "I have read many papers in this area.",
            "rating": "6: Weak Accept",
            "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.",
            "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.",
            "title": "Official Blind Review #1",
            "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.",
            "review": "In this paper, the authors outline a method for system control utilizing an \"agent\" formed by two neural networks and utilizing a differentiable grid-based PDE solver (assuming the PDE describing the system is known). The agent is split into a control force estimator (CFE) which applies a force to advance the state of the controlled system, and an observation predictor (OP) which predicts the trajectory needed to reach the target state. The objective is to reach the target state with minimal total amount of applied force. The order of CFE and OP calls is discussed and the importance of keeping the trajectory predictions conditioned on the actual previous state of the system, so that errors from previous steps can be taken into account.\n\nThree application examples are discussed: Burger's equation (1D), and incompressible flow (2D) with direct and indirect control. In all cases the proposed scheme of \"prediction refinement\" leads to better or comparable results than standard iterative optimization, and is much more computationally efficient (at inference time, not taking into account the cost of training).\n\nThe paper presents an interesting mix of neural networks and traditional PDE solvers for system control, and I vote for acceptance. An additional advantage of the paper is the authors' promise to open source their differentiable PDE solver implemented in TensorFlow, which should make it easy for others to build upon their work. The text is easy to read, but quite verbose, with many of the technical details relegated to the (sizeable) appendices. I would recommend trying to trim it down where possible (for instance, the description of the U-nets could be more compact, perhaps in table form; 2nd paragraph of the background section seems a bit out of context and could probably be omitted, etc).\n\nQuestions and suggestions for improvements:\n\n* What form of L_o^* and alpha was used in all the experiments?\n* It looks like pretraining was used for all cases except for the most challenging one with indirect control. Was it truly necessary for the simpler experiments? \n* Improve naming consistency. It looks like \"differentiable physics\" and \"differentiable solver\" are used for the same thing in different parts of the paper. My recommendation would be to use the latter term everywhere.\n* How many time steps are used in the indirect control experiment?\n* IIUC, the optimization of Eq. 3 is always done end-to-end. Have any experiments been done to estimate how many time steps can be reliably handled by the proposed procedure before the optimization problem becomes too hard?\n"
        }
    ]
}